<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[外文翻译丨“王者对战”之 MySQL 8 vs PostgreSQL 10（深度） - 今日头条]]></title>
    <url>%2F2018%2Fd12061f0%2F</url>
    <content type="text"><![CDATA[现在是时候回顾一下这两大开源关系型数据库是如何彼此竞争的。在这些版本之前，人们普遍认为，Postgres在功能集表现更出色，也因其“学院派”风格而备受称赞。 参与翻译 (5人) &#58; 雪落无痕xdj, 无若, LinuxTech, Tocy, kevinlinkai 英文原文：Showdown&#58; MySQL 8 vs PostgreSQL 10 既然 MySQL 8 和 PostgreSQL 10 已经发布了，现在是时候回顾一下这两大开源关系型数据库是如何彼此竞争的。 在这些版本之前，人们普遍认为，Postgres 在功能集表现更出色，也因其“学院派”风格而备受称赞，MySQL 则更善长大规模并发读/写。 但是随着它们最新版本的发布，两者之间的差距明显变小了。 1、特性比较 让我们来看看我们都喜欢谈论的“时髦”功能。 过去经常会说 MySQL 最适合在线事务，PostgreSQL 最适合分析流程。但现在不是了。 公共表表达式(CTEs) 和窗口函数是选择 PostgreSQL 的主要原因。但是现在，通过引用同一个表中的 boss_id 来递归地遍历一张雇员表，或者在一个排序的结果中找到一个中值（或 50%），这在 MySQL 上不再是问题。 在 PostgreSQL 中进行复制缺乏配置灵活性，这就是 Uber 转向 MySQL 的原因。但是现在，有了逻辑复制特性，就可以通过创建一个新版本的 Postgres 并切换到它来实现零停机升级。在一个巨大的时间序列事件表中截断一个陈旧的分区也要容易得多。 就特性而言，这两个数据库现在都是一致的。 2、有哪些不同之处呢？ 现在，我们只剩下一个问题 —— 那么，选择一个而不选另一个的原因是什么呢？ 生态系统是其中一个因素。MySQL 有一个充满活力的生态系统，包括 MariaDB、Percona、Galera 等等，以及除 InnoDB 以外的存储引擎，但这也可能是和令人困惑的。Postgres 的高端选择有限，但随着最新版本引入的新功能，这会有所改变。 治理是另一个因素。当 Oracle（或最初的 SUN）收购 MySQL时，每个人都担心他们会毁掉这个产品，但在过去的十年里，这并不是事实。事实上，在收购之后，发展反倒加速了。而 Postgres 在工作管理和协作社区方面有着丰富的经验。 基础架构不会经常改变，虽然近来没有对这方面的详细讨论，这也是值得再次考虑的。 来复习下： 3、进程vs线程 当 Postgres 派生出一个子进程来建立连接时，每个连接最多可以占用 10MB。与 MySQL 的线程连接模型相比，它的内存压力更大，在 64 位平台上，线程的默认堆栈大小为 256KB。（当然，线程本地排序缓冲区等使这种开销变得不那么重要，即使在不可以忽略的情况下，仍然如此。） 尽管“写时复制”保存了一些与父进程共享的、不可变的内存状态，但是当您有 1000 多个并发连接时，基于流程的架构的基本开销是很繁重的，而且它可能是容量规划的最重要的因素之一。 也就是说，如果你在 30 台服务器上运行一个 Rails 应用，每个服务器都有 16 个 CPU 核心 32 线程，那么你有 960 个连接。可能只有不到 0.1% 的应用会超出这个范围，但这是需要记住的。 4、聚簇索引 vs 堆表 聚簇索引是一种表结构，其中的行直接嵌入其主键的 b 树结构中。一个（非聚集）堆是一个常规的表结构，它与索引分别填充数据行。 有了聚簇索引，当您通过主键查找记录时，单次 I/O 就可以检索到整行，而非集群则总是需要查找引用，至少需要两次 I/O。由于外键引用和 JOIN 将触发主键查找，所以影响可能非常大，这将导致大量查询。 聚簇索引的一个理论上的缺点是，当您使用二级索引进行查询时，它需要遍历两倍的树节点，第一次扫描二级索引，然后遍历聚集索引，这也是一棵树。 但是，如果按照现代表设计的约定，将一个自动增量整数作为主键&#91;1&#93;——它被称为代理键——那么拥有一个聚集索引几乎总是可取的。更重要的是，如果您做了大量的 ORDER BY id 来检索最近的（或最老的）N 个记录的操作，我认为这是很适用的。 Postgres 不支持聚集索引，而 MySQL(InnoDB)不支持堆。但不管怎样，如果你有大量的内存，差别应该是很小的。 5、页结构和压缩 Postgres 和 MySQL 都有基于页面的物理存储。(8KB vs 16KB) PostgreSQL 物理存储的介绍 页结构看起来就像右边的图。它包含一些我们不打算在这里讨论的条目，但是它们包含关于页的元数据。条目后面的项是一个数组标识符，由指向元组或数据行的（偏移、长度）对组成。在 Postgres 中，相同记录的多个版本可以以这种方式存储在同一页面中。 MySQL 的表空间结构与 Oracle 相似，它有多个层次，包括层、区段、页面和行层。 此外，它还有一个用于撤销的单独段，称为“回滚段”。与 Postgres 不同的是，MySQL 将在一个单独的区域中保存同一记录的多个版本。 如果存在一行必须适合两个数据库的单个页面，，这意味着一行必须小于 8KB。（至少有 2 行必须适合 MySQL 的页面，恰巧是 16KB/2 = 8KB） 那么当你在一个列中有一个大型 JSON 对象时会发生什么呢？ Postgres 使用 TOAST，这是一个专用的影子表(shadow table)存储。当行和列被选中时，大型对象就会被拉出。换句话说，大量的黑盒不会污染你宝贵的缓存。它还支持对 TOAST 对象的压缩。 MySQL 有一个更复杂的特性，叫做透明页压缩，这要归功于高端 SSD 存储供应商 Fusio-io 的贡献。它设计目的是为了更好地使用 SSD，在 SSD 中，写入量与设备的寿命直接相关。 对 MySQL 的压缩不仅适用于页面外的大型对象，而且适用于所有页面。它通过在稀疏文件中使用打孔来实现这一点，这是被 ext4 或 btrfs 等现代文件系统支持的。 有关更多细节，请参见：在 FusionIO 上使用新 MariaDB 页压缩获得显著的性能提升。 6、更新的开销 另一个经常被忽略的特性，但是对性能有很大的影响，并且可能是最具争议的话题，是更新。 这也是Uber放弃Postgres的另一个原因，这激起了许多Postgres的支持者来反驳它。 MySQL 对Uber可能是合适的, 但是未必对你合适- 一篇PostgreSQL对Uber的回应 (PDF)两者都是MVCC数据库，它们可以隔离多个版本的数据。 为了做到这一点，Postgres将旧数据保存在堆中，直到被清空，而MySQL将旧数据移动到一个名为回滚段的单独区域。 在Postgres中，当您尝试更新时，整个行必须被复制，以及指向它的索引条目也被复制。这在一定程度上是因为Postgres不支持聚集索引，所以从索引中引用的一行的物理位置不是由逻辑键抽象出来的。 为了解决这个问题，Postgres使用了堆上元组（HOT），在可能的情况下不更新索引。但是，如果更新足够频繁（或者如果一个元组比较大），元组的历史可以很容易地超过8 KB的页面大小，跨越多个页面并限制该特性的有效性。修剪和/或碎片整理的时间取决于启发式解决方案。另外，设置不超过100的填充参数会降低空间效率——这是一种很难在创建表时考虑的折衷方案。 这种限制更深入; 因为索引元组没有关于事务的任何信息，所以直到9.2之前一直不能支持仅索引扫描。 它是所有主要数据库（包括MySQL，Oracle，IBM DB2和Microsoft SQL Server）支持的最古老，最重要的优化方法之一。 但即使使用最新版本，当有许多UPDATE在可见性映射中设置脏位时，Postgres也不能完全支持仅索引扫描，并且在我们不需要时经常选择Seq扫描。 在MySQL上，更新发生在原地，旧的行数据被封存在一个称为回滚段的独立区域中。 结果是你不需要VACUUM，并且提交非常快，而回滚相对较慢，这对于大多数用例来说是一个可取的折衷。 它也足够聪明，尽快清除历史。 如果事务的隔离级别设置为READ-COMMITTED或更低，则在语句完成时清除历史记录。 事务记录的大小不会影响主页面。 碎片化是一个伪命题。 因此，在MySQL上能更好，更可预测整体性能。 7、Garbage Collection 垃圾回收 在Postgres中VACUUM上开销很高，因为它在主要工作在堆区，造成了直接的资源竞争。它感觉就像是编程语言中的垃圾回收 - 它会挡在路上，并随时让你停下来。 为具有数十亿记录的表配置autovacuum仍然是一项挑战。 在MySQL上清除（Purge）也可能相当繁重，但由于它是在单独的回滚段中使用专用线程运行的，因此它不会以任何方式影响读取的并发性。即使使用默认配置，变膨胀的回滚段使你执行速度减慢的可能性也是很低的。 拥有数十亿记录的繁忙表不会导致MySQL上的历史数据膨胀，诸如存储上的文件大小和查询性能等事情上几乎是可以预测的并且很稳定。 开源中国翻译频道：对于技术达人来说，广纳知识点是进步的源泉。通过阅读技术文章我们可以学到很多东西，既可以学到业务技能，又可以了解行业动态，最不济，也锻炼了阅读和学习的能力。开源中国翻译频道旨在每天为用户推荐并翻译优质的外网文章。再也不用怕因为英语不过关，被挡在许多技术文章的门外。 转载来源：外文翻译丨“王者对战”之 MySQL 8 vs PostgreSQL 10（深度） - 今日头条]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>MariaDB</tag>
        <tag>Uber</tag>
        <tag>固态硬盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习 —— 浅谈贝叶斯和MCMC]]></title>
    <url>%2F2018%2F84be87fc%2F</url>
    <content type="text"><![CDATA[关于贝叶斯和MCMC一些数学原理的讲解和代码的实现 转载来源：机器学习 —— 浅谈贝叶斯和MCMC]]></content>
      <tags>
        <tag>人工智能头条</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[医生端移动医疗APP使用调研报告：医生需求表现出“务实性”，工具类APP或成最大赢家]]></title>
    <url>%2F2018%2F37a04eff%2F</url>
    <content type="text"><![CDATA[动脉网vcbeat|本次调研主要基于动脉网平台的医生资源，通过随机发送问卷并收集整理反馈的问卷，分析调研结果，制作了此份报告。报告呈现了医生端移动医疗的发展国产与未来趋势 转载来源：医生端移动医疗APP使用调研报告：医生需求表现出“务实性”，工具类APP或成最大赢家]]></content>
      <tags>
        <tag>动脉网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教你用IPFS安全地分享区块链上的文件 - 区块链兄弟]]></title>
    <url>%2F2018%2F75f1c634%2F</url>
    <content type="text"><![CDATA[教你用IPFS安全地分享区块链上的文件 - 区块链兄弟 教你用IPFS安全地分享区块链上的文件 - 区块链兄弟 转载来源：教你用IPFS安全地分享区块链上的文件 - 区块链兄弟]]></content>
  </entry>
  <entry>
    <title><![CDATA[曹山石点评独角兽基金：CDR不会高位接美股回A股 - 今日头条]]></title>
    <url>%2F2018%2F29cbb122%2F</url>
    <content type="text"><![CDATA[新时代证券研究所所长孙金炬CDR研报已经出到系列十。ADR、HDR、TDR、双重上市、第二上市、分拆上市、双向存托凭证．．．．．说实话，系列研报追下来，要问我学到啥。 最近A股新名词层出不穷，很是热闹。新时代证券研究所所长孙金炬CDR研报已经出到系列十。 ADR、HDR、TDR、双重上市、第二上市、分拆上市、双向存托凭证．．．．．说实话，系列研报追下来，要问我学到啥。我可以明确的告诉你：很多。要是你再追问细节，我同样可以明确的告知：请让我再看一次研报。 为了达到蛊惑人的目的，魔鬼可以为你背诵圣经。让我们说话的方式简单点。 简而言之，A股当前的重头戏（发展任务）就是：独角兽战略和沪伦通。 消息说了，由证监会主导的6只独角兽基金将于下周一也即6月11日起开始募集，并在十天内快速成立。 昨天（6月5日），华夏、汇添富、易方达、南方、招商、嘉实等公募（其中五家也是证金资管计划管理方），纷纷晒出新品海报——有意思的是，从这些海报来看，跟以往的产品宣传海报不同，它们既没有产品名称，也没有产品发行日期。 从宣传材料来看，银行对各家基金公司的“独角兽”产品基本采用了同一套说辞，对独角兽基金主要提到了“前所未有的战略力度”“前所未有的战略机遇”“前所未有的普惠金融”“前所未有的低费让利”等四大优势。 关系到钱的时候：咱们能说数字，就别整形容词。 6只产品募集上限为500亿，也就是3000亿公募独角兽基金。 相比之下，2017年全年A股IPO规模为2100亿。 应该说，金融圈内不乏聪明人：与过往采用战略配售的IPO案例中直接发行和战略配售的价格往往一致不同，独角兽基金参与CDR项目的战略配售有望拿到较高程度的折价，这将大大提高独角兽基金的吸引力。 所以说，3000亿募集必然是不成问题的，毕竟有四大行两八肋插刀，要知道，单只一个招行，理财资金规模就超过2万亿。 给新基折价打独角兽，成都打新房就是新近成功案例。 成都限购政策，堪称中国城市限购史上“教科书级表演”。通过高新区和天府限购，高位回收流动性，防止外来资金高位出逃。然后陆续实施限贷，限价，限捂盘，一二手倒挂，2017下半年，成功祭出人才落户大杀器，政策大开大合，但每一次都体现了成都精致利民而又步步紧逼的智慧。 当然，有人腹诽CDR相当于高位接美股回来给A股，若美股跌20%估值，那画面太美不敢看。我认为这是杞人忧天，美股泡沫风险年初监管层就提上日程了。个人要相信组织。 至于锁定三年期后事情，现在说得清吗？房子都还限售五年不照样抢？ 忙完这一阵，接下来就可以忙下一阵了，心疼证监会。搞完独角兽，年内还得开沪伦通。 中信证券报告称，计划在年内开通的沪伦通预计将初步采用双向存托凭证机制。预计伦敦上市公司在华融资规模大致在4600亿人民币左右。 报告最后还说：整体流动性压力不大。嗯，知道了。 听说啊，有机构想不明白，两个交易时间不重叠的市场怎么通，互相开夜盘？主管讲领导说了能通，就一定能通，这机构一定是知识储备还不够。 两边发DR，全球成熟市场通——全球通只要是能移动的用户，都能理解的。 监管力推资本市场这一派蓬勃发展之态，往日那些金融巨头正忙不迭发展科技。 马明哲已经公开表态，中国平安未来的发展方向与其说是一家金融机构，不如说是一家科技公司，其对标的将是BAT这样的科技公司。 招商银行旗帜鲜明地提出了“金融科技银行”的新定位，将科技变革作为未来3至5年的重中之重。 去年底，蚂蚁金服邀请相熟的媒体主管夜话喝茶，主题是如何从大众眼中的金融企业变为科技企业。一晚聊下来，我印象最深刻的副总裁那句话——马老板说，妈的当初蚂蚁金服这名字，还不如叫蚂蚁科服。 当然，英国政府2015年3月提出的监管沙盒（Regulatory Sandbox）概念，可以很好的解释这一切，按照英国金融行为监管局的定义，“监管沙盒”是一个“安全空间”，在这个安全空间内，金融科技企业可以测试其创新的金融产品、服务、商业模式和营销方式，而不用在相关活动碰到问题时立即受到监管规则的约束。 像京东金融的股权融资，这样6层嵌套，搞那么复杂。现在为了监管方便，要求穿透，这不是平添监管工作任务吗？ 所以，现在银行监管机构几乎每天都在蚂蚁金服杭州总部监控其金融服务业务。路透说，受到来自央行的压力，蚂蚁金服旗下的芝麻信用已经停止发布个人信用评级。现阶段，芝麻信用仅能用于非金融目的，比如在自行车租用和签证审批时作为信用审查。 花开两朵，各表一枝。 说完证监会牛仔很忙，来看各家机构在操心啥。 从当前的情冴来看， 2018年仍然值得担忧的风险有两个方面：一是居民部门杠杆率的高企及其与房地产市场的深度捆绑，二是PPP项目泛滥与棚改如火如荼的背后，地方政府债务压力的不断上升。 这意味着，未来防风险的领域将从金融部门扩展到居民部门与政府部门，政策将从致力于金融去杠杆扩展到居民与政府部门去杠杆。 如今机构在与投资者交流过程中，无论是债券还是权益市场，最为关心的是信用风险会不会继续发酵？有哪些领域可能作为下一阶段的重灾区？ 那今天呢，我看到家属接近部委的中信证券固收研究主管明明说了，“下半年降准仍然是有可能的，只是上半年已经降了两次了，年中没有必要这么频繁的降。” 这就意味着，本月资金面有点难盼到有源头活水来。 莲花山下史丹利招商证券固收团队，最近研报主题是：《信用风险行业比较：逻辑、框架与测度》、《破解违约债券的基因密码》； 那兴业证券固收团队，主题则是《议信用风险的演化、市场冲击及政策对冲措施》《再议。。。》《“解码”信用资质系列专题（大概会一二三吧）》 应该说，全市场最早提示并专题研究信用风险的，是长江证券宏观首席赵伟团队，只不过语言比较学术（繁荣的顶点），不是很合买方和市场的牙口。 你说，有两卖方标题《砥砺前行》和《未来已来》，怎么辨别多空态度？ 这些研报，有一说一，说实话我都看完了。 市场上公开信息足够多，需要通过工具把这些碎片化的信息有效的梳理，放在价值链上去应用。 投资是个专业的活，要是都是一套简单逻辑：公司前景够好，管理层有动力，股票就一定好——这不就等同说，只要兄弟够忠心，老婆够漂亮，此生足矣。 北宋有一个哥们，他是卖炊饼的… 那么，结合这些研报，我总结一下专业排雷口诀： 三长一短选最短，三短一长选最长，长短不一选择B，层次不起就选D，同长为A，同短为C，以抄为主，以蒙为辅，蒙抄结合，一定及格。 还有几个老油条的说法： 避免老千股这种事儿，财务可以提供一些蛛丝马迹，但完全靠报表那点儿数据确实不容易。可综合以下手段：1，意图层面，有大笔套现或者圈钱嫌疑的不碰；2，业务生僻难懂的公司尽量不碰；3，生僻难懂还利润奇高的更不碰；4，下游客户难寻却生意做得很大的不碰；5，基本没有同业竞争对手或创世界技术奇迹的，要高度谨慎；6，现金流差而资本运作动作大或者频繁的要谨慎；7，经营数据与同业相比差异过大，原因又很蹊跷的不碰。 无论是选项目还是配股票，财报很重要，这四条一定要盯紧，多问个为什么。 1）逆天的年底业绩变脸。 2）经营现金流与净利润背离。 3）庞大且不正常的在建工程。 4）巨额披露不详的减值准备。 案例探讨一下，去年7月底一家公司在建工程2016年完工进度98%，2017年99%，在建工程占资产的一半。结果还出来融资，以为很多投资人只看利润表和对赌。今年业绩大规模预减了解一下。 最后，来点正能量，啄木鸟啄虫，是为了树的健康。 认识有些年的对冲基金老友就说： 对独角兽们的IPO，很多人看不清楚它所带来的影响。按证监会透露的国内独角兽分批上市规划，100家资产10亿美金，50家资产20亿美金。那就是2000亿美金约合12600亿元资产。怎么发？怎么个节奏？ 我个人觉得这是一个绝佳的机会收拾干净国内资本市场。也就是说，进入机构博弈时代。五个“二十万亿”级别方阵博弈的格局，即：私募、公募、产业、养老社保、外资。选股能力成为常态，退市和发行制度对称，整体换手下降，散户和股神文化回归国际常识，正确的投机，大于投机正确。 打个比方吧，老蒋当年完全有能力将红军困在湘桂边境，但他的小诸葛杨永泰建议驱兵入西南，顺带收拾云贵川滇的军阀，一举多得。当然是否如此历史上有争议，但实际效果是为未来的抗日留下了稳健的大后方。 借大小独角兽们厘清投资格局，开拓注册制，建立标准化的常效模式，吸引境内外规范资金，创新进取，应付未来金融之动荡，这也许是管理层的苦心。 但路径也许会一波三折，利弊皆有。 而不可忽视的时代特征是，今年是改革开放40周年。四季度可能召开十九届四中全会，历次四中全会均制定经济和改革重要事项，华泰宏观首席李超认为这将有望成为中国A股牛市的重要催化剂。 李超同时认为，从中长期来看，2018年可能将会和2000年互联网泡沫时期类似，大概率出现美元指数和美股同步下行。 在其看来，本轮美元周期已来到大周期向下拐点，美元周期趋弱时资本回流新兴市场的可能性较大，中国在新兴市场的对比当中优势明显，未来A股中长期可能触发外生流动性宽松牛市。 回首2006-2007 年，正是由于资本流入而触发了一轮以价值重估为主线的牛市。外生的流动性宽松持续压低无风险利率，而且外生流动性宽松与2008年金融危机以前我国贸易增速较高共同推高企业盈利预期，上证综指一度超过6000点。 也就是，我国存量流动性宽裕，在金融去杠杆的大背景下，如果经济形势较好，央行会倾向于较快地收紧流动性，因此基本面很难触发A股牛市。 所以，如果美国股市大幅调整又没有引发金融危机的话，外汇占款增长将会成为我国基础货币供给的新支点， 外生性宽松将在较长时间内利好A股市场。 一句话，如果美股崩而不倒，A股有望由此迎长牛。 本文源自山石观市 更多精彩资讯，请来金融界网站(www.jrj.com.cn) 转载来源：曹山石点评独角兽基金：CDR不会高位接美股回A股 - 今日头条]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>美股</tag>
        <tag>基金</tag>
        <tag>蓝筹股</tag>
        <tag>芝麻信用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何精确统计页面停留时长 - 今日头条]]></title>
    <url>%2F2018%2F61443e80%2F</url>
    <content type="text"><![CDATA[active页面活跃时长visible页面可见时长//仅支持Desktopduration页面总停留时长6。 1.背景页面停留时间（Time on Page）简称 Tp，是网站分析中很常见的一个指标，用于反映用户在某些页面上停留时间的长短，传统的Tp统计方法会存在一定的统计盲区，比如无法监控单页应用，没有考虑用户切换Tab、最小化窗口等操作场景。 基于上述背景，重新调研和实现了精确统计页面停留时长的方案，需要 兼容单页应用和多页应用，并且不耦合或入侵业务代码。 2.分析我们可以把一个页面生命周期抽象为三个动作： 「进入」、「活跃状态切换」、「离开」 如下图，计算页面停留时长既如何监控这三个动作，然后在对应触发的事件中记录时间戳，比如要统计活跃停留时长就把 active 区间相加即可，要统计总时长既 tn -t0 。 2.1 如何监听页面的进入和离开？ 对于常规页面的 首次加载、页面关闭、刷新 等操作都可以通过 window.onload 和 window.onbeforeunload 事件来监听页面进入和离开，浏览器前进后退可以通过 pageshow 和 pagehide 处理。 对于单页应用内部的跳转可以转化为两个问题：1.监听路由变化，2.判断变化的URL是否为不同页面 。 2.1.1 监听路由变化 目前主流的单页应用大部分都是基于 browserHistory (history api) 或者 hashHistory 来做路由处理，我们可以通过监听路由变化来判断页面是否有可能切换。注意是有可能切换，因为URL发生变化不代表页面一定切换，具体的路由配置是由业务决定的（既URL和页面的匹配规则）。 browserHistory 路由的变化本质都会调用 History.pushState() 或 History.replaceState() ，能监听到这两个事件就能知道。通过 popstate 事件能解决一半问题，因为 popstate 只会在浏览器前进后退的时候触发，当调用 history.pushState() or history.replaceState() 的时候并不会触发。 The popstate event is fired when the active history entry changes. If the history entry being activated was created by a call to history.pushState() or was affected by a call to history.replaceState(), the popstate event’s state property contains a copy of the history entry’s state object. Note that just calling history.pushState() or history.replaceState() won’t trigger a popstate event. The popstate event will be triggered by doing a browser action such as a click on the back or forward button (or calling。history.back() or history.forward() in JavaScript). 这里需要通过猴子补丁(Monkeypatch)解决，运行时重写 history.pushState 和 history.replaceState 方法： hashHistory hashHistory 的实现是基于 hash 的变化，hash 的变化可以通过 hashchange 来监听 2.1.2 判断URL是否为不同页面 问题本质是怎么定义一个页面，这里我们无法自动获取，因为不同业务场景定义不同，需要业务方在初始化的时候配置 rules 参数，默认不传入 rules 的情况取 location.pathname 为 key，key 不相同则判断为不同的页面，配置的语法： 对于页面进入和离开相关事件整理 2.2 如何监听页面活跃状态切换？ 可以通过 Page Visibility API 以及在 window 上声明 onblur/onfocus 事件来处理。 2.2.1 Page Visibility API 一个网页的可见状态可以通过 Page Visibility API 获取，比如当用户 切换浏览器Tab、最小化窗口、电脑睡眠 的时候，系统API会派发一个当前页面可见状态变化的 visibilitychange 事件，然后在事件绑定函数中通过 document.hidden 或者 document.visibilityState 读取当前状态。 2.2.2 onblur/onfocus 2.3 什么时机上报数据？ 2.3.1 页面离开时上报 对于页面刷新或者关闭窗口触发的操作可能会造成数据丢失 2.3.2 下次打开页面时上报 会丢失历史访问记录中的最后一个页面数据 目前采用的方案2，对于单页内部跳转是即时上报，对于单页/多页应用触发 window.onbeforeunload 事件的时候会把当前页面数据暂存在 localStorage 中，当用户下次进入页面的时候会把暂存数据上报。有个细节问题，如果用户下次打开页面是在第二天，对于统计当天的活跃时长会有一定的误差，所以在数据上报的同时会把该条数据的页面进入时间/离开时间带上。 3.设计3.1 UML类关系图 Tracer 核心类，用来实例化一个监控，对原生事件和自定义事件的封装，监听 enter activechange exit 事件来操作当前 Page 实例。 P.S. 取名来自暴雪旗下游戏守望先锋英雄猎空(Tracer)，直译为：追踪者。 Page 页面的抽象类，用来实例化一个页面，封装了 enter exit active inactive 等操作，内部通过 state 属性来维护当前页面状态。 3.2 事件派发关系图 4.兼容性Desktop Mobile 5.思考对于页面停留时长的定义可能在不同场景会有差异，比如内部业务系统或者OA系统，产品可能更关心用户在页面的活跃时长；而对于资讯类型的产品，页面可见时长会更有价值。单一的数据对业务分析是有限的，所以在具体的代码实过程中我们会把停留时长分三个指标，这样能更好的帮助产品/运营分析。 active 页面活跃时长 visible 页面可见时长 //仅支持Desktop duration 页面总停留时长 6.TODO移动端的兼容性目前还没完全覆盖； 对于页面的配置目前还不够灵活，考虑支持 react-router / vue-router 的配置； byted-cg-tracer 待封装；开发中 7.参考https&#58;//developer.mozilla.org/en-US/docs/Web/API/WindowEventHandlers/onhashchange https&#58;//developer.mozilla.org/en-US/docs/Web/Events/popstate https&#58;//developer.mozilla.org/en-US/docs/Web/API/Page_Visibility_API https&#58;//stackoverflow.com/questions/4570093/how-to-get-notified-about-changes-of-the-history-via-history-pushstate 转载来源：如何精确统计页面停留时长 - 今日头条]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>路由器</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[史上最全vue组件库！极速围观 - 今日头条]]></title>
    <url>%2F2018%2Fee828ce9%2F</url>
    <content type="text"><![CDATA[史上最全vue组件库https&#58;//github.com/ElemeFE/element&quot;element饿了么出品的Vue2的webUI工具套件https&#58;//github.com/airyland/vux&quot;Vux基于Vue和WeUI的组件库https&#58;//github.com/ 史上最全vue组件库 https&#58;//github.com/ElemeFE/element” element 饿了么出品的Vue2的web UI工具套件 https&#58;//github.com/airyland/vux” Vux 基于Vue和WeUI的组件库 https&#58;//github.com/ElemeFE/mint-ui” mint-ui Vue 2的移动UI元素 https&#58;//github.com/iview/iview” iview 基于 Vuejs 的开源 UI 组件库 https&#58;//github.com/JosephusPaye/Keen-UI” Keen-UI 轻量级的基本UI组件合集 https&#58;//github.com/marcosmoura/vue-material” vue-material 通过Vue Material和Vue 2建立精美的app应用 https&#58;//github.com/museui/muse-ui” muse-ui 三端样式一致的响应式 UI 库 https&#58;//github.com/vuetifyjs/vuetify” vuetify 为移动而生的Vue JS 2组件框架 https&#58;//github.com/wangdahoo/vonic” vonic 快速构建移动端单页应用 https&#58;//github.com/egoist/eme” eme 优雅的Markdown编辑器 https&#58;//github.com/monterail/vue-multiselect” vue-multiselect Vue.js选择框解决方案 https&#58;//github.com/ratiw/vue-table” vue-table-简化数据表格 https&#58;//github.com/OYsun/VueCircleMenu” VueCircleMenu-漂亮的vue圆环菜单 https&#58;//github.com/Coffcer/vue-chat” vue-chat-vuejs和vuex及webpack的聊天示例 https&#58;//github.com/luojilab/radon-ui” radon-ui-快速开发产品的Vue组件库 https&#58;//github.com/MopTym/vue-waterfall” vue-waterfall-Vue.js的瀑布布局组件 https&#58;//github.com/myronliu347/vue-carbon” vue-carbon-基于 vue 开发MD风格的移动端 https&#58;//github.com/FE-Driver/vue-beauty” vue-beauty-由vue和ant design创建的优美UI组件 https&#58;//github.com/chenz24/vue-blu” vue-blu-帮助你轻松创建web应用 https&#58;//github.com/taylorchen709/vueAdmin” vueAdmin-基于vuejs2和element的简单的管理员模板 https&#58;//github.com/vuejs/vue-syntax-highlight” vue-syntax-highlight-Sublime Text语法高亮 https&#58;//github.com/ElemeFE/vue-infinite-scroll” vue-infinite-scroll-VueJS的无限滚动指令 https&#58;//github.com/David-Desmaisons/Vue.Draggable” Vue.Draggable-实现拖放和视图模型数组同步 https&#58;//github.com/surmon-china/vue-awesome-swiper” vue-awesome-swiper-vue.js触摸滑动组件 https&#58;//github.com/jinzhe/vue-calendar” vue-calendar-日期选择插件 https&#58;//github.com/pi0/bootstrap-vue” bootstrap-vue-应用于Vuejs2的Twitter的Bootstrap 4组件 https&#58;//github.com/ElemeFE/vue-swipe” vue-swipe-VueJS触摸滑块 https&#58;//github.com/ElemeFE/vue-amap” vue-amap-基于Vue 2和高德地图的地图组件 https&#58;//github.com/apertureless/vue-chartjs” vue-chartjs-vue中的Chartjs的封装 https&#58;//github.com/hilongjw/vue-datepicker” vue-datepicker-日历和日期选择组件 https&#58;//github.com/jrainlau/markcook” markcook-好看的markdown编辑器 https&#58;//github.com/GuillaumeLeclerc/vue-google-maps” vue-google-maps-带有双向数据绑定Google地图组件 https&#58;//github.com/hilongjw/vue-progressbar” vue-progressbar-vue轻量级进度条 https&#58;//github.com/alessiomaffeis/vue-picture-input” vue-picture-input-移动友好的图片文件输入组件 https&#58;//github.com/PeachScript/vue-infinite-loading” vue-infinite-loading-VueJS的无限滚动插件 https&#58;//github.com/lian-yue/vue-upload-component” vue-upload-component-Vuejs文件上传组件 https&#58;//github.com/Haixing-Hu/vue-datetime-picker” vue-datetime-picker-日期时间选择控件 https&#58;//github.com/wangdahoo/vue-scroller” vue-scroller-Vonic UI的功能性组件 https&#58;//github.com/icai/vue2-calendar” vue2-calendar-支持lunar和日期事件的日期选择器 https&#58;//github.com/surmon-china/vue-video-player” vue-video-player-VueJS视频及直播播放器 https&#58;//github.com/Wanderxx/vue-fullcalendar” vue-fullcalendar-基于vue.js的全日历组件 https&#58;//github.com/ccforward/rubik” rubik-基于Vuejs2的开源 UI 组件库 https&#58;//github.com/OYsun/VueStar” VueStar-带星星动画的vue点赞按钮 https&#58;//github.com/egoist/vue-mugen-scroll” vue-mugen-scroll-无限滚动组件 https&#58;//github.com/mint-ui/mint-loadmore” mint-loadmore-VueJS的双向下拉刷新组件 https&#58;//github.com/matfish2/vue-tables-2” vue-tables-2-显示数据的bootstrap样式网格 https&#58;//github.com/Akryum/vue-virtual-scroller” vue-virtual-scroller-带任意数目数据的顺畅的滚动 https&#58;//github.com/SimonZhangITer/DataVisualization” DataVisualization-数据可视化 https&#58;//github.com/surmon-china/vue-quill-editor” vue-quill-editor-基于Quill适用于Vue2的富文本编辑器 https&#58;//github.com/hifarer/Vueditor” Vueditor-所见即所得的编辑器 https&#58;//github.com/PeakTai/vue-html5-editor” vue-html5-editor-html5所见即所得编辑器 https&#58;//github.com/ElemeFE/vue-msgbox” vue-msgbox-vuejs的消息框 https&#58;//github.com/warpcgd/vue-slider” vue-slider-vue 滑动组件 https&#58;//github.com/Vanthink-UED/vue-core-image-upload” vue-core-image-upload-轻量级的vue上传插件 https&#58;//github.com/hilongjw/vue-slide” vue-slide-vue轻量级滑动组件 https&#58;//github.com/JALBAA/vue-lazyload-img” vue-lazyload-img-移动优化的vue图片懒加载插件 https&#58;//github.com/Alex-fun/vue-drag-and-drop-list” vue-drag-and-drop-list-创建排序列表的Vue指令 https&#58;//github.com/MatteoGabriele/vue-progressive-image” vue-progressive-image-Vue的渐进图像加载插件 https&#58;//github.com/vuwe/vuwe” vuwe-基于微信WeUI所开发的专用于Vue2的组件库 https&#58;//github.com/rowanwins/vue-dropzone” vue-dropzone-用于文件上传的Vue组件 https&#58;//github.com/hchstera/vue-charts” vue-charts-轻松渲染一个图表 https&#58;//github.com/weilao/vue-swiper” vue-swiper-易于使用的滑块组件 https&#58;//github.com/littlewin-wang/vue-images” vue-images-显示一组图片的lightbox组件 https&#58;//github.com/Wlada/vue-carousel-3d” vue-carousel-3d-VueJS的3D轮播组件 https&#58;//github.com/QingWei-Li/vue-region-picker” vue-region-picker-选择中国的省份市和地区 https&#58;//github.com/cngu/vue-typer” vue-typer-模拟用户输入选择和删除文本的Vue组件 https&#58;//github.com/NewDadaFE/vue-impression” vue-impression-移动Vuejs2 UI元素 https&#58;//github.com/galenyuan/vue-datatable” vue-datatable-使用Vuejs创建的DataTableView https&#58;//github.com/santiblanko/vue-instant” vue-instant-轻松创建自动提示的自定义搜索控件 https&#58;//github.com/hilongjw/vue-dragging” vue-dragging-使元素可以拖拽 https&#58;//github.com/NightCatSama/vue-slider-component” vue-slider-component-在vue1和vue2中使用滑块 https&#58;//github.com/BosNaufal/vue2-loading-bar” vue2-loading-bar-最简单的仿Youtube加载条视图 https&#58;//github.com/weifeiyue/vue-datepicker” vue-datepicker-漂亮的Vue日期选择器组件 https&#58;//github.com/hilongjw/vue-video” vue-video-Vue.js的HTML5视频播放器 https&#58;//github.com/ElemeFE/vue-toast-mobile” vue-toast-mobile-VueJS的toast插件 https&#58;//github.com/dai-siki/vue-image-crop-upload” vue-image-crop-upload-vue图片剪裁上传组件 https&#58;//github.com/Akryum/vue-tooltip” vue-tooltip-带绑定信息提示的提示工具 https&#58;//github.com/weizhenye/vue-highcharts” vue-highcharts-HighCharts组件 https&#58;//github.com/surmon-china/vue-touch-ripple” vue-touch-ripple-vuejs的触摸ripple组件 https&#58;//github.com/Kocisov/coffeebreak” coffeebreak-实时编辑CSS组件工具 https&#58;//github.com/coderdiaz/vue-datasource” vue-datasource-创建VueJS动态表格 https&#58;//github.com/phoenixwong/vue2-timepicker” vue2-timepicker-下拉时间选择器 https&#58;//github.com/Bubblings/vue-date-picker” vue-date-picker-VueJS日期选择器组件 https&#58;//github.com/BosNaufal/vue-scrollbar” vue-scrollbar-最简单的滚动区域组件 https&#58;//github.com/CroudSupport/vue-quill” vue-quill-vue组件构建quill编辑器 https&#58;//github.com/phanan/vue-google-signin-button” vue-google-signin-button-导入谷歌登录按钮 https&#58;//github.com/MMF-FE/vue-svgicon” vue-svgicon-创建svg图标组件的工具 https&#58;//github.com/bkzl/vue-float-label” vue-float-label-VueJS浮动标签模式 https&#58;//github.com/Dafrok/vue-baidu-map” vue-baidu-map-基于 Vue 2的百度地图组件库 https&#58;//github.com/nicolasbeauvais/vue-social-sharing” vue-social-sharing-社交分享组件 https&#58;//github.com/davidroyer/vue2-editor” vue2-editor-HTML编辑器 https&#58;//github.com/Ginhing/vue-tagsinput” vue-tagsinput-基于VueJS的标签组件 https&#58;//github.com/shhdgit/vue-easy-slider” vue-easy-slider-Vue 2.x的滑块组件 https&#58;//github.com/vue-bulma/datepicker” datepicker-基于flatpickr的时间选择组件 https&#58;//github.com/miaolz123/vue-chart” vue-chart-强大的高速的vue图表解析 https&#58;//github.com/yunyi1895/vue-music-master” vue-music-master-vue手机端网页音乐播放器 https&#58;//github.com/vue-bulma/handsontable” handsontable-网页表格组件 https&#58;//github.com/F-loat/vue-simplemde” vue-simplemde-VueJS的Markdown编辑器组件 https&#58;//github.com/myronliu347/vue-popup-mixin” vue-popup-mixin-用于管理弹出框的遮盖层 https&#58;//github.com/fangyongbao/cubeex” cubeex-包含一套完整的移动UI https&#58;//github.com/CroudSupport/vue-fullcalendar” vue-fullcalendar-vue FullCalendar封装 https&#58;//github.com/loujiayu/vue-material-design” vue-material-design-Vue MD风格组件 https&#58;//github.com/bbonnin/vue-morris” vue-morris-Vuejs组件封装Morrisjs库 https&#58;//github.com/tianyong90/we-vue” we-vue-Vue2及weui1开发的组件 https&#58;//github.com/legeneek/vue-image-clip” vue-image-clip-基于vue的图像剪辑组件 https&#58;//github.com/jbaysolutions/vue-bootstrap-table” vue-bootstrap-table-可排序可检索的表格 https&#58;//github.com/wyzant-dev/vue-radial-progress” vue-radial-progress-Vue.js放射性进度条组件 https&#58;//github.com/staskjs/vue-slick” vue-slick-实现流畅轮播框的vue组件 https&#58;//github.com/bajian/vue-pull-to-refresh” vue-pull-to-refresh-Vue2的上拉下拉 https&#58;//github.com/matfish2/vue-form-2” vue-form-2-全面的HTML表单管理的解决方案 https&#58;//github.com/vue-comps/vue-side-nav” vue-side-nav-响应式的侧边导航 https&#58;//github.com/mint-ui/mint-indicator” mint-indicator-VueJS移动加载指示器插件 https&#58;//github.com/vue-bulma/chartjs” chartjs-Vue Bulma的chartjs组件 https&#58;//github.com/suguangwen/vue-scroll” vue-scroll-vue滚动 https&#58;//github.com/BosNaufal/vue-ripple” vue-ripple-制作谷歌MD风格涟漪效果的Vue组件 https&#58;//github.com/icebob/vue-touch-keyboard” vue-touch-keyboard-VueJS虚拟键盘组件 https&#58;//github.com/ankane/vue-chartkick” vue-chartkick-VueJS一行代码实现优美图表 https&#58;//github.com/lisiyizu/vue-ztree” vue-ztree-用 vue 写的树层级组件 https&#58;//github.com/shiye515/vue-m-carousel” vue-m-carousel-vue 移动端轮播组件 https&#58;//github.com/dai-siki/vue-datepicker-simple” vue-datepicker-simple-基于vue的日期选择器 https&#58;//github.com/alexqdjay/vue-tabs” vue-tabs-多tab页轻型框架 https&#58;//github.com/aweiu/vue-verify-pop” vue-verify-pop-带气泡提示的vue校验插件 https&#58;//github.com/vue-comps/vue-parallax” vue-parallax-整洁的视觉效果 https&#58;//github.com/JackGit/vue-img-loader” vue-img-loader-图片加载UI组件 https&#58;//github.com/eduardostuart/vue-typewriter” vue-typewriter-vue组件类型 https&#58;//github.com/Teddy-Zhu/vue-smoothscroll” vue-smoothscroll-smoothscroll的VueJS版本 https&#58;//github.com/xinxingyu/vue-city” vue-city-城市选择器 https&#58;//github.com/weibangtuo/vue-tree” vue-tree-vue树视图组件 https&#58;//github.com/Treri/vue-ios-alertview” vue-ios-alertview-iOS7+ 风格的alertview服务 https&#58;//github.com/ibufu/dd-vue-component” dd-vue-component-订单来了的公共组件库 https&#58;//github.com/yeseason/paco-ui-vue” paco-ui-vue-PACOUI的vue组件 https&#58;//github.com/doodlewind/vue-cmap” vue-cmap-Vue China map可视化组件 https&#58;//github.com/steven5538/vue-button” vue-button-Vue按钮组件 开发框架 https&#58;//github.com/vuejs/vue” vue.js-流行的轻量高效的前端组件化方案 https&#58;//github.com/fundon/vue-admin” vue-admin-Vue管理面板框架 https&#58;//github.com/SimulatedGREG/electron-vue” electron-vue-Electron及VueJS快速启动样板 https&#58;//github.com/petervmeijgaard/vue-2.0-boilerplate” vue-2.0-boilerplate-Vue2单页应用样板​ https&#58;//github.com/hanan198501/vue-spa-template” vue-spa-template-前后端分离后的单页应用开发 https&#58;//github.com/nolimits4web/Framework7-Vue” Framework7-Vue-VueJS与Framework7结合 https&#58;//github.com/wangxg2016/vue-bulma” vue-bulma-轻量级高性能MVVM Admin UI框架 https&#58;//github.com/rodzzlessa24/vue-webgulp” vue-webgulp-仿VueJS Vue loader示例 https&#58;//github.com/Metnew/vue-element-starter” vue-element-starter-vue启动页 常用vue库 https&#58;//github.com/vuejs/vuex” vuex-专为 Vue.js 应用程序开发的状态管理模式 https&#58;//github.com/monterail/vuelidate” vuelidate-简单轻量级的基于模块的Vue.js验证 https&#58;//github.com/zerqu/qingcheng” qingcheng-qingcheng主题 https&#58;//github.com/ElemeFE/vue-desktop” vue-desktop-创建管理面板网站的UI库 https&#58;//github.com/declandewet/vue-meta” vue-meta-管理app的meta信息 https&#58;//github.com/imcvampire/vue-axios” vue-axios-将axios整合到VueJS的封装 https&#58;//github.com/cenkai88/vue-svg-icon” vue-svg-icon-vue2的可变彩色svg图标方案 https&#58;//github.com/eddyerburgh/avoriaz” avoriaz-VueJS测试实用工具库 https&#58;//github.com/lmk123/vue-framework7” vue-framework7-结合VueJS使用的Framework7组件 https&#58;//github.com/Coffcer/vue-bootstrap-modal” vue-bootstrap-modal-vue的Bootstrap样式组件 https&#58;//github.com/QingWei-Li/vuep” vuep-用实时编辑和预览来渲染Vue组件 https&#58;//github.com/Sopamo/vue-online” vue-online-reactive的在线和离线组件 https&#58;//github.com/yeyuqiudeng/vue-lazy-render” vue-lazy-render-用于Vue组件的延迟渲染 https&#58;//github.com/apertureless/vue-password-strength-meter” vue-password-strength-meter-交互式密码强度计 https&#58;//github.com/lynzz/element-admin” element-admin-支持 vuecli 的 Element UI 的后台模板 https&#58;//github.com/SimulatedGREG/vue-electron” vue-electron-将选择的API封装到Vue对象中的插件 https&#58;//github.com/vue-bulma/cleave” cleave-基于cleave.js的Cleave组件 https&#58;//github.com/cklmercer/vue-events” vue-events-简化事件的VueJS插件 https&#58;//github.com/iFgR/vue-shortkey” vue-shortkey-应用于Vue.js的Vue-ShortKey 插件 https&#58;//github.com/kartsims/vue-cordova” vue-cordova-Cordova的VueJS插件 https&#58;//github.com/weinot/vue-router-transition” vue-router-transition-页面过渡插件 https&#58;//github.com/mlyknown/vue-gesture” vue-gesture-VueJS的手势事件插件 https&#58;//github.com/FranckFreiburger/http-vue-loader” http-vue-loader-从html及js环境加载vue文件 https&#58;//github.com/superman66/vue-qart” vue-qart-用于qartjs的Vue2指令 https&#58;//github.com/gocanto/vuemit” vuemit-处理VueJS事件 https&#58;//github.com/icebob/vue-websocket” vue-websocket-VueJS的Websocket插件 https&#58;//github.com/pinguinjkeke/vue-local-storage” vue-local-storage-具有类型支持的Vuejs本地储存插件 https&#58;//github.com/gocanto/lazy-vue” lazy-vue-懒加载图片 https&#58;//github.com/yangmingshan/vue-bus” vue-bus-VueJS的事件总线 https&#58;//github.com/ropbla9/vue-reactive-storage” vue-reactive-storage-vue插件的Reactive层 https&#58;//github.com/se-panfilov/vue-notifications” vue-notifications-非阻塞通知库 https&#58;//github.com/Coffcer/vue-lazy-component” vue-lazy-component-懒加载组件或者元素的Vue指令 https&#58;//github.com/AStaroverov/v-media-query” v-media-query-vue中添加用于配合媒体查询的方法 https&#58;//github.com/Akryum/vue-observe-visibility” vue-observe-visibility-当元素在页面上可见或隐藏时检测 https&#58;//github.com/HerringtonDarkholme/vue-ts-loader” vue-ts-loader-在Vue装载机检查脚本 https&#58;//github.com/matfish2/vue-pagination-2” vue-pagination-2-简单通用的分页组件 https&#58;//github.com/dkfbasel/vuex-i18n” vuex-i18n-定位插件 https&#58;//github.com/David-Desmaisons/Vue.resize” Vue.resize-检测HTML调整大小事件的vue指令 https&#58;//github.com/xanf/vuex-shared-mutations” vuex-shared-mutations-分享某种Vuex mutations https&#58;//github.com/BosNaufal/vue-file-base64” vue-file-base64-将文件转换为Base64的vue组件 https&#58;//github.com/vue-bulma/modal” modal-Vue Bulma的modal组件 https&#58;//github.com/irwansyahwii/Famous-Vue” Famous-Vue-Famous库的vue组件 https&#58;//github.com/LeoHuiyi/leo-vue-validator” leo-vue-validator-异步的表单验证组件 https&#58;//github.com/MetinSeylan/Vue-Easy-Validator” Vue-Easy-Validator-简单的表单验证 https&#58;//github.com/imcvampire/vue-truncate-filter” vue-truncate-filter-截断字符串的VueJS过滤器 https&#58;//github.com/vue-comps/vue-zoombox” vue-zoombox-一个高级zoombox https&#58;//github.com/syropian/vue-input-autosize” vue-input-autosize-基于内容自动调整文本输入的大小 https&#58;//github.com/yodfz/vue-lazyloadImg” vue-lazyloadImg-图片懒加载插件 服务端 https&#58;//github.com/nuxt/nuxt.js” nuxt.js-用于服务器渲染Vue app的最小化框架 https&#58;//github.com/danmademe/express-vue” express-vue-简单的使用服务器端渲染vue.js https&#58;//github.com/ccforward/vue-ssr” vue-ssr-非常简单的VueJS服务器端渲染模板 https&#58;//github.com/hilongjw/vue-ssr” vue-ssr-结合Express使用Vue2服务端渲染 https&#58;//github.com/leaves4j/vue-easy-renderer” vue-easy-renderer-Nodejs服务端渲染 辅助工具 https&#58;//github.com/MiCottOn/DejaVue” DejaVue-Vuejs可视化及压力测试 https&#58;//github.com/vue-play/vue-play” vue-play-展示Vue组件的最小化框架 https&#58;//github.com/OYsun/vscode-VueHelper” vscode-VueHelper-目前vscode最好的vue代码提示插件 https&#58;//github.com/NetanelBasal/vue-generate-component” vue-generate-component-轻松生成Vue js组件的CLI工具 https&#58;//github.com/xwpongithub/vue-multipage-cli” vue-multipage-cli-简单的多页CLI https&#58;//github.com/MetinSeylan/VuejsStarterKit” VuejsStarterKit-vuejs starter套件 实际开发案例 应用实例 https&#58;//github.com/phanan/koel” koel-基于网络的个人音频流媒体服务 https&#58;//github.com/pagekit/pagekit” pagekit-轻量级的CMS建站系统 https&#58;//github.com/Vuedo/vuedo” vuedo-博客平台 https&#58;//github.com/jackhutu/jackblog-vue” jackblog-vue-个人博客系统 https&#58;//github.com/lzxb/vue-cnode” vue-cnode-重写vue版cnode社区 https&#58;//github.com/ycwalker/CMS-of-Blog” CMS-of-Blog-博客内容管理器 https&#58;//github.com/mrgodhani/rss-reader” rss-reader-简单的rss阅读器 https&#58;//github.com/viko16/vue-ghpages-blog” vue-ghpages-blog-依赖GitHub Pages无需本地生成的静态博客 https&#58;//github.com/wh469012917/swoole-vue-webim” swoole-vue-webim-Web版的聊天应用 https&#58;//github.com/thelinuxlich/vue-dashing-js” vue-dashing-js-nuvo-dashing-js的fork https&#58;//github.com/sapjax/fewords” fewords-功能极其简单的笔记本 https&#58;//github.com/surmon-china/vue-blog” vue-blog-使用Vue2.0 和Vuex的vue-blog Demo示例 https&#58;//github.com/shinygang/Vue-cnodejs” Vue-cnodejs-基于vue重写Cnodejs.org的webapp https&#58;//github.com/javaSwing/NeteaseCloudWebApp” NeteaseCloudWebApp-高仿网易云音乐的webapp https&#58;//github.com/hilongjw/vue-zhihu-daily” vue-zhihu-daily-知乎日报 with Vuejs https&#58;//github.com/useryangtao/vue-wechat” vue-wechat-vue.js开发微信app界面 https&#58;//github.com/lzxb/vue2-demo” vue2-demo-从零构建vue2 + vue-router + vuex 开发环境 https&#58;//github.com/liangxiaojuan/eleme” eleme-高仿饿了么app商家详情 https&#58;//github.com/kenberkeley/vue-demo” vue-demo-vue简易留言板 https&#58;//github.com/zhengguorong/maizuo” maizuo-vue/vuex/redux仿卖座网 https&#58;//github.com/codecasts/spa-starter-kit” spa-starter-kit-单页应用启动套件 https&#58;//github.com/Sioxas/vue-music” vue-music-Vue 音乐搜索播放 https&#58;//github.com/jiakeqi/douban” douban-模仿豆瓣前端 https&#58;//github.com/liangxiaojuan/vue-Meizi” vue-Meizi-vue最新实战项目 https&#58;//github.com/yatessss/zhihudaily-vue” zhihudaily-vue-知乎日报web版 https&#58;//github.com/lavyun/vue-demo-kugou” vue-demo-kugou-vuejs仿写酷狗音乐webapp https&#58;//github.com/SimonZhangITer/VueDemoSellEleme” VueDemoSellEleme-Vue2高仿饿了么外卖平台 https&#58;//github.com/canfoo/vue2.0-taopiaopiao” vue2.0-taopiaopiao-vue2.0与express构建淘票票页面 https&#58;//github.com/jiangjiu/vue-leancloud-blog” vue-leancloud-blog-一个前后端完全分离的单页应用 https&#58;//github.com/yjj5855/node-vue-server-webpack” node-vue-server-webpack-Node.js+Vue.js+webpack快速开发框架 https&#58;//github.com/wendaosanshou/mi-by-vue” mi-by-vue-VueJS仿小米官网 https&#58;//github.com/okoala/vue-fis3” vue-fis3-流行开源工具集成demo https&#58;//github.com/superman66/vue2.x-douban” vue2.x-douban-Vue2实现简易豆瓣电影webApp https&#58;//github.com/ChuckCZC/vue-demo-maizuo” vue-demo-maizuo-使用Vue2全家桶仿制卖座电影 https&#58;//github.com/iHaPBoy/vue-zhihudaily” vue-zhihudaily-知乎日报 Web 版本 https&#58;//github.com/liujians/vue-adminLte-vue-router” vue-adminLte-vue-router-vue和adminLte整合应用 https&#58;//github.com/superman66/vue-axios-github” vue-axios-github-登录拦截登出功能 https&#58;//github.com/pomelo-chuan/Zhihu-Daily-Vue.js” Zhihu-Daily-Vue.js-Vuejs单页网页应用 https&#58;//github.com/rokups/hello-vue-django” hello-vue-django-使用带有Django的vuejs的样板项目 https&#58;//github.com/wszgxa/vue-cnode” vue-cnode-vue单页应用demo https&#58;//github.com/CommanderXL/x-blog” x-blog-开源的个人blog项目 https&#58;//github.com/xrr2016/vue-express-mongodb” vue-express-mongodb-简单的前后端分离案例 https&#58;//github.com/secreter/websocketchat” websocketchat-基于vue和websocket的多人在线聊天室 https&#58;//github.com/beidan/photoShare” photoShare-基于图片分享的社交平台 https&#58;//github.com/cs1707/vue-zhihudaily-2.0” vue-zhihudaily-2.0-使用Vue2.0+vue-router+vuex创建的zhihudaily https&#58;//github.com/lin-xin/notepad” notepad-本地存储的记事本 https&#58;//github.com/elva2596/vueBlog” vueBlog-前后端分离博客 https&#58;//github.com/hql123/vue-ruby-china” vue-ruby-china-VueJS框架搭建的rubychina平台 https&#58;//github.com/littlewin-wang/ZhihuDaily” ZhihuDaily-基于Vue和Nodejs的Web单页应用 https&#58;//github.com/Molunerfinn/vue-koa-demo” vue-koa-demo-使用Vue2和Koa1的全栈demo https&#58;//github.com/vincentSea/vue2.x-Cnode” vue2.x-Cnode-基于vue全家桶的Cnode社区 https&#58;//github.com/shaqihe/life-app-vue” life-app-vue-使用vue2完成多功能集合到小webapp https&#58;//github.com/SidKwok/github-explorer” github-explorer-寻找最有趣的GitHub库 https&#58;//github.com/wenye123/vue-trip” vue-trip-vue2做的出行webapp https&#58;//github.com/albertchan/vue-ssr-boilerplate” vue-ssr-boilerplate-精简版的ofvue-hackernews-2 https&#58;//github.com/nswbmw/vue-bushishiren” vue-bushishiren-不是诗人应用 https&#58;//github.com/peng1992/houtai” houtai-基于vue和Element的后台管理系统 https&#58;//github.com/QRL909109/ios7-vue” ios7-vue-使用vue2.0 vue-router vuex模拟ios7 https&#58;//github.com/tyllo/Framework7-VueJS” Framework7-VueJS-使用移动框架的示例 https&#58;//github.com/BubblyPoker/cnode-vue” cnode-vue-基于vue和vue-router构建的cnodejs web网站SPA https&#58;//github.com/zhoou/vue-cli-multipage-bootstrap” vue-cli-multipage-bootstrap-将vue官方在线示例整合到组件中 https&#58;//github.com/jiananle/vue-cnode” vue-cnode-用 Vue 做的 CNode 官网 https&#58;//github.com/GitaiQAQ/HyaReader” HyaReader-移动友好的阅读器 https&#58;//github.com/xrr2016/zhihu-daily” zhihu-daily-轻松查看知乎日报内容 https&#58;//github.com/Alex-xd/seeMusic” seeMusic-跨平台云音乐播放器 https&#58;//github.com/Damonlw/vue-cnode” vue-cnode-使用cNode社区提供的接口 https&#58;//github.com/moonou/zhihu-daily-vue” zhihu-daily-vue-知乎日报 https&#58;//github.com/sailengsi/sls-vuex2-demo” sls-vuex2-demo-vuex2商城购物车demo https&#58;//github.com/ITCNZ/vue-dropload” vue-dropload-用以测试下拉加载与简单路由 https&#58;//github.com/soulcm/vue-cnode-mobile” vue-cnode-mobile-搭建cnode社区 https&#58;//github.com/fishenal/Vuejs-SalePlatform” Vuejs-SalePlatform-vuejs搭建的售卖平台demo https&#58;//github.com/Halfeld/v-notes” v-notes-简单美观的记事本 https&#58;//github.com/BosNaufal/vue-starter” vue-starter-VueJs项目的简单启动页 https&#58;//github.com/youknowznm/vue-memo” vue-memo-用 vue写的记事本应用 转载来源：史上最全vue组件库！极速围观 - 今日头条]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>编程语言</tag>
        <tag>GitHub</tag>
        <tag>文本编辑器</tag>
        <tag>WebApp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用Python入门不明觉厉的马尔可夫链蒙特卡罗（附案例代码） - 今日头条]]></title>
    <url>%2F2018%2F78666272%2F</url>
    <content type="text"><![CDATA[大数据文摘作品编译：Niki、张南星、Shan LIU、Aileen这篇文章让小白也能读懂什么是人们常说的Markov Chain Monte Carlo。 大数据文摘作品 编译：Niki、张南星、Shan LIU、Aileen 这篇文章让小白也能读懂什么是人们常说的Markov Chain Monte Carlo。 在过去几个月里，我在数据科学的世界里反复遇到一个词：马尔可夫链蒙特卡洛（Markov Chain Monte Carlo , MCMC）。在我的研究室、podcast和文章里，每每遇到这个词我都会“不明觉厉”地点点头，觉得这个算法听起来很酷，但每次听人提起也只是有个模模糊糊的概念。 我屡次尝试学习MCMC和贝叶斯推论，而一拿起书，又很快就放弃了。无奈之下，我选择了学习任何新东西最佳的方法：应用到一个实际问题中。 通过使用一些我曾试图分析的睡眠数据和一本实操类的、基于应用教学的书（《写给开发者的贝叶斯方法》，我最终通过一个实际项目搞明白了MCMC。 《写给开发者的贝叶斯方法》 https&#58;//github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers 和学习其他东西一样，当我把这些技术性的概念应用于一个实际问题中而不是单纯地通过看书去了解这些抽象概念，我更容易理解这些知识，并且更享受学习的过程。 这篇文章介绍了马尔可夫链蒙特卡洛在Python中入门级的应用操作，这个实际应用最终也使我学会使用这个强大的建模分析工具。 此项目全部的代码和数据： https&#58;//github.com/WillKoehrsen/ai-projects/blob/master/bayesian/bayesian_inference.ipynb 这篇文章侧重于应用和结果，因此很多知识点只会粗浅的介绍，但对于那些想了解更多知识的读者，在文章也尝试提供了一些学习链接。 案例简介 我的智能手环在我入睡和起床时会根据心率和运动进行记录。它不是100%准确的，但现实世界中的数据永远不可能是完美的，不过我们依然可以运用正确的模型从这些噪声数据提取出有价值的信息。 典型睡眠数据 这个项目的目的在于运用睡眠数据建立一个能够确立睡眠相对于时间的后验分布模型。由于时间是个连续变量，我们无法知道后验分布的具体表达式，因此我们转向能够近似后验分布的算法，比如马尔可夫链蒙特卡洛（MCMC）。 选择一个概率分布 在我们开始MCMC之前，我们需要为睡眠的后验分布模型选择一个合适的函数。一种简单的做法是观察数据所呈现的图像。下图呈现了当我入睡时时间函数的数据分布。 睡眠数据 每个数据点用一个点来表示，点的密度展现了在固定时刻的观测个数。我的智能手表只记录我入睡的那个时刻，因此为了扩展数据，我在每分钟的两端添加了数据点。如果我的手表记录我在晚上10：05入睡，那么所有在此之前的时间点被记为0（醒着），所有在此之后的时间点记为1（睡着）。这样一来，原本大约60夜的观察量被扩展成11340个数据点。 可以看到我趋向于在10：00后几分钟入睡，但我们希望建立一个把从醒到入睡的转变用概率进行表达的模型。我们可以用一个简单的阶梯函数作为模型，在一个精确时间点从醒着（0）变到入睡（1），但这不能代表数据中的不确定性。 我不会每天在同一时间入睡，因此我们需要一个能够模拟出这个个渐变过程的函数来展现变化当中的差异性。在现有数据下最好的选择是logistic函数，在0到1之前平滑地移动。下面这个公式是睡眠状态相对时间的概率分布，也是一个logistic公式。 在这里，β (beta) 和 α (alpha) 是模型的参数，我们只能通过MCMC去模拟它们的值。下面展示了一个参数变化的logistic函数。 一个logistic函数能够很好的拟合数据，因为在logistic函数中入睡的概率在逐渐改变，捕捉了我睡眠模式的变化性。我们希望能够带入一个具体的时间t到函数中，从而得到一个在0到1之间的睡眠状态的概率分布。我们并不会直接得到我是否在10：00睡着了的准确答案，而是一个概率。创建这个模型，我们通过数据和马尔可夫链蒙特卡洛去寻找最优的alpha和beta系数估计。 马尔可夫链蒙特卡洛 马尔可夫链蒙特卡罗是一组从概率分布中抽样，从而建立最近似原分布的函数的方法。因为我们不能直接去计算logistic分布，所以我们为系数(alpha 和 beta)生成成千上万的数值-被称为样本-去建立分布的一个模拟。MCMC背后的基本思想就是当我们生成越多的样本，我们的模拟就更近似于真实的分布。 马尔可夫链蒙特卡洛由两部分组成。蒙特卡洛代表运用重复随机的样本来获取一个准确答案的一种模拟方法。蒙特卡洛可以被看做大量重复性的实验，每次更改变量的值并观察结果。通过选择随机的数值，我们可以在系数的范围空间，也就是变量可取值的范围，更大比例地探索。下图展示了在我们的问题中，一个使用高斯分布作为先验的系数空间。 能够清楚地看到我们不能在这些图中一一找出单个的点，但通过在更高概率的区域（红色）进行随机抽样，我们就能够建立最近似的模型。 马尔可夫链（Markov Chain） 马尔可夫链是一个“下个状态值只取决于当前状态”的过程。（在这里，一个状态指代当前时间系数的数值分配）。一个马尔可夫链是“健忘”的，因为如何到达当前状态并不要紧，只有当前的状态值是关键。如果这有些难以理解的话，让我们来设想一个每天都会经历的情景–天气。 如果我们希望预测明天的天气，那么仅仅使用今天的天气状况我们就能够得到一个较为合理的预测。如果今天下雪，我们可以观测有关下雪后第二天天气的历史数据去预测明天各种天气状况的可能性。马尔可夫链的定义就是我们不需要知道一个过程中的全部历史状态去预测下一节点的状态，这种近似在许多现实问题中都很有用。 把马尔可夫链（Markov Chain）和蒙特卡洛（Monte Carlo），两者放到一起，就有了MCMC。MCMC是一种基于当前值，重复为概率分布系数抽取随机数值的方法。每个样本都是随机的，但是数值的选择也受当前值和系数先验分布的影响。MCMC可以被看做是一个最终趋于真实分布的随机游走。 为了能够抽取alpha 和 beta的随机值，我们需要为每个系数假设一个先验分布。因为我们没有对于这两个系数的任何假设，我们可以使用正太分布作为先验。正太分布，也称高斯分布，是由均值（展示数据分布），和方差（展示离散性）来定义的。下图展示了多个不同均值和离散型的正态分布。 具体的MCMC算法被称作Metropolis Hastings。为了连接我们的观察数据到模型中，每次一组随机值被抽取，算法将把它们与数据进行比较。一旦它们与数据不吻合（在这里我简化了一部分内容），这些值就会被舍弃，模型将停留在当前的状态值。 如果这些随机值与数据吻合，那么这些值就被接纳为各个系数新的值，成为当前的状态值。这个过程会有一个提前设置好的迭代次数，次数越多，模型的精确度也就越高。 把上面介绍的整合到一起，就能得到在我们的问题中所需进行的最基本的MCMC步骤： 为logistic函数的系数alpha 和beta选择初始值。- 基于当前状态值随机分配给alpha 和beta新的值。- 检查新的随机值是否与观察数据吻合。如果不是，舍弃掉这个值，并回到上一状态值。如果吻合，接受这个新的值作为当前状态值。- 重复步骤2和3（重复次数提前设置好）。- 这个算法会给出所有它所生成的alpha 和beta值。我们可以用这些值的平均数作为alpha 和beta在logistic函数中可能性最大的终值。MCMC不会返回“真实”的数值，而是函数分布的近似值。睡眠状态概率分布的最终模型将会是以alph和beta均值作为系数的logistic函数。基于当前状态值随机分配给alpha 和beta新的值。 重复步骤2和3（重复次数提前设置好）。 Python实施 我再三思考模拟上面提到的细节，最终我开始用Python将它们变成现实。观察一手的结果会比阅读别人的经验贴有帮助得多。想要在Python中实施MCMC，我们需要用到PyMC3贝叶斯**库，**它省略了很多细节，方便我们创建模型，避免迷失在理论之中。 通过下面的这些代码可以创建完整的模型，其中包含了参数alpha 、beta、概率p以及观测值observed，step变量是指特定的算法，sleep_trace包含了模型创建的所有参数值。 为了更直观地展现代码运行的效果，我们可以看一下模型运行时alpha和beta生成的值。 这些图叫做轨迹图，可以看到每个状态都与其历史状态相关，即马尔可夫链；同时每个值剧烈波动，即蒙特卡洛抽样。 使用MCMC时，常常需要放弃轨迹图中90%的值。这个算法并不能立即展现真实的分布情况，最初生成的值往往是不准确的。随着算法的运行，后产生的参数值才是我们真正需要用来建模的值。我使用了一万个样本，放弃了前50%的值，但真正在行业中应用时，样本量可达成千上万个、甚至上百万个。 通过足够多的迭代，MCMC逐渐趋近于真实的值，但是估算收敛性并不容易。这篇文章中并不会涉及到具体的估算方法（方法之一就是计算轨迹的自我相关性），但是这是得到最准确结果的必要条件。PyMC3的函数能够评估模型的质量，包括对轨迹、自相关图的评估。 轨迹图（左）和自相关性图（右） 睡眠模型 建模、模型运行完成后，该最终结果上场了。我们将使用最终的5000个alpha和beta值作为参数的可能值，最终创建了一个单曲线来展现事后睡眠概率： 基于5000个样本的睡眠概率分布 这个模型能够很好的代表样本数据，并且展现了我睡眠模式的内在变异性。这个模型给出的答案并不是简单的“是”或“否”，而是给我们一个概率。举个例子，我们可以通过这个模型找出我在特定时间点睡觉的概率，或是找出我睡觉概率超过50%的时间点： 虽然我希望在晚上10点入睡，但很明显大多时候并不是这样。我们可以看到，平均来看，我的就寝时刻是在晚上10&#58;14。 这些值是基于样本数据的最有可能值，但这些概率值都有一定的不确定性，因为模型本身就是近似的。为了展现这种不确定性，我们可以使用所有的alpha、beta值来估计某个时间点的睡觉概率，而不是使用平均值，并且把这些概率值展现在图中。 晚上10&#58;00睡觉的概率分布 这些结果能够更好地展现MCMC模型真正在做的事情，即它并不是在寻找单一的答案，而是一系列可能值。贝叶斯推论在现实世界中非常有用，因为它是对概率进行了预测。我们可以说存在一个最可能的答案，但其实更准确的回复应当是：每个预测都有一系列的可能值。 起床模型 同样我可以用我的起床数据创建类似的模型。我希望能够在闹钟的帮助下总能在早上6&#58;00起床，但实际上并不如此。下面这张图展现了基于观测值我起床的最终模型： 基于5000个样本的起床事后概率 可以通过模型得出我在某个特定时间起床的概率，以及我最有可能起床的时间： 看来我需要一个更生猛的闹钟了…. 睡眠的时间 出于好奇以及实践需求，最后我想创建的模型是我的睡眠时间模型。首先，我们需要寻找到一个描述数据分布的函数。事先，我认为应该是正态函数，但无论如何我们需要用数据来证明。 睡眠时间长短分布 正态分布的确能够解释大部分数据，但是图中右侧的异常值却无法得到解释（当我睡懒觉的时候）。我们可以用两个单独的正态分布来代表两种模式，但我要用偏态分布。偏态分布有三个参数：平均值、偏离值，以及alpha倾斜值。这三个参数的值都需要从MCMC算法中得到。下面的代码创建了模型，并且使用了Metropolis Hastings抽样。 现在，我们可以使用三个参数的平均值来建立最有可能的分布模型了。下图为基于数据的最终偏态分布模型。 时长模型 模型看上去很完美！通过模型可以找出我至少睡多长时长的可能性，以及我最经常的睡觉时长： 结论 我想再次强调，完成这个项目让我体会到解决问题的重要性，尤其是有现实应用意义的项目！在我尝试使用马尔可夫链蒙特卡洛来端到端建立贝叶斯推论的时候，我重新熟悉了许多基础知识，并且非常享受这个过程。 我不仅了解到自身需要改进的习惯，而且当别人在谈论MCMC和贝叶斯推论时，我终于真的明白他们在谈论什么了！数据科学正是关于持续不断地在你自己的知识库中输入新的工具，而这最有效的办法就是发现一个问题，然后应用你所学的去解决问题！ 原文链接： https&#58;//towardsdatascience.com/markov-chain-monte-carlo-in-python-44f7e609be98 转载来源：用Python入门不明觉厉的马尔可夫链蒙特卡罗（附案例代码） - 今日头条]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>睡眠</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文读懂CNN如何用于NLP - 为程序员服务]]></title>
    <url>%2F2018%2Ffe7b6758%2F</url>
    <content type="text"><![CDATA[一文读懂CNN如何用于NLP - 为程序员服务 一文读懂CNN如何用于NLP - 为程序员服务 转载来源：一文读懂CNN如何用于NLP - 为程序员服务]]></content>
  </entry>
  <entry>
    <title><![CDATA[兔妈妈把土抛开，地下钻出一群兔宝宝，好有爱啊！ - 今日头条]]></title>
    <url>%2F2018%2F7bae2e03%2F</url>
    <content type="text"><![CDATA[兔妈妈把土抛开，地下钻出一群兔宝宝，好有爱啊！ 转载来源：兔妈妈把土抛开，地下钻出一群兔宝宝，好有爱啊！ - 今日头条]]></content>
      <categories>
        <category>视频</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[左晖“进化论”：贝壳或将淘汰链家？ - 今日头条]]></title>
    <url>%2F2018%2F63e52723%2F</url>
    <content type="text"><![CDATA[4月底在成都闭门举行的一场地产公司董事长年会上，万科董事局主席郁亮、万科创始人王石、原华远地产集团董事长任志强等房企老总坐在台下，台上的链家集团董事长左晖抛出了一个观点。 运动员能当裁判员吗？ 4月底在成都闭门举行的一场地产公司董事长年会上，万科董事局主席郁亮、万科创始人王石、原华远地产集团董事长任志强等房企老总坐在台下，台上的链家集团董事长左晖抛出了一个观点：理论上中国城镇人口的住宅问题，已经基本得到解决。 言下之意，盖房子已经不再是中国房地产行业的主题。这不是左晖第一次当着一众房企老板的面看空新房交易市场。他的底气来自于链家在存量房租赁及交易市场上庞大的交易额规模。 根据链家研究院披露的数据，链家网GMV（Gross Merchandise Volume,网站成交金额）在2016年、2017年均超过万亿元人民币，跟电商巨头相比，这一数据接近京东，仅次于阿里巴巴。 2001年，链家地产的第一家门店创立于北京，30岁的左晖还是北漂租房一族；2018年，链家已经入驻全国36城，开店8000余家，下辖经纪人超过20万，集团公司估值逾400亿元，左晖个人持股对价超过150亿元。 靠保险销售赚到第一桶金的左晖，在链家将满18岁这一年，出人意料地开始了另一场“冒险”——转型做平台。2018年4月底，他忙于在链家集团内部推动一场自上而下、全员参与的二次创业。 据时间财经了解，多名链家高管被抽调至线上新平台“贝壳找房”，链家城市级管理人员则被提拔为区省级，部分链家直营店的基层经纪人逐渐向集团旗下负责加盟业务的德佑地产流转。 左晖似乎正在“分解”链家：高管去了贝壳，基层经纪人去了德佑。链家集团CFO魏勇几乎是唯一不受影响的核心高管，他向时间财经介绍，他仍在集团负责链家的财务，分管金融业务，但对公司上市对赌的传闻未予置评，“上市的事还是以左总的表态为准。”时间财经发现，此前拨通过的左晖的电话号码被呼叫转移到公关秘书的手机上。 取代链家网、囊括链家核心人力资源，“贝壳找房”要做什么？ 德佑地产的COO祁世钊是集团人事巨变后第一个对外发声的链家核心高管。他对媒体表示，58实际是信息发布平台，贝壳不止有信息发布，还要能形成闭环。 早在“贝壳找房”上线之前，左晖已将链家定义为“互联网公司”。但房产经纪行业市盈率PE的平均水平能容下400亿元的庞大链家吗？更何况，贝壳找房要精准找到对手和朋友也非易事。在这种情况下，左晖对链家进行手术刀式的改革又有多少胜算？ 转型先兆？“撤店了，但我还在链家，我们之间的委托合同还是有效的。”2018年春节假期过后，来自河南的房产经纪人马小凤接到了多位老客户的电话，她没有返回北京五环外北苑中街的链家门店上班，这家营业部被关闭，取而代之入驻的是一家不知名的小中介。 北京热点租房区域集中在五环外，第三方数据监测机构“林克艾普”在2017年11月公布的数据显示，立水桥－北苑是北京租房客最为集中的区域，12.87%的北京租客在此居住。同时，这一区域也是北京二手房交易热点楼盘的集中区。 但时间财经走访发现，2017年9月至今，链家至少已经关闭了该热点区域的3家门店，将员工分流到临近的门店。在北京，一些被关闭的链家门店紧接着由竞争对手“抢驻”。其中，不乏麦田房产、我爱我家这类直接竞争者。 链家罕见收缩的消息早前就不翼而飞。2017年年中，网络上流传链家在北京将关店300家，上海、成都、重庆等地链家关店、员工离职潮的消息。链家官方回应称，北京关店数量是87家，目的是优化店面管理。 本能的疑问是，扩张时期经过咨询论证后精准选址的链家门店，有的已经精耕周边社区多年。左晖为什么要主动让出链家的部分地盘？ 最直接的原因是二手房交易行情下行的大趋势。2017年楼市在调控强监管政策下，全国多个大中城市出台了被称为史上最强、最严的限购、限贷政策，这导致二手房交易量持续萎缩，中介公司和经纪人进入行业“寒冬”，一线城市正是链家直营门店布局的重点。 以北京为例，据云房网数据显示，2017年3月17日“认房又认贷”等一系列调控政策发布后，活跃中介机构（指当月有二手住宅成交记录的中介机构）数量一路走跌，10月最低仅为246家。2018年略有反弹，但3月也仅有281家，去年同期的数字则是523家。 存量房租赁和交易市场中还隐藏着太多不确定性。除了政策变化，互联网端口费的提价也是动态风险之一。2018年一季度，58集团单方面宣布提高房源线上端口费，引发链家、我爱我家、麦田房产等多家中介公司的联合抵制。北京链家最为激进，一度下架了其在58同城和安居客上的所有房源。 这不是58系第一次单方面涨价，其在存量房线上交易流量上具有一定的垄断定价权。我爱我家副总裁胡景晖曾对时间财经表示，我爱我家端口投放的60%-70%都在58集团，麦田房产可能也高达60%，链家相对较小一些。 时间财经此前曾独家报道（详情见《58系向房产中介联盟妥协 房源端口费大提价落空》），58集团向中介联盟妥协，涨价计划最终落空。但市场占有率如链家这般稳固，也难以获得线上端口费的议价权。8000家门店、20万经纪人——链家拥有中介市场上规模最庞大的线下团队，这也意味着日费斗金且仍将持续上涨的经营成本。 还有一个容易被忽略的问题，链家集团并购德佑地产、入股21世纪不动产等多家中介公司，链家网被定义为开放平台，其线上房源端口供所有链家系中介共享，这直接影响了链家直营店经纪人的收入。 “链家旗下经纪人代理同一个小区的房源，但别的中介佣金比链家直营要低，客户就流失到他们那边了。”在北京链家工作五年多的马小凤向时间财经抱怨，“从集团的角度可能是多赚了一些，但对链家直营的经纪人来说很不公平。” 这种内部竞争的利弊也是左晖必须权衡的问题。一位接近链家决策层的人士告诉时间财经，左晖的态度越来越决绝，“他传递给外界的信息是，链家不能停在中介公司层面，非做平台不可了。” 四面树敌 2018年5月5日，左晖在一场创业者闭门课堂上发表演讲时表示，链家与同行早已不在一个时代。两周后的5月18日，链家集团召开战略会议，宣布了一系列堪称“动荡”的重大人事调整。 4月刚刚成立的新平台“贝壳找房”被定义为链家集团的战略核心，链家集团CEO彭永东同时担任贝壳找房CEO，原成都链家总经理徐万刚担任贝壳找房大中华北区COO，原深圳链家总经理张海明担任贝壳大中华南区COO。 时间财经了解到，在集团层面，链家网的技术团队也转移到贝壳体系，左晖一向看重的校园招聘业务也将在2019年转到贝壳体系。在分公司层面，链家直营的城市经理调任到贝壳城市经理，直营管理层出现大量岗位空缺，一部分区域、门店经理得以晋升。 落到具体的目标数字上，左晖更是野心勃勃。据4月23日贝壳找房上线发布会上彭永东的介绍，贝壳找房将覆盖全中国超过300个城市，服务超过2亿的社区家庭，连接100万职业经纪人和10万家门店，赋能超过100个品牌，规模将数倍于目前的链家。 必须要提醒的是，没有上市时间表是左晖一贯的表态。纵观资本市场，房产经纪公司的估值普遍较低，这也是链家不急于IPO而急于转型互联网平台的背景之一。 时间财经梳理市场公开数据发现，A股市场的房产经纪公司中，我爱我家2017年借助昆百大A登陆A股时市盈率PE是13.1倍，世联行在2017年的平均市盈率PE是26.35倍；美股市场上，类似链家、我爱我家的房产经纪公司Redfin市盈率PE仅为9.57倍。 由链家直营转向贝壳开放平台的“高管大挪移”公开后，留在上海掌管德佑地产的祁世钊是第一个公开发声的链家核心人物。他曾表示，贝壳不只是要做类似58系的信息发布平台，更希望做服务平台，形成闭环。整体战略角度看，链家和德佑都是商户，都将入驻贝壳平台。 对于左晖力推的贝壳平台，市场上成熟的房产经纪平台型公司反应各不相同。 有传闻称，58集团旗下安居客成立“打贝办”，他们警告中介经纪人：安居客的房源一旦在贝壳找房出现，将进行下架处理。但安居客方面对时间财经否认了这一消息。 老对手搜房网尚未对“贝壳找房”形成警惕感和危机感。一位不愿具名的搜房网高管为时间财经找出了一张链家集团在2014年发布的声明。声明称，北京链家全面终止同搜房网的合作，理由之一是搜房网已经变成一家中介公司，已经把原部分端口销售团队转为经纪人并开始在各经纪公司挖人，成为链家的竞争对手。 “当初做平台的搜房网去做中介，链家反对。如今做中介的链家去搞开放平台，其他中介会支持？”中原地产首席分析师张大伟对时间财经说：“既要当运动员，又要当裁判员，行业内很难获得接受和认可。” 谁的贝壳？ 更令人担忧的是，无论“贝壳”成败与否，链家直营或将不复存在。 时间财经从贝壳找房试点城市郑州了解到，按照最新的收益分配模式，链家独家采集归纳的真房源楼盘字典被共享，所有房源在贝壳平台对所有经纪人开放，经纪人得到房源的委托、对房源的拍照、对客户的吸纳、提供成交后的服务都会形成相应业绩，系统会将最终成交经纪人佣金中的对应部分划归到不同的贡献人账户。 尽管这一模式具有行业创新性和颠覆性，但对于马小凤这样链家直营店的经纪人，此前的竞争优势荡然无存。“如果是这样的模式，我不会再做直营，还不如到其他中介，起码要去有底薪的地方。”马小凤说。 她只是这样想，一些同行已经这样做了。时间财经了解到，链家直营面临瓦解的风险，长三角一线城市的链家直营经纪人已经有部分转到德佑加盟店甚至自办中介公司，下沉到二三线城市。也就是说，左晖或将面临一个尴尬的局面：无论贝壳成败，链家直营都有可能不复存在。 部分业内人士表示，贝壳体系的意图之一是让链家同化甚至兼并小型房产中介公司，增加市场占有率以达到垄断地位。但我爱我家集团董事长谢勇此前曾公开表示，综合全国来看，头部公司能占到20%就已经很不错了，这个行业太过分散。目前全国最大的链家只占了10个点，单个城市的行业集中度可能出现了三分天下、五分天下，但是头部公司也只占到50%。“还有大量的夫妻店存在，开在社区门口，你不可能把这些门店消灭掉。” 时间财经了解到，尽管贝壳找房目前不收取线上端口费，但我爱我家、中原地产、麦田房产等多家连锁型房产中介公司都暂时没有将房源上传至贝壳的计划。普遍的疑虑大致集中在：链家系和非链家系的经纪人是否将被区别对待？贝壳究竟是谁的贝壳？ 谁的贝壳？这一问题在链家集团组织架构方面也同样扑朔迷离。工商登记信息显示，“贝壳找房”官方网站的注册主体公司是天津小屋信息科技有限公司，与链家网、德佑地产、链家地产等链家集团的子公司不同的是，这是一家注册成立于2017年11月的初创企业，左晖持股94.38%，链家联合创始人单一刚持股5.62%。与注册主体相反，贝壳找房的员工合同仍在链家地产或链家网一边，尚未转签。 链家IPO后与贝壳重组，还是两者分拆独立上市？目前仍是未知。唯一可以确定是，集团董事会上，面对融创中国的孙宏斌、万科的刘肖、华兴资本的包凡甚至是腾讯的马化腾以及百度的李彦宏，左晖和他的管理层持股团队仍然掌握话语权。穿透股权结构，左晖直接及间接对链家集团的持股接近50%。 吸纳来自万科、融创等股东的B轮融资之后，早期投资左晖和链家的财务投资人已经基本套现退出。时间财经获得的一份链家地产B轮融资计划书显示，2016年4月的这轮融资中，老股转让28.8亿元，占比为45%。鼎晖资本和复兴集团的押注获得了回报，不差钱的左晖是否选对了链家未来发展壮大的战略股东呢？ 事实上，链家获得股东们的战略资源支持并不多。目前，链家与股东之间最为直接的战略合作是，京东金融的白条租房与链家的自如公寓打通，租客可以申请分期付款。不过，一位前京东金融高管告诉时间财经，自如寓和京东金融的合作不具备同业排他性，“京东白条本身是一个开放的金融场景，与多家长租公寓运营商都有合作。” 值得一提是，作为链家战略股东之一的腾讯只给了资金，并未提供核心资源。 当左晖选择腾讯投资的那一刻，也就意味着他站在了阿里的对面——目前，支付宝的信用租房平台已经进入南京、上海、北京、深圳、杭州、成都、西安、郑州八个城市，主打真房源、免押金和房租月付。 从美股市场私有化的易居中国则可能成为贝壳找房的最直接竞争对手。该公司看重房产交易市场，已经启动“易居房友”项目，目标是做聚拢经纪人的基础交易平台。 颇具玩味的是，易居中国成为贝壳的对手，那也意味着左晖当初没有吸纳的这些缺乏互联网基因的股东，将成为竞争对手的强大后盾。时间财经了解到，2016年5月，包括恒大在的多家房企都曾表达了参投链家B轮融资的意向，左晖最终只选择了万科和融创。在链家之后启动融资的易居中国拿到了恒大、碧桂园、富力地产等24家头部开发商的战投。 内忧外患之中，左晖能否顺利完成这场链家历史上最大规模的变革？时间将给出答案。（北京时间财经 岳嘉） 转载来源：左晖“进化论”：贝壳或将淘汰链家？ - 今日头条]]></content>
      <categories>
        <category>房产</category>
      </categories>
      <tags>
        <tag>购房</tag>
        <tag>华远地产</tag>
        <tag>我爱我家</tag>
        <tag>链家地产</tag>
        <tag>二手房</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[老司机回答药品到底能卖多少的相关问题]]></title>
    <url>%2F2018%2F5c4069d3%2F</url>
    <content type="text"><![CDATA[医药魔方 转载来源：老司机回答药品到底能卖多少的相关问题]]></content>
      <tags>
        <tag>医药魔方数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI寒冬将至？「人工智能衰退论」再起，却遭LeCun怒斥 - 今日头条]]></title>
    <url>%2F2018%2F2876e19b%2F</url>
    <content type="text"><![CDATA[如GeoffHinton、吴恩达、YanLeCun、李飞飞、GaryMarcus等，并以「谷歌、Facebook等公司对AI的研究兴趣正在衰退」作为论据。 《AI Winter is Well on its Way》是计算机视觉和 AI 领域专家 Filip Piekniewski 所写的一篇文章，文中提到了很多深度学习顶级研究者的观点，如 Geoff Hinton、吴恩达、Yan LeCun、李飞飞、Gary Marcus 等，并以「谷歌、Facebook 等公司对 AI 的研究兴趣正在衰退」作为论据。本文主要涉及「深度学习蒙尘」、对深度学习扩展能力和自动驾驶的讨论、对该领域炒作的批判，最终结论是 AI 寒冬必将到来。对此，Yann LeCun 认为这篇文章「very uninformed」，并列出了几点理由。 近日，一篇名为《AI Winter is Well on its Way》的文章刷屏了（嗯哼，即将刷屏，微笑），对此 Yan Lecun 的评价是： 这篇文章非常无知。Facebook、谷歌、微软等企业近期增加了他们在 AI 方面的努力。Facebook 现在拥有一个专注于 AI 研究的大型组织，还有人工智能副总裁。微软事业部的名称里就有「AI」（而没有提到「Windows」或「Office」）。谷歌将其整个研究组织重命名为「Google AI」。这三家公司在雇佣 AI 科学家和工程师方面一直在加速。目前来看并没有平台期或者减速现象。 《AI Winter is Well on its Way》究竟在讲什么呢？机器之心对该文章进行了编译介绍： 近几年来，深度学习一直处于所谓「人工智能革命」的前沿，许多人认为，正是这颗银色的子弹将把我们带到技术奇点的神奇世界（通用人工智能）。很多企业在 2014、2015 和 2016 年进行了多次押注，当时人工智能还有一些新的进展，如 AlphaGo 等。特斯拉等公司宣布，人类距离全自动驾驶汽车已近在咫尺，特斯拉甚至已经开始向客户推销这一概念，以便未来的软件更新能够将其实现。 现在已到 2018 年中，情况已经发生了变化，虽然表面上还看不出来。NIPS 会议仍被过度炒作，企业公关的新闻稿中仍然充斥着人工智能，马斯克依然承诺制造自动驾驶汽车，谷歌 CEO 不断重复吴恩达的口号——「人工智能的影响大于电力」（AI is bigger than electricity）。但这种表述开始出现漏洞。正如我在之前的文章（https&#58;//blog.piekniewski.info/2016/11/15/ai-and-the-ludic-fallacy/）中所预测的那样，最明显的漏洞是自动驾驶这一技术在现实世界中的实际应用。 深度学习蒙尘 当 ImageNet 问题得到有效解决（注意，这并不意味着视觉问题得到解决），该领域的许多著名研究人员（甚至包括一贯低调的 Geoff Hinton）都在积极地接受新闻采访，在社交媒体上发表文章（如 Yann LeCun、吴恩达、李飞飞）。总的来说，我们正面临着一场巨大的革命，从现在开始，一切只能加速。几年过去，这些人的 Twitter feeds 变得不那么活跃了，以吴恩达的 Twtter 为例： 2013 年：每天 0.413 条推文2014 年：每天 0.605 条推文2015 年：每天 0.320 条推文2016 年：每天 0.802 条推文2017 年：每天 0.668 条推文2018 年：每天 0.263 条推文（截至 5 月 24 日） 或许这是因为吴恩达骇人的主张现在受到了社区更多的审视，如以下推文所示： 很明显，人气已经大幅下滑，称赞深度学习是终极算法的推特少之又少，论文不再那么具有颠覆性，而是被视为一种发展演变。自从发布 AlphaGo Zero 以后，DeepMind 再也没有什么突破性进展，即使是 AlphaGo Zero 也没有那么令人兴奋，因为只需要大量的计算，而且只适用于游戏（参见莫拉维克悖论）。OpenAI 相当安静，他们最后一篇爆款文章是《Dota 2》（我想这一突破应该会像 AlphaGo 一样引起轰动，但却很快就销声匿迹了）。实际上，有文章甚至称谷歌也不知道该如何处理 DeepMind，因为它们的结果显然不像原来预期的那样实际……著名的研究人员一般都是去加拿大或法国与政府官员会面，以争取未来的资助，Yann LeCun 甚至从 Facebook 研究负责人的位置退了下来，成为首席人工智能科学家（颇具象征意义）。从有钱的大公司到政府资助机构的逐渐转变让我觉得，其实这些公司（我想到了谷歌和 Facebook）对这类研究的兴趣正在慢慢消退。这些都是早期的迹象，他们没有大声说出来，只给出了肢体语言。 深度学习（并没有）扩展 其中一个关键口号是不停重复说「深度学习几乎可以毫不费力地实现扩展」。2012 年 AlexNet 出现，拥有大约 6 千万参数，那么现在我们的模型或许具备至少 1000 倍的参数吧？或许是的，但是问题在于：性能也是之前的 1000 倍吗？或者 100 倍？OpenAI 的一项研究显示： 在视觉应用领域，我们可以看到 VGG 和 ResNet 在计算资源到达一定数量级之后逐渐饱和（参数数量实际上减少了）。Xception 是谷歌 Inception 架构的变体，事实上它在 ImageNet 数据集上的性能仅比 Inception 好一点点，也只是稍微优于其他模型，因为 AlexNet 本质上解决了 ImageNet 问题。那么即使我们使用的计算量是 AlexNet 的 100 倍，我们得到的也是饱和的架构，不论是视觉模型还是图像分类。神经机器翻译是所有网络搜索公司都参与的一次大型「战役」，也无怪乎它使用了能使用的所有计算资源（尽管 Google Translate 效果比之前好了一些，但仍然不够优秀）。上图的最后三个点非常有趣地展示了强化学习相关项目，它们被应用于 DeepMind 和 OpenAI 的游戏中。尤其是 AlphaGo Zero 和更通用的 AlphaZero 耗费的计算量大到荒谬，而且无法在现实应用中使用，因为相当一部分计算量用在了模拟和生成数据上，此类模型需要大量数据。那么我们现在可以在几分钟内训练 AlexNet，而不用花费数天时间，但是我们可以在几天时间内训练出 1000 倍大的 AlexNet，并取得更好的性能吗？明显不能…… 事实上，上图原本旨在展示深度学习扩展的优异性，但是却达到了相反的效果。我们无法扩展 AlexNet，并得到更好的结果，我们必须使用特定的架构，且高效额外的计算量在缺乏数量级增长的数据样本的情况下无法带来较大的性能改进，而这么多数据只有在模拟游戏环境中才能获得。 自动驾驶车祸 目前对深度学习最大力的鼓吹在自驾汽车领域（我曾在很长时间内对此有所期待）。起初，人们认为端到端深度学习可以在某种程度上解决这个问题，这也是英伟达曾大肆宣扬的假设。虽然不敢保证，但我不认为这个世界上还有人会相信这个说法。看看去年的加州 DMV 脱离报告中，英伟达的汽车无法在没有脱离的情况下驾驶十公里。2016 年以来发生了好几起特斯拉自动导航引起的事故，有些甚至是致命的。可以认为特斯拉的自动导航不应该和自驾混淆，但至少在核心上它们是依赖于相同的技术。在今天，除了偶尔的特大失误，它仍然无法在十字路口停车、识别交通灯或通过交通环岛。这还是在 2018 年 5 月，在承诺穿越美国东西海岸（coast to coast）的特斯拉自动驾驶旅程（并没有发生，虽然谣言称他们曾尽力尝试，但并不能在没有约 30 次脱离的条件下成功）的几个月之后的状况。在几个月前（2018 年 2 月），马斯克在一次电话会议中被问及 coast to coast 自驾时重复道： 「我们本来应该完成穿越东西海岸的自动驾驶行程，但它需要太多的专用代码才能有效地执行，这令其变得脆弱，才能在特定的路径中工作，而不能得到通用的解决方案。因此我认为我们可以在相同的路径下重复使用一个方案，但却不适用于任何其它路径，这根本不是真正的解决方案…」「神经网络领域的进展令我感到兴奋。它和那些呈指数级增长的技术发展趋势类似，起初并没有什么进展、并没有什么进展… 然后突然间就 Wow~。自驾汽车可能也是这样。」 看看上面那张来自 OpenAI 的图，似乎并没有出现指数级的增长趋势。本质上，以上马斯克的声明应该这样解释：「我们目前并没有能安全实现可以横跨美国的自动驾驶技术，虽然我们可以假装有，如果想的话（可能是这样）。我们非常希望神经网络的能力的指数级增长能很快出现，并把我们从耻辱和大量诉讼中解救出来。」 但目前为止，对 AI 泡沫的最重一击是 Uber 自驾汽车在亚利桑那州撞死行人的事故。从 NTSB 的初步报告中，我们可以看到惊人的论述： 在这份报告中，除了通常的系统设计失败之外，令人惊讶的是它们的系统用了很长的时间来确定它在前面到底看到了什么（那是行人、自行车、汽车，还是别的什么），而不是在这样的场景中做出唯一符合逻辑的决策，即确保不会撞到前面的事物。有这么几个原因：首先，人们通常使用言语表达来传递事实。因此人类通常会这样说：「我看到了一个骑自行车的人，因此我必须左转来避开他。」而大量的心理物理学文献提出相当不同的解释：人类看到的事物在其神经系统的快速感知回路中被很快地理解为障碍，因此他做出了快速回应来避开障碍，在很长时间后他才意识到发生了什么，并提供言语解释。 我们每天都做出了大量未被言语化的决策，在驾驶过程中就包含很多这样的决策。言语化是很费时费力的，现实中通常没有这样的时间。这些经历了十亿年进化而出现的机制让我们保持安全，而驾驶场景（虽然是现代的）使用了很多这样的反射。由于这些反射不是特定为驾驶而演化的，它们可能导致错误。在汽车里由于被胡蜂蛰而导致的膝跳反射可能导致很多事故和死伤。但我们对三维空间、速度的一般理解，预测智能体行为和出现在我们路径上的物理对象行为的能力是一种本能，在一亿年前也发挥着和当前一样的作用，并在进化过程中得到了充分的磨砺。 但是由于这些能力大部分很难用言辞表达，因此我们很难去衡量它们，也无法基于它们优化机器学习系统。现在这只在英伟达的端到端方法上是可行的：学习图像 → 动作映射，该方法跳过了任何言语表达，某种程度上这是正确的做法，但……问题在于输入空间的维度非常高，而动作空间的维度非常低。因此「标签」的「数量」与输入信息量相比非常小。在这种情况下，很容易学到虚假关系，正如深度学习对抗样本中那样。我们需要一种不同的方法，我假设整个感知输入的预测和动作是使系统抽象出世界语义的第一步，而非虚假关系。 事实上，如果我们从深度学习爆发中学到了什么的话，那就是（10k+ 维度的）图像空间中有足够多的虚假模式，以至于它们能够泛化至很多图像，且给人一种印象，即我们的分类器实际上理解它们所看到的事物。这就是事实，甚至 AI 领域顶级研究者也这么认为（参见论文《Measuring the tendency of CNNs to Learn Surface Statistical Regularities》）。根据我的观察，实际上很多顶级研究者不应该那么愤怒，Yann Lecun 曾经提醒过人们对 AI 的过度兴奋以及 AI 寒冬，即使 Geoffrey Hinton 在一次采访中也承认这可能是个死胡同，我们需要重新再来。现在的炒作太厉害了，甚至没有人听该领域创始人的看法。 Gary Marcus 和他对炒作的反对 我应该提一下意识到这种狂妄并敢于公开发表反对意见的人。其中一个活跃人物就是 Gary Marcus。尽管我并不完全认同他在 AI 方面的观点，但是我们有一点共识，即深度学习现状并不如炒作宣传所描绘的图景那样强大。事实上还差得远。参见《Deep Learning&#58; A Critical Appraisal》和《In defense of skepticism about deep learning》，在文章中他非常细致地解构了深度学习炒作。我非常尊重 Gary，他的行为是一个真正的科学家应该做的，而所谓的「深度学习明星」的行为则是廉价的。 结论 预测 AI 寒冬就像预测股市崩盘一样——你不可能知道它什么时候发生，但这是一个必然事件。就像股市崩盘之前一样，大多数人被宣传冲昏了头脑，忽略了熊市的先兆，即使事实就摆在眼前。在我看来，已经有迹象表明深度学习的衰退已经临近（可能在 AI 方面，现在这个名词已经被公司的宣传滥用了），事实是如此的明显，但由于越来越多的宣传报道，大部分人还毫无预料。这样的寒冬会有多「冷」？我不知道。下一个热点是什么？我也不知道。但我非常清楚变革即将来临，而且很快就会发生。 转载来源：AI寒冬将至？「人工智能衰退论」再起，却遭LeCun怒斥 - 今日头条]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>Facebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Service Worker技术来做一个桥接互联网跟IPFS之间的网关 - 今日头条]]></title>
    <url>%2F2018%2F6ead61ee%2F</url>
    <content type="text"><![CDATA[文因互联的前端&amp;数据工程师林东吴分享主题：ServiceWorker技术来做一个桥接互联网跟IPFS之间的网关。 文因互联的前端&amp;数据工程师 林东吴 分享主题： Service Worker技术来做一个桥接互联网跟IPFS之间的网关。 这个IPFS网关，我们要明确一下它的定义，它是让用户能通过互联网技术来访问IPFS网络上面的资源的一种程序，这张图上是一个我们一般说的一个网关，它是一个反向代理，右边是你的浏览器，你去访问一个网站，比如说文因互联的官网首页，这时候其实浏览器访问是我们的反向代理服务器，就图上这个地方，其实我们真实的服务器是被挡在代理服务器后方的，我们所有的页面资源实际上是存在这个地方，而用户通过这个网关来访问它们。 对于IPFS上的资源我们也是通过类似的方式，可以看到右边有一大串的网址，它们是之前曾经可以使用IPFS网关地址，现在很多都不能用了。这边挡在网关后面的IPFS上的一些一些节点，它们上面有些存储在IPFS上面的数据，那现在你的浏览器在右边，通过互联网访问这个IPFS网关的话，就可以让这个网关去访问挡在后面的IPFS网络，到IPFS网络上去取数据。 现在大家可能都会去使用这个IPFS官方提供的网关，主要原因是因为第三方网关很多都挂掉了，那怎么样才能让世界上有更多这种第三方网关，不让它们一个一个的挂掉，那我们就需要降低第三方维护网关的成本。 Service Worker也是一种网关，只不过这个网关不是运行在服务器上，它是运行在浏览器上。当我们打开这个网页，右边这个可以看做是后端服务器暴露API的地方，那么在后端程序员开发的API服务器和浏览器中间其实还隔了个Service Worker，Service Worker是W3C提出的一个规范，现在大部分浏览器都已经实现了。一般我们可以在设备上面去做一个反向代理服务器，在党在这个我们的浏览器跟API之间，但现在你看，我们可以在这边直接从IPFS网络上取数据，反回给前端。 这就是基于Service Worker的IPFS网关的基本原理，那为什么要做这个Service Worker网关呢？是因为运行在服务器上的网关有这几个缺陷，它很难scale up，比如说你只有一台服务器，那这时候有七八十万个人同时来访问一个爆款资源，都通过你的网关访问，如果它们访问都是不同的文件的话，这时候你你的这个节点就要把一大堆文件，从IPFS网络上都先load到你的服务器上，再通过这个你的网关去传给用户的浏览器，那这时候你这个服务器负载就非常大。 而且如果部署这样的服务器，你必须要有一个能运行够或者JS或者是Go的环境。那这就意味着你服务器配置不能很低，不能运行在一个比如说树莓派或者是ruff这种开发板上面。那当然它有一些好处，比如说它可以pin住一些文件，比如 pin 住一些热点文件，它就可以类似于变成一个静态服务器，可以很快地做一些响应。这是它的好处。 我们就可以想 Service Worker 在浏览器上，而不是运行在服务器上，那如果在浏览器上做的话，真正的服务器只需要是一个静态服务器，它只需要把页面还有一段带有 Service Worker 的JS脚本发送给浏览器，让浏览器来执行，也说服务器本身是不执行任何东西，它只是一个静态服务器，所以说你可以用开发版来做这样的服务器，那唯一的成本你需要买一个https的证书，还有个域名了。 唉当然它有一些坏处，比如说我们在服务器上的网关它可能会有一些缓存机制，那当前这个缓存机制我们还没有在 Service Worker 上开发出来。还有它只能给人类的用户使用，因为 Service Worker 它是一个浏览器上的规范。那如果说你通过一个程序，把它当做一个 REST API ，通过在程序里面写 AJAX 调用的话，那你是取不到东西了，因为 AJAX 调用的时候，你不能运行这个 Service Worker 。 还有一些可能的缺陷，我还没有测试过，有些网页它可能也使用了Service Worker。毕竟 Service Worker 已经是一种被广泛使用的技术，它可以把一个网页，变成一个桌面端的APP。像饿了吗好像在使用这种技术，你在手机上打开网页版饿了吗，会弹出一个提示让你把网页保存到首页，变成一个手机 APP 的应用图标，你再点这个首页上这个图标的话，它并不是打开的网页浏览器，而是打开一个像真的饿了吗 APP 一样的一个东西，叫 PWA 的东西。这种 Progress Web APP 中的核心技术Service Worker，那如果通过 Service Worker IPFS网关来访问饿了吗部署在 IPFS 上的应用，那可能它那就不会正常工作，这个我还没有测试过。因为饿了吗它们还没有把应用部署到IPFS上面…… 这边可以看一下，这个绿色的是已经支持这项技术的浏览器，可以看到大部分的浏览器都是支持的。 那这个网关我来先来说一下它具体的实现原理： 它原理非常简单，主要就分为两个部分，第一部分：你看左边这边是一个人，它通过浏览器来访问这个网址，比如说 ipfsgateway.xyz/ipfs/somehash，它把这个东西输入到浏览器之后访问，而这时候第一步是访问这个网页，它上面带有一个 Service Worker 的 JS 脚本，这个JS脚本就开始安装到它的浏览器上面。 安装完之后，这个脚本就开始就开始启动了一个挡在它的手机和真正互联网之间的代理服务器。就在它手机上面运行的一个小服务器，反正代理服务器。这层代理服务器有两个部分的程序，第一个是有向无环图的这个遍历器，还有一个是各种不同类型文件的解析器。具体的实践原理如下： 我写的这个网关是参考IPFS官方JS网关，只做了一些适配 Service Worker 的改动。如果你是其他区块链项目的开发者，你也可以试着在 Service Worker 这一层去适配你的区块链网络，也就是说这一层可以做古典互联网和其他区块链网络的桥接，这一用法可能是一开始这个提出 Service Worker 这一规范的人都并没有想到的吧。 以上是我今天今天分享的全部内容，谢谢大家的聆听。 转载来源：Service Worker技术来做一个桥接互联网跟IPFS之间的网关 - 今日头条]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>程序员</tag>
        <tag>区块链</tag>
        <tag>脚本语言</tag>
        <tag>WebApp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[送你一张24季私享家礼券，一起买买买]]></title>
    <url>%2F2018%2Fe41484f4%2F</url>
    <content type="text"><![CDATA[送你一张24季私享家礼券，一起买买买 对不起，您访问的页面已被删除或不存在 - 有赞 转载来源：送你一张24季私享家礼券，一起买买买]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ian Goodfellow等提出自注意力GAN，ImageNet图像合成获最优结果]]></title>
    <url>%2F2018%2F1c9b74fc%2F</url>
    <content type="text"><![CDATA[谷歌大脑的IanGoodfellow等人在他们的最新研究中提出“自注意力生成对抗网络”。将自注意力机制引入到卷积GAN中，作为卷积的补充，在ImageNet多类别图像合成任务中取得了最优的结果。 新智元编译 来源：arxiv.org 翻译：肖琴 【新智元导读】图像合成是计算机视觉中的一个重要问题。谷歌大脑的Ian Goodfellow等人在他们的最新研究中提出“自注意力生成对抗网络”（SAGAN），将自注意力机制引入到卷积GAN中，作为卷积的补充，在ImageNet多类别图像合成任务中取得了最优的结果。 论文地址：https&#58;//arxiv.org/pdf/1805.08318.pdf 图像合成（Image synthesis）是计算机视觉中的一个重要问题。随着生成对抗网络（GAN）的出现，这个方向取得了显著进展。基于深度卷积网络的GAN尤其成功。但是，通过仔细检查这些模型生成的样本，可以观察到，在ImageNet这类的有许多图像类别的数据集上训练时，卷积GAN合成的图像不尽如人意。 针对这个问题，谷歌大脑的Ian Goodfellow和Augustus Odena，以及罗格斯大学的Han Zhang和Dimitris Metaxas等人在他们的最新研究中提出“自注意力生成对抗网络”（SAGAN），将自注意力机制（self-attention mechanism）引入到卷积GAN中，作为卷积的补充，取得了最优的结果。 摘要 在这篇论文中，我们提出自注意力生成对抗网络（ Self-Attention Generative Adversarial Network ，SAGAN）。SAGAN允许对图像生成任务进行注意力驱动、长相关性的建模。传统的卷积GAN生成的高分辨率细节仅作为在低分辨率特征图上的空间局部点的函数。在SAGAN中，可以使用来自所有特征位置的线索来生成细节。此外，鉴别器可以检查图像的远端部分的高度详细的特征彼此一致。此外，最近的研究表明，生成器条件会影响GAN的性能。利用这些发现，我们将谱归一化到GAN生成器中，并发现这改进了训练动态。我们提出的SAGAN达到了state-of-the-art的结果，将Inception score从当前最高的36.8提高到52.52，并且在具有挑战性的ImageNet数据集上将Frechet Inception distance从27.62降低到18.65。注意力层的可视化表明，生成器利用与对象形状相对应的邻域，而不是固定形状的局部区域。 SAGAN：将自注意力机制引入GAN 尽管最先进的ImageNet GAN模型 &#91;17&#93; 擅长合成几乎没有结构性限制的图像类别（例如，海洋、天空和景观类，它们的区别更多在于纹理而不是几何结构），但它无法捕获在某些类别中经常出现的几何模式或结构模式（例如，狗通常有逼真的皮毛纹理，但没有明确区分的脚）。 一种可能的解释是，以前的模型严重依赖于卷积来建模不同图像区域之间的依赖关系。由于卷积运算符具有一个局部感受域，所以在经过几个卷积层之后，只能处理长距离的相关性。 由于各种原因，这可能会阻止学习长相关性（long-term dependencies）：小的模型可能无法表示它们，优化算法可能无法发现参数值，这些参数值仔细协调多个层，以捕获这些相关性，并且这些参数化在统计学上可能相当脆弱，当应用于以前未见过的输入时容易失败。增加卷积核的大小可以提高网络的表征能力，但这样做也会失去利用局部卷积结构获得的计算和统计效率。 另一方面，自注意力（Self-attention）可以更好地平衡模型的长相关性和计算与统计效率。self-attention模块以所有位置的特征加权和来计算响应，其中权重（或attention vectors）只以很小的计算成本来计算。 图 1：我们提出的SAGAN通过利用图像远端部分的互补特征来生成图像，而不是固定形状的局部区域，从而可以生成一致的对象/场景。图中每一行的第一个图像显示了带颜色编码点的五个代表性查询位置。其他五个图像是针对这些查询位置的 attention maps，其中对应的颜色编码的箭头概括了最受关注的区域。 在这项工作中，我们提出了自注意力生成对抗网络（SAGAN），它将自注意力机制（self-attention mechanism）引入到卷积GAN中。自注意力模块（self-attention module）是对卷积的补充，有助于模拟跨越图像区域的长距离、多层的依赖关系。通过self-attention，生成器可以绘制图像，所绘制图像中每个位置的精细细节都与图像远端的精细细节充分协调。此外，鉴别器还可以更准确地对全局图像结构执行复杂的几何约束。 图2：所提出的self-attention机制。⊗表示矩阵乘法，在每一行上执行softmax操作 除了self-attention之外，我们还将最近关于网络调节（network conditioning）的见解与GAN的性能结合起来。A. Odena等人的研究&#91;18&#93;表明，调节良好的生成器往往表现更好。我们建议使用以前仅应用于鉴别器的谱归一化技术（spectral normalization）来加强GAN生成器器的调节。 我们在ImageNet数据集上进行了大量的实验，以验证所提出的self-attention机制和稳定技术的有效性。SAGAN在图像合成方面的表现远远超过了state-of-the-art的表现，将此前报告的最高Inception score从36.8提高到52.52，将Fréchet初始距离（Fréchet Inception distance，FID）从27.62降低到18.65。attention层的可视化显示，生成器利用与对象形状相对应的区域，而不是固定形状的局部区域。 ImageNet上的图像合成实验为了评价所提出的方法，我们在LSVRC 2012 （ImageNet）上数据集进行了大量的实验。首先，我们对评估所提出的两种稳定GAN训练的技术进行有效性实验。其次，对所提出的self-attention mechanism进行了研究。最后，将SAGAN与其他state-of-the-art的图像生成方法进行了比较。 评估指标 我们使用Inception score（IS）和Fréchet初始距离（FID）进行定量评估。Inception score越高，表示图像质量越好。 FID是一个更加基于规则和综合性的指标，并且在评估生成的样本的真实性和变异性方面已被证明与人类的评估更加一致。越低的FID值意味着合成数据分布与真实数据分布之间的距离更近。 图3：基线模型与我们的模型的训练曲线，利用了我们提出的稳定技术 表1：GAN的Self-Attention与Residual块的比较。这些块被添加到网络的不同层。所有模型都经过100万次迭代的训练，并报告最佳的Inception score（IS）和Fréchet初始距离（FID）。 图4：基线模型和我们的模型随机生成的128×128图像样本 图5：attention maps的可视化。这些图像都由SAGAN生成 与state-of-the-art模型的比较 在ImageNet上，SAGAN与最先进的GAN模型&#91;19,17&#93;进行了比较。如表2所示，我们提出的SAGAN得到了Inception score和FID。Inception score方面，SAGAN将此前0最高的36.8提高到52.52；FID（18.65）也表明，SAGAN可以通过使用self-attention模块对图像区域之间的全局依赖关系进行建模，从而更好地模拟原始图像的分布。图6展示了由SAGAN生成的一些示例图像。 表2&#58; 将所提出的SAGAN与最先进GAN模型进行比较，任务是ImageNet上的类别条件图像生成 图6：SAGAN 生成的不同类别的128×128分辨率示例图像。每行展示一个类别的示例 总结在本研究中，我们提出自注意力生成对抗网络（SAGAN），它将self-attention机制引入到GAN的框架。 self-attention 模块在建模长相关性（ long-range dependencies）方面很有效。另外，我们证明了应用于生成器的谱归一化可以稳定GAN的训练，并且TTUR加速了正则化鉴别器的训练。SAGAN在ImageNet的分类条件图像生成任务上达到最先进的性能。 【加入社群】 新智元 AI 技术 + 产业社群招募中，欢迎对 AI 技术 + 产业落地感兴趣的同学，加小助手微信号&#58; aiera2015_3 入群；通过审核后我们将邀请进群，加入社群后务必修改群备注（姓名 - 公司 - 职位；专业群审核较严，敬请谅解）。 转载来源：Ian Goodfellow等提出自注意力GAN，ImageNet图像合成获最优结果]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>可视化</tag>
        <tag>盗梦空间</tag>
        <tag>艺术</tag>
        <tag>科普</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学刘知远：知识表示学习及其应用（PPT下载）]]></title>
    <url>%2F2018%2Fb2b8c876%2F</url>
    <content type="text"><![CDATA[本讲座选自清华大学计算机系副教授刘知远于2018年4月27日在第二届“大数据在清华”高峰论坛上所做的题为《知识表示学习及其应用》的演讲。 本讲座选自清华大学计算机系副教授刘知远于2018年4月27日在第二届“大数据在清华”高峰论坛上所做的题为《知识表示学习及其应用》的演讲。 注：后台私信回复关键词“0520”，下载完整版PPT。 演讲全文刘知远：今天跟大家分享的题目叫”知识表示学习及其应用”。 大概在二三十年前，我们早就面临所谓的数据过载的问题,当时就有一个专门的领域叫信息检索，研究如何在大数据里面快速地获取相关的信息。 搜索引擎是一个非常重要的应用，我们每天都要无数次地使用，比如谷歌、百度，它们已经有快20年的历史了。 我们过去的搜索更多地是使用关键词匹配的形式。首先，用户写入若干关键词，然后搜索引擎进行关键词的匹配。2012年，谷歌提出新的口号，叫“Things，Not Strings”。它的意思是说搜索引擎不希望只是把用户输入的关键词或者它要处理的海量互联网数据，看成一个一个的字符串，而是希望能够真正地去认识，或者说真正地挖掘这些字符串背后所反映的现实世界的真实事情。 在这个理念的驱动下，诞生了谷歌的知识图谱产品。无论用户使用百度、搜狗还是谷歌，无论搜索名人、一个机构还是地名，都会出现关于机构或者人的一些结构化信息。 比如，我们搜索姚明，姚明的相关信息就会列出来，这些信息就是所谓的知识图谱。它尝试着把现实世界所有的信息都能够通过结构化的形式来存储。这种知识图谱，不只是为了支持我们的搜索引擎，能够把信息更精准地推送给我们，也是人工智能一些应用的基础设施。我们单从搜索引擎来看，在知识图谱的支持下，已经有了非常多新的应用。 在搜索引擎里，越来越多的时候不需要输入一些关键词，也不需要到网页里找答案，而是直接去问这个问题，搜索引擎就可以把答案告诉我们。 比如我们问”中国GDP最高的省份是哪个？”，它就可以直接把相关的答案告诉你。如果可以的话，还可以点击进去了解相关的信息。 比如我们问“清华大学成立于哪一年？”，它会把相关的信息告诉你，这些信息都是存储在背后的知识图谱里，需要应用自然语言处理技术还有知识图谱的技术，来了解你的问题，然后到知识图谱里找到答案。 甚至还可以尝试着回答一些更复杂的问题，比如说“清华和北大哪个好？”。搜狗告诉我们：有64%的人认为是清华好。 在知识图谱的支持下，我们还可以进行相关的智能推理。比如说“梁启超儿子的妻子的情人是谁？”，它的答案并不直接存在知识图谱里，而是需要在知识图谱结构里，跳若干次才能找到答案。这本身需要相关的一些智能推理来完成。实际上无论是谷歌，还是中国的百度，这些相对的搜索引擎都在尝试构建大量的知识图谱，给用户提供更好的服务。对于大数据时代来说，这件事情非常重要。 甚至还可以尝试着回答一些更复杂的问题，比如说“清华和北大哪个好？”。搜狗告诉我们：有64%的人认为是清华好。 在知识图谱的支持下，我们还可以进行相关的智能推理。比如说“梁启超儿子的妻子的情人是谁？”，它的答案并不直接存在知识图谱里，而是需要在知识图谱结构里，跳若干次才能找到答案。这本身需要相关的一些智能推理来完成。实际上无论是谷歌，还是中国的百度，这些相对的搜索引擎都在尝试构建大量的知识图谱，给用户提供更好的服务。对于大数据时代来说，这件事情非常重要。 到目前为止，这些商业的知识图谱应用都秉承一种比较传统的表示，我们称为”符号表示”。在计算机里，要想把知识图谱表示进来，就要把每一个实体都表示成一个独一无二的符号，把它表示成一个非常长的向量，只有一个位置是1，其他的全是0，这样就可以把不同的对象区分开。 这次深度学习的浪潮，席卷了人工智能非常多的领域，包括自然语言处理领域。分布式表示的对象均被表示成一个低维的稠密、实值向量。通过这种方式，我们就可以利用对象在空间的相对距离，反映它们之间的语义关系。两个对象离得越近，说明关系越紧密，两个对象离得越远，说明它们之间没有太强的关系。 自然语言处理是一种典型的长尾分布的大数据，最大的特点是会在长尾的部分有非常显著的数据稀疏问题。如果把这些对象都表述在低维向量空间里面，可以在这个空间里面利用少量的但是特别高频的对象，学习得到这个空间里面不同位置上的语义。当把那些长尾上稀疏的数据也映射到这个空间的时候，就可以借助那些高频的数据，一定程度上可以帮助我们解决大数据里面典型的长尾分布带来的数据稀疏问题。 另外一个非常重要的挑战是，自然语言存在多种粒度语言单位。在进行自然语言处理的时候，往往需要专门设计算法进行不同粒度单位的语义计算，比如算一个词跟一个句子的相似度，算一个句子跟一个文档的相似度。如果能够把这些对象都放在低维的向量空间里面，我们就可以有一个统一的计算方案，可以算它们之间的相似度。 比如对于同一个研究对象，一个句子或者一个文档，都会有非常多不同的任务，要做词化分析、句法分析或者语义分析，底层的表示如果一致，也能够更好地帮我们提供多任务学习的支持，这是我们认为的分布式表示的一个优势。 大规模知识图谱传统表示也是基于符号的方式，都是用独一无二的符号来进行表示。把知识图谱映射到低维的向量空间里面去，就是所谓的知识表示学习。 知识图谱里面有很多的事实，我们可以把每一个事实，它的向量看成是从头实体到尾实体向量平移的操作。 如上图，头实体用h表示，尾实体用t表示。假如说存在r的关系，这个r就是从头实体到尾实体的平移。简言之，我们的优化目标，就是要让h+r=t。这样有了成千上百万的三元组一起做优化，我们就可以得到所有实体和它们关系之间低维的向量表示。有了低维向量表示，就可以做非常多的相关的语义的计算。 从大规模知识图谱到低维向量空间过程中一定是有信息损失的，但是能够快速定位那些最有可能的实体集合，然后利用一些更复杂的算法找它的真正的答案。这是低维向量表示的应用意义。 我们尝试利用知识图谱进行关系预测，得到了所有实体和关系之间的表示，用t-h就可以判断。 知识获取的另一个非常重要的来源是文本信息，可以通过一句话判断两个实体之间可能存在的关系。 如果把知识图谱映射到低维向量空间里面，能够非常好地把文本语义空间结合起来，相当于信息量能够充分地扩展出来，显著地提升知识获取的准确度。 另外一个尝试叫做实体对齐。我们面临一个问题，不同的机构和国家，他们可能会构建各种各样不同的知识图谱，这些知识图谱既有不同，也会存在一定共性。我们怎么能够把这些不同来源的知识图谱给融合成一个更大的知识图谱，这里面就面临一个实体对齐的问题。知识图谱里面的实体和另一个知识图谱的实体是同一个实体，我们叫做实体对齐。 两个知识图谱可以分别学习两个空间，然后用已知的两个知识图谱里面对齐的实体，就可以把这两个空间真正关联起来。我可以知道这个空间里面的一个位置，跟这个空间里面的另一个位置，它们之间有关联，相当于分别学习两个Knowledge Graph的表示空间，然后用非常有限的种子的实体，把这两个空间给融合在一起。 大量的实验证明，我们的方法能够显著地提高两个知识图谱进行对齐的效果，同时说明知识图谱有非常显著的长尾效应，把它映射到低维向量空间里，能够更好地利用知识图谱全局信息建立语义空间。 第三个任务叫实体分类，这对于理解一句话，或者从这句话中抽取实体之间的关系都非常重要。最大的问题在于知识图谱如果用符号表示，它很难能够跟深度学习结合在一起。现在由于可以进行分布式表示，那么很自然地可以把这两个模型融合在一起。 在过去，知识图谱虽然很大很重要，但是很难用，因为它是一个典型的结构化的信息，跟文本的信息很难融合。但是现在有了低维向量表示，就真正地可以把知识图谱的知识，和文本信息放在一个空间里面进行相关的操作。在这个方面，我们认为未来对于知识图谱的大规模表示的语义空间，会在非常多的方向上有应用。但是，我们发现在一些通用的知识图谱上，学一个大规模知识图谱表示学习的模型还是比较难。所以我们做了一个平台，把目前来看比较有效的一些知识表示的模型全都实现，都用统一的接口。 我们面向两个通用的大规模知识图谱WikiDATA和Freebase，基于表示学习的技术将知识图谱映射到一个低维的语义空间里面，有望深入地应用到多个领域，如信息检索、推荐系统。这两个领域都在积极考虑使用大规模知识图谱信息，我们也正尝试把知识用低维空间提升检索效果，效果非常明显。 在金融、医疗、法律等垂直领域，构建知识图谱的过程非常复杂且耗时耗力，我们认为表示学习能够在知识获取方面发挥一些作用。目前，大规模知识图谱对日常知识的覆盖度以及更新的速度都非常有限。未来我们希望能够做一些深入的工作，花足够多的力气在知识图谱技术上。以上就是今天希望跟大家分享的主要内容，谢谢大家！ 转载来源：清华大学刘知远：知识表示学习及其应用（PPT下载）]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>大数据</tag>
        <tag>清华大学</tag>
        <tag>刘知远</tag>
        <tag>PowerPoint</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动驾驶攻破的难点在哪，何时能到Level 5？ - 知乎]]></title>
    <url>%2F2018%2F71e6c12c%2F</url>
    <content type="text"><![CDATA[知乎用户的回答，获得 42 个赞同 ## 转载来源：自动驾驶攻破的难点在哪，何时能到Level 5？ - 知乎]]></content>
  </entry>
  <entry>
    <title><![CDATA[Chinese Word Vectors：目前最全的中文预训练词向量集合]]></title>
    <url>%2F2018%2F894c9f0f%2F</url>
    <content type="text"><![CDATA[近日，来自北京师范大学和人民大学的研究者开源了「中文词向量语料库」，试图为大家解决这一问题，该库包含经过数十种用各领域语料（百度百科、维基百科、人民日报 对于国内自然语言处理的研究者而言，中文词向量语料库是需求很大的资源。近日，来自北京师范大学和人民大学的研究者开源了「中文词向量语料库」，试图为大家解决这一问题，该库包含经过数十种用各领域语料（百度百科、维基百科、人民日报 1947-2017、知乎、微博、文学、金融、古汉语等）训练的词向量，涵盖各领域，且包含多种训练设置。目前，该研究的论文《Analogical Reasoning on Chinese Morphological and Semantic Relations》已经被 ACL2018 大会接收。 项目链接：https&#58;//github.com/Embedding/Chinese-Word-Vectors 该项目提供使用不同表征（稀疏和密集）、上下文特征（单词、n-gram、字符等）以及语料库训练的中文词向量（嵌入）。在这里，你可以轻松获得具有不同属性的预训练向量，并将它们用于各类下游任务。 此外，开发者还在该工具中提供了一个中文类比推理数据集 CA8 及其评估工具包，用户可以以此评估自己词向量的质量。 格式 本资源中的预训练词向量文件以文本格式存储。每一行包含一个单词及其词向量。每个值由空格分开。第一行记录元信息：第一个数字表示该单词在文件中的排序，第二个数字表示维度大小。 除了密集单词向量（以 SGNS 训练），该项目还提供了稀疏向量（以 PPMI 训练）。它们与 liblinear 格式相同，其中「：」前的数字代表维度索引，「：」后的数字表示值。 预训练中文词向量 基本设定 多领域词汇 中文词向量在不同的表征、上下文特征和语料库上进行了训练。 *该项目提供了字向量，因为古汉语大多数汉字独立成词。 多种共现信息 开发者发布了在不同的共现（co-occurrence）统计数据上的词向量。目标和上下文向量在相关的论文中一般称为输入和输出向量。 在这一部分中，我们可以获取词层面之上的任意语言单元向量。例如，汉字向量包含在词-汉字的上下文向量中。所有向量都在百度百科上使用 SGNS 训练。 表征 现有的词表征方法一般可分为两种，即密集型和稀疏型的词嵌入表征。SGANS 模型（word2vec工具包中的模型）和 PPMI 模型分别是这两种表征的典型案例。SGNS 模型通过一个浅层神经网络学习低维度的密集向量，这也称为神经嵌入方法。PPMI 模型是一种稀疏的特征袋（bag-of-feature）表征方法，且它会使用正逐点互信息（PPMI）对特征进行加权。 上下文特征 三种上下文特征：单词、n-gram 和字符在词嵌入文献中很常用。大多数词表征方法本质上利用了词-词的共现统计，即使用词作为上下文特征（词特征）。受语言建模问题的启发，开发者将 n-gram 特征引入了上下文中。词到词和词到 n-gram 的共现统计都被用于训练 n-gram 特征。对于中文而言，字符（即汉字）通常表达了很强的语义。为此，开发者考虑使用词-词和词-字符的共现统计来学习词向量。字符级的 n-gram 的长度范围是从 1 到 4（个字符特征）。 除了词、n-gram 和字符或汉字以外，还有其它对词向量的属性具有重要影响的特征。例如，使用整个文本作为上下文特征能将更多的主题信息引入到词嵌入向量中，使用依存关系解析树作为上下文特征能为词向量添加语法信息等。本项目考虑了 17 种同现类型。 语料库 开发者做了大量工作来收集多个领域的语料库。所有的文本数据都通过删除 html 和 xml 标记进行了预处理。只有纯文本被保留并使用 HanLP(v_1.5.3) 进行词分割。语料库的详细信息如下： 所有的单词都被包含其中，包括低频词。 工具包 所有的词向量由 ngram2vec 工具包训练。ngram2vec 工具包是word2vec和 fasttext 工具包的超集合，其支持抽象上下文特征和模型。 ngram2vec：https&#58;//github.com/zhezhaoa/ngram2vec/- word2vec：https&#58;//github.com/svn2github/word2vec- fasttext：https&#58;//github.com/facebookresearch/fastTextword2vec：https&#58;//github.com/svn2github/word2vec 中文词类比基准 词向量的质量通常由类比问题任务进行评估。在该项目中，开发者使用了两个基准来评估。第一个是 CA-translated，其中大多数类比问题直接从英语基准中翻译得到。虽然 CA-translated 在很多中文词嵌入论文中被广泛应用，但它仅包含了三个语义问题和 134 个中文词。相对的，CA8 是专门为中文语言设计的。它包含了 17813 个类比问题，覆盖了综合的词法和语义关联。CA-translated、CA8 和它们的详细信息在 testets 文件夹中。 评估工具包 评估工具包在 evaluation 文件夹中。 运行以下代码可评估密集向量： 运行以下代码可评估稀疏向量： 参考文献 如果要使用这些嵌入和 CA8 数据集，请引用开发者的论文： Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, Xiaoyong Du, Analogical Reasoning on Chinese Morphological and Semantic Relations, ACL 2018. 转载来源：Chinese Word Vectors：目前最全的中文预训练词向量集合]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Python</tag>
        <tag>Word</tag>
        <tag>HTML</tag>
        <tag>金融</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[兴趣导向：95后用户内容消费洞察报告]]></title>
    <url>%2F2018%2Ffa3eb7ab%2F</url>
    <content type="text"><![CDATA[95后的内容消费习惯。 兴趣导向：95后用户内容消费洞察报告_36氪 转载来源：兴趣导向：95后用户内容消费洞察报告]]></content>
  </entry>
  <entry>
    <title><![CDATA[AI 算法已趋同？亿分之一的人脸识别辨识度意味着什么？]]></title>
    <url>%2F2018%2F98511603%2F</url>
    <content type="text"><![CDATA[依图科技联合创始人、CEO朱珑主题为“引领人工智能，创造无限可能”的2018年中国图灵大会5月19日在上海召开。 依图科技联合创始人、CEO朱珑 【新智元导读】主题为“引领人工智能，创造无限可能”的2018年中国图灵大会5月19日在上海召开，于1966年由国际计算机协会（ACM）设立的“图灵奖”，当之无愧是计算机界最负盛名、最崇高的奖项，因而有“计算机界的诺贝尔奖”之称。今年的中国图灵大会，更是汇聚了学界、业界的“最强大脑”，嘉宾阵容可谓豪华。在5月19日的论坛上，依图CEO朱珑博士给大家带来了一场深刻而又发人深省的关于AI时代的演讲。 在美国学习工作了十年之后，2012年的朱珑回国创立依图，也成为这一代AI创业的典型代表。他的履历上来看有几段重要的经历，第一段是在UCLA的博士时期做统计建模和统计学计算，师从艾伦·尤尔，艾伦的博士导师正是著名的理论物理学家霍金；然后在MIT的AI Lab做计算机视觉建模相关领域的博士后研究员；最后一段则是回国前，在深度学习爆发之前的NYU的Yann Lecun实验室做研究员。 在2012年之前，很少有人会说自己是做AI的，只会说做统计建模、统计学习这些具体的方向。但从2016年AlphaGo登上《自然》杂志，到美国著名的《经济学人》杂志多期报道，AI频繁登上世界最著名的杂志成为封面主题，如今已经进入了一个言必称AI的时代。与AI相关的各种言论，关于机器学习、图像识别、无人车、健康医药等等都逐步成为热点。而朱珑一直关注的是未来到底AI能发生一些什么？ 没有权威的时代让AI正变得真假难辨 在朱珑的演讲中，他提到目前AI跟过去比较重大的区别：因为AI发展太快，现在技术处于一个很难辨别真假、好坏的时代。以深度学习为代表新的AI技术，因为过去参与的人和实践不多，全球性研究的大规模以及长时间的积累并不够。因为太“热”，使得各方都热衷参与到AI的讨论，交流甚至宣传当中，AI的观点就变得非常多，这客观上使得很多专家真正有见地的意见和其他的言论很难区分开来，这不仅是中国，在美国也是同样。 另外一个则是：技术到了一个没有权威的时代。过去不管是从计算机视觉，还是整个人工智能领域，最好的实验室几乎能够垄断预测全球百分之七八十的进展，但是现在AI无论是在美国，还是在中国或欧洲，大家的发展是比较跳跃性的，在一两个实验室非常难预测主流到底在关注什么。这是整个时代的特点。 朱珑的背景是跨越学术界和工业界的创业典型，经历了中国2012年到2018年这五、 六年非常特殊的阶段，正如他在演讲中提到的，过去中国没有成熟的科技创业的情景和市场机制。过去，政府、投资者、媒体这三者可以频繁交流，在2012年之前，学术界不像今天这样经常会被政府或一流基金邀请交流。美国则因为市场成熟，这些人经常会在一起交流，甚至都是朋友。中国这几年开始，各种背景的人在一起交流的越来越多，这是新的形态。 技术突破打开了工业界应用的突破 技术上，2015年，机器识别人脸的水平正式超过人类。人脸识别中机器比人强，最简单基础应用就是1：1的比对，证明你就是你，大家熟知的是2017年iPhone推出的刷脸开机；其次是1：N，是通过任一设备里捕捉到的人脸，从一个省（亿级）或一个国家的人像库（十亿级）里来回答你是谁，这对识别性能的要求提升了一个量级，是千倍万倍地增长。这意味着识别技术的突破，打开了工业界中的产品的突破。 2012年之前，可以认为人脸识别技术几乎没有什么发展，2017年人脸识别最高水平可识别规模在20亿人，大概比2016年可识别千万提高两百倍，比2015年提高了数万倍。那未来的发展到底是什么样？会不会再10倍、100倍甚至万倍地发展？ 大家现在也有个讨论，技术是不是发展到了瓶颈？各项算法之间有没有区别？随着AI热潮的涌现，各家AI公司都会频繁参加一些业界的比赛以证明自己的算法实力，以人脸识别算法为例，可以看到各AI公司在LFW等类似的计算机视觉比赛中都取得99.xx%的成绩。于是人们会问：AI算法是否已经趋同了？如果算法精度差别不大（只有几个百分点），是否意味着创业公司的技术已经同质化了，没有技术创业的核心竞争力了呢？ 但实际上，这是典型的认知误区。我们在朱珑的演讲中看到了一张表，可能更准确的回答了这个问题，这是中国某省1亿人像库的情况下，真实的刑侦案件的破案环境的性能测试对比的表，参与方是知名的几大人脸识别公司： 我们可以这样理解这张图：必须对应场景来谈算法精度。不同场景的算法精度不具备任何可比性，甚至不代表有相关性。换句话说在简单场景下算法精度高，不代表在复杂的高难度场景下有更大的概率可以把算法精度做高，就比如在小学生的考试中拿满分，不见得可以在大学的考试中也拿满分。因为很多学术界的比赛使用的都是公开数据集，数据集内多是互联网照片，类似于难度小的开卷考试，大家很容易把测试成绩刷到比较高。但在实际的应用中则会遇到各种高难度场景，包括变形、昏暗、逆光、强光、光照不均、低清、运动模糊、遮挡、跨年龄段比对等，在这种情况下各家的差距迅速拉开了，第二名和第一名的错误率都会相差几倍以上，远未到趋同的程度。 第二，这些实战中的技术差距体现在具体产品或应用上，不是简单的好用和一般好用的差距，而是可用和不可用的差距。实战中是要以最高效率解决实际问题为目的的。在一个1亿级别人像系统中进行1：N的静态比对时，错误率相差几倍，就导致使用者做事效率下降几倍，那么自然而然，即使他使用的是一个多算法平台，他也只会倾向于使用第一名的算法。 AI帮助探索人类智慧的边界 AI除了在产业界的实际应用外，更能够帮助我们理解人类的智慧、人类智慧的边界。 我们以前是没办法了解人类自己识别能力的规模和精度，到底是什么程度？过去没法做这个科学实验，1万人还是10万人你辨别不出来。而机器在大规模的情况下，很轻易地识别1亿人、10亿人，甚至更多的时候，机器识别就相当于提供了一把尺子，根据相似度比例筛选出来给人去测，可以在有效的时间里面，测出一个人自己“看”这个世界的能力。 这是人类第一次有一个非常稳定且强大的机器，有识别能力看到人和机器智能差别到什么程度。依图曾做过一个实验，在几千万量级的身份数据库上，一个人把他女朋友生活照输入进去，在机器输出相似度前十的照片中，他是非常难辨别哪张是他的女朋友。过去机器认识生人的能力比人强，但是今天机器识别熟人脸的能力也超越人了。 今天机器是有了高性能的，比人类大很多倍的这种识别能力，能够帮助我们回答这些更有趣的问题：在13亿中国人中有多少人跟你长的一模一样？一模一样我们可以先定义为自己的妈妈辨别不出来谁是谁。经过依图的实验，结果是，每1亿人当中有一个人跟你长的一样，所以全中国差不多12个人跟你长的一模一样的。 这个意味着什么？ 1亿人当中有一个人跟你长的像，这又意味着什么？ 人类进化过程中，视觉识别能力在各大感官中的比重越来越大，也可能是人类穿衣服，嗅觉识别家庭成员的能力在哺乳动物中比较低下，主要是看人脸来辨别同类。选择压力驱使人类的脸之间的区分度需要尽量的大，这样保证家庭成员的稳定性得到保障。 而人作为社群动物，需要和大量同类打交道，脸部识别错误的代价是失去整个基因组的遗传继承。对应的编码人脸形状的基因数量需要很大，目前知道有一条染色体的一大块用于编码脸部特征。一亿分之一的识别度是一个具有巨大社会学意义的统计数值，背后更多的生物学意义需要更近一步探讨。与之对应的一个未经实验证实的观察是，动物的脸部特征区分度不像人类这么大。比如猫和狗，光看脸，我们很不容易区分出来。 脸部信息对于身份的确认是非常重要的，人类如果不具备辨别能力，出门回来之后你认不出你的小孩、老婆，就会出现社会的骚乱，所以说人脸识别对基因的进化有非常巨大的影响。 1950年图灵发表《计算机器与智能》，提出著名的“图灵测试”，成为人工智能的思想起源，而在2018年的图灵大会中，依图朱珑博士的演讲也给我们打开了认知人工智能现状和未来的一扇窗户，在嘈杂的言论中给我们更多的启发和思考。期待听到更多这样的演讲。 转载来源：AI 算法已趋同？亿分之一的人脸识别辨识度意味着什么？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>基金</tag>
        <tag>大学</tag>
        <tag>阿兰·图灵</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌OKR目标管理法，代替KPI的管理利器]]></title>
    <url>%2F2018%2F25ae2d50%2F</url>
    <content type="text"><![CDATA[他会让一个无法用数字考核的团队通过层层分解目标、关键任务，向同一个方向前行。如果总是满分证明目标设置太低，如果是0分，要说明为什么不完成这件事情，比如市场发生了变化等，但是不能删除，如果总是0分，就证明目标设置有问题。 这里是科技前哨，我是赵文轩。 连接创新上下行，让产业用好技术，让技术赋能产业。 如果说KPI是秒表，OKR就是指南针。他会让一个无法用数字考核的团队通过层层分解目标、关键任务，向同一个方向前行。 一、OKR：谷歌的目标管理法 OKR，是“objective and key results”（目标与关键成功法）的缩写。简单来说就是整个公司、团队和个人，都要设立目标（objective）和衡量这些目标完成与否的关键结果（key results）。 OKR的设置逻辑 谷歌的每个员工每个季度之初都需要给自己定一个或几个目标，每个人的OKR大约半页纸，写好后放到自己公司网页上，大家都可以看到，这样也是很好的监督。 到了季度结束前，谷歌的每一个人会给自己的目标完成情况打分0-1分。大部分会在0.7-0.8。1分是完成，如果总是满分证明目标设置太低，如果是0分，要说明为什么不完成这件事情，比如市场发生了变化等，但是不能删除，如果总是0分，就证明目标设置有问题。 二、OKR设置样例 三、OKR管理工具 现代协作SaaS软件可以帮助你更好地来进行OKR相关任务的跟踪和协同，减少重复的文档工作，保持日常任务进度沟通的便捷性，让任务成员能够保持同步，让新成员能够很快上手，让公司更多人能够了解和参与到OKR任务中，也能够在跟踪和复盘的时候有一个清晰的清单。任务协作软件是助力一个企业实施OKR的工具。每个人能清晰的看见自己的进度，也能看到自己的努力对于公司整体进度的贡献。 对齐公司，部门，团队和个人目标，让每个人的贡献走到一起。 多团队合作，保持了解高层计划取得的成就，告知你的规划和决策 衡量团队绩效，查看趋势报告 四、OKR怎么解决绩效考核问题呢？ 答案是他不解决绩效考核问题，而是通过360度环评的绩效管理。 简单来说，就是被考核人周围的同事，包括直属经理都会给其打分，最后加权算出一个得分。这个分数，决定了被考核人的晋升、奖金、股票。 这是不是太主观？是的，目前谷歌、微软，以及发明OKR的因特尔都是这样。对于怎么解决工程师的绩效考核问题，整个科技界都没有好办法。唯一的办法，就是通过多方均衡，让主观打分尽量客观。 目前也在通过各种OKR软件，与KPI结合等方法探索考核的办法。 360度环评的绩效管理和OKR的目标管理，是前行的两条腿，缺谁都会寸步难行。 五、具体应该如何使用OKR这根指南针呢？ 第一，目标要有野心，关键结果要可衡量。既然不考核，设立目标时，应鼓励大家挑战极限。 第二，最多5个目标，每个目标最多4个关键结果，这样才能聚焦。 第三，目标从公司，到团队，到个人，层层分解。从上到下的OKR，总体上是包含关系。下级也可自定义OKR，但要与大方向一致。 第四，所有OKR公开透明。大家要知道彼此在干什么，确保方向一致。这样也会给目标过低、结果过差的员工施以压力。 六、OKR与KPI的比较 总结一下： 1、OKR能带来的好处为：更好的沟通，敏捷，聚焦，公开透明，自下而上，前瞻性思考。 2、OKR的关键：每个季度和年度都有OKRs，并保持这样一个节奏的；可量化的；个人、组、公司层面上均有；全公司公开；每个季度都打分。 转载来源：谷歌OKR目标管理法，代替KPI的管理利器]]></content>
      <categories>
        <category>职场</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>Google</tag>
        <tag>KPI</tag>
        <tag>指南针</tag>
        <tag>英特尔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学而思小学数学重大升级：全面转型多元综合能力！]]></title>
    <url>%2F2018%2Fdda2deb3%2F</url>
    <content type="text"><![CDATA[受益一生的能力。 转载来源：学而思小学数学重大升级：全面转型多元综合能力！]]></content>
      <tags>
        <tag>家长帮幼教</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[看看你排第几]]></title>
    <url>%2F2018%2F2a769632%2F</url>
    <content type="text"><![CDATA[看看你排第几 转载来源：看看你排第几]]></content>
  </entry>
  <entry>
    <title><![CDATA[什么年纪需要每天吃阿司匹林？]]></title>
    <url>%2F2018%2Fe26a3bc6%2F</url>
    <content type="text"><![CDATA[文/子泉心肌梗死非常致命，中风可能导致半身不遂甚至终身瘫痪。但真相是：对于没有心脑血管疾病风险的普通老年朋友，长期服阿司匹林，不是益寿延年，而是处在各种副作用风险中。 文/子泉 心肌梗死非常致命，中风可能导致半身不遂甚至终身瘫痪。服用阿司匹林可对缺血性、血栓性心脑血管疾病的预防起到很大作用。 曾经有人建议所有老年朋友长期服用小剂量阿司匹林，说“有病治病，无病强身”，花很少的钱就可以预防，何乐而不为？ 但真相是：对于没有心脑血管疾病风险的普通老年朋友，长期服阿司匹林，不是益寿延年，而是处在各种副作用风险中。 阿司匹林在一级预防的地位已经有所降低。所谓一级预防，即患者存在危险因素，但还未发病。 2014年日本一级预防项目“JPPP”研究发现，每日服用小剂量阿司匹林，并不能使心血管疾病的低危和中危人群明显获益。 美国FDA综合了大量的研究数据后，也不推荐阿司匹林用于心脑血管疾病的一级预防。 而且，阿司匹林还有很多副作用（胃肠道症状和出血倾向），不能随意吃。 什么年纪需要每天吃阿司匹林？很多人上了年纪之后医生会建议长期服用阿司匹林。但是并不是说与年纪就一定相关。 具体如下：阿司匹林长期服用可以防止中风和心肌梗死及心绞痛。为什么，因为这些疾病本质上就是血管里面长了血栓，所以阿司匹林有很好的预防以及治疗作用。所以吃不吃阿司匹林不仅与年龄相关，最主要的是你得这些血栓性疾病的可能性大不大。这个往往还要参考其他因素，比如你是否有高血压、糖尿病，血脂高不高，等等。 哪些人该服用？已经发生过心脑血管疾病和极可能会发生心脑血管疾病的人群都该服用阿司匹林。 发生过动脉粥样硬化性心血管疾病的患者，如果没有禁忌，应该终生服用阿司匹林，药不能停。 抗血小板的药不少，除了最接地气的阿司匹林，还有氯吡格雷、替格雷洛等。冠心病患者，可能会需要在阿司匹林基础上结合服用氯吡格雷或替格雷洛一年左右，除非有禁忌症或严重并发症，阿司匹林是真正应该长期服用的。 心脑血管疾病高风险人群也建议长期服用阿司匹林。哪些人属于这一类呢？ 一、符合下列三项及以上危险因素者，建议服用： 男性超过50岁或女性绝经后；1. 高血压；1. 早发心脑血管病家族史；1. 吸烟者。高血压； 吸烟者。 二、高血压合并糖尿病。 三、高血压合并慢性肾功不全。 四、经医生评估10年内心血管事件风险大于20%。 版权声明：本文为《健康指南》（微信号：jkzn1988）原创，未经授权谢绝转载。 转载来源：什么年纪需要每天吃阿司匹林？]]></content>
      <categories>
        <category>健康</category>
      </categories>
      <tags>
        <tag>糖尿病</tag>
        <tag>心血管病</tag>
        <tag>高血压</tag>
        <tag>心肌梗死</tag>
        <tag>中风</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AI+教育的核心：自适应教育]]></title>
    <url>%2F2018%2Fe6ddfc9e%2F</url>
    <content type="text"><![CDATA[《报告》中介绍：人工智能自适应教育是一次行业改革实验，对机构、对学生、对老师三方都具有降本提效的价值。 图片来源：摄图网 2017年财富全球论坛上，有人问马化腾下一波能超过BAT的千亿美金市值公司会出自哪里？马化腾回答：AI+教育或AI+医疗。在艾瑞咨询发布的《2018年中国人工智能行业研究报告》，在教育领域，自适应教育才是“AI+教育”的核心。《报告》中介绍：人工智能自适应教育是一次行业改革实验，对机构、对学生、对老师三方都具有降本提效的价值,其核心价值是把教育行业从劳动密集型的农业时代带向成本更低、效率更高的工业时代。目前国内共有41家做人工智能自适应教育的公司，两大教育巨头自2015年起，就下重金布局人工智能自适应教育，自适应教育俨然成为下一个风口之势。 什么是自适应教育？自适应教育最早出现在上世纪90年代美国的“智能辅导系统”中，当时所谓的智能其实就是按学习水平的高低对学生做一个简单的分层，把学生分成好、中、差等几大类，让每一类学生都匹配到他最需要的学习内容和路径。这是一种十分粗糙的个性化教育，其理念类似于分班。 自适应学习就是通过算法，将获取到的学习者的数据分析反馈给已有的知识图谱，为学习者提供个性化难度和个性化节奏的课程和习题等，从而提高学习者的学习效率和学习效果。 自适应学习与传统教学的不同在于主要教学方式不同：传统教育通常是以班、组为单位的，由老师提供统一的教学内容和进度安排的，学生的练习和需要做的测评也都是统一化的，而自适应教育是以个人为单位的，接受不同的学习进度和学习内容，练习与测评内容的个性化程度高。 自适应教育凭什么成为“AI+教育”的核心目前，基于人工智能技术的教育产品包括拍照搜题、分层排课、口语测评、组卷阅卷、作文批改、作业布置等各种产品伴随着移动互联网、新高考改革等一波接一波的浪潮，热热闹闹地生长了起来，这些工具应用了先进的人工智能技术，但应用场景只停留在学习过程的辅助环节上，其价值也停留在减少重复劳动的层面上，并不会直接带来教学质量和效果的提升。而越是学习核心环节，越依赖于对教育行业和学习规律本身的理解（这一点对技术人员来说越陌生），也越依赖于对先进科技的灵活运用（这一点对教育人员来说是困难），创造出的产品也就越少。自适应则能够把人工智能技术渗透到教学的核心环节中，打造教学机器人，从根本上改进学习的理念和方式，是正式意义上的教育变革。 美国人工智能教育领域独角兽Knewton创始人Jose Ferreira认为，自适应教育最大的优势在于能够定位到每位学生的知识漏洞，而且在中国教育的课外辅导市场尤为有效。老师的精力都是有限的，一名最优秀的名师也不可能全面了解到学生的知识漏洞，更不可能跟踪到学生的学习情况随着学习时间的变化，自适应教育借助于人工智能和大数据分析技术便能够做到这一点。 突破瓶颈是关键在过去的10多年间，自适应教育一直不温不火，主要瓶颈在于知识点拆分不够精细——该把一个知识拆分成多少知识点，才能让每一个学生都有自己最适合的学习方案？理论上来说自然是越多越好，但知识拆分的越多，对机构的测评和教研能力要求就越高，一般机构无力企及；即使机构能够企及，高昂的成本也会抬高产品售价，令一般用户望而却步。这也是为什么人工驱动的一对一教学模式虽然低效，但仍然广泛存在的原因，而计算机驱动的自适应学习虽然美好，但实践起来总是虚晃一枪。 目前来看，知识点的拆分就是自适应教育产业中一个非常大的难题，只有更细腻地拆分每个知识点，并且利用人工智能技术全面介入到学生的课前测试、学习流程、课后测试、作业流程等整个学习过程中，进行可定义、可测量、可传授的个性化教育，才能让每个学生都成为学霸。 近几年，有些企业基于人工智能技术的自适应学习系统不仅能够做到一人一个学习方案，而且还能根据学生学习的实时情况，动态调整下一步的学习内容和路径，从而实现可规模化的个性化教育。 如今，自适应教育已正成为下一个风口，许多企业纷纷地挤入这个行业，它不依赖于名师，只是在模拟一个优秀名师的教学经验和知识经验。相比于过去的以老师为中心的在线教育，自适应教育则是以学生为中心，带给学生更灵活、更有效的学习方式。但有些企业并没有真正做到自适应教育，只是借自适应教育之名来获取用户，这些企业未来必将会被高质量的自适应教育所取代，谁能够突破自适应教育的瓶颈，谁就有机会成为下一个行业独角兽。 本文转自微信公号“中关村互联网教育创新中心（ID：zgc-mtb）”，作者陈帅。 转载来源：AI+教育的核心：自适应教育]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>在线教育</tag>
        <tag>移动互联网</tag>
        <tag>大数据</tag>
        <tag>马化腾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[激荡18年，“医药界华为”如何成为离全球医药创新最近的中国公司]]></title>
    <url>%2F2018%2Ffac0efe3%2F</url>
    <content type="text"><![CDATA[3月27日，无锡药明康德新药开发股份有限公司拿下接力棒，仅用了50天时间过会，并弯道超车，率先拿到IPO批文，并宣布本月8日于A股正式挂牌上市，成为首只以IPO形式回归A股的中概股。 3 月 8 日，富士康工业物联网FII闪电过会，科技创新企业的上市便牵动各方神经。3 月 27 日，无锡药明康德新药开发股份有限公司（以下简称：药明康德）拿下接力棒，仅用了 50 天时间过会，并弯道超车，率先拿到 IPO 批文，并宣布本月 8 日于 A 股正式挂牌上市，成为首只以 IPO 形式回归 A 股的中概股。 根据招股书，药明康德 IPO 发行约 1.04 亿股，占发行后总股数的 10%。每股发行价格 21.6 元，据此计算，药明康德计划通过 IPO 筹集 21 亿元资金。当时外界就**预计 A 股上市后，加上旗下两家全资子公司，药明康德集团整体的市值将超过千亿。** 在 5 月 8 日的上市首日，药明康德开盘股价高开大涨逾 20 %，涨幅达 43.98 %，达到上市首日涨幅限制。而在接下来的 9、10、11 日，药明康德实现连续涨停，上市 4 日累涨逾 91 %，截至发稿报 41.39 元。 截至 5 月 10 日收盘，合全药业总市值 199.01 亿元，药明生物总市值 752.16 亿元，药明康德总市值 392 亿元，药明康德集团整体合计总市值已经达到 1304 亿元。 此次药明康德上市事件备受各方关注，一则是因为药明康德举足轻重的业内地位，其与众多世界顶级制药公司都合作紧密：全球排名前 20 制药公司里，有 18 家是药明康德的客户，包括默克、强生、GSK、辉瑞等；二则是因为，与此前坊间的猜测不同，药明康德此次回归并不是“借壳上市”，4 月 16 日药明康德启动 A 股 IPO，也因此成为首只以 IPO 形式回归 A 股的中概股。 值得注意的是，与之前披露的招股意向书相比，此次拟募集资金 57.41 亿元调整为 21.3 亿元，缩水高达 63 %。尽管募集资金大幅度调整，但发行规模却并未改动，这意味着公司选择以更低的市盈率发行，给二级市场留下较大空间。业内人士分析称，比富士康晚 19 天过会的药明康德之所以能率先拿到 IPO 批文，其“代价”正是募集资金的缩水。 鉴于该公司以显著低于行业市盈率的估值发行，预计上市后将给中签者带来可观的收益。可以预见，此次药明康德登陆 A 股，必将会给医药板块带来巨大振动。 鉴于药明康德的市场地位和研发能力，药明康德被誉为“医药界的华为”。作为一只经历过纽交所上市、海外并购、退市、子公司分拆上市的医药巨兽，药明康德所走过的 18 年，也正是中国新药研发能力和技术平台发展的一个缩影，**而它接下来的决定，很可能代表着中国先进生物技术公司的重要方向。** 靠“研发外包”起家药明康德成立于 2000 年，在其大客户名单中，全球最知名的药企，默沙东、强生、罗氏、GSK、辉瑞等名字赫然在列。早在 2002 年，药明康德便建立了与这些巨头的合作关系。这些制药巨头之间的激烈厮杀从未停止过，但长期共同使用药明康德的服务似乎又成了彼此之间的“默契”。 药明康德以医药研发外包服务（CRO）起家，而 CRO 公司所发挥的作用是替其他公司研发新药。 之所以会有这样的市场分工，是因为大部分药厂不具备足够的药物研发能力：一些制药公司没有研发团队，有的药厂即使拥有制药团队，在药物研发上也力量薄弱。据美国塔夫茨大学的一份报告，开发一个新药的平均成本大约为 25.6 亿美元，一个新药从药物研发阶段到A批准上市平均需要 10-15 年的时间，同时新药研发成功率平均只有18%。大部分药物都在研发过程中失败，无法通过全部流程。 图丨新药的研发成本不断升高，现在平均一款新药成本大约为 26 亿美元 因此，制药企业与 CRO 公司合作有着非常充足的理由。首先，凭借高度专业化的研究网络和新药注册团队，CRO 公司可以使新药研发的资金投入和潜在风险分散到该行业的整个产业链上，进而降低制药企业的研发成本；其次，CRO 公司缩短研发时间。 毕竟，可能没有其他行业比医药企业更能感受到时间所带来的危机感了：创新药的专利往往只有几十年，研发就会占去10 到 15 年，如此紧迫的生命周期意味着时间就是金钱。 数据显示，CRO 的高度专业化，可以帮助药企缩短 30 %的研发时间，提高收入。一个年销售额超过 20 亿美元的药物早上市一个月，就能为药企新增 2 亿美元的潜在收入。 药明康德 73 %的收入，正是来自 CRO 这种外包服务。药明康德如今已经成为国内规模最大、全球排名前列的小分子医药研发服务企业，当之无愧的国内 CRO 巨头：根据知名医药咨询公司 Igeahub 日前发布《 2018 年全球 10 大合同研究组织》显示，药明康德全球排名第 9 位。 事实上， CRO 这种外包服务的门槛非常高。在医疗领域，CRO 主要包含临床试验方案和病例报告表的设计和咨询、临床试验监查工作、数据管理、统计分析等等，其目标市场主要集中在医药公司对药物做医学统计和临床试验等业务。委托方制药企业在选择医药研发合同外包服务机构时，将考核 CRO 企业的实验结果可信度、不同研究阶段之间的数据衔接、以及知识产权的保护等。 毫无疑问，随着 18 年来的开疆拓土，药明康德已经形成了以小分子新药研发和生产、生物药研发和生产、细胞及基因疗法研发生产、医疗器械检测、基因组学及分子检测五大支柱能力共存的格局，成为了全球少数几个覆盖全产业链的医药研发服务企业之一。 与此同时，中国的 CRO 行业发展也已发生了翻天覆地的变化。尤其是近几年，借由政策驱动，国内刮起了制药企业由仿到创的新风向，国内创新药的加速发展， CRO 市场规模也相应扩大。 数据显示，在过去的十多年里，中国的 CRO 产业迅速发展，数量已经从 2009 年的 300 家发展到了 2016 年的 1000 多家。中国成为了全球 CRO 产业发展最快的国家之一，并超越印度成为世界医药研发服务业的首选地。 而这一次，药明康德的上市无疑会为 CRO 概念再打上一轮“鸡血”。随着各路资本相继涌入以及**全球医药产业链条向新兴市场靠拢，中国 CRO 市场也将迎来新一轮的竞争周期。** 作为 CRO 龙头企业，药明康德将面对来自国内外企业的猛烈攻势，经受更为严峻的市场考验。 图丨药明康德主营业务可分为两大板块、共四类业务单元 借助此次的资本运作，药明康德有望继续攻城略地，毕竟，其高质量的全产业链已备好了开枝散叶的绝佳土壤。根据药明康德的招股书，融资主要用于拓展药明康德现有研发业务范围、提升生产能力、为客户服务的水平，涉及较大规模的固定资产投资。 离全球医药创新最近的中国公司根据 Igeahub 发布的今年的全球 CRO 公司排名，药明康德目前位于第 9 名，年收入 10.11 亿美元。 图丨该榜单的排序有6个标准，并分配了不同的权重，包括：年度总收入（70%）、年度收入增长（10%）、净收入（5%）、开支比例（5%）、雇员平均收入（5%）、服务组合资产的范围（5%）。最终得分统计代表了每家公司在临床试验领域的财务健康、竞争优势和活动状态 从榜单中我们也能看出，药明康德已经是国内当之无愧的 CRO 领头羊，然而，只是 CRO 巨头，并不能满足药明康德的野心，成为整个医药界的操盘手才是CEO李革的最终梦想。 2000 年李革首次将 CRO 的模式带入中国，使一个发展中的中国看见了医药研发可以带来的巨大利益。但质疑也一直不绝于耳：这种客户指哪打哪的“外包服务”显得有点 low。因此，在外界给予的众多称号中，还有一个名字让李革难以接受——**“医药界富士**康”。 众所周知，富士康在代工市场已做到极致，尽管“全球最大的电子代工厂”的地位已经无法撼动。药明康德与它有类似之处，尽管在与众多制药巨头的合作中赚得盆满钵盈，但在从行业层次来看，是给大医药公司“打工”和做服务的，严重依赖大制药公司，在行业内难以“掌舵”。 诚然，对于药物研发动辄十余年甚至数十年的研发周期以及百万乃至上亿的花费，几乎没有初创公司或是心有抱负的科学家可以负担，他们只能将治病救人的药物在脑海中不停地重复。研发药物的品种、治疗的疾病类型、药物受众数量，这些关系到病人生死的关键问题，在那些掌握选择权的制药巨头眼中都要给资本市场让路。 “现在新药的数量远远满足不了病人的需求，唯一的办法就是让更多的人可以参与创新，把他的知识和经验有效地商品化。”这是李革给出的答案。 他一直希望，通过创建开放式的能力和技术平台，任何人任何公司的研发之梦得以实现。 药明康德执行副总裁、首席运营官杨青就曾表示，阿里巴巴针对消费者的平台、亚马逊网络服务帮助企业规模化成长的平台、台积电帮助全球半导体产业创新的平台给了药明康德很多启示。具体而言，药明康德正是参考了以上公司的平台逻辑，打破制药业的游戏规则，将药物研发变成一场接力赛——通过一体化平台，将药物研发的各个步骤拆分开，从设计、研发、测试到开发、生产，使更多有想法、有能力的人或初创公司参与进来，也许是手握分子结构图的化学家、或是刚刚合成一种小分子而未开展临床试验的初创公司，或是已经退休但经验丰富的老教授，每个人都可以在平台上找到他们的位置，每个人都可以将自身价值发挥到极致。 对于药明康德来说，一体化平台的建立也使药明康德成为一站式服务商，同时可以满足其他公司所有的外包需求，而不是单纯的药物开发，整个平台的知识和经验也能得到充分的利用和商业化。 化零为整，药明康德正在用它四两拨千斤的方式向世界制药巨头靠拢，建立最低的门槛，充分利用平台的价值及已积累的技术及经验，相信药明康德的创新模式会在之后中国医药产业从仿制向创新转型的过程中发挥重要作用。 长期关注生物技术投资的华创资本合伙人熊伟铭对 DT 君表示，李革的这种布局实际上已经展现出了非常强的作为国内药企领导者的势头，“这家公司会是中国药企非常重要的一个风向标”，他说。 至于药明康德最终究竟会发展为医药界“华为”、“富士康”还是如李革所希望的“阿里巴巴”，不同的人会有不同的答案，而一家药企能够吸引到这么多的标签，已经足够说明它的特殊性，这种特殊性的背后又暗藏着中国科技企业某些共通性：迎来前所未有的历史性机遇，也也面临着诸多新的挑战，能否迎来更大的发展空间将取决于其能否有更多原创性技术突破。 李革和他的“医药界的阿里巴巴”一个能在市场站稳脚跟的医药研发服务企业，本身就具有相当程度的技术壁垒。而药明康德取得如今的成绩，离不开其背后的缔造者——“中国医药研发外包产业第一人”李革。 李革为中国药物研发所带来的影响，也远不止一家总市值超千亿生物科技集团。李革任药明康德董事长兼首席执行官至今，2008 年曾入选《福布斯》25 位知名美籍华人行列。 1989 年毕业于北京大学化学系的李革，和那个时代的优秀年轻人一样，希望出国深造，但如何在众多优秀学府中选择一个，让他游移不定。“如果你可以在纽约生活，那你就可以在全世界任何地方生存，”正是电视剧《神探享特》里的这句话帮助李革做出了选择，他决定前往美国哥伦比亚大学。 图丨李革 在哥伦比亚大学求学的几年，李革充分展现了他在化学领域的天赋和勤奋，仅用了三年时间就完成了博士学习。1993 年 4 月，他与导师等 4 人一起创立了美国新泽西州普林斯顿组合化学公司 Pharmacopeia Inc.，并协助公司于 1995 年在纳斯达克上市，取得了巨大的成功。 而在国内，有一个情况引起了李革的注意，那就是中国的新药研发主体仍然以科研院所和高校为主，专门从事研发的商业企业几乎为零。2000 年，同时具有医药研发技术背景和商业运作经验的他决定放弃在美国已获得的成就，回国再次创业。 2000 年底，他和刘晓钟、林涛、张朝晖三位伙伴一同成立了药明康德新药开发有限公司，将医药研发外包这种模式引进中国，**因此被称为中国医药研发外包产业第一人**。 然而，在当时，李革的这个选择并不被欧美医药界和风投界所看好，他们普遍认为，CRO 公司在中国根本没办法做起来，因为中国当时的整个医药研发市场还处于非常初级的阶段，不具备 CRO 发展所需的研发实力和商业土壤。 幸运的是，李革凭借自己的商业嗅觉找到了药明康德的第一个“伯乐”——江苏太湖水集团。这个药明康德的首个投资者，为这只“初生牛犊”带来了充足的资金和人脉。而相比从 0 开始啃中国市场的硬骨头，李革选择首先招揽国际客户。他在美国制药领域的经验也让药明康德很快拿到第一张订单。此后，公司业绩连续增长，并获得不少知名创投基金的投资。 刚起步的那段时间，药明康德可谓“国内国外两手抓、两手都要硬”：在国内，他积极招揽人才、布局软硬件设施，在国外，药明康德则大力拓展国际市场，其优质服务得到了大量知名药企的肯定。 在他的带领下，药明康德势如破竹，在成立的第 7 年（2007年）登陆纽交所，融资1.85 亿美元，成为第一家从本土走向国际资本市场的 CRO 公司，为医药界“中国研发”打了一剂强心针。 李革和他的药明康德在中国医药界发展中扮演着重要角色：借助药明康德的 CRO 服务，中国药企的实力得到提升，而药明康德也在通过其国际影响力为中国市场带来国外制药巨头的先进经验。 图丨2007年药明康德在纽交所上市 如果没有李革，很难想象中国的 CRO 将会是如何的姗姗来迟，但即便已经在纽交所上市，向世界证明了CRO 在中国的成功，也不足以平复李革的野心，因为他的心里药明康德的定义不该是一个“药厂”。 相比被称为“医药界的华为”，李革更喜欢被称为“医药界的阿里巴巴”，“打造一体化平台”才是李革心心念念的答案，在他的心里有个更大的舞台。2008 年，药明康德大刀阔斧的开始了他的变身之路。1 月，药明康德斥资近 1.6 亿美元收购了美国生物制药和医疗器械服务供应商 AppTec 公司，布局生物医疗及医疗器械领域，这是当时继联想并购IBM后的最大海外并购案例。 但并非所有人都和李革一样看到了药明康德的无限可能，资本市场中反对的声浪渐渐传出。2010 年 7 月，国际 CRO 巨头查尔斯河实验室对药明康德价值16亿美元的收购案遭到收购方大股东反对，最终宣布终止。 作为一个 CRO 起家的公司，市场对于其“不务正业”的态度也很快就表现在了股价上，2015 年 3 月，当季度财报公布后，药明康德的股价大跌 20%，而更让人吃惊的却是药明康德壮士断腕的态度。 2015 年 8 月，药明康德宣布与包括李革在内的团体达成 33 亿美元私有化约束性协议。李革曾对此表示：“我们想要保持创新，却不能得到正向的激励。回归私有化能够帮助我们更加大胆地投资平台建设，更加灵活地把握新兴机会。” 自 2015 年 12 月美股退市后，药明康德大刀阔斧的将旗下三类业务拆分上市：2015 年 4 月，旗下全资子公司合全药业（以医药合同定制工艺研发生产业务，即 CDMO 为主，为医药企业提供小分子创新药研发生产服务）登陆新三板，目前市值约 203 亿人民币；2017 年 6 月，旗下全资子公司药明生物港股上市，目前市值约 938.5 亿港元。 加上 A 股上市，药明康德成功完成 A 股、新三板、港股的上市计划，价值上千亿的中国生物科技集团自此起飞，**其一拆三上市的方式也对药明康德系整体市值带来了最大化的推动。** 2015 年从美股退市后，药明康德分拆为三大类业务分别上市。 2015 年 4 月，子公司合全药业登陆新三板，2017 年 6 月药明康德另一家药明生物香港联合交易所上市，而此次药明康德回归 A 股，标志着“一拆三”全部完成，对千亿元市值发起“攻势”。 如今，李革喜欢这样描述药明康德：一个提供能力和技术的平台公司，让任何人、任何公司都可以研究发现新药和新的医疗产品来造福病患。 “在药明康德的研发平台上，一个人有新药研发想法的话，一张纸、一支笔、一张信用卡，就可以开药厂了。他只需要拿张纸，把想做的分子结构画一下，拿个手机拍张照送给我们，我们就可以帮着实现”，药明康德人力资源负责人赵宁曾如此表示。 转载来源：激荡18年，“医药界华为”如何成为离全球医药创新最近的中国公司]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>IPO</tag>
        <tag>药品</tag>
        <tag>康德</tag>
        <tag>中国医药</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科技公司的两种哲学：帮人类做事 vs 为人类赋能]]></title>
    <url>%2F2018%2F9644a693%2F</url>
    <content type="text"><![CDATA[这些大会，不仅传递了这些巨头的新业务与变化，还传递出了这些巨头公司运营背后的哲学观念。著名分析师BenThompson发表了一篇文章，详细阐述了科技公司背后的两种哲学：帮人类做事与为人类赋能。 编者按：Facebook的F8大会，谷歌的 I / O 大会，微软的Build 大会已经召开。这些大会，不仅传递了这些巨头的新业务与变化，还传递出了这些巨头公司运营背后的哲学观念。著名分析师Ben Thompson发表了一篇文章，详细阐述了科技公司背后的两种哲学：帮人类做事与为人类赋能。在他看来，两种哲学都是必不可少的，在不同的哲学指导下，科技公司的发展方向也会有所不同。文章由36氪编译，希望能够为你带来启发。 虽然离苹果的开发者大会还有几周时间，但我觉得，可以肯定地说，谷歌 I / O 大会主题演讲上的Google Duplex演示，将是技术会议季最令人印象深刻的一幕。如果你还有没看过，我强烈建议你看下。 最令我印象深刻的是谷歌首席执行官桑达尔·皮查伊（Sundar Pichai）的是如何切入这一部分的： 我们对Assistant的愿景是帮助你完成任务。 以及他如何结束这一部分的： 所有这一切的共同主题是，我们正在努力为用户节省时间。在谷歌，我们一直对此非常痴迷。就搜索来说，我们一直痴迷于让用户快速得到答案，并给予他们想要的东西。 在谷歌看来，计算机可以帮助你完成任务，通过帮你做事来节省时间。Duplex是最令人印象深刻的例子，一台能够为你打电话的计算机。而且，这个概念也适用于谷歌许多其他的演示，特别是那些基于人工智能的演示：谷歌照片不仅会对你的照片进行分类和标记，现在还会提出具体的编辑建议；谷歌新闻会为你找到你需要的新闻，谷歌地图会为你在附近找到新的餐馆和商店。而且，恰如其分的是，主题演讲以Waymo结束，它将载着你。 谷歌和 Facebook 的哲学一个星期前，马克·扎克伯格（Mark Zuckerberg）在Facebook F8大会的主题演讲中，也有一个特别的部分让我印象深刻： 我相信我们需要设计一种技术，来帮助人们更加紧密地联系在一起。我相信这种情况不会自己发生。因此，要做到这一点，解决方案的一部分就是，有一天我们的技术需要更多地关注人们和我们的关系。现在，我们不能保证我们能做好这件事。这是一件艰难的事情。我们会犯错误，错误将产生后果，我们需要纠正它们。但我可以保证的是，如果我们不在这个问题上努力，这个世界自己不会朝着这个方向发展。 Facebook不仅想为你做事，还想做其首席执行官明确表示不会做的事情。然而，过去一年里，救世主般的热情似乎压倒了扎克伯格，这仅仅意味着Facebook采用了一种比谷歌更极端的做法，但这背后的哲学是一致的：计算机为人类做事。 微软和苹果的哲学早些时候，在微软首席执行官萨蒂亚·纳德拉 (Satya Nadella) 在微软 Build 大会发表主题演讲时，用了一种截然不同的说法；在描述了计算机变得无形，无处不在之后，纳德拉说： 这是我们的机会。 从某种意义上说，这是无止境的，但我们也有责任。我们有责任确保这些技术赋予每个人权力，让这些技术通过确保每个行业都能增长和创造就业机会，来创造公平的增长。作为技术行业中的一员，我们有责任建立人们对技术的信任。汉斯·乔纳斯（Hans Jonas）是一位在五、六十年代工作的哲学家，他写了一篇关于技术和责任的论文……他谈到了要行动，来让行动的效果与永恒的或真正的生活相容。这是我们需要思考的问题，因为他所说的技术的力量，远远超过了我们完全控制它的能力，尤其是它对后代的影响。因此，我们需要制定一套原则来指导我们做出选择，因为我们做出的选择将决定未来……正是这种机会和责任，使我们有理由履行使命，赋予地球上每一个人和每一个组织权力，让它们取得更多的成就。我们专注于技术构建，这样我们就可以增强其他人构建更多技术的能力。我们已经调整了我们的使命，我们构建的产品，我们的商业模式，因此你们的成功就是我们成功的关键。这是完全一致的。 这是技术行业的第二种哲学，它与另一种哲学截然相反：人们期望的不是计算机为你工作，而是计算机使你能够更好、更高效地完成工作。在这种哲学的指导下，责任就不同了。在谷歌主题演讲开场上，皮查伊承认，“我们感到有一种很深的责任感，去做正确的事情”，但这种说法的内涵是谷歌的中心地位和其管理者的直接责任。另一方面，纳德拉坚持认为，责任在于技术行业集体，以及我们所有寻求单独利用技术的人。 计算机是头脑的自行车第二种哲学，即计算机是对人类的一种帮助，而不是他们的替代物，是两者中较老的一种；它最大的支持者，是微软最大的竞争对手，史蒂夫·乔布斯（Steve Jobs），他选择的类比是自行车： 我小时候曾在《科学美国人》上读过一篇文章，文中对比了地球上各种不同物种的移动速率，比如鸟，猫，狗，鱼，山羊等等，当然还有人类，计算它们每移动一公里消耗的热量，最后秃鹫赢了，它的移动效率最高。作为万物之灵的人类，排在倒数几位。不过，杂志特地测量了人类骑自行车的速率。结果把秃鹫远远甩在了身后，在排名上遥遥领先。这篇文章给我留下了深刻的印象，人类擅长发明工具，工具赋予我们奇妙的能力。苹果以前有一条广告：计算机是头脑的自行车，我坚信如果将来有人回顾人类历史，计算机将是人类最伟大的发明。 这正是纳德拉所追求的&#58;“赋予地球上每个人和每个组织权力，以取得更多成就”就是“增强这些人和组织的固有能力”；我们的目标不是为他们做事，而是让他们做以前从未做过的事。此外，需要补充的是，苹果和微软在同一个哲学上仍然存在很大分歧。 鸡和蛋的问题有人认为，这两种哲学源自于它们的历史背景。苹果和微软这两家”头脑自行车”公司成立的时间，只相隔一年，而且几十年来商业模式大致相似：当然，微软销售软件，而苹果销售软件差异化的硬件，但这两家公司的核心都是个人电脑公司，进而也是平台。 另一方面，谷歌和Facebook是互联网的产物，互联网不是通向平台的，而是通向聚合者的。虽然平台需要第三方发挥作用，并通过创建生态系统来构建护城河，但聚合者凭借其固有的实用性，来吸引用户，随着时间的推移，供应商如果希望触达用户，就别无选择，只能遵从聚合者的规则。 商业模式源于这些基本的差异&#58;平台提供商没有广告空间，因为平台的主要功能，是为用户实际需要的应用程序提供舞台。另一方面，聚合者，特别是谷歌和Facebook，主要是处理信息，广告也不过是另一种信息。此外，由于聚合者差异化的关键点是其平台上的用户数量，广告是唯一可能的商业模式；当涉及到广泛采用时，没有比“免费”更重要的吸引点了。 尽管如此，这并没有减少这两种哲学的真实性：谷歌和Facebook一直以为用户做事为前提，就像微软和苹果，一直致力于让用户和开发人员能够做出更多自己完全无法预见的事情一样。 科技公司的阴和阳有两种哲学，并不一定意味着一种是对的，一种是错的：现实是，我们需要两种哲学。有些问题最好靠人类的聪明才智来解决，微软和苹果等公司使这些问题得以解决；有些问题则是需要通过集体行动来解决的。不过，这也解释了为什么谷歌和Facebook从根本上来说更加危险：集体行动传统上是政府的领域，其最佳形式是受民众意愿的限制。另一方面，谷歌和Facebook则不对任何人负责。它们最近受到审查是应该的，甚至可以说应该受到更多的审查。 不过，这种审查以及由此产生的任何法规，都不能忽视这种哲学分歧：创造新的可能性的平台——不仅仅是苹果和微软——在应对即将到来的计算机为人们提供就业机会的浪潮方面，是最重要的经济力量。所以，针对聚合者但限制平台的法规将不可避免地弊大于利。 事实是，我上周写到用户的极度挑剔的情绪，不仅是低端业务颠覆的解药，也是乐观的理由：正如我指出的那样，像苹果和亚马逊这样的公司，从长远来看，可以通过提供卓越的用户体验赢得胜利，但更重要的是，不满的情绪带来的红利，将为建立新企业和创造新的工作机会来缓解这种不满情绪开辟一片新天地。为此，我们需要建立这些平台，是的，我们需要人工智能来为我们做事，这样我们才有时间。 原文链接：https&#58;//stratechery.com/2018/techs-two-philosophies 编译组出品。编辑：郝鹏程 转载来源：科技公司的两种哲学：帮人类做事 vs 为人类赋能]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>苹果公司</tag>
        <tag>Facebook</tag>
        <tag>微软</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度分析：区块链技术未来发展的 8 个趋势]]></title>
    <url>%2F2018%2Fbddbaf4e%2F</url>
    <content type="text"><![CDATA[CB Insights日前发表了一份关于区块链技术的研究报告，结合区块链目前的发展现状，提出了区块链技术未来发展的8个趋势。 编者按：CB Insights日前发表了一份关于区块链技术的研究报告，结合区块链目前的发展现状，提出了区块链技术未来发展的8个趋势。文章由36氪编译，希望能够为你带来启发。 虽然加密货币和加密资产的价格已从2017年的峰值回落，但区块链创业公司的股权投资，在2018年正步入历史高点。 尽管围绕该行业的媒体风暴已经平息，但监管机构仍在采取更积极、更果断的行动，向不良行为者发出传票，并为好的行为者提供指导。此外，尽管谷歌搜索“比特币”和“区块链”指数有所下滑，但2017年ICO热潮、加密货币价格上涨和风险资本投资带来的现金依然充裕，而且正在投入使用。 换句话说，虽然投机炒作基本上已经消失，但工程师正在努力开发，团队正在组建起来，区块链技术的发展仍在快速进行中。 在本报告中，我们将深入探讨影响区块链未来的八大趋势。 具体来说，我们将讨论： ICO：- 风险投资公司如何越来越多地投资曾被视为禁忌的代币和ICO？- 监管活动，以及它如何成为行业参与者的双刃剑风险投资活动：- 顶级风投在区块链领域下注——从基础设施到加密猫- 证券代币作为一种独特的资产类别兴起- 2017年的赢家如何变成了资金经理、风险投资者和收购者企业活动：- 哪些大公司可能会在财报电话会议上虚张声势- 投资增长和既视感的负面案例- 尽管面临挑战，哪些联盟仍在向前迈进？ ICOICO，是希望筹集资金的区块链公司出售代币的行为。根据持有ICO的团队的说法，代币提供了对去中心化生态系统的访问权，或在去中心化生态系统中的效用。代币是稀缺的，如果需求大于供给，代币的价值可能会上升。 例如，如果是一个去中心化的社交网络，代币可能会授予访问权限。如果有更多的人想要访问这个网络，那么代币的价值可能会随着人们购买和出售他们的代币而上升。 在这种情况下，让我们深入探讨一些关键趋势。 ICO与股权融资之间的界限日益模糊在风投用现金换股权的地方，ICO投资者正在用现金换代币。 股权融资与 ICO 之间的界限日益模糊。传统的股权投资者，正在投资那些计划在自己的商业模式中使用代币的公司。 它们正通过预售、 SAFT 合约(如下所述)和符合监管规定的发行方式直接获取代币，这在几个月前似乎是不可能的。 预售是在大型的公开ICO之前举行的。它们不遵循统一的结构。在某些情况下，预售向早期投资者(经认证和未经认证)提供折扣的代币。在另一些情况下，团队在ICO前出售少量股权以换取资金。ICO价格昂贵，经常需要法律、营销和咨询费用。向风险投资预售，可以在通过ICO获取现金之前支付这些费用。 在其他情况下，经认证的投资者通过加密货币购买协议购买代币。一个常见的版本是SAFT (Safe Agreement for Future Tokens)。SAFT充当代币的未来合约，合约在部署有功能的网络后进行转换。因此，创业公司并不出售股权，而是出售其网络中购买某些代币的权利。这种转换可能发生在首次出售后数年。 预售和SAFT的兴起，反映出风险基金希望从代币经济中获利。回想一下，2017年上市的风投支持的科技公司从首次融资到IPO之间时间约为9年。代币通常在网络启动之前就能在交易所交易，并提供近乎即时的流动性。至于SAFT，代币转换可能在一两年内发生，也为风险投资者提供了快速的流动性。 此外，许多风险公司都有规定，要求它们投资于特定资产类别。SAFT和某些预售，可能是一种在符合要求的情况下投资代币的方式，相比之下，通过交易所或直接通过ICO购买代币可能不符合这些要求。 向预售的转变在数据中得到了证实，风险投资呈上升趋势，纯粹的ICO则呈下降趋势。 根据TokenData的数据，今年2月，ICO通过私人融资和预售筹集了近60 %的资金。以下是一些数据，其中“其他”风险投资股权交易在区块链交易中的份额大幅上升。其中包括一些私人投资和预售。 更多证据显示，纯ICO交易和价格均出现下跌；3月，113家ICO的收盘价约为5亿美元，低于2月份的121家的12亿美元。换句话说，2月份收盘的ICO平均筹资约1000万美元，3月份平均筹资450万美元。作为提醒，这些数字有些滞后——我们只计算已完成的ICO，没计算仍在进行的ICO。 一个值得关注的预售例子是Telegram，其举行了非常大规模的预售，以至于它取消了公开发售的计划。这个加密信息服务提供商，通过出售“加密货币购买协议”(而不是股票)，在两轮独立的私人交易中，从175名私人投资者那里筹集到17亿美元。 另一个区块链团队，Basis，从2018年第一季度末开始，通过的SAFT销售，从225名投资者那里筹集到了1.25亿美元。Basis正在构建一种“稳定的货币（stablecoin）”，这种货币的波动性要小于其他加密货币。 预售就是一个混合包。一方面，它们仍然有相当大的风险，监管机构仍未充分介入。另一方面，它们将风险转移到经认证的风险投资者身上，这对消费者和监管机构来说都是好事。随着监管机构继续打击公共ICO，我们预计这种向预售和私下销售的转变将继续下去。 监管活动是一把双刃剑——对ICO不利，对其他的形式有利ICO传道者喜欢争辩说，ICO是新的金融工具，需要新的立法和监管机构。到目前为止，美国监管机构似乎并不同意这种说法。包括SEC、CFTC和FinCEN在内的美国监管机构，对新的融资机制普遍表现出怀疑和不满。 与此同时，监管机构对该行业日益严格的审查，实际上是在鼓励新公司进入该行业。 SEC、CFTC和FinCEN (以及其他政府机构)似乎正以不同的方式与该行业打交道。 SEC 认为，大多数代币都是证券。2017年11月，SEC主席杰伊·克莱顿（Jay Clayton）表示&#58;“我还没有看到一个有足够多的安全标志的ICO。”三个月后，也就是今年2月，克莱顿在国会面前说&#58;“我想回到分离ICO和加密货币的问题上来。ICO是证券发行，我们应该像监管证券发行一样监管它们。”与此同时，SEC也传唤了一些持有ICO的组织和持有加密货币的对冲基金。 从其言论和活动来看，SEC似乎正在将ICO视为证券。这对持有它们的团队或它们的法律顾问来说不是什么好兆头。这些公司现在可能会面临法律后果。与此同时，SEC似乎正在将一些现有的加密资产视为货币或大宗商品，而不是证券。 美国财政部金融犯罪执法网络FinCEN，在3月份给参议员罗恩·怀登（Ron Wyden，参议院金融委员会的成员)写了一封信，信中写道&#58;“开发商出售可转换的虚拟货币，或者以ICO或代币的形式，来兑换另一种代替货币的价值，是货币发行者，必须遵守相关的规定。”这种将加密货币视为货币的观点，与CFTC将加密货币定义为商品的定义形成了鲜明对比。FinCEN的结论，使发行代币的团队可能面临被罚款或其他影响的重大风险。 最重要的是，这三种不同的定义，突出了监管上的分歧和混乱。行业政策组织(如Coin Center)已经迅速向立法者和监管者提供有关区块链技术的教育资源。著名的风投Andreessen Horowitz和Union Square Ventures，甚至私下约见SEC，寻求虚构货币的避风港。 另一方面，监管声明也导致了一些关键行业的转变。如上所述，SEC明显区分了作为货币和证券的加密资产，这有助于两方面的发展。 首先，SEC加强了监管审查，导致许多加密公司在融资方面采取了更加谨慎的做法。合法的加密公司正在转向风险投资和避免纯粹的ICO，而其他公司则在追求ICO，但要确保他们的代币发行符合要求。一个提供合规解决方案的平台是Templum，它分两轮筹集了近1300万美元。Templum为代币化的资产产品(作为证券的ICOs)和后续二级交易提供“符合法规的解决方案”。 在SEC文件中，也有其他自我监管的尝试；公司正在更频繁地提交这些文件。在一项分析中，2017年有12家与“加密”和“区块链”相关的公司向SEC提交了文件，2018年已有23家提交了文件。 SEC立场的第二个影响，以及更广泛的监管透明度，鼓励了一些传统的企业在该行业采取第一步行动。Square 的 Cash 应用程序现在允许用户交易比特币，而Robinhood则开始提供一些加密资产的交易。5月初，高盛宣布将开设比特币交易业务。 最终，监管似乎对未受监管的公开ICO造成了破坏，但对其他大多数公司来说，这是福音。预计监管机构将对ICO进行越来越频繁的打击，包括罚款和起诉。与此同时，推动行业自律的努力令人鼓舞。期望行业参与者和监管机构就更明确的立法和监管达成一致。 风险投资活动2017年，与区块链公司有关的风险投资活动——股权融资，而非ICO——达到了最高点：230多宗交易，超过10亿美元的资金，分别来自于141家风投公司、119家企业和它们的风险投资部门。 下面，我们将探讨影响该行业风险投资的三个趋势。 顶级风投正在接受代币，从“区块链”转向“加密货币”ICO的兴起促使风投重新考虑其传统的融资机制。正如弗雷德·威尔逊(Fred Wilson) (Union Square Ventures的著名合伙人)在其博客上写道，“在新模式、代币刚刚起步的时候，它提出了一个问题，即它将如何影响我们的投资方式。” 事实上，风险公司正越来越多地投资代币。有证据表明，该行业最活跃的两家风险投资公司——Andreessen Horowitz和Union Square Ventures——正越来越广泛地投资于公共区块链和加密资产。 两家公司都以股权投资者(Polychain Capital)和有限合伙人(MetaStable)的身份投资了加密货币对冲基金。据报道，Andreessen还准备成立一个专门的加密资产基金。此外，两家公司的投资组合中的公司都持有或计划持有代币销售。 下面，我们将展示它们在这一领域的投资战略是如何演变的。我们重点介绍股权投资、对加密货币对冲基金的投资以及相关的投资组合公司。两家公司最近的投资都反映出向“加密货币”而不是“区块链技术”的转变。其中的一些投资，比如Andreessen对Basis的投资，使用了SAFT合约。 来看看Union Square Ventures，弗雷德·威尔逊在最近的一篇博客文章中提出了他的观点&#58;“如果2016年下半年和2017年全年都是关于筹集资金以资助开发工作(并对所有这些进行推测)的，那么我们肯定会觉得，2018年是我们开始获得去中心化应用程序的一年。” 事实上，Union Square Ventures在该领域的一些投资与去中心化应用程序有关。例如，CryptoKitties就是一种去中心化应用程序。Andreessen也参与了其1200万美元的A轮融资。另一个例子是OpenBazaar，它正在建立一个去中心化的市场。OpenBazaar已经从这两个投资者那里获得了连续的投资。 Union Square Ventures还投资了两家希望与比特币竞争的加密货币团队。今年2月，由于比特币面临交易延迟，Algorand筹集了400万美元种子资金，来构建一个高速的支付协议。Chia是一种新的“绿色”加密货币，它使用比比特币的“工作量证明”更节能的共识机制。公司在3月底筹集了340万美元的种子资金。 转到Andreessen Horowitz，随着时间的推移，该公司更明确地改变了在该领域的投资战略。 Andreessen早期的投资集中在比特币和加密货币交易上。该公司参加了Earn的多轮融资，这是第一个比特币采矿公司，后来被Coinbase收购。Andreessen随后转向了企业用例，投资了Axoni和Ripple。 相比之下，Andreessen最近在区块链的投资偏向于基础设施建设。Dfinity希望成为Ethereum的竞争对手，而Orchid，旨在创建更具包容性的、不受约束的互联网。Harbor正在部署一个“证券代币”协议(下面将详细介绍)。 值得注意的是，Dfinity在2017年2月举办了一个“种子阶段”的ICO，仅在后来从Polychain Capital和Andresen Horowitz筹集了6100万美元。该公司首席执行官多米尼克·威廉姆斯( Dominic Williams )表示，鉴于监管活动，该公司对举行另一次公开ICO持谨慎态度。 总之，Andreessen的战略经历了一个明确的转变——从比特币到区块链，再到加密货币。Union Square Ventures的转变较少，该公司从未投资企业区块链供应商。两家公司都转向代币，首先是通过加密货币对冲基金，现在是通过更直接的投资，这是值得注意的，红杉资本、Bain Capital Ventures和 Founders Fund等公司也在进行投资。考虑到涉及的名字类别，这种趋势很可能会持续下去。 投资者的兴趣正在增加 法规也催生了一批新的公司，来构建证券代币平台。 证券代币就是它们听起来的样子；区块链上的证券。证券代币可以数字化地代表任何数量的现实世界资产，从房地产或车辆所有权到公司的股票。这些代币与实用的工具代币明显不同，实用的工具代币表示给定网络的访问权或网络内的实用工具。最重要的是，证券代币必须遵守证券法规。 证券代币也是“可编程的”。这意味着代码可以决定如何使用它们。例如，以数字形式表示的贷款，可以根据商定的还款时间表自动偿还。这种代码可以在不使用传统中间人(如银行)的情况下执行。 另一个优势是流动性。将缺乏流动性的资产(如风险基金或汽车)代币化，可以使通过网络交易这些资产变得更容易，流动性也会提高，进而减少交易的障碍。 Harbor就是一家从事这方面工作的公司。Andreessen Horowitz和Founders Fund参与了Harbor在4月份进行的2800万美元B轮融资。Harbor的“R -代币标准”将代币中的规则编码。这些规则只允许合格的投资者投资，并要求他们遵守KYC（充分了解你的客户）和AML（反洗钱）规则。 Polymath也是这一领域的公司。Polymath希望帮助“数万亿美元的金融证券转移到区块链上。”在其发布时，该公司的POLY 代币还希望优化现有的规则，如KYC / AML。 其他研究证券代币的团队还有Overstock的tZero、CoinList 和 Securitize。总而言之，证券代币在法律上似乎没有ICO那么模糊不清，尤其是在监管调查中。顶级投资者也赞同这种做法，我们预计将会出现更多证券化的代币公司。 现金充裕的加密货币公司正在变成资金管理公司、风险投资者和收购者加密货币拟议的使用案例，从去中心化的支付网络到用户控制的社交网络，再到预测市场等，尚未得到实质性的用户支持。 许多盈利能力非常强、资金充足的区块链公司都从投机活动中获利，而不是从实际的运用中。这些包括交易，如 Coinbase，或者基础层协议，比如 Ethereum。 由于2017年的狂热，这些公司赚了很多钱。现在，他们正在投资风险资本，疯狂收购，或者建立“生态系统基金”。所有公司都在努力寻找用例和用户。 交易所意识到了猖獗的投机行为，并正通过风险投资寻找真正的投资案例。Coinbase推出了自己的风险投资部门Coinbase Ventures 。5月初，一家中国交易所火币宣布成立一支10亿美元的基金，用于开发亚洲区块链生态系统。Binance——按交易量计算最大的交易所——也宣布为百慕大区块链生态系统投资1500万美元。 基础层协议仍在构建工作平台。为了激励去中心化应用程序的发展，一些公司正在启动“生态系统基金”。“Dfinity将与Ethereum展开竞争，今年2月从 Andreessen 和 Polychain 获得了6100万美元的资金。 大部分资金将用于激励开发人员在Dfinity协议的基础上进行开发。同样，Blockstack去年8月宣布成立一支2500万美元的基金，用于在其平台之上构建应用生态系统。而且，在5月初，IOTA启动了IOTA生态系统，以鼓励其物联网集中协议的开发。 企业也变得越来越“贪婪”。今年2月，二月份，OTC服务商 Circle 以4亿美元的价格收购了加密货币交易所 Poloniex。Circle 过去一直与美国监管机构密切合作，这对 Poloniex 的未来有极大的帮助 。按交易量计算，Poloniex是全球的顶级交易所之一。 4月13日，Coinbase收购了去中心化应用浏览器和加密钱包Cipher。几天后，该交易所获收购了Earn(据报道为1.2亿美元)，并任命其首席执行官巴拉吉·斯里尼瓦桑( Balaji Srinivasan )担任Coinbase新的首席技术官。Earn经历了多次迭代——该公司最初是一家比特币矿商，然后是一家芯片制造商，最后是一个社交网络，用户可以通过付费(用加密货币)来回复电子邮件。目前还不清楚Coinbase 将如何把Earn整合到自己的业务中。不过，这笔交易表明，除了投机之外，Coinbase还在押注于行业的使用案例。 再加上监管方面的考虑，我们预计，资金充裕的公司将继续投资于新的令人兴奋的用例。有监管风险的盈利公司可能会大举收购，Circle收购Poloniex就是例证。突然获得大量现金的团队将把钱花在开发各自的生态系统上。所有因2017年的投机狂潮而暴富的公司，都将会继续部署资金，寻找区块链的杀手级应用。 企业活动在财报电话会议上提到“区块链”的次数快速增长截至4月底，在2018年第一季度财报电话会议上，“区块链”已经被提及近300次。这表明，企业和分析师对这项技术有着真正的兴趣。 从纳斯达克到联邦快递，各个垂直行业的公司都在财报电话会议中提到了这项技术。一些公司甚至表示要在核心产品上采用这种技术，然后股票价格就出现了迷之飙升。 不过，最近的飙升并不令人意外。或许更值得注意的是，其中一些公司已经在2015年开始谈论这项技术了，远远早于去年的狂热。 万事达卡首席执行官阿贾伊·班加（Ajay Banga）在2015年第4季度财报电话会议上强调了公司对这项技术的兴趣。“我们已经在这个领域进行了一段时间的实验，并申请了专利，进行了风险投资。” 两年后，在2017年第4季度，班加详细地谈到了区块链。“我们这个领域有很多事情要做：虚拟卡片、万事达信用卡、 Vocalink，所有这些都是为了支持跨境和国内的 B2B 支付流。这就是我们对区块链的想法。” 然而，在这两次财报电话会议之间的两年时间里，万事达一次都没有提及区块链技术。此外，该公司在2018年第1季度的财报电话会议中，页没有提及区块链技术。这表明该公司对该技术的投入尚未成熟，或者是随着市场的广泛炒作而拿捏不定。 其他公司则表现出更加持续的关注。自2013年以来，在财报电话会议中提及区块链最多的公司是&#58;Overstock( 182次)、纳斯达克( 57次)、Broadridge Financial Solutions( 51次)、IBM ( 48次)和US Global Investors( 35次)。除了US Global Investors，所有这些公司都连续几个季度谈到了区块链技术。 Overstock正在all in。该公司的核心业务仍然是其电子商务市场，但首席执行官帕特里克·伯恩(Patrick Byrne)则专注于区块链技术。Overstock宣布于2014年9月接受比特币付款。2017年8月，它宣布接受其他加密货币(如以太币和莱特币 )。接受加密货币使 Overstock 成为一个特例；加密货币的交易用途仍然有限，特别是在顶级电子商务交易中。 伯恩甚至在2016年第4季度财报电话会议中，将 Overstock 描述为一家“控股公司”。“想象一下（ Overstock ）是一家控股公司，也是一家&#91;……&#93;每年亏损7500万美元互联网零售公司。另一面是Medici Ventures，它在区块链和和金融技术方面有很多投资。” 另一家经常谈论区块链技术的公司是纳斯达克。该公司在私人股票交易平台 Nasdaq Private Market产品中测试了这种技术，但财报电话会议记录和其他数据点都显示，这种技术的部署有些滞后。 在2015年第2季度，纳斯达克表示，它正在“探索区块链技术在Nasdaq Private Market的应用，并计划在2015年第4季度首次推出这项技术。”随着这项技术的测试，NPM和区块链在几个季度内都齐头并进。 到了2016年第1季度，财报电话会议中称这项技术已经获得了成功。“我们会继续以崭新和创新的方法优化这个平台，以减低私营机构现在所面对的行政复杂性和成本。这一成功，是继上个季度在私有领域成功执行第一个启用区块链的交易之后的又一次成功。” 在接下来的几个季度中，纳斯达克同时提到NPM和区块链的频率变低。相反，它更经常提到它的新产品纳斯达克金融框架(Nasdaq Financial Framework，NFF )。NFF于2016年推出，帮助客户将清算和结算等业务流程与新技术相结合。NFF是纳斯达克向金融科技更广泛转变的一部分。到2017年，纳斯达克的10-K文件完全没有提到区块链技术与NPM的关系。所有这一切可能表明推动力和部署有限，或者向NFF产品的全面战略转变。 与此同时，纳斯达克对加密货币和加密货币交易采取了更为慎重的态度。正如纳斯达克总裁兼首席执行官阿迪纳·弗里德曼( Adena Friedman )在4月接受采访时所说&#58;“我相信，数字货币将继续存在……这只是一个问题，即需要多长时间才能成熟……一旦你看到它，就会说，‘我们想为它提供一个受监管的市场吗？’当然，纳斯达克会考虑的。” 尽管如此，发出声明并不需要太多成本。什么公司真正感兴趣，什么不是，还有待观察。衡量公司真正兴趣的一个标准可能是投资活动，我们将在下一个趋势中深入探讨这一点。 公司投资和合作伙伴关系激增，但我们以前也经历过2017年，有119家公司和公司的风投部门投资了区块链技术，这是迄今为止最多的一年。此外，2018年第一季度的数量接近这一数字的一半，这意味着2018年将是该行业公司交易的一个重要年份。 最近的这一激增，可能意味着公司正在参与其中了，但许多公司已经参与其中相当一段时间了。事实上，一些早期的、备受吹捧的伙伴关系已经停滞不前，或者完全瓦解，这表明新的伙伴关系可能面临类似的考验。 2017年1月，Du Telecom与NMC Healthcare 合作，探索基于区块链的医疗记录。然而，Du Telecom的前项目负责人已经离开了公司，后来也没有关于该项目的进一步声明。该项目本计划于2018年初启动。 矿业公司BHP Billiton也上演了类似的故事。BHP Billiton于2016年启动了区块链项目，以加强安全性，并跟踪实时采矿数据。2017年4月，BHP Billiton的项目负责人离开，加入了Consensys ( 一家Ethereum开发公司)，目前还没有关于该项目的进一步消息。 金融服务公司也受到了挑战。有传言称，摩根大通正在考虑分拆其内部的区块链项目Quorum。该项目负责人安珀·鲍德( Amber Baldet )于4月初离开了公司。英国《金融时报》报道称，摩根大通不愿使用由竞争对手银行运行的分布式分类账来获取关键的数据。 其他公司正在关注的，不仅仅是联盟和公司用例的范畴。2017年第4季度，Theta Labs从索尼创新基金和贝塔斯曼数字媒体投资公司(以及其他公司)获得了800万美元的种子资金。Theta 实验室正在建立一个去中心化的视频流平台，并使用本地代币(Theta)。这是这两家投资者首次在区块链技术领域进行投资。 随着越来越多的公司参与其中，我们预计许多公司会发现一些熟悉的问题。在本报告中，一个贯穿始终的主题是，区块链技术并不新鲜，但它的重要性日益突出。由于价格大幅上涨，更多的利益相关方坐到了谈判桌前。问题仍然是：区块链技术的杀手级应用程序是什么？在部署可能的解决方案之前，企业应该三思而后行。 虽然联盟领先，但问题依然存在如上所述，2017年，119家公司向区块链公司注入了资本。其中39家参加了向金融服务软件提供商和R3联盟的1.07亿美元的A轮融资。值得注意的是，2015年也出现了类似的情况&#58; 89家公司在该行业进行了直接股权投资，42家公司投资了R3。 虽然其他联盟——特别是Hyperledger和Enterprise Ethereum Alliance( EEA )——出现并成为头条新闻，但联盟的努力仍然没有什么可展示的。成员继续波动，试点项目和概念证明已经大张旗鼓地开始，然后慢慢地从公众视线中消失。联盟尚未将区块链和分布式分类帐解决方案，有意义地集成到公司IT堆栈中。 理论上来说，联盟应把同一个垂直的组织纳入分布式数据库，从而为传统上具有竞争力的公司建立一个合作中立的基础。在实践中，促进市场参与者之间的合作具有挑战性。分布式分类帐是协作工具，竞争对手通常不喜欢协作。 R3既是软件提供商，也可能是最知名的金融服务集团。该公司正在构建Corda &#58;开源、分布式分类帐软件，主要面向金融服务机构。为了鼓励采用，R3组建了一个由付费会员组成的私人联盟，其中大多数是银行。 如上所述，R3自2015年以来的几轮融资中已筹到1亿多美元。第一次融资三年后，R3宣布了一些试点项目，并发布了Corda的公开版本。然而，该联盟仍面临诸多挑战。 在DTCC的金融科技研讨会上，R3 Todd McDonald的联合创始人谈到了一些试点项目面临的一些法律问题，尽管该技术本身如所希望的那样发挥了作用。“从法律的角度来看， 一笔交易，大约有七、九张纸需要签署……这一切都不容易。我们需要引入现有的法律架构。还有很多工作要做。” 尽管如此，R3现在有200多个成员，其试点项目尽管数量有限，规模较小，但已经（宣称）获得了一些成功。该公司为银团贷款(与Finastra合作)以及跨境支付部署了解决方案。 Enterprise Ethereum Alliance是另一个联盟，拥有500多个成员。虽然成立于一年多前，但该联盟一直保持沉默，只是刚刚公布了其第一份“路线图”，概述了它的开放标准工作。 由Linux基金会管理的Hyperledger是一项开源的跨行业联盟，旨在为企业创建分布式分类帐框架。 该联盟现在有200多个成员和各种工作组正在探索分布式分类账用例。尽管Hyperledger在2017年看到一些成员流失，但它还增加了60个成员和3个新框架：Burrow，Indy和Quilt。 一些IT咨询公司在自己的区块链产品中使用Hyperledger。IBM区块链是一个商业版的分类帐。去年，沃尔玛、克罗格和雀巢利用IBM区块链公司跟踪供应链中的食品。最近，中国科技巨头华为宣布了一个以分类账为动力的区块链。这将允许客户围绕供应链以及其他使用情形构建智能合约应用程序。 Ripple是这个群体中的一个异类；它不是一个联盟，而是组装使用其软件的联盟。Ripple获得了9400万美元的风险融资，用于构建跨境支付解决方案。今年3月，Ripple表示，它正在构建一个去中心化的支付应用程序，用于60多家日本银行之间的快速交易。 Ripple的加密货币XRP引起了一些争议。虽然Ripple的私人市场估值约为2.55亿美元(截至2016年9月的5500万美元B轮融资)，但XRP的市值为260亿美元(截至2018月4月17日)。市场对Ripple软件的估值远低于其相关的加密货币。这两种估值之间的巨大差异表明市场发生了更广泛的变化，因为投资者现在关注的是加密货币(如XRP )，而不是区块链软件(如Ripple)。 Ripple拥有大部分XRP，并以意想不到的方式部署了它。有一次，该公司投资2500万美元用于家庭存储和租赁创业公司Omni。在另一个项目中，它向 Blockchain Capital 投资了2500万美元，这是该公司自己的投资者之一。 面对这一切，以企业为中心的联盟正面临一场硬仗。 一些公司得出结论，区块链技术可能是一个正在寻找问题的解决方案。DTCC最近以更便宜的替代方案为由，搁置了区块链的回购协议交易。去年，区块链供应商 Paxos与Euroclear之间的合作关系破裂。 对于R3、EEA、Hyperledger和Ripple来说，2017年是一个重要的年份——但问题依然存在：这些联盟中的哪一个将是首批推出大规模实用产品的？ 与此同时，随着联盟加强其队伍并探索用例，它们还应该关注互操作性。对于以合作为基础的技术来说，它很可能不会是一个赢家通吃的场景。 结语：前方的道路2018年将是区块链技术的又一个突破年。尽管监管还没有给出明确的结论，但投资者仍在向该行业投入大量资本，团队正在吸引人才并挖掘新的使用案例。 不过，投资者应保持谨慎。毕竟，大多数问题可能不需要区块链的解决方案。不过，2017年大量现金的注入，将为各个团队寻找区块链杀手级应用提供跑道。 原文链接：https&#58;//www.cbinsights.com/research/blockchain-future-trends/ 编译组出品。编辑：郝鹏程 转载来源：深度分析：区块链技术未来发展的 8 个趋势]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
        <tag>比特币</tag>
        <tag>区块链</tag>
        <tag>金融</tag>
        <tag>Square</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小程序•小故事(9)——音视频组件]]></title>
    <url>%2F2018%2Fa5d0ffe0%2F</url>
    <content type="text"><![CDATA[今天，我们跟大家分享小程序「音视频组件」背后的故事 转载来源：小程序•小故事(9)——音视频组件]]></content>
      <tags>
        <tag>微信开发者</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分销模式不是原罪，知识付费正急于电商化]]></title>
    <url>%2F2018%2F63b01543%2F</url>
    <content type="text"><![CDATA[知识付费没有被叫做“知识社交”，可在一轮轮刷屏微信朋友圈的营销过后，知识付费平台们在“分销+营销”并行的模式上可谓屡试不爽。试图找到知识付费平台疯狂“刷屏”的答案，不妨先来回顾一下大家熟悉的三类产品：网红电商拼多多、一度火爆的直播答题、时下风靡的游戏小程序。 知识付费没有被叫做“知识社交”，可在一轮轮刷屏微信朋友圈的营销过后，知识付费平台们在“分销+营销”并行的模式上可谓屡试不爽。试图找到知识付费平台疯狂“刷屏”的答案，不妨先来回顾一下大家熟悉的三类产品：网红电商拼多多、一度火爆的直播答题、时下风靡的游戏小程序。 “社交+”的黄金法则在流量红利消失成为共识的时候，拼多多在三年不到的时间内做到了400亿的恐怖规模，较于淘宝、京东之类的“传统电商”，拼多多的创新之处可以归结如下： 首先是拼团，原价59元的衣服，通过拼团只需要39元，用户可以把拼团链接朋友圈或微信群等社交渠道；其次是砍价，商品链接发送给好友，点击链接后便会显示相应砍掉的价格，以更低或者免费的形式获得商品；再次是分享，拼多多的运营活动不乏“1分钱抽大奖”、“天天领现金”、“现金签到”、“助力享免单”等，参与门槛正是分享链接给好友。 曾经火爆一时的直播答题，同样有一个巧妙的设置，用户把专享邀请码分享给朋友，可以获得一次复活机会；这在最近风靡各个微信群的“弹球王者”等游戏小程序上得到了继承，游戏结束后可以不同的微信群，以换取复活的机会。 不难从中总结出共同的关键词，即社交裂变。在流量越来越集中，竞争门槛越来越高的时候，尽其所能地搭上社交关系，在一次次分享转发中裂变为病毒式传播，不失为流量获取的一条捷径。尽管腾讯为此设置了近乎苛刻的标准，比如不允许诱导分享，不允许利益诱惑，不允许夸张的文案，“社交+”照旧成了不少运营者心中的黄金法则，一茬接着一茬的知识付费课程也不例外。 知识付费的电商化知识付费一轮接着一轮的刷屏，目的恐怕不是成为寄生在微信等社交平台上，而是指向了这样一个事实：蹭流量只是手段，电商化才是归途。 有人总结过知识付费课程刷屏的几大特征： 1、红底、大字“超市”系海报；2、10W+、爆款一个不少；3、扫你的码，送我的钱；4、错过一天，再等一年；5、功利性的传播文案。 这个略带调侃型的总结并非没有道理，海报、爆款、文案、限时等无不是电商运营常见的手段，至于“分销”的销售模式，一方面是当前最行之有效的流量获取途径，另一方面也有营销加持的因素，甚至说承担了知识付费向电商化发展过渡的使命。 在知识付费还处于混沌期的时候，就已经出现了“分销”的尝试，典型的就是为罗振宇“代班”被外界熟知的樊登。创立于2013年的“樊登读书会”，很早就尝试过通过地方代理销售会员卡的玩法，与各地有独立法人资质的公司签订代理合同，并将销售的一半分给代理商。到2018年初的时候，“樊登读书会”的注册会员人数近600万，实际付费会员达300万，在全球设立了超过1500家分会，年收入过亿。 如果说“樊登读书会”的崛起依赖的是线下模式，网易云课堂、喜马拉雅等玩家更具备所谓的互联网思维。 《网易运营方法论》原价199元，促销价只要39.9元，并且采用了分销模式；新世相在被口水淹没前也曾成功运营过《成为不可替代的人》精品课，以99.9元的定价和一级分销的形式，分享可得49.9元；千聊推出的《掌握知识付费的底层逻辑》，同样采用了二级分销，一级分销可获得70%提成，二级分销可获得20%提成…… 从结果来看，《网易运营方法论》的参与人数在20万以上，新世相的职场课在24小时内卖了近8万份，千聊的课程也很快卖到了10万份。同时也出现了一系列连锁反应，网易开年大课被微信封掉后又解封，千聊的分享链接被微信封掉后，还导致自家APP被App Store下架。 和电商领域的拼多多一样，在流量成本越来越贵的情况下，利用“分销”的思路打通社交关系链，进而完成低成本的拉新。同时也和早期的电商一样，知识付费课程在野蛮生长之后，谁拿到了更多的流量，或者说低成本获得流量的方法，无疑多了几分胜算。 分销是知识付费的必然严格来说，分销模式的存在并不缺少合理性，线下星罗棋布的代理商和门店是分销，诸如返利网等电商产业链上的关键角色，价值也是分销。而“分销”之所以成为知识付费的“敏感词”，并被质疑带传销属性，还要归咎于大众认知的错位。 好比说50元的分销课程，如果别人通过你分享的海报购买，随即可以获得一定比例的分成，这也是知识付费的“分销”模式被质疑传销的关键所在。需要厘清的前提是：知识付费课程本身是一件商品吗？如果答案是肯定的，本质上和电商平台的返利、导购没有本质区别，不管是今日头条、阿里妈妈还是京东，都有着类似的商业模式。如果答案是否定的，各大知识付费平台恐怕早就被查封。 至少就目前来看，知识付费课程的源源不断，分销模式已经被大多数玩家效仿，离不开三个必然趋势：- 当免费泛滥的时候，付费是必然。易观在一篇报告中将知识共享分为三个阶段，百度百科、互动百科等静态知识平台，百度知道、知乎等动态知识社区，然后才是在行、分答等知识变现平台，当然第三个阶段中不乏上一个阶段的玩家，比如网易云课堂、喜马拉雅、知乎等等。 可以肯定的是，互联网上免费的知识存量远远高于各个国家的图书馆，付费得到的往往是其中一隅。但当知识免费且泛滥的时候，时间反倒成了稀缺品，面对庞大的知识海洋，倾向于用更少的时间来获取需要的知识。这决定了知识付费早期的产品形态，要么是经验性的分享，要么是技能型的传授，要么是碎片化知识的二次加工。也决定了知识付费产品的商业形态，需要快且准地找到买单者。- 知识付费成为一门生意的时候，产业链条化是必然。如今外界对知识付费的讨论，早已升级为“知识付费是不是一门好生意”，对于知识付费的正当性几乎不再存疑。而当知识付费成为一门生意之后，产业链条化就是必然，内容生产方、平台方、销售方和消费者各司其职。 知识付费课程对于“分销”机制的依赖恰恰是不成熟的表现，恰是因为缺少完整的产业链，导致对其中一环过渡施压。同时也是知识付费进行市场教育的必然过程，知识付费的平台方们完全可以进行中规中矩的玩法，代价却是很可能将整个行业扼杀在萌芽之中，没有持续性的流量和收入，内容生产者势必难以坚持。就这个角度来看，知识付费早期的娱乐化、刷屏等都不乏合理解释。- 市场混乱到一定程度的时候，淘汰和优化是必然。知识付费兴起的时间并不长，焦点就几经变换，付费问答、付费社区、付费音频以及形式各异的付费课程。知识付费不是眼球经济，运营着所面对的不只是拉新的难题，还有打开率、完成率、复购率等一系列考核因素。 恰因如此，知识付费还要经历很长的试错期，伴随着知识付费产品的不断丰富，毕竟目前已经开始向文史、财经、亲子、外语、艺术等垂直领域延伸。但产品多元化和大爆炸的同时，也意味着流量的进一步分散，不可避免的进行一轮又一轮洗牌赛，最终淘汰出符合大众需求的知识付费产品，符合大众消费习惯的商业模式。 由此也就不难解释分销模式流行的时间节点，知识付费已经走过了早期的市场教育阶段，产业链条化和商业模式的优化，将是下一阶段的着力点。在知识付费轮番的尝试中，分销模式最终脱颖而出。只是对于知识付费玩家来说，分销也容易诱导投机和分一杯羹的心态，恐将逐渐失去生存空间。 知识付费仍需要不断进化作为消费者，我们可以怀着包容的心态容许知识付费平台犯错，可对于知识付费玩家而言，该如何让用户心甘情愿的掏钱？在时间红利结束后如何谋变？分销模式不缺乏合理性，但市场中依旧出现了一些不和谐的现象，还需要从课程本身去思考进化的方向：- 知识付费课程的去功利化有人说中产阶级的“焦虑”是知识付费存在的诱因，市场上也充斥着各类“通往财富之路”、“XX天学会XXX”之类的付费内容，中产阶级的身份焦虑、竞争焦虑、安全焦虑、财富焦虑等等，可能会成为知识付费瞄准的用户痒点，去“焦虑”化则是知识付费摆脱“知识骗子”的必然选择。- 从重营销转向重经营分销模式所带来的流量高潮，足以让无数参与者为之兴奋，致命的问题却在于：用户的注意力被过渡聚焦在分销利润和营销上，课程内容反倒成了次要因素。营销上的成功是一个好的开局，如何进行持续的用户经营，解决打开率、复购率等外界诟病的痛点，则是知识付费课程逃不掉的问题。- 合理的定价机制原价XXX，限时价XX，分销后价格X.X的做法，可以说是知识付费向电商运营学习的精髓，也是流量的保障之一。在这个阶段过去后，如何让用户对知识付费课程有一个理性的价格认知，使得内容消费成为一种潮流。- 培育精准的受众几乎所有的知识付费产品都在广撒网，怎么沉淀下忠实用户，针对性地提供优质内容，同样需要思考。- 持续性打造优质内容大多数知识付费平台过于依赖明星、大V，缺少明确的内容筛选机制，也缺少“草根大V”的上升渠道。- 解决用户注意力的问题很多人认为知识付费是个伪需求，论据就是知识付费课程不明显的学习效果。在现有的模式下，要么是纯粹的听讲，要么是视频观看，都停留在被动学习的层面，知识留存率可想而知。当然，知识付费很难做到像高中课堂式的教授和实践，否则就演变成了在线教育，但从单向传授到双向沟通是必然趋势，并以此来解决用户注意力稀缺的问题。- “隐形贫困人口”的启示新近流行一个词叫“隐形贫困人口”，指那些看起来有吃有喝有玩，实际上非常穷的人。运营、营销、技术等技能型的隐形贫困人口，可能是知识付费最应该聚焦的人群，不缺少一定的专业基础，又处于“学而不精”的尴尬境地，相比于小白，这些人才是知识付费玩家应该占领的头批用户。 或许可以列出这样一个公式：被认可的商业模式=稳定的流量精准的受众优秀的产品。拼多多走出舆论困境，进而走向资本的怀抱，在于打通了流量、产品和用户的完整环节。知识付费的所有过程都才刚刚开始，为了解决流量问题，分销模式是无可厚非的选择，只是在内容和用户经营上还有很长的路要走。 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 转载来源：分销模式不是原罪，知识付费正急于电商化]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>市场营销</tag>
        <tag>电子商务</tag>
        <tag>移动互联网</tag>
        <tag>京东</tag>
        <tag>大众汽车</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说shuō客？坐骑qí？我怕是上了个假学！]]></title>
    <url>%2F2018%2F36712e53%2F</url>
    <content type="text"><![CDATA[这可能是我离孔乙己最近的一次了。 转载来源：说shuō客？坐骑qí？我怕是上了个假学！]]></content>
      <tags>
        <tag>Vista看天下</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国零售新物种研究报告（二）——泛生鲜模式分析]]></title>
    <url>%2F2018%2F83db56f6%2F</url>
    <content type="text"><![CDATA[产地直采与冷链物流运用对于解决上述痛点至关重要；供应链整合与线上线下融合是泛生鲜零售升级的两大趋势，上述重塑将有效提升行业效率并降低行业成本。 核心观点 行业痛点而言，流通环节加价与损耗率高是生鲜行业的突出痛点，产地直采与冷链物流运用对于解决上述痛点至关重要；- 供应链整合与线上线下融合是泛生鲜零售升级的两大趋势，上述重塑将有效提升行业效率并降低行业成本；- 就门店特征而言，泛生鲜零售新物种通常具备店仓合一，业态融合、数字化应用融入等特征，在提升行业效率的同时优化购物体验。供应链整合与线上线下融合是泛生鲜零售升级的两大趋势，上述重塑将有效提升行业效率并降低行业成本； 泛生鲜零售新物种 生鲜零售：品类特征与行业痛点分析 生鲜零售成为零售行业升级的首选品类，是由其独特的品类特征和渠道分布特征共同决定的。就品类特征而言，生鲜作为高频刚需的食品品类，具有保质期短、流通环节易损耗等特点，且多为非标品；上述特征很大程度上制约了其电商渗透水平；就销售渠道而言，目前我国生鲜品类以线下渠道销售为主；其中，我国超市渠道生鲜销售比例显著低于发达国家水平，市场潜力巨大；此外，生鲜零售网点布局分散，多以个体经销商为主，经销环节逐层加价，无形中抬高了成本，行业整合空间巨大。因此，供应链整合与线上线下融合是生鲜零售未来发展的重要趋势。 案例分析——7FRESH 7FRESH作为京东无界零售在生鲜品类的线下落地，依托京东生鲜积累的资源优势，为消费者提供高品质生鲜食材、食品百货及餐饮体验。 就经营模式而言，7FRESH同样支持线上加线下全渠道零售模式，以及超市+餐饮的业态融合创新。与其他泛生鲜零售新物种相比，7FRESH的核心优势主要体现在两大方面：选品及其依托的供应链优势和门店购物中的数字化体验。 就需求定位而言，7FRESH将顾客需求分为三个层次并将其作为选品规划的依据。根据需求层次划分，7FRESH的选品分为常规性产品、天然&amp;生态产品及差异化产品三个层次。其中，常规化需求对应于大众需求，满足个阶层消费者对于食品特别是生鲜类食品的基本需求；天然&amp;生态产品满足高于基本需求的消费升级品质化需求，对于原品风味和应季时令提出更为严格地要求；差异化产品依托独家合作资源，满足消费者个性化需求。上述选品层次分别针对不同消费者对于生鲜产品的需求特征，但就基本要求而言，均在品控方面对生鲜供应链各环节提出更高的要求。 就品控而言，7FRESH从源头采购到仓储物流环节均采取了多项有效措施，确保生鲜产品的高品质呈现。首先是源头品控，通过与原产地优质供应商进行深度合作，实现产地直采，减少经销环节带来的成本加价与产品损耗，保障生鲜产品的原料新鲜；其次，通过借助京东生鲜既有的仓储物流与冷链技术应用，在仓储物流环节持续保鲜；此外，通过将分拣、包装、处理环节前置，进一步降低生鲜产品损耗。 在门店管理与到店体验方面，7FRESH采用了诸多“黑科技”应用。店内黑科技的运用主要基于两类用途：门店管理、购物环节体验优化。其中门热力图分析是门店管理中最具代表性的数字化运用之一，主要解决客流时间空间分布的监测，为门店运营数据洞察提供依据；购物环节体验优化覆盖购物行进、单品消费决策、结算支付、店内候餐等环节，为顾客提供智能化购物体验。 案例分析——盒马鲜生 盒马鲜生作为阿里旗下的泛生鲜零售新物种，以线上线下融合和业态创新为主要经营特征。截至2018年3月，盒马在全国共有门店36家，覆盖北京、上海、深圳、杭州、苏州、宁波、成都、福州、贵阳等9个城市。2018年3月28日，盒马生鲜与13家全国性地产商签订新零售战略合作协议，作为零售新业态盘活商业地产价值的重要尝试。 就经营模式而言，盒马区别于传统生鲜零售渠道和纯线上生鲜电商；盒马生鲜采用门店（超市+餐饮）+线上模式，通过打通线上线下及业态创新融合，为消费者提供即时便捷、高品质、场景化的泛生鲜消费解决方案。以下分别从消费需求视角与零售行业视角，对盒马鲜生提供的解决方案与经营模式重塑进行分析。 案例分析——食得鲜 食得鲜成立于2014年，总部位于广州。通过移动互联网+现代化物流+大数据模式，逐步发展为华南地区领先的泛生鲜零售新物种。 食得鲜的泛生鲜零售升级实践基于对生鲜零售发展现状与行业痛点的深入洞察：高昂的市场覆盖成本&amp;低下的行业效率与消费者消费升级需求满足间的内在矛盾。如何通过行业模式重塑，提升行业效率，降低市场覆盖成本，成为解决上述矛盾的关键。 传统生鲜零售的市场覆盖成本由租金成本、库存成本，以及门店运营成本等部分构成。上述成本结构自身暗含着低效的成分，因而行业效率的提升自然从改善原有成本结构入手。就具体措施而言，食得鲜进行了如下探索：首先，全渠道运营以及自建物流配送体系。上述举措旨在提升单位门店顾客覆盖能力，变相降低租金成本、库存成本及门店运营成本，同时有效提升动销率。其次，与上游供应商关系的改善。与多数传统零售商不同，食得鲜在采购环节采用现款现货模式，以此获得更低的购货价格，在保证销售毛利同时，以更低的定价将商品提供给消费者。 此外，以食得鲜为代表的泛生鲜零售新物种的崛起，意味着优质的区位将不再成为制约商超发展的首要因素。传统商超实体零售对于优质区位的依赖性强，线下流量水平直接决定销售额的多少。全渠道运营的零售升级背景下，那些区位次优，但品牌属性优良的零售商线下门店，甚至可以盘活原有的闲置物业，反哺商业物业，并通过线上流量的汇聚提升整体经营业绩，这对于商业物业价值的提振与线下价值重估具有重要意义。 案例分析——苏宁小店 苏宁小店定位于针对场景化需求的新型O2O便利店，是服务于“最后一公里” 的智 慧零售业态。从店面模型来看，苏宁小店主要围绕社区、CBD和大客流地段进行差异化构建。其中，社区店主要面向家庭用户，以生鲜和快消为主打品类；CBD店主要面向办公室白领，在选品结构方面主要满足的白领阶层对于工作就餐（轻餐饮）的需求；大客流店则会针对不同大客流场景配置各类商品。以下首先以社区店为例分析苏宁小店的模式创新与核心价值体现。 作为苏宁大快消战略布局的项目落地，苏宁小店社区店以“生鲜+快消”品类切入，从社区场景需求出发，通过从日常购物到便民服务的社区消费链条延伸，掌握社区场景消费的入口，这也成为苏宁小店作为泛生鲜零售新物种的核心价值所在。 与传统的便利店只注重快消品不同，苏宁小店从生鲜品类切入，以“生鲜+快消”的高频刚需品类组合，满足社区消费场景的基本需求，以此实现场景化的流量汇聚并形成用户黏性。鉴于生鲜品类固有的保质期短、易损耗等特点，冷链物流配套设施的完善尤为重要。对此，苏宁通过自建冷链仓的方式以确保其在生鲜零售领域的核心竞争力。根据规划，苏宁将新开广州、南京、上海、北京、武汉、成都、沈阳、西安八座冷链仓。新开的八座冷链仓均采用B2B店配和B2C客户包装发货模式，满足苏宁生鲜业态的冷链物流需求。 通过上述调整实现流量汇聚与用户黏性提升后，苏宁小店作为流量入口的价值通过服务延伸进一步凸显：通过线上和线下流量入口，小店可进一步为居民提供家政服务、家电维修、快递代收发、政务办理等多项虚拟服务，实现从商品销售到服务提供的延伸。就所承载的功能而言，小店成为整个社区场景下消费服务链条的入口。 就苏宁小店的整体业务模式而言，其最为突出的特征在于对传统便利店进行O2O赋能：以“双中心+三大场景定位”为内核，根据用户行为特征锁定用户所在场景，并通过供应链优势将上述场景打通。O2O模式本质上是消费升级的体现，其核心价值在于提升消费的便利程度。苏宁小店通过线上线下双中心运营模式，将线上线下渠道有机融合，并通过对用户场景的定位提供针对性解决方案，实现便利店业态功能价值的提升，更好地满足消费者需求。就三大场景定位而言，根据用户所处消费场景的不同分别提供解决方案。其中，在1公里范围外主推苏宁易购精选商品，1公里范围内主推小店商品+易购精选，店内主推小店商品。 通过苏宁供应链优势满足用户在不同场景下的需求。 案例分析——天天果园 天天果园作为泛生鲜零售新物种，成立于2009年，目前业务主要覆盖华东、华北、华南三大市场。其发展初期主要以B2C精品水果电商为业务模式，逐步建立起包含官网、独立APP以及域外线上渠道的线上渠道体系，并由此实现了线上用户群的早期积累；2014年以来，天天果园在销售品类上进行拓展，从原有的水果品类逐步拓展至泛生鲜以及熟食、速食等品类。2015年开始大力布局多渠道，由 B2C 电商逐步转型为全渠道零售商；目前，天天果园已初步建立围绕 App 、区域店（城市超市）、社区店以及智能终端（自助售货机）的“四位一体”的综合业态。 天天果园的业务发展路径，基于其对泛生鲜零售市场趋势的基本判断，具体而言包含以下三点。 首先是渠道布局。在移动互联网红利期，线上边际获客成本低，通过电商渠道获客的逻辑顺理成章；2015年以来，随着线上获客成本急剧攀升，纯电商运营模式陷入瓶颈，通过线上+线下渠道打通的全渠道运营模式成为诸多零售商转型的选择。因此，从发展趋势看，未来的泛生鲜零售是全渠道打通的，线上线下有机融合。天天果园的全渠道转型正是基于上述趋势的预判。 其次是品类延伸。生鲜属于高频刚需品类，但单一品类经营会降低购买频次，难以实现规模效应；因此销售品类延伸与SKU扩充对于泛生鲜零售而言至关重要；在核心品类聚焦的同时，还应通过多品类延伸满足消费者场景化需求。 最后是配送时效。生鲜品类特征决定了消费需求的即时性。对于线上下单周边配送的模式，配送服务时效性的达成，将成为生鲜零售商的重要核心竞争力之一。 针对上述趋势预判，天天果园的业务转型同样从上述三方面展开。 全渠道多场景的综合业态模式通过线上渠道、区域店、社区店和智能终端的“四位一体”全面布局，分别解决用户在不同场景下消费需求。通过线上线下打通，共享流量与仓储物流成本，有效改善原有模式下的成本结构。 品类延伸与SKU扩充将原有优势品类（水果）逐步扩展为泛生鲜品类，在已有供应链优势基础上持续深耕产地直采，以确保高品质与稳定的货源。此外，通过与城市超市（CITY SHOP）达成合作，共享优质生鲜供应链资源，并引入熟食、冷食、鲜切等多元化品类进一步扩充SKU，以提升消费者购买频次，实现规模效应。 配送时效的提升配送时效的提升依赖于高效的物流配送网络。就天天果园而言，其物流配送通过自建冷链物流（鲜速运）与第三方合作实现，其中在上海地区，已经实现鲜速运的全面覆盖；同时，其社区服务店具备前店后仓的功能，在承担前门店销售功能的同时作为前置仓，通过线上线下打通有效提升了周边区域覆盖能力，并为配送时效的显著提升提供了可能。 此外，为确保高效的经营效率与良好的用户体验，天天果园对于科技与研发能力持续投入，以实现业务链条各环节的数字化全覆盖。在生产流通上游，通过自动分拣生产线的应用与水果实验室的建立，强化生产流通环节品控；在流通环节中游，通过产品溯源、流通状态追踪以及产品新鲜度管理的综合运用，提升产品流通环节的信息化程度，进一步强化品控与流通效率；在商品销售环节，通过对交易数据实时分析，精确刻画消费者需求偏好变化，并为潜在需求挖掘与精准营销提供支持。 案例分析——网易味央 网易味央的业务探索始于2009年，专注提供高品质肉类生产及行业解决方案。与生鲜零售新业态有所不同，网易味央的创新之处更多体现为生鲜零售向上游生产环节延伸以实现全供应链品控覆盖；此外，其对品质生鲜（黑猪肉及其制品）品牌化与全渠道运营的创新实践，对于生鲜类产品消费升级具备重要借鉴意义。 就发展历程而言，网易味央主要经历了三个阶段。 第一阶段：模式探索期（2009-2016.12） 该阶段为网易味央产品上市前的探索阶段，以2016年12月网易味央黑猪在“黑五拍卖”后正式在网易域内电商渠道开售为界。在此期间主要完成了对网易味央养殖模式的探索，为后续项目实践与量产奠定基础。 第二阶段：创新实践期（2016.12-2017.09） 该阶段为网易味央产品上市后的创新实践阶段，以2017年9月网易味央江西高安产业园奠基为界。在此期间，网易味央进行了诸多创新探索，包括以“全民养猪众筹”为代表的线上营销活动，同时与外婆家合作开设猪爸体验店，进行线下渠道体验化探索。在此期间，网易味央还完成了1.6亿元人民币的A轮融资（美团点评、创新工场领投；京东战略投资），主要用于下一阶段的模式复制。 第三阶段：复制扩张期（2017.09-至今） 江西高安猪场奠基后，网易味央进入复制扩张期，以规模化量产与模式复制为主要特征。 就供应链而言，网易味央在猪种选育与养殖环节完全自控，以确保生产源头品质；在屠宰分割与包装加工环节，主要通过外部合作实现，但在合作方资质审核与选取标准方面严格执行，以确保中间环节全程可控；在仓储物流与渠道体系建设方面，将内部资源与外部合作相结合，充分结合网易自身与外部合作方的相对优势，以实现流通与销售环节的品控与效率提升。 就生产养殖过程而言，网易味央采用多种新技术应用，分别针对传统养殖过程中的痛点进行了改善。首先，通过电子耳标身份识别追踪解决了品质溯源问题；其次，在饲喂方面采用液态饲喂技术，在降低猪患哮喘的风险同时很大程度上改善饲养环境。此外，在粪污收集与处理方面，创新性采用猪马桶技术与“零污染”环保处理系统，从根本上改善养殖环境，进而为猪肉及其制品的品质提供保障。 作为网易旗下品牌，味央在品牌运营与互联网营销方面也具备天然优势。通过“黑五拍卖”与“全民养猪众筹”等极具互联网化特征的营销活动，提升品牌知名度与形象；还通过打造拟人化IP形象，提升网易味央在年轻消费群体中的品牌认知，对于泛生鲜品牌IP化运营具备良好的借鉴意义。 转载来源：中国零售新物种研究报告（二）——泛生鲜模式分析]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>电子商务</tag>
        <tag>移动互联网</tag>
        <tag>京东</tag>
        <tag>苏宁易购</tag>
        <tag>O2O</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自媒体、新媒体运营工具集合，收藏起来帮助你提高运营效率！]]></title>
    <url>%2F2018%2F0f895147%2F</url>
    <content type="text"><![CDATA[365编辑器秀米编辑器i排版V5编辑器新榜编辑器135编辑器长微博生成器小蚂蚁编辑器易点微信编辑器人人秀编辑器H5工具。 今天分享一波干货，我们不管是在运营自媒体还是运营新媒体，都会使用到运营工具，今天小编就总结了一些关于自媒体、自媒体运营会使用到的工具，自媒体人赶紧收藏起来，提高自己的运营效率！ 排版工具： 365编辑器- 秀米编辑器- i排版- V5编辑器- 新榜编辑器- 135编辑器- 长微博生成器- 小蚂蚁编辑器- 易点微信编辑器- 人人秀编辑器秀米编辑器 V5编辑器 135编辑器 小蚂蚁编辑器 人人秀编辑器 H5工具： 秀米- 微页- 易企秀- MAKA- 咫尺网络- 创客贴- 凡科- 百度H5- 腾讯风铃微页 MAKA 创客贴 百度H5 配图工具 Icon-FontIconfont- 昵图网- 花瓣网- 500px- 千图网- Street Will- IM Free- 全景- 360识图- 图鱼- forwallpaper- 视觉中国- Behance- Pixabay- Unsplash- Pexels- Visual Hunt- 别样网- Gratisography昵图网 500px Street Will 全景 图鱼 视觉中国 Pixabay Pexels 别样网 数据分析工具 搜狗微信搜索- 新榜- CNZZ- Datahoop大数据- 阿里指数- 站长工具- 百度指数- 百度统计- 百度搜索风云榜- 微指数新榜 Datahoop大数据 站长工具 百度统计 微指数 问卷工具 简道云- 番茄表单- 腾讯问卷调查- 麦客- ICTR- 申请通- 问道网- 问卷星- 乐调查- 调查派- 问卷网- 金数据番茄表单 麦客 申请通 问卷星 调查派 金数据 好啦，以上就是小编给你们分享整理的新媒体、自媒体运营所需要的工具集合，希望大家能够更好运营提高自己的运营效率，如果还有工具遗忘的话，大家可以留言补充，小编及时更新！ 转载来源：自媒体、新媒体运营工具集合，收藏起来帮助你提高运营效率！]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>产品运营</tag>
        <tag>自媒体</tag>
        <tag>百度统计</tag>
        <tag>视觉中国</tag>
        <tag>西红柿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各大网站都在用的“轮播图”，其实转化率很低]]></title>
    <url>%2F2018%2F08b71eaa%2F</url>
    <content type="text"><![CDATA[市场营销从来就是一门玄学，到底是使用多图轮换来尽可能多地向顾客展示产品信息好，还是用静态图片只传递单一信息有效呢。 编者按：市场营销从来就是一门玄学，到底是使用多图轮换来尽可能多地向顾客展示产品信息好，还是用静态图片只传递单一信息有效呢？到底哪一种能带来更高的商业转换率呢？本文作者告诉大家，与其一味随大流地在网站主页上使用“图片轮换”，不如看看调查数据和听听专家的意见，再做决定，毕竟跟谁走，都不如跟钱走来得实在。 就算没见过成百上千个，我相信你肯定也见过几十个图片轮换页面吧？这些图片会自动切换或者滚动（这种模式也称为“旋转供图”）。 你可能挺喜欢它们。 但事实是，这种展现图片的模式，可能不利于提高商业转化率。 既然这种模式没什么卵用，那为什么人们还是用得乐此不疲呢？原因有两个： 有些人认为这种展现图片的模式很酷炫。 但酷炫和赚钱可是两码事。- 不同部门和各种经理都希望在公司主页上，尽可能多地展现他们的信息。不同部门和各种经理都希望在公司主页上，尽可能多地展现他们的信息。 测试告诉了我们什么？ 绝不只是我一个人这么想，许多转换率优化专家的实验，都说明了同一个事实： 来自Wider Funnel的Chris Goward评论道：“我们已经多次测试了轮换图片所带来的效果，发现这绝对不是展示主页内容的好方法。” “图片轮换一无是处，真应该立即从首页上把它们删除。” 来自Site Tuner的Tim Ash是这么说的。 Jakob Nielsen（是的，就是那名可用性测试大师）在测试中证实了这一点。 他组织开展了一项可用性研究，在研究中，他让用户完成以下任务：在自动轮换幻灯片中，找出 “西门子对洗衣机是否有特别优惠？”。 这项信息被放在最明显的幻灯片上，但是用户却视而不见，因为“广告盲区”的效应，用户们忽略了这条消息。Nielsen总结认为，这些幻灯片完全被忽略了。 Notre Dame大学也对图片轮换的效果进行了测试。 在所有图片中，只有第一张幻灯片得到了消费者的关注（仅有1％！），其他幻灯片几乎没有人点击。而那张只获得了消费者1％关注度的幻灯片却占据了页面的一半版面。 产品设计大师Luke Wroblweski总结如下： “&#64; erunyon，基本上，数据告诉我，千万别使用图片轮换。”- Luke Wroblewski（&#64;lukew）2013年1月22日 在StackExchange UX上，有一些有关自动轮换图片的讨论。 以下是一些开展不同测试的人的说法： Adam Fellows 说： 几乎我管理的所有测试都说明通过图片轮换展示的内容常被用户忽略。 很少有人与那些轮换幻灯片互动，很多消费者还认为他们长得像广告，所以我们发现‘广告盲区’效应就这样产生了。在节省版面空间和提升内容质量，许多竞争信息也都会在同一个位置传递出去，这使得用户的关注点飘忽不定，无法专注。 这是另一个评论，来自Lee Duddell： 图片轮换能有效地告诉市场营销或者高级管理人员他们的新想法被展现在主页上。但是，它们对用户而言是无用的，并且由于它们看起来和广告十分相似用户常常“跳过”他们。 因此，图片轮换的确是在主页上展示无用信息的好方法（它的作用请看本段第一句）。总之，你可以用它们来承载用户在你的主页上一定会忽略的内容。 或者，如果你愿意，干脆就再也别用图片轮换来展示信息来，再也不要了。顺便说一句，这些观点不是我自己的观点，是基于成千上万的用户的测试数据产生的结论。 最后一个评论来自Craig Kistler： 在我所做的所有测试中，主页上的图片轮转完全无效。一方面，除了展示的第一张图片，其他任何内容得到访问者交互的可能都会大大减少。 而且，轮转图片中所展示的信息与访客想寻找内容相匹配的机会很渺茫。 所以在这种情况下，图片轮转就成为了一个会被忽略的横幅。 在数次测试之后，访问者在进入带有大型轮转图片页面时所做的第一件事就是向下滚动页面，跳过图片轮转，并开始寻找按钮开始自己的下一步动作。 这里有两个主要原因，告诉我们为什么图片轮转不起作用： 理由＃1：人眼对运动产生反应（会使我们错过重要的东西） 我们的大脑有3层，最古老的部分，在爬行动物身上也能看到。这一部分它主要与人类生存有关。对于爬行动物而言，地平线上任何突然的变化都有可能是生死攸关的问题。因此人眼对各种运动产生反应 - 包括不断移动的图像和轮播图片。 这听着很不错啊，对吧？ 除非轮播图片是你网站上唯一的东西（这听着就不太好了！），无法展示更多的内容，这听着可不是一件好事。这意味着轮播图片带走了消费者对其他东西的关注 - 其实主页上除了轮播图片，还有其他重要的东西，比如定价，网站内容，产品讯息等等。 原因＃2：消息太多等于没有消息 那些浏览网页的人们由于广告盲区对轮播图片毫不关心，但即使是那些注意到图片轮播的人，也无法从中找出有用的信息。 访问者前往你的网站。在轮播图片上看到一条消息，然后开始阅读。 “今年秋天你会……”啪！字不见了。通常图片播放的速度很快，快到人们甚至无法完成阅读就翻页了（即使那时候他们想要继续读）。 关注传递单一主要信息，然后采取行动，是更加有效的方法。 原因＃3：广告盲区 这些提供信息的图片轮播看起来就像广告似的，人们浏览的时候往往会跳过它们。 用户需要有控制权 轮播图片的实用性极低 - 它们切换得太快，导航图标太小（如果上面有任何导航图标的话），并且即使用户想要手动浏览它们呈现的内容，它们也经常常自动移动。用户界面设计的关键原则之一就是，让用户享有控制权。 现在有很多电子商务网站还在使用图片轮换 - 我认为并不是这些网站基于测试结果认为图片轮换有效，而是由于从众心理 - “其他网站都有，我们的网站上也应该有”。 Forever21的图片轮换，就像我们说的一样糟糕 ——轮换展示三个优惠，每4秒更换一次： 如果人们看到的第一个优惠不是他们喜欢的（或者与他们的 兴趣，相关性比较低），那么怎么办呢？如果他们不喜欢三者中的任何一个呢？这些图片轮换肯定不会帮助你提高公司客户的长期价值。 但图片轮换值得称赞的一点是，一旦你点击图片轮播的箭头，图片自动轮换就会停止。不仅如此，当你稍后再回到这个网站时，网站会显示的是你想看的那张幻灯片。 我建议与其如此，不如呈现一个单一的静态报价。 这里是J.J.巴克利提供静态报价 - 只专注于传达一条消息： 一些过去使用图片轮播的企业，比如Adobe，Gap和Hilton现在也转为使用静态消息。 Adobe： Gap： 大家应该能注意到，希尔顿有一个可以滑动图像的滑块键，但它不并会自动滑动。如果你想要移动的话，你可以单击按键实现： 结论 如果条件允许的话，尽量避免使用轮换图片。 不要跟风时尚，潮流总是会过时的，还是只追求钱比较实在。 那么不放轮换图片的话，要放上什么图片呢？你可以使用静态图像，或者： &#64;kshermphoto我建议将其替换为用户实实在在的内容，因为那才是访客真正访问网站的原因。- Erik Runyon（&#64;erunyon）2013年1月22日 Brad Frost承认：“尽管轮换图片效果不佳，但我不知道怎么样能让它们快速消失”，并写下了另一篇文章，告诉大家如何让轮换图片更好地发挥作用。 你的图片轮换体验是什么呢？无论你是网站所有者还是用户，都来和我们说说你的体验吧。 编译组出品。编辑：郝鹏程 转载来源：各大网站都在用的“轮播图”，其实转化率很低]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>市场营销</tag>
        <tag>电子商务</tag>
        <tag>Adobe</tag>
        <tag>爬行动物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌I/O 2018的AI亮点：从TPU3.0到DeepMind支持的Android P]]></title>
    <url>%2F2018%2F97465f4e%2F</url>
    <content type="text"><![CDATA[2018 年 5 月 8 日，一年一度的谷歌 I/O 开发者大会在美国加州山景城开幕。在今日刚刚结束的 Keynote 中，机器学习依旧是整个大会的主旋律：谷歌发布了 TPU 3.0、Google Duplex，以及基于 AI 核心的新一代安卓操作系统 Android P，也介绍 2018 年 5 月 8 日，一年一度的谷歌 I/O 开发者大会在美国加州山景城开幕。2016 年谷歌从移动优先到人工智能优先（AI-first），两年来我们从谷歌 I/O 看到了谷歌如何践行这一战略。在今日刚刚结束的 Keynote 中，机器学习依旧是整个大会的主旋律：谷歌发布了 TPU 3.0、Google Duplex，以及基于 AI 核心的新一代安卓操作系统 Android P，也介绍了自己在 News、Map、Lens 等众多产品中对 AI 与机器学习模型的应用。本文带你一览谷歌 I/O 2018 首日 keynote 的核心亮点。 在今天的 Keynote 中，谷歌 CEO 桑德尔·皮查伊等人介绍了谷歌一年来的多方面 AI 研究成果，例如深度学习医疗、TPU3.0、Google Duplex 等，也展示了 AI 如何全方位地融入了谷歌每一条产品线，从安卓到 Google Lens 和 Waymo。在本文中，机器之心对 Keynote 的核心内容进行了整理。 深度学习医疗 大会刚开始，昨天谷歌所有的 AI 研究合并出的 Google AI 发布了一篇博客，介绍谷歌在医疗领域的研究： 联合斯坦福医学院、加州大学旧金山分校 、芝加哥大学医学中心，谷歌今天在 Nature Partner Journals&#58; Digital Medicine 上发布了一篇论文《Scalable and Accurate Deep Learning with Electronic Health Records》。 在此研究中，谷歌使用深度学习模型根据去识别的电子病历做出大量与病人相关的预测。重要的是，谷歌能够使用原始数据，不需要人工提取、清洁、转换病历中的相关变量。 在预测之前，深度学习模型读取早期到现在所有的数据点，然后学习对预测输出有帮助的数据。由于数据点数量巨大，谷歌基于循环神经网络与前馈网络开发出了一种新型的深度学习建模方法。 病人病历中的数据以时间线的形式展示 至于预测准确率（标准：1.00 为完美得分），如果病人就医时间较长，论文提出的模型预测得分为 0.86，而传统的 logistic 回归模型得分为 0.76。这一预测准确率已经相当惊人。 Looking to Listen：音频-视觉语音分离模型 而后，皮查伊介绍了谷歌博客不久前介绍的新型音频-视觉语音分离模型。 在论文《Looking to Listen at the Cocktail Party》中，谷歌提出了一种深度学习音频-视觉模型，用于将单个语音信号与背景噪声、其他人声等混合声音分离开来。这种方法用途广泛，从视频中的语音增强和识别、视频会议，到改进助听器，不一而足，尤其适用于有多个说话人的情景。 据介绍，这项技术的独特之处是结合了输入视频的听觉和视觉信号来分离语音。直观地讲，人的嘴的运动应当与该人说话时产生的声音相关联，这反过来又可以帮助识别音频的哪些部分对应于该人。视觉信号不仅在混合语音的情况下显著提高了语音分离质量（与仅仅使用音频的语音分离相比），它还将分离的干净语音轨道与视频中的可见说话者相关联。 在谷歌提出的方法中，输入是具有一个或多个说话人的视频，其中我们需要的语音受到其他说话人和/或背景噪声的干扰。输出是将输入音频轨道分解成的干净语音轨道，其中每个语音轨道来自视频中检测到的每一个人。 皮查伊还介绍了谷歌其他 NLP 应用，例如通过谷歌的键盘输入摩斯电码让语言障碍者重新获得表达能力、GMail 中利用语言模型与语境信息预测输入。 之后，皮查伊介绍了谷歌在计算机领域的一些研究成果与应用，包括医疗影像方面的研究，移动设备中应用的照片理解、抠图、自动上色和文档处理等。 TPU 3.0 去年，谷歌 I/0 公布了 TPU 2.0，且开放给了谷歌云客户。今天，皮查伊正式宣布 TPU 3.0 版本。 皮查伊介绍，TPU 3.0 版本功能强大，采用液冷系统，计算性能是 TPU 2.0 的 8 倍，可解决更多问题，让用户开发更大、更好、更准确的模型。更多有关 TPU 3.0 的信息也许会在之后放出。 Google Assitant 与 Google Duplex 集成谷歌人机交互研究的 Google Assistant 在今日的 keynote 中必然会亮相。Google Assitant 负责工程的副总裁 Scott Huffman 介绍了 Google Assitant 过去一年的成果，谷歌产品管理总监 Lilian Rincon 介绍了带有视觉体验的 Google Assistant 产品，且有数款产品将在今年 7 月份发布。 而后谷歌 CEO 桑德尔·皮查伊在 Keynote 中展示了语言交互的重要性，并正式介绍了一种进行自然语言对话的新技术 Google Duplex。这种技术旨在完成预约等特定任务，并使系统尽可能自然流畅地实现对话，使用户能像与人对话那样便捷。 这种自然的对话非常难以处理，因为用户可能会使用更加不正式或较长的句子，且语速和语调也会相应地增加。此外，在交互式对话中，同样的自然语句可能会根据语境有不同的意思，因为人类之间的自然对话总是根据语境尽可能省略一些语言。 为了解决这些问题，Duplex 基于循环神经网络和 TensorFlow Extended（TFX）在匿名电话会话数据集上进行训练。这种循环网络使用谷歌自动语音识别（ASR）技术的输出作为输入，包括语音的特征、会话历史和其它会话参数。谷歌会为每一个任务独立地训练一个理解模型，但所有任务都能利用共享的语料库。此外，谷歌还会使用 TFX 中的超参数优化方法优化模型的性能。 如下所示，输入语音将输入到 ASR 系统并获得输出，在结合 ASR 的输出与语境信息后可作为循环神经网络的输入。这一深度 RNN 最终将基于输入信息输出对应的响应文本，最后响应文本可传入文本转语音（TTS）系统完成对话。RNN 的输出与 TTS 系统对于生成流畅自然的语音非常重要，这也是 Duplex 系统关注的核心问题。 在 Duplex 系统的语音生成部分，谷歌结合了拼接式的 TTS 系统和合成式的 TTS 系统来控制语音语调，即结合了 Tacotron 和 WaveNet。 由于这样的系统引入了「嗯、额」等停顿语，系统生成的语音会显得更加的自然。当结合拼接式 TTS 引擎中大量不同的语音单元或添加合成式停顿时，这些引入的停顿语允许系统以自然的方式表示它还需要一些处理时间。 总的来说，Google Duplex 的这些结构与方法对生成更自然的对话与语音有非常大的帮助。目前虽然主要是针对特定领域中的语言交互，但确实提升了语音会话中的用户体验。 安卓以及闪现的 DeepMind 即将在今年 9 月迎来自己 10 岁生日的安卓也在 I/O 上宣布了新一代操作系统。继承 Android Oreo 工作的新版安卓系统被命名为 Android P。 「本次发布有三个主题，分别是智能（Intelligence）、简洁（Simplicity）与数字健康（Digital Wellbeing）。Android P 是我们『AI 位于操作系统核心』愿景的第一步，而 AI 也是『智能』主题的奠基石。」谷歌工程副总裁 Dave Burke 如是展开了他的演讲。 智能部分里首先介绍了两个功能，Adaptive Battery 自适应电池管理系统和 Adaptive Brightness 自适应亮度调节系统。 其中，Adaptive Battery 通过卷积神经网络来预测用户接下来会使用的应用程序，通过适应用户的使用模式将电池仅用于你接下来可能需要的应用程序中，这减少了 30% 的后台 CPU 唤醒。而 Adaptive Brightness 则不再单纯根据照明情况调节亮度，而是加上了用户喜好和所处环境因素。超过一半的测试用户减少了他们手动调节亮度条的频率。 事实上，这两个功能均来自之前一度被美媒质疑「烧钱还傲娇不干实事」的 DeepMind。DeepMind 本次并没有直接在 I/O 露出，只是在博客上发表了一篇文章（https&#58;//deepmind.com/blog/deepmind-meet-android/），说明了 Android 的这两个新功能来自 DeepMind for Google 团队。 除此之外，Android P 也将去年发布的、准确率达到 60% 的「用户接下来可能使用哪个 App」预测更进一步，转而预测「用户接下来可能用什么 App 进行什么操作」，并直接在上滑菜单顶部呈现给用户。 Dave Burke 在介绍上述每一个功能时都着重强调了所有的预测均由在端上运行的机器学习模型完成，以确保用户隐私得到最大程度的保护。 除了将 AI 融入操作系统的优化之外，Android 还试图降低非机器学习背景的开发者使用相关技能的门槛：包括图片标注、文字识别、智能回复等一系列 AI 相关的 API 将以 ML Kit 的形式开放给开发者。 「你可以将 ML Kit 视作基于 TensorFlow Lite 提供的、为移动设备优化过的、随拿随用机器学习模型。」Dave Kurve 介绍说。而且，谷歌非常大方地同时对 iOS 系统开放了这一 API 集。 开发者今天就能在 Pixel 上实验 Android P Beta 的效果了。值得一提的是，除了 Pixel 之外，Android P Beta 还对其他 7 家手机生产厂商的旗舰机开放，其中有 4 家都来自中国，它们分别是小米、vivo、oppo 和一加。 无人驾驶 昨日，起源于斯坦福人工智能实验室的自动驾驶汽车初创公司 Drive.ai 于 7 日宣布，将与德克萨斯州的弗里斯科政府以及 Hall 集团进行合作，在德州落地首个无人出租车服务。而在今天的 Keynote 中，Waymo CEO John Krafcik 通过视频展示了居住在凤凰城的一些人参与其 EarlyRider 项目（即体验 Waymo 的自动驾驶技术）的场景。Krafcik 称 Waymo 将在今年于凤凰城开始 passenger-pickup 项目，凤凰城是第一站。 结语 一年一度的谷歌 I/O 开发者大会首日 Keynote 中的核心内容如上，相比于偏重机器学习技术的 2016 年与 2017 年，今年的内容更多关于 AI 的应用与产品。两年来，我们看到了谷歌如何践行 AI First 战略。接下来几天，机器之心将会继续报道谷歌 I/O 2018 的更多精彩内容。 转载来源：谷歌I/O 2018的AI亮点：从TPU3.0到DeepMind支持的Android P]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>Keynote</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为我助力，你也可获得1次数钱机会，最高1万元奖励哦~]]></title>
    <url>%2F2018%2Fd843b286%2F</url>
    <content type="text"><![CDATA[为我助力，你也可获得1次数钱机会，最高1万元奖励哦~ 转载来源：为我助力，你也可获得1次数钱机会，最高1万元奖励哦~]]></content>
  </entry>
  <entry>
    <title><![CDATA[python学习系列(八) --- socket实现简单的即时通讯 - CSDN博客]]></title>
    <url>%2F2018%2F7a564be1%2F</url>
    <content type="text"><![CDATA[python学习系列(八) — socket实现简单的即时通讯 - CSDN博客 tcpclient.py 转载来源：python学习系列(八) — socket实现简单的即时通讯 - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[【首发】微医刚刚宣布：5亿美金Pre-IPO融资完成！估值55亿美元！]]></title>
    <url>%2F2018%2Fa2a290f6%2F</url>
    <content type="text"><![CDATA[动脉网vcbeat|微医成为了目前行业最大的独角兽企业，也为上市进行着最后一轮的冲刺。 转载来源：【首发】微医刚刚宣布：5亿美金Pre-IPO融资完成！估值55亿美元！]]></content>
      <tags>
        <tag>动脉网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[下一个教育行业独角兽，就藏在这五大趋势里｜真格投资手记]]></title>
    <url>%2F2018%2Fee2db38c%2F</url>
    <content type="text"><![CDATA[“教育即生活，生活即教育”。我们认为有五个趋势不容小觑，而每个大趋势都将催生不同的企业形态，对应不同的创业与投资方向。 “教育即生活，生活即教育”。 科技的助力，国人教育意识的改变，以及国家新政策的出现都引发了我们对接下来教育领域走向的更多期待和猜想。 2018 年教育的风会往哪里吹？我们认为有五个趋势不容小觑，而每个大趋势都将催生不同的企业形态，对应不同的创业与投资方向。 其中的一些”风口”我们已经有所布局，而另一些”风口”我们仍然在寻找最让人心动的团队。欢迎关注教育的投资人以及行业创业者与真格教育基金副总裁姜敏联系（微信：jiang-zishan）。 2018 年教育行业有五个大势不可小觑： · 微信生态下的裂变模式 · 千亿素质教育市场爆发 · 在线和双师赋能 K12 辅导 · 政策变化下的高考改革 · 职业教育迎来上市窗口期 每个大势下将催生不同的企业形态，对应不同的创业与投资方向： 五大趋势及对应的教育投资机会 微信生态下的教育裂变模式—— 关注低单价高毛利的轻产品 微信生态里的教育市场已经悄然超过百亿，教育企业通过微信可以与 9 亿用户 0.1 秒级连接。 过去教育行业也一直有人用微信来裂变获客，但现在微信甚至连服务都可以承载。特别是对非刚需教育品类来说，企业自己的 App 几乎无人下载，在下载、活跃、留存、转介上全面被微信超越，微信群和服务号就是用户服务的第一选择，公众号、微信群、小程序全都可以用来获客。 微信生态下的教育已经完成两次升级： 最初只是在微信上获客，第一次升级是薄荷阅读、英语流利说等产品开始把内容和轻服务打包，通过微信同时完成获客、转化和交付。 第二次升级使得需要场景转换的产品也可以通过微信来完成获客、转化和服务，只是其中重度服务的学习环节或者耗时较长的内容观看还是要回到 PC 上去。 这个变化来得很迅猛，以至于我们无法预测在微信里还能生长出怎样的结构，也很难界定知识付费和教育产品之间的边界。 但对于这个领域我们将重点关注，希望能够找到优秀的创业者借助微信生态打造低单价、高毛利的轻产品，针对更广泛的人群，在微信上实现低成本获客和低成本服务。 千亿市场素质教育迎来爆发—— 关注在线和综合体 超越新东方的不是下一个新东方，而是做 K12 辅导的好未来；超越好未来的也未必是下一个好未来，其中一种可能就是素质教育。 国人的教育意识正在快速变化，素质教育需求的刚性在不断提升，整体市场规模超过千亿。但是用户的素质学习需求品类繁多且分散善变，所以素质教育机构看似可以像 K12 辅导机构一样有长生命周期，但其实都比较难超过两年。 在千亿素质教育市场我们看到两个大机会，一个是线下的素质教育综合体，第二个是在线素质教育。 综合体的思路是开设面积超过 3000 平米的一站式素质服务机构，尽可能多地覆盖需求品类，从而提高用户生命周期价值和单店产能，以实现规模化扩张。 在这个方向我们投资了安徽艺朝艺夕教育集团，艺朝艺夕一站式地为家长和孩子提供音乐、美术、舞蹈、体育、英语教育服务，覆盖素质教育的绝大多数品类。 目前在合肥、南京和杭州三个城市开设教学中心，公司拥有超过三十个素质教育综合体，2017 年收入超过 2 亿元。 在线素质教育的思路则是通过在线直播消除地理位置的限制，使得机构和用户零距离，让教育服务像自来水一样拧开即用。 我们在 4-14 岁已经投资了 5 家素质教育在线培训公司，包括在线英语小班机构魔力耳朵、在线数理逻辑机构成长保、在线创意美术机构画啦啦、在线钢琴陪练及教学机构美悦钢琴、在线少儿编程机构vipcode，共计覆盖 5 个素质教育品类。 2018 年我们继续看好这个方向，关注所有可被在线化的素质科目。 K12辅导是教育的核心战场—— 关注在线班组和双师 K12 在线辅导市场已经诞生了多家独角兽、准独角兽，是教育的核心战场。 做在线 K12 辅导的可以分成两派，一派叫”天网派”，指的是像作业帮、猿辅导这样先从互联网流量切入，然后再做辅导服务或者提供付费内容的公司。另一派叫”地网派”，指的是像掌门一对一、海风教育这样一上来就直接做辅导服务的公司。 天网派的风口将持续存在，因为对天网派企业来说，核心是找到一个足够刚性的功能性切入点，然后用最快的速度把用户量和品牌做起来，因为技术的革新和场景的变化，这种可能持续存在，绝不仅仅是现在的拍照搜题和在线作业。 而地网派**的**核心是成本结构和规模化运营，一对一的成本结构问题尚无定论，2018 年的新风口是班组和双师。如果说低年龄段还需要靠一对一的强互动来解决孩子无法在电脑前保持注意力的问题，那么面向小学高年级（小学 4-6 年级）和初高中的辅导业务是可以班组化的，其成本结构显然更优。 双师模式的提出已经超过两年时间，但到目前为止，看起来更像是传统巨头下沉的利器，很少见到独立的 K12 辅导双师项目。 但我们认为 K12 辅导一定有独立双师机构的机会，可能是进一步下沉，也可能是差异化人群定位。 高考改革进入深水区—— 关注政策影响 高考是整个中国教育体系的指挥棒，高考政策哪怕是细微的调整都会逐级向下传导从而对 K12 教育带来巨大的影响，更何况这次从 2014 年开始的高考改革是有史以来动作最大的改革方案。 我们认为新高考改革主要会有四个方面的影响： ① “ 6 选 3 “或者” 7 选 3 “的选科制度对初高中日常教学模式的影响。 从浙江上海开始试点的走班制将继续扩大，2018 年又有四个省市要开始实施走班制，学校需要相关的方案和系统支持； ② 高考志愿填报和招录模式的变化对生涯规划、背景提升、志愿填报咨询、自主招生咨询等领域的影响。 志愿填报的复杂度陡然上升，学生需要在升入高中时就有相对清晰的生涯规划，裸分录取的比例将越来越低，自主招生、综合评价等个性化录取方式将成为主流； ③ 英语一年两考和增加口语成绩比重对英语课外辅导、外教入校、口语自动测评、在线口语等领域的影响； ④语文总分增加、书目阅读量增加对语文课外辅导、分级阅读、整本阅读等领域的影响。 针对上述变化，我们已经投资了国内领先的走班选课系统提供商晓羊教育和高考志愿填报、自主招生咨询服务提供商百年育才，我们将继续保持对高考改革影响的关注。 在线职业教育或将迎来上市窗口期 关注规模和增长 职业教育往往是教育行业的先行者，最早运用在线直播教学的其实是职业教育，这两年上市公司并购的很多也都是职业教育公司。 这跟职业教育本身领域分散、天花板低，但用户学习自主性强、付费意愿强等特征都是有关的，所以在线教育最先有规模化利润的也是职业教育公司。 行业里几家在线职业教育公司已经具备了上市所需的利润规模。 我们在该方向投资了对啊网和北风网。 对啊网主要为有志于进入会计、教师和公务员等行业的人群提供证书考试相关辅导服务，北风网则为在职 IT 人员提供系统化的大数据、人工智能课程，以帮助普通 IT 从业者实现个人能力的升级转型。 因为职业教育的客户有明确的目的性，我们在确保公司培训效果的前提下，继续关注年收入规模超过 5000 万且每年仍以超过 80%的速度增长的在线职业教育企业。 2017 年，平均每天超过 2 个教育项目宣布获得融资。8 月份作业帮宣布获得 1.5 亿美元 C 轮融资以及真格基金参与投资的 VIPKID 宣布获得 2 亿美元 D 轮融资更是将整个热潮推向了一个高点，教育行业吸引了越来越多的目光。 但是 2018 年在上述 5 个大势的影响下会持续爆发，迎来创业新风口。 真格教育基金投资布局图 真格教育基金作为专注投资教育行业的基金，致力于发现更真、更新、更好的教育，希望跟未来的教育独角兽们共同成长。 欢迎关注教育的投资人以及从事这方面业务的创业者与真格教育基金副总裁姜敏联系（**微信：jiang-zishan）。** 转载来源：下一个教育行业独角兽，就藏在这五大趋势里｜真格投资手记]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>在线教育</tag>
        <tag>好未来</tag>
        <tag>移动互联网</tag>
        <tag>新东方学校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对标严选平台，考拉优教想做儿童素质教育在线私校]]></title>
    <url>%2F2018%2Fdaef7491%2F</url>
    <content type="text"><![CDATA[早上8点，还未出门上班的父母给孩子挑选了英语启蒙课程，和孩子一起学习后就去上班。从2016年成立至今，考拉优教通过搭建3-12岁儿童素质教育内容与服务的严选平台，为全国家庭打造素质教育私校。 考拉优教网站芥末堆 红印儿 3月16日报道 早上8点，还未出门上班的父母给孩子挑选了英语启蒙课程，和孩子一起学习后就去上班。中午休息时，父母给自己挑选了正面管教相关的课程。下班回家后，父母又给孩子挑选了美术课程，看着孩子完成了一幅蜡笔画。 考拉优教创始人钱晋文曾这样描述他设想的素质教育“家庭私校”。 从2016年成立至今，考拉优教通过搭建3-12岁儿童素质教育内容与服务的严选平台，为全国家庭打造素质教育私校。“我们想让每个家庭都可以自主规划孩子的学习任务，就像学校里排课表那样去安排课程计划。”钱晋文解释。 近几年，素质教育成为又一炙手可热的赛道。体育、艺术、科创等细分领域相继出现很多创业项目，比如巨石达阵、荷马教育、麦德魔方等。领域聚焦带来的一个好处是容易跑通商业模式，但考拉优教选择了看起来“少有人走”的平台化之路。 “素质教育的一大特点就是需求分散，并且孩子的兴趣变得很快。”钱晋文说，“因此需要一个多元化的平台去满足用户的需求。” 目前，考拉优教拥有超过150万注册用户，平台上的课程超过10000节，用户每个月平均选学27节课程。 从内容严选起步，数据与行业经验是支撑作为具有联结属性的教育平台方，持续聚合并产出优质的内容是必备能力。目前，考拉优教的内容主要有两大来源，一是从外部平台引入内容版权，一是与机构、KOL及个人联合制作内容。 哪些内容值得引入或是联合制作呢？考拉优教采用了“数据+经验”双管齐下的筛选方式。 在考拉优教的后台，全网近百个亲子或儿童频道的内容情况都被纳入观测数据库里。系统会在综合分析内容的热度数据后，给出具体内容或是内容方向的推荐意见，包括爱奇艺、喜马拉雅、BBC等在内的多个国内外部平台都是潜在的内容来源。 随后，结合教研团队成员在多个细分领域的行业经验，考拉优教会再决定是否要引入内容版权。例如，考拉优教app里人气热度很高的科学课程《科学小子席德》就来自PBS Kids儿童教育频道。 当一些热点或有潜力的内容方向出现时，考拉优教还会去找对应领域的KOL联合制作课程。这些KOL或是育儿达人，或是某一素质教育细分领域的专家和机构，或是一些跨界的教育者。目前，考拉优教的课程种类覆盖科学、英语、历史、艺术等多个领域。 在联合制作中，考拉优教将自身对于用户、教育和教学的理解与KOL的专业背景相结合，课程研发参考5E体系，即Engage(参与)、Explore(探索)、Explain(解释)、扩展(Extend)、Evaluate(评价)。 这些KOL达人圈层内部联络密切，考拉优教很快就联结了大批内容合作者。现阶段，与考拉优教合作的KOL或机构超过1000个。不过，优质的教育内容始终是稀缺资源。钱晋文表示，接下来还会与外部平台联合进行内容研发。 加入教具和线下体验课服务，打造一站式体验虽然内容优质构成用户付费的前提之一，但就现阶段中国消费者对线上教育内容的付费习惯来说，同时提供线下的产品和服务可以增加消费者付费的“踏实感”。一些早幼教在线产品如企鹅童话、铁皮人等推出配套图书或教具就是一个例子。 对于素质教育课程来说，教具有时是必不可少的学习辅助品。同时，教具也可以在一定程度上提升产品的单价。 考拉优教在课程内容初步就位后，相继将教具引入课程中。例如，名为《汉字奇遇》的课程将视频课程、汉字卡片、游戏卡牌等打包售卖，教具由外部供应商负责发货。现有的乐高系列课也分为教具版与非教具版两种，教具版课程定价高出非教育版课程数百元。 43%的受调查家长表示接受在线授课形式教具虽然可以令线上课程的学习体验更加完整，但一些用户的需求并不就此止步。由睿艺和家长帮联合发布的《2017年中国家庭素质教育消费报告》显示，担心孩子无法与老师和小伙伴互动是多数家长不选择在线教育课程的最主要原因。相比线上课程节省时间与交通成本的好处，线下课程往往能给孩子带来更直观与深入的学习体验。 2017年，考拉优教通过K-PASS卡推出了线下课程体验服务。购买K-PASS卡后，家庭能以较优惠的价格去住址附近的素质教育线下培训机构试听三次课程。考拉优教会根据学生的在线学习表现、住址和兴趣综合推荐一批机构，最终由家庭自主选择与决策合适的培训机构。 K-PASS卡示意图与考拉优教在课程体验方面合作的线下机构多经考拉优教团队拓展与联络而来，双方尝试在内容开发与流量抓取上形成协同效应。钱晋文介绍，签约的线下培训机构会有比较明确的线上推广的需求，有的机构还尝试将一部分课程在线化接入考拉优教的平台。 沉淀数据，联动线上线下切入市场即便对于线下培训机构来说，利用微信群、专有app等互联网方式向家长反馈孩子的学习状况也逐渐成为家校沟通的主要手段。在大数据与人工智能技术的加速发酵下，数据变成很多机构的新抓手。 从内容筛选到课程服务，数据是串联起考拉优教各项业务的那根“隐形的绳子”。从单节课程推荐到整合推送的个性化周期课程表，再到线下体验机构的推荐，考拉优教的个性化推荐都基于对学生数据的分析来实现。 左图为考拉优教推荐的单节课程，右图为推荐的个性化课表作为一款主要面向C端的产品，考拉优教今年还计划开设200个线下体验门店，以接触更多C端用户。考拉优教体验门店中将展示上百种与线上课程相关的教具，并设置体验教室，供家长了解教具的使用方法。 由于经营线下门店涉及到选址、仓储、配送等多个方面，考拉优教于去年提前储备了一个线下运营团队，团队成员之前有过运营全国性教育品牌的经验。与多数儿童教育品牌的运作方式类似，考拉优教的门店会也会采取直营与加盟并行的运营方式，其中直营店重在验证商业模式。 钱晋文介绍，考拉优教的线下门店将主要分布在北上广及一些一二线城市，因为这些地区的C端市场对素质教育的接受度相对较高，并且一二线城市的中产家庭也是考拉优教主打的用户定位。与此同时，考拉优教也在尝试通过社群、KOL达人以及一些机构来集中获客。 线上付费课程、配套教具、K-PASS卡服务构成考拉优教现阶段主要的营收来源。接下来，考拉优教还将尝试以整体解决方案的形式打包提供线上线下的内容与服务。据悉，考拉优教正在准备新一轮的融资。 芥末堆注：如需联系该作者／创业者，欢迎发送需求到service&#64;jmdedu.com，芥末堆帮你牵线搭桥。 转载来源：对标严选平台，考拉优教想做儿童素质教育在线私校]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>英语</tag>
        <tag>爱奇艺</tag>
        <tag>在线教育</tag>
        <tag>树袋熊</tag>
        <tag>美术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[职业教育强势崛起 学前教育成新蓝海]]></title>
    <url>%2F2018%2Fd6e3fd55%2F</url>
    <content type="text"><![CDATA[教育不振则实业不兴，国民之生计日绌”。教育对于个人以及国家发展的重要性毋庸置疑。随着互联网如空气般渗透进每个人的生活，教育行业也衍生出新的业态和商业模式。 图片来源：摄图网我国著名教育家陈嘉庚先生曾经说过，“教育为立国之本，兴学乃国民天职。教育不振则实业不兴，国民之生计日绌。”教育对于个人以及国家发展的重要性毋庸置疑。时代的车轮滚滚向前，教育始终是国民关注的热点，教育行业也愈发繁荣。随着互联网如空气般渗透进每个人的生活，教育行业也衍生出新的业态和商业模式。 教育行业发展至今，已经有众多的细分领域，按照不同的教育阶段，大致可以分为学前教育、K12教育、职业教育等（详见教育行业细分领域示意图）。按照教学场景，又可以分为线下教育和在线教育。 在线教育，或称互联网教育，是指依托于互联网，借助技术手段，实现学习与教学的教育形式；其特点在于打破了传统教育形式（面授）时间和空间的限制，同时大幅降低了课程费用，这也使得在线教育成为近年来资本追逐的热点。 市场规模提升 投融资热度不减教育行业产值年均增长15.8% 仍有巨大空间据国家统计局数据，2004年中国教育行业产值为4892.56亿元，2009年增长至10,481.79亿元，首次突破1万亿元；2014年进一步增长至21,159.90亿元，首次突破2万亿元。可以看出，教育行业保持着一个高速发展的态势，2004-2015年行业整体年均增长率为15.8%，教育行业产值在GDP中的占比由2004年3.10%提升至2014年3.29%，其中2007年、2008年、2010年的占比低于3%。不过，这一水平与发达国家相比仍存在较大差距，据网络公开历史数据，美国、日本、加拿大的教育支出占国民生产总值的比例分别为7.3%、5.1%、6.6%。 来源：国家统计局在线教育市场与用户规模均保持高速增长数据显示，在线教育市场规模由2008年352.20亿元增长至2016年1560.20亿元，预计2017年将达到1916.70亿元，年均增长率为20.76%；在线教育用户规模由2011年3413万人增加至2016年9001万人，预计2017年将突破1亿人次，年均增长率为21.36%。 数据显示，在线教育用户规模的年均增长率略高于市场规模的年均增长率，这说明消费者对于在线教育的需求不断提高，另一方面，以消费者实际购买力衡量的费用有所下降；这两点又共同促成了在线教育的渗透率进一步提高，形成了一种正向循环的关系。 来源：根据网络公开资料整理来源：根据网络公开资料整理从细分领域看，市场规模排在前三位的分别是高等学历教育、职业教育、中小学教育，2016年其市场规模分别为830.70亿元、355.60亿元、191.30亿元，企业E-learning、学前教育的市场规模相对较小，分别为55.80亿元、3.80亿元。 来源：根据网络公开资料整理在线教育营收规模高速增长 投融资热度不减2016年中国在线教育营收规模达1560.2亿元人民币，据易观统计，2017年第1季度、第2季度中国在线教育营收规模分别为458.4亿元、561.1亿元，即2017年上半年中国在线教育营收规模已达到2016年全年的65.3%。再来看用户规模，据上文所述，2016年中国在线教育用户规模为9001.4万人，2017年将达到1.09亿人，同比增长率超过20%。 在营收规模、用户规模都处于高速增长时，资本也仍在不断地进入。2016年5月，猿辅导宣布完成E轮融资，融资金额为1.2亿美元，这是截至目前国内互联网教育K12领域最大的一笔融资，由华平投资集团（Warburg Pincus）领投，腾讯公司跟投。2016年6月10日，在线教育公司51Talk在美国纽约证券交易所正式挂牌交易，股票代码为COE，成为中国在线教育赴美上市第一股。 由此可见，2016年在线教育市场资本投融资依然热度不减，伴随着技术的发展，以及用户对优质内容的刚性需求，在线教育市场仍有巨大潜力。 早期教育与职业教育发展势头迅猛人均可支配收入提高 教育成为刚需据国家统计局数据，1978年我国城镇居民家庭人均可支配收入为343元，1987年突破1000元，达到1002元；1997年突破5000元，达到5160元；2005年首次破万，2011年达到2万元，2015年该数据为31790元。可以看出，我国城镇居民家庭人均可支配收入自改革开放以来，获得了巨大的提升，由最初的几百元增长到3万多元。 来源：国家统计局根据马斯洛需求层次理论，人类在满足了最基本的生理需求（如食物、水、空气）后，开始追求安全需求，即人身安全、生活稳定以及免遭痛苦、威胁或疾病等；在满足了生理需求、安全需求后，人类开始有较高层次的需求，如对友谊、爱情及隶属关系的需求；再往上是尊重需求和自我实现需求。 将马斯洛需求理论应用在教育上，只有在满足生理需求的基础上，学生才有可能接受教育；进一步讲，学习需要一个安全的环境，如果要随时担心会有爆炸发生，学生是不可能安心学习的；再到社交需求，学生需要感觉到自己是一个集体的成员，游戏、团队合作都是很好的方式；再往上的尊重需求，要让学生感觉到受重视，比如通过口头鼓励的方式；最后是自我实现需求，比如将自己所学到的知识教给更多的人，创造更多价值。 教育与马斯洛需求上述5个层级中，满足生理需求和安全需求是获得教育的基本条件，而从社交需求开始，教育已经成为满足需求的重要途径。联合国教科文组织在《2016全球教育检测报告》中指出，教育比以往任何时候都更有责任培养人们学会实现可持续的包容性增长所需的适当技能、态度和行为。 家庭教育支出占收入超三成 重视早期教育俗话说“再穷不能穷教育，再苦不能苦孩子”，国人对于教育的重视程度可见一斑。2012年的一项调查显示，在义务教育阶段，我国城市家庭教育支出平均占家庭养育子女费用总额的76.1%，占家庭经济总收入的30.1%。近年来，除了正常的教育支出，学区房成了不少家长沉重的负担，2016年某购房网站上甚至出现10平米标价150万元的“学区过道”；学区房价格屡创新高，反映的是优质教育资源的稀缺。 从家庭教育支出的具体费用看，《2016年中国家庭教育消费者图谱》统计数据显示，一线城市、二线城市和三四线城市月平均教育产品支出大于1000元的比例分别为32.8%、17.2%和7.0%;整体来看，38.6%的家庭每年家庭教育产品支出大于6000元。另一方面，教育产品支出费用受家庭收入影响明显，家庭月收入低于5000元的家庭有58.0%平均每月用于教育产品的支出不足300元，而家庭月收入高于3万元的家庭有37.0%平均每月教育产品支出高于2000元，即每年教育产品支出至少为2.4万元，以2016届大学本科毕业生的平均月薪4376元来衡量，（家庭月收入高于3万元的）家庭每年教育产品支出至少相当于一个大学本科毕业生近半年的薪水。不论从家庭教育支出的绝对值，还是从其在家庭收入中的占比来看，教育支出是家庭消费支出的重要组成部分，并且随着收入的提高，占比有显著提升。 来源：艾瑞咨询《2016年中国家庭教育消费者图谱》如今，从小在“我要当科学家”的人生理想中成长起来的80后逐渐步入而立之年，陆续加入到结婚生子的大军中，开始为人父母，未来10年，由第一代独生父母养育第二代子女的家庭将超过1000万个，也就是说，80后成为家长中的一个主体人群。这部分家长普遍具有较高的学历素质，多为企事业白领，拥有较高的收入；对于孩子的教育，他们不再像上一辈有强烈的“望子成龙”的期待，更多的是希望孩子能够成为一个具有良好道德情操和修养的人，拥有快乐幸福的童年。 他们也意识到，宝宝生命的初始阶段（通常指0-6岁）是培养良好生活习惯，智力发展最快、记忆力、模仿力最强的阶段。因此，越来越多的家长开始重视早期教育，艾瑞数据显示，一线、二线以及三四线城市对于早教产品的月平均支出分别为500-1000元、300-500元、100-300元。伴随着二胎政策的推广，以及政府有意识地引导社会资金投入到早期教育服务体系建设中；家长对于早教产品的需求还将持续增长。 职业教育集团化势力崛起 市场空间快速扩张职业教育按“是否颁发毕业证书等国家承认的学历证书”为标准，可分为学历类和非学历类，在此仅分析非学历类职业教育，主要包含直接面向消费者的职业技能、从业资格认证、人才招录考试和面向企业的培训。职业教育致力于中高端层次人才的培养，用户主要为白领，这部分人群关注的核心是价格和教学效果。 具体来看，职业教育包含多种类别，如职业技能培训、从业资格培训、招录考试培训和企业培训。其中，职业技能培训又包含财会类、IT应用类、外语类等，从业资格培训包括金融财会类、司法类、建筑类等，招录考试培训包括公务员考试、事业单位考试等，企业培训包括管理培训和企业内训。 职业教育细分领域据艾瑞数据，2016年中国职业教育行业市场规模约为432.5亿元，其中IT应用类是最大的细分市场，市场规模为179.1亿元，份额占比41.4%；财会类培训份额第二，占比30.1%；营销类培训份额最小。2013-2016年行业整体年复合增长率为21.9%，保持高速发展态势。 目前，我国职业教育中外语培训、公务员考试等领域已发展得较为成熟，其中一个标志是出现龙头企业，如在纽交所上市的新东方(EDU.N)和在新三板挂牌的华图教育(830858.OC)，新东方、华图教育2016年营业总收入分别为97.26亿元、19.22亿元，同比增长率分别为18.57%、41.43%，在职业教育细分领域同行中收入遥遥领先，同时保持高速增长。 新东方(EDU.N)财务摘要华图教育(830858.OC)财务摘要职业教育蓬勃发展 一线城市需求与日俱增职业教育和K12数量最多 集中分布于北上广由于公益属性、外资禁入、多头监管等限制因素，我国教育资产证券化主要以三类业态的形式呈现：上市公司跨界并购教育资产、挂牌新三板和海外IPO。其中，新三板市场上的教育类企业数量最多，以2016年营收过亿为标准进行筛选，新三板上共有25家教育类企业，按照用户群体以及受教育阶段的不同，可分为职业教育、K12教育、学前教育、游学以及高等教育。其中，职业教育、K12教育企业数量最多，分别有9家、8家，合计占比68%。 从下图可以看出，新三板教育企业主要分布于北京、上海，分别有10家、4家，合计占比56%；广东、湖北、江苏、山东分别有2家，福建、海南、河南各有1家。整体来看，新三板教育企业分布情况与我国教育资源分布情况基本一致，北京拥有全国最丰富的教育资源，相应的教育企业数量也最多；其次是东部沿海地区，西部地区则无一家企业入选。 职业教育、学前教育、K12教育成交活跃数据显示，2016年，新三板教育行业25家企业中18家有成交记录，占比72%；上述18家企业2016年平均成交量、平均成交额分别为820.25万股、1.87亿元；细分领域中，职业教育、学前教育的成交额均值排在前两位，分别为2.78亿元、2.54亿元，其次是K12教育1.75亿元；高等教育和游学的成交额均不足亿元，分别为1936.72万元、65.65万元。 新三板整体有成交记录的企业，2016年全年的平均成交量和平均成交额分别为854.2万股、4470.8万元。经过对比可以发现，职业教育、学前教育、K12教育的成交额水平远超均值，而高等教育和游学则未达到均值水平。数据表明，新三板教育行业不同细分领域成交活跃度差距较大，这可能有以下两方面原因，一是从成立时间（平均值）看，前三个细分领域成立时间较早，发展相对更加成熟；其中职业教育企业成立于2005年，K12、学前教育企业成立于2006年，而游学、高等教育企业则分别成立于2008年、2009年；另一方面，不同细分领域的受众决定了其在市场空间上存在天然的差异，新三板上两家高等教育企业新道科技(933694)、金智教育(832624)主营业务为教学系统开发等，客户多为高等院校；而游学市场相对小众，新三板游学企业2016年的平均营业收入为2.1亿元，不及新三板教育行业营收均值为3.57亿元。 职业教育营收规模、成长性均排在首位下图显示，从营收均值看，2014-2016年新三板教育行业细分领域中，职业教育始终排在首位，学前教育、高等教育、K12教育则不分上下，游学的营收规模相对较小；另一方面，从2014-2016年年均增长率来看，职业教育以106.85%排在首位并遥遥领先，K12教育、游学、学前教育分列二至四位，年均营收增长率分别为67.29%、65.42%、62.4%，差距不大；年均营收增长率最低的是高等教育仅为20.53%。数据表明，职业教育在市场规模居首的情况下仍保持高速增长，显示出其背后庞大的用户群体和日益增加的教育需求；K12教育由于用户群体的升学压力客观存在，相应的市场需求也保持稳定增加；游学目前还属于相对小众的市场，学前教育则随着80后成为家长主体而越来越受到重视。 用户类型对企业利润率有重大影响K12教育盈利能力强2014-2016年数据显示，K12领域8家企业无一亏损，连续三年保持盈利状态，其中5家净利润连续增加，占比62.5%；而得益于赢鼎教育（833173）、威科姆（831601）的业绩在2015年获得爆发性增长（赢鼎教育的净利润由2014年29.94万元增加至2015年1.10亿元，同比增长36711.29%；威科姆的净利润由2014年130万元增加至2015年3944.77万元，同比增长2934.33%），K12教育年均净利润增长率达到1710.7%；年均净利润增长率仅次于K12教育的是职业教育194.7%，不同于K12，职业教育的9家企业中仅3家的净利润保持稳定增长，其余6家企业近三年业绩起伏较大，如起航股份（833380）由2014年盈利1174.96万元转为2015年亏损326.58万元，2016年扭亏为盈，实现净利润911.65万元。 企业毛利率差异巨大 费用管理能力是关键数据显示，新三板教育行业2014-2016年毛利率均值为51.89%，细分领域中K12、学前教育、职业教育与均值水平差别不大，高等教育明显高于均值达73.61%，游学则明显低于均值仅为39.78%；从净利率来看，新三板教育行业近三年净利率均值达10.62%，其中游学处于亏损状态，K12、高等教育、学前教育的净利率排在前三位，分别是18.95%、14.39%、10.37%；职业教育的净利率相对较低，为9.90%。 从上图可以看出，高等教育在毛利率大幅领先的情况下，净利率并无明显优势；毛利率高主要因其成本较低，2016销售成本率仅为25.78%，几乎仅为行业均值的一半；但是期间费用率高达62.79%，行业均值为37.73%，其中销售费用、管理费用比例均超出教育行业均值；处于亏损状态的游学则主要是成本率较高造成的。 K12、学前教育、职业教育3个细分领域毛利率差距较小，分别为51.37%、50.70%、51.97%；但是，净利率方面，K12以18.95%明显超出学前教育10.37%、职业教育9.90%；从上图可以看出，上述3个细分行业的销售成本率依然很接近，但K12的期间费用率明显低于学前教育、职业教育，这主要是由销售费用造成的。 以职业教育、K12细分领域中营收规模最大的华图教育（830858）、威科姆（831601）为例，华图教育2016年的销售费用为3.39亿元，占营收比重为17.66%，公告称这是由于其通过增设分公司等措施扩大规模，相应的人工成本、宣传费用增加；威科姆2016年销售费用为4198万元，占营收比例为11.86%。从前五大客户可以看出，华图教育面向个人用户，获取用户需要较高的成本，而威科姆面向企业用户，在获得供应商资格后，销售情况相对稳定，客户集中度较高，2016年仅中国联合网络通信有限公司的销售占比就达到44.1%。 资本驱动教育行业高速发展2016年，新三板教育行业有13家企业完成融资，占比52%，共计融资25.05亿元，平均融资额1.93亿元。从分布情况看，融资额在1000-3000万元的企业数量最多，有5家；其次是融资额在1-2亿元的企业有3家；融资额最高的两家企业分别是华图教育（830858）8.80亿元、和君商学（831930）8.64亿元，这两家企业都属于职业教育这一细分领域，华图教育主要从事公务员考试培训，和君商学主要面向企业提供管理培训。 在进一步对新三板教育行业细分领域融资额进行统计后可以看出，职业教育融资表现最为突出，除了前述华图教育、和君商学分别融资8亿余元，另有晶格科技（430638）、启航股份（833380）、行动教育（831891）、星科智能（430545）4家职业教育企业完成融资，融资额分别为6615万元、3358万元、1570万元、1105万元；职业教育企业融资额合计达18.70亿元，占比74.7%；另一方面，从平均值来看，职业教育依然以3.12亿元排在首位，其次是K12教育1.80亿元。资本在2016年纷纷布局职业教育，进一步说明了这一领域具备良好的成长性和广阔的市场空间。 （本文转自拉贝网） 转载来源：职业教育强势崛起 学前教育成新蓝海]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>在线教育</tag>
        <tag>加拿大</tag>
        <tag>职业教育</tag>
        <tag>马斯洛</tag>
        <tag>日本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[沦为“花瓶”的项目式学习作业？]]></title>
    <url>%2F2018%2F8fb81541%2F</url>
    <content type="text"><![CDATA[他们需要制造一个收集静电的仪器，具体怎么收集我也不知道，反正最终是要产生足够的电，打到老师手有麻感。 图片来源：摄图网在刚过去的周末，女儿让我下午一点到五点之间，帮他们的小组做一个发电的项目。 他们需要制造一个收集静电的仪器，具体怎么收集我也不知道，反正最终是要产生足够的电，打到老师手有麻感。 一点之后，同学们陆续来了，大家坐在一起嘻嘻哈哈之后，就开始吐槽。我问他们为什么不去做项目？他们自己也很郁闷，说根本不知道老师想要干什么。 收集静电我只知道穿毛线衣。总的来说，我学的是文科，对物理知之甚少。不然的话，我这个年龄都该成高校讲席教授了，如同我们同届的理科大牛同学那样。但时势造英雄，面对几个稀里糊涂的高中生，我只好拔下一根毫毛，吹了口气，变成了物理教练。 物理我不懂，但是怎么在一起做事我懂。每个人做事都可以有些套路，我的套路是设计思维。 她们做一个学校的项目，需要“移情”（Empathy), 也就是了解要学的到底是什么？再不济，得知道老师的要求是什么。然后你得界定问题(Define)，想象你最终的产品是什么样子，达到什么目的。 他们是在创意产生的阶段（Ideate)卡住了：他们坐一起“头脑风暴”，结果是想出一个点子，其他人就七嘴八舌将该点子枪毙。团队的互动，头脑风暴中听不中用。人在一起，创意产生会受“意见领袖”影响，或相互之间的干扰。 我让他们换个方法，独立地每个人想几个主意，互不影响，然后把各自的想法拿出来，凑一起再商讨、筛选、深化。这是我对于头脑风暴的升级，或许对于别的团队也一样有益。 这么分析一下，他们才慢慢开始上手。他们看了网上的一些示范，然后找来纸盒、木板、CD、钉子、电线，裁剪、切割、钻孔、打磨，各种土法炼钢，制造这个静电收集器。 他们是照着Youtube上的教程亦步亦趋。我问这个工具的原理是什么，他们说不上来。他们甚至还没有学到电力的部分。 我说，“老师不讲，你们不问吗？学问学问，要学也要问。你们没有学到，又不去问，如何长进？” 他们说问过，老师说下一门课才会上。就是上到，恐怕也是白搭。这位老师是用“翻转课堂”教学法，“知识”部分是要孩子们自己看的，而今动手也自己在家动手，我都不知道课堂上干什么。 类似的“项目”，我接触得多了。 比如西班牙语课的作业，是让学生做关于自己兴趣爱好的装饰画，然后描述这样的画。我女儿是个完美主义者，花了大量时间做这张画。但是画这种画的过程当中，她学到了什么西班牙语? No lo sé. 这些项目，均属作业中的花瓶。教育观察者詹妮弗·冈萨雷斯（Jennifer Gonzales)有个更形象的说法：希腊古瓮作业（Grecian Urn Projects)。 《希腊古瓮颂》是济慈的一首名诗。诗人赞颂希腊古瓮上精美的浮雕：艺术的保存下，少女容颜常驻，吹笛少年永远年轻，树木长春，乡镇恬静。作为艺术品，古瓮穿越千百年时光，仍旧魅力动人。作为教育项目的比喻，古瓮则华而不实，不可取不宜学。 冈萨雷斯曾遇到过的一位新老师，在教古希腊历史时，让学生用气球和报纸，做出“希腊古瓮”，然后在上面绘画，描述自己对希腊文化的了解。 冈萨雷斯追问这位老师作业和课程目标如何关联，新老师哑口无言。他也只是继承一代又一代老师的“项目式作业”而已。冈萨雷斯就此称那些有趣但没料、教学目标和教学过程脱节的作业为“希腊古瓮式”作业。 项目式学习之所以可能成为“花瓶作业”，一个原因是轻视知识的积累。学习含量低，所以才显得像摆设，像花瓶。 和中国以及注重知识积累的其他国家相比，美国的基础教育阶段学习，对于知识和理解的讲究少一些。 布鲁姆的“认知分类论”，将认知技能分为由低到高的知道、理解、应用、综合、评估等领域。知道和理解是“低层次”的认知技能，强调知道和理解的“死记硬背”成了教育界的大忌。 这种低端与高端认知技能的平衡，我在新书《过剩时代的学习》（华东师大出版社，2018年）中提到不少，欢迎关注。 布鲁姆的“认知分类论”项目式作业，就是为了突破积累知识的填鸭式教学。诚然，有的项目是精彩的，让孩子自己独立研究，团队合作，动脑也动手，能够锻炼一些“高端技能”。另外，这种作业，孩子们往往也觉得比较好玩，能够引发学习兴趣。这种情感要素，有利于学习者的成长，不容忽视。 不过脱离知识让孩子直接上马做“项目”，就好比脱离地基建大厦。 我们过于讲究知识积累，打压学生积极性，固然不好；若跳到另外一个极端，布置花里胡哨的花瓶作业、噱头作业，也一样不好。中美的作业观念，应像钟摆一样，太过了就得摆回来。 另外，很多美国学校的项目作业，是老师自己发挥想象，在教学甚至Pinterest等网站找教程，直接在班上用。期间缺乏将学习目标和方法关联的深思熟虑。这种做法，也和对教学大纲的把控过于分散化有关。 我孩子所在学区都是“独立学区”，不要说没有联邦统一的教学大纲，连州统一的教学标准也没有，只有统一的名叫德克萨斯州学力达标检测（The State of Texas Assessments of Academic Readiness ，简称STAAR) 的“验收”。授课中老师自由度非常大，于是作为教育过程中的元素，项目式作业实施起来良莠不齐。 另外，近年来，美国基础教育阶段人口结构也发生了变化。在我们德州这里，基本上是白人、黑人、西班牙裔三分天下。公立学校学生因来源复杂，在这个所有孩子都要得奖杯的“瞬间满足”时代，小组项目作业最容易让人浑水摸鱼。 可是一旦有良好的设计，项目式学习能给学习带来巨大改变。 首先，对于教学质量要有一定的把关。我是一位教学设计人员，在我们的大学，我的工作内容之一是审查课程大纲，尤其是大纲中关于学习结果和测评方法的描述。 另外，我比较倾向于在项目式学习中增加“真实任务”。世界上问题已经够多的了，如果学生需要花几个星期甚至整个学期时间去完成一个任务，要有各种调研，要花费大量时间，那倒不如找一个真实的问题去探索，拿出真实的任务来打磨。 我遇到的一个最有趣的学习任务，是金融系的一门课。这门课的老师不知当初怎么和学校领导游说的，让学校领导同意从学校的信托基金中，拿出了11万美元，让学生真刀真枪地去管理。每年上这门课的学生，就把这笔钱用来投资。到去年为止，这笔钱已经被学生炒到了100万美元。如此真实任务让作业中的花瓶变成了“聚宝盆”。 本文转自LIFE创新教育，作者方柏林，文章为作者独立观点，不代表芥末堆立场。 转载来源：沦为“花瓶”的项目式学习作业？]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>大学</tag>
        <tag>物理</tag>
        <tag>约翰·济慈</tag>
        <tag>Pinterest</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在线教育公司该有哪些标配]]></title>
    <url>%2F2018%2F44d7dae9%2F</url>
    <content type="text"><![CDATA[经济观察报周枫/文在线教育行业现在正处于一个风口。全国现在包括大学生在内大概有2亿左右的学生，这么大一个市场，中间很多需求都没有被满足，还可以干很多事。 （图片提供：全景视觉） 经济观察报 周枫/文在线教育行业现在正处于一个风口，这是一个很好的时机，因为行业起步的关键问题都解决了。一些投资人集中聊起在线教育，也是近几年发生的事情。 2013、2014年是在线教育的投资高峰。2015、2016年这个行业遇冷，很多创业公司都因拿不到钱死掉。2017年又是在线教育行业增长迅猛的一年。 在线教育这个盘子非常大，整个教育大概万亿级的市场，大几千亿的中小学的教育生意，全国现在包括大学生在内大概有2亿左右的学生，这么大一个市场，中间很多需求都没有被满足，还可以干很多事。我们做了三年多时间在线教育，这个行业还没有一个特别清晰的规划，要做好在线教育业务，究竟需要做好哪些方面的事情。 MOOC的弯路 从2011年底有道词典突破1亿大关，我们就觉得这个肯定是可以做教育业务的。但当时我们很明确判断是卖不出去。 当时我们的想法是，既然有这么多学习用户，那把它推到线下去。所以有道当时跟一些线下的培训机构合作，让用户去尝试他们的产品。最后，这个产品形态变成了一个营销型的产品。 根据这个模式我们做了几年，这个模式现在还在，叫有道智选的广告服务。 2013、2014年，市场出了一大堆教育产品，当时有个投资高峰，但是大家的产品形态还不成熟，开门面店，然后让老师们过来上传课程，上传的都是录播课，上传之后老师自己定价。然后就开始出现有老师把价格定特别低，也有老师把课特别高，课程水平参差不齐，有些时候看着介绍特别好，观看之后发现讲得一般。最后发现，引一大堆用户过来，结果买的课不是很多，而且买完之后口碑还很差，所以很多公司在2016年左右关门，当时有道没有想着在13、14年进这个局，只是想做一个好产品。 我们愿意花很长时间，做好一件事。因此，有道不受融资周期的影响。网易是一家极度以用户为中心的公司，这是我们愿意做基业长青的事情。我们觉得教育这边有巨大的需求，有大量做出好产品，做出好内容的机会。我们100%的精力会全部放在如何做、怎么做。因为那么多用户摆在那里，将来一定会赚大钱。既然你将来会挣大钱，那现在赶紧干活就是对的。如果瞻前顾后，只会让你在这条路上走得更慢。你去做这件事情，只要把内容做好，用户一定会来。 但2017年，这个行业迎来了一个增长点，而且曾经行业遇到的关键问题已经被解决。一是教育支付问题，二是学习动力问题。教育支付是虚拟产品，买了之后其实是拿不到东西的。而且往往教育服务也比较贵。比如说一个课程5000元甚至上万，对于这样一个虚拟服务，大家能不能信任？ 其次，可以看到，从2011年起步到2013年左右的高峰，再到2015年左右的低谷，在线教育行业走了一个巨大的弯路，这个弯路就是MOOC。当时大家以为这就是未来在线教育的全部形态，在经过好几年的摸索之后，才有一些公司勇敢地跳出来说，我们应该做直播教学，MOOC并不能代表未来的整个在线教育，因为它最大问题是不能解决学习动力问题。 任何东西如果能提升学习效率的都是好东西，既能解决效率又能解决动力的就是会大卖的产品。MOOC是只能解决效率，对于动力没任何帮助。有的学生看着录播的课就会睡着了。 在线教育的TEACH模型 有道本身不是一个追逐风口的公司，在这个行业目前我认为最核心的是品质。 三十年前，微软公司提出软件开发的铁三角，若要做好软件开发，先要做好铁三角：产品管理、开发、测试。我的电商朋友告诉我，做好电商，要做好6个方面：采购、库存、流量、设计、物流、客服。这些方向选择是非常有道理的，比如设计，在电商经营中，产品卖相非常重要，所以你看到电商网页都设计得非常精美。 那么，在线教育业务模型应该是怎样的？这个问题很复杂。我一直强调，在线教育产品最核心的是品质。它跟线下教育很不一样。线上教育没有地域限制，大家的竞争是一个更加拼产品的竞争，所有组织都要围绕怎么样把产品做好，更多的是去解决内容和服务的品质的问题。 上周融资发布会，我讲的我对于有道业务模式的理解是五个字母：TEACH，这五方面做好可能你的业务就八九不离十。 T，指的有道的工具型产品（tools）。E，老师（educator）。A，以AI为代表的教育科技。C是Content，内容，H，即Hardware，是硬件。最开始和朋友聊天，大家提出来的是营销再加教研教学，然后再加IT系统，我个人觉得这个思路更传统一些。 Tools，工具。我们自己做了很多免费的学习型工具产品。既然你是在线，最好服务用户办法是做免费产品，学习本身是件反人性的事情，相比于娱乐社交产品，学习教育产品本身不容易做到体量非常大，但因为你做免费工具产品解决了用户很多场景下的某个痛点的需求，这是公司给整个社会带来影响力非常好的方式。那么另一方面，可以让你获得流量。其实“T”在业内比较普适的可能是流量（traffic），只不过在流量越来越贵的今天，我们认为单纯对流量的追求不能解决做好在线教育这件事的根本。 当然，好内容这件事情是一个很长时间以来大家都在做的事情，通过持续的长时间分享好内容就可以聚拢大量用户。我们做的事情是工具，目前我们已经积累8亿全平台用户和1700万全平台日活。 E，educator，老师，非常重要，他扮演的不是标准化念稿子的角色，我们认为明星老师是提升学习动力和学习效率的最佳驱动力。2016年，因为基于这样的判断，就推出了同道计划，通过投入5个亿，打造20个教育工作室。在线教育环境下，工作室是组织所有教学活动非常好的方式。因为没有地域的困难，可以把所有资源集中在一起做成办公室。有道教育办公室有个特点，是全国性的、人格化的，采用工作室模式，以及最后和老师分成运营。这样的模式我们运作两年以后发现非常有利，2017年业务对比2016年，带来530%的增长，全年听课学生数量超过300万，单课程同时在线学习人数是47000人，这个说明了工作室的模式其实是合理的。 持久成功的明星老师的特质：第一，三观正。第二，教学业务一流，对应领域的翘楚。第三，耐得住寂寞，他的很多方式要针对网络特点做修改，不断打磨产品。第四，会带团队。 A就是AI，AI是增强我们的工作室模式的能力的一个手段。这轮AI带来的革命，本质是使用数据来编程，它可以拓宽我们解决的大量问题的范围，解决问题的精度，使很多问题变成可能性，它的影响非常大，我们认为未来五年将要改变教育面貌。 C，内容。我们看到非常可喜的一个事情是在线教育课程中，教研过程很重要。2017年有个爆款课程是逻辑英语，最初这个课程大概40万左右月营收，开设的是传统的口语、单词类的专项课程，第二阶段我们把专项课改成了合班课程，业务规模增长了4倍。业务增长，一种办法是加强营销，一种办法是继续深挖教研，我们选择后者。所以到第三阶段我们推出有道痴学社产品，陪伴用户学习为主的概念，这样就是从卖课的思维转变成了提供服务的思路，用户可以利用碎片时间随时练习，通过这个，课程有了进一步增长，到现在每月接近千万的数量级的变化。所以课程迭代非常关键。 最后是硬件，如果公司想要布局在线教育的未来，那一定会考虑做硬件，但做硬件确实非常困难。有个最大的疑问是你将来很可能会被手机收割。但做硬件也有好的方面，教育行业和其他行业不同，教育场景不能被手机覆盖。小学生纸笔交互要求非常高，家长非常强调护眼需求，不想让小孩子用手机，小孩子有非常强的语音交互，这些都支持我们用智能硬件。二是越来越多用户开始接受智能硬件。 教育+AI重在落地 在线教育产品中，我坚持使用教育+AI的说法。在应用AI过程中，要分清楚是接近成熟的技术还是尚在实验室阶段的技术。在线教育行业里，要做到脱颖而出，最核心还是两方面，一是品质，就是有基因，在这里面永远是有有价值的。二是用户流量和AI这样的技术，是加分的项目。现在AI整个行业现在最大的困扰，就是说我有一大堆技术拿来干什么，很多公司变成拿锤子找钉子，先做一大堆锤子，然后墙上到处找钉子。那我们从一开始就觉得AI要落地，这才是关键。 我们对AI的看法是质变到量变的过程，不是改变教育的面貌，纯AI老师在一些领域是有它的用武之地的，比如外语学习，是有可能可以的，因为外语很多是基于练习的过程。但是在大量的中小学数理化语文学科学习中间，AI可以发挥非常大的作用，可以做很多原来做不了的事情，比如作业反馈，比如作文提升空间能够发挥更大的作用，我们也会花很大力气把这些系统去实际落地。 我们的愿景就是通过技术和AI让语言交流、学习工作变得更加轻松和有效。这个就是最大的机会，因为对于新一代年轻人来说，他们面临的挑战太多了。 （周枫系网易高级副总裁兼网易有道CEO，本报记者陈伊凡、实习记者张燕征采访整理） 转载来源：在线教育公司该有哪些标配]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>电子商务</tag>
        <tag>在线教育</tag>
        <tag>MOOC</tag>
        <tag>有道词典</tag>
        <tag>网易有道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在线教育公司该有哪些标配]]></title>
    <url>%2F2018%2F7fa8dd6d%2F</url>
    <content type="text"><![CDATA[经济观察报周枫/文在线教育行业现在正处于一个风口。全国现在包括大学生在内大概有2亿左右的学生，这么大一个市场，中间很多需求都没有被满足，还可以干很多事。 （图片提供：全景视觉） 经济观察报 周枫/文在线教育行业现在正处于一个风口，这是一个很好的时机，因为行业起步的关键问题都解决了。一些投资人集中聊起在线教育，也是近几年发生的事情。 2013、2014年是在线教育的投资高峰。2015、2016年这个行业遇冷，很多创业公司都因拿不到钱死掉。2017年又是在线教育行业增长迅猛的一年。 在线教育这个盘子非常大，整个教育大概万亿级的市场，大几千亿的中小学的教育生意，全国现在包括大学生在内大概有2亿左右的学生，这么大一个市场，中间很多需求都没有被满足，还可以干很多事。我们做了三年多时间在线教育，这个行业还没有一个特别清晰的规划，要做好在线教育业务，究竟需要做好哪些方面的事情。 MOOC的弯路 从2011年底有道词典突破1亿大关，我们就觉得这个肯定是可以做教育业务的。但当时我们很明确判断是卖不出去。 当时我们的想法是，既然有这么多学习用户，那把它推到线下去。所以有道当时跟一些线下的培训机构合作，让用户去尝试他们的产品。最后，这个产品形态变成了一个营销型的产品。 根据这个模式我们做了几年，这个模式现在还在，叫有道智选的广告服务。 2013、2014年，市场出了一大堆教育产品，当时有个投资高峰，但是大家的产品形态还不成熟，开门面店，然后让老师们过来上传课程，上传的都是录播课，上传之后老师自己定价。然后就开始出现有老师把价格定特别低，也有老师把课特别高，课程水平参差不齐，有些时候看着介绍特别好，观看之后发现讲得一般。最后发现，引一大堆用户过来，结果买的课不是很多，而且买完之后口碑还很差，所以很多公司在2016年左右关门，当时有道没有想着在13、14年进这个局，只是想做一个好产品。 我们愿意花很长时间，做好一件事。因此，有道不受融资周期的影响。网易是一家极度以用户为中心的公司，这是我们愿意做基业长青的事情。我们觉得教育这边有巨大的需求，有大量做出好产品，做出好内容的机会。我们100%的精力会全部放在如何做、怎么做。因为那么多用户摆在那里，将来一定会赚大钱。既然你将来会挣大钱，那现在赶紧干活就是对的。如果瞻前顾后，只会让你在这条路上走得更慢。你去做这件事情，只要把内容做好，用户一定会来。 但2017年，这个行业迎来了一个增长点，而且曾经行业遇到的关键问题已经被解决。一是教育支付问题，二是学习动力问题。教育支付是虚拟产品，买了之后其实是拿不到东西的。而且往往教育服务也比较贵。比如说一个课程5000元甚至上万，对于这样一个虚拟服务，大家能不能信任？ 其次，可以看到，从2011年起步到2013年左右的高峰，再到2015年左右的低谷，在线教育行业走了一个巨大的弯路，这个弯路就是MOOC。当时大家以为这就是未来在线教育的全部形态，在经过好几年的摸索之后，才有一些公司勇敢地跳出来说，我们应该做直播教学，MOOC并不能代表未来的整个在线教育，因为它最大问题是不能解决学习动力问题。 任何东西如果能提升学习效率的都是好东西，既能解决效率又能解决动力的就是会大卖的产品。MOOC是只能解决效率，对于动力没任何帮助。有的学生看着录播的课就会睡着了。 在线教育的TEACH模型 有道本身不是一个追逐风口的公司，在这个行业目前我认为最核心的是品质。 三十年前，微软公司提出软件开发的铁三角，若要做好软件开发，先要做好铁三角：产品管理、开发、测试。我的电商朋友告诉我，做好电商，要做好6个方面：采购、库存、流量、设计、物流、客服。这些方向选择是非常有道理的，比如设计，在电商经营中，产品卖相非常重要，所以你看到电商网页都设计得非常精美。 那么，在线教育业务模型应该是怎样的？这个问题很复杂。我一直强调，在线教育产品最核心的是品质。它跟线下教育很不一样。线上教育没有地域限制，大家的竞争是一个更加拼产品的竞争，所有组织都要围绕怎么样把产品做好，更多的是去解决内容和服务的品质的问题。 上周融资发布会，我讲的我对于有道业务模式的理解是五个字母：TEACH，这五方面做好可能你的业务就八九不离十。 T，指的有道的工具型产品（tools）。E，老师（educator）。A，以AI为代表的教育科技。C是Content，内容，H，即Hardware，是硬件。最开始和朋友聊天，大家提出来的是营销再加教研教学，然后再加IT系统，我个人觉得这个思路更传统一些。 Tools，工具。我们自己做了很多免费的学习型工具产品。既然你是在线，最好服务用户办法是做免费产品，学习本身是件反人性的事情，相比于娱乐社交产品，学习教育产品本身不容易做到体量非常大，但因为你做免费工具产品解决了用户很多场景下的某个痛点的需求，这是公司给整个社会带来影响力非常好的方式。那么另一方面，可以让你获得流量。其实“T”在业内比较普适的可能是流量（traffic），只不过在流量越来越贵的今天，我们认为单纯对流量的追求不能解决做好在线教育这件事的根本。 当然，好内容这件事情是一个很长时间以来大家都在做的事情，通过持续的长时间分享好内容就可以聚拢大量用户。我们做的事情是工具，目前我们已经积累8亿全平台用户和1700万全平台日活。 E，educator，老师，非常重要，他扮演的不是标准化念稿子的角色，我们认为明星老师是提升学习动力和学习效率的最佳驱动力。2016年，因为基于这样的判断，就推出了同道计划，通过投入5个亿，打造20个教育工作室。在线教育环境下，工作室是组织所有教学活动非常好的方式。因为没有地域的困难，可以把所有资源集中在一起做成办公室。有道教育办公室有个特点，是全国性的、人格化的，采用工作室模式，以及最后和老师分成运营。这样的模式我们运作两年以后发现非常有利，2017年业务对比2016年，带来530%的增长，全年听课学生数量超过300万，单课程同时在线学习人数是47000人，这个说明了工作室的模式其实是合理的。 持久成功的明星老师的特质：第一，三观正。第二，教学业务一流，对应领域的翘楚。第三，耐得住寂寞，他的很多方式要针对网络特点做修改，不断打磨产品。第四，会带团队。 A就是AI，AI是增强我们的工作室模式的能力的一个手段。这轮AI带来的革命，本质是使用数据来编程，它可以拓宽我们解决的大量问题的范围，解决问题的精度，使很多问题变成可能性，它的影响非常大，我们认为未来五年将要改变教育面貌。 C，内容。我们看到非常可喜的一个事情是在线教育课程中，教研过程很重要。2017年有个爆款课程是逻辑英语，最初这个课程大概40万左右月营收，开设的是传统的口语、单词类的专项课程，第二阶段我们把专项课改成了合班课程，业务规模增长了4倍。业务增长，一种办法是加强营销，一种办法是继续深挖教研，我们选择后者。所以到第三阶段我们推出有道痴学社产品，陪伴用户学习为主的概念，这样就是从卖课的思维转变成了提供服务的思路，用户可以利用碎片时间随时练习，通过这个，课程有了进一步增长，到现在每月接近千万的数量级的变化。所以课程迭代非常关键。 最后是硬件，如果公司想要布局在线教育的未来，那一定会考虑做硬件，但做硬件确实非常困难。有个最大的疑问是你将来很可能会被手机收割。但做硬件也有好的方面，教育行业和其他行业不同，教育场景不能被手机覆盖。小学生纸笔交互要求非常高，家长非常强调护眼需求，不想让小孩子用手机，小孩子有非常强的语音交互，这些都支持我们用智能硬件。二是越来越多用户开始接受智能硬件。 教育+AI重在落地 在线教育产品中，我坚持使用教育+AI的说法。在应用AI过程中，要分清楚是接近成熟的技术还是尚在实验室阶段的技术。在线教育行业里，要做到脱颖而出，最核心还是两方面，一是品质，就是有基因，在这里面永远是有有价值的。二是用户流量和AI这样的技术，是加分的项目。现在AI整个行业现在最大的困扰，就是说我有一大堆技术拿来干什么，很多公司变成拿锤子找钉子，先做一大堆锤子，然后墙上到处找钉子。那我们从一开始就觉得AI要落地，这才是关键。 我们对AI的看法是质变到量变的过程，不是改变教育的面貌，纯AI老师在一些领域是有它的用武之地的，比如外语学习，是有可能可以的，因为外语很多是基于练习的过程。但是在大量的中小学数理化语文学科学习中间，AI可以发挥非常大的作用，可以做很多原来做不了的事情，比如作业反馈，比如作文提升空间能够发挥更大的作用，我们也会花很大力气把这些系统去实际落地。 我们的愿景就是通过技术和AI让语言交流、学习工作变得更加轻松和有效。这个就是最大的机会，因为对于新一代年轻人来说，他们面临的挑战太多了。 （周枫系网易高级副总裁兼网易有道CEO，本报记者陈伊凡、实习记者张燕征采访整理） 转载来源：在线教育公司该有哪些标配]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>电子商务</tag>
        <tag>在线教育</tag>
        <tag>MOOC</tag>
        <tag>有道词典</tag>
        <tag>网易有道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IBM、哈佛联合提出Seq2Seq-Vis：机器翻译模型的可视化调试工具]]></title>
    <url>%2F2018%2F0d418878%2F</url>
    <content type="text"><![CDATA[例如，之前由于 seq2seq 翻译系统将「早上好」错误的翻译为了「攻击他们」，导致错误的逮捕事故。 语言翻译中出现的细微错误对于人类而言常常是很明显的，并会导致差异很大的结果。例如，之前由于 seq2seq 翻译系统将「早上好」错误的翻译为了「攻击他们」，导致错误的逮捕事故。深度学习模型的不可解释性更是普遍存在的问题。为此，IBM 研究院、Watson AI Lab、哈佛 NLP 团队和哈佛视觉计算团队联合研发了一款针对 seq2seq 模型的可视化调试工具 Seq2Seq-Vis，使用户可以可视化模型执行过程中的注意力、单词预测、搜索树、状态轨迹和近邻词列表等，从而更高效地进行分析和调试。 项目演示地址：http&#58;//seq2seq-vis.io/- GitHub 地址：https&#58;//github.com/HendrikStrobelt/Seq2Seq-VisGitHub 地址：https&#58;//github.com/HendrikStrobelt/Seq2Seq-Vis 图 1：（左图）Seq2Seq-Vis 中翻译视图（Translation View）示例：输入语句为「our tool helps to find errors in seq2seq models using visual analysis methods」，目标是将其翻译为德语。编码器和解码器之间对单词「seq2seq」的关注（attention）是正确的（红色高亮线条），但目标语言的语言词典 (language dictonary) 中并没有对应单词。观察「seq2seq」的编码器近邻词（右图）可以发现，另一个未知单词「hunki」与其距离很近。各种按钮能够支持用户完成更深层分析的交互需求。 介绍 基于神经网络的深度学习方法在诸多人工智能任务中都表现出了惊人的提升效果，但复杂的结构也令人们很难解释其预测结果。基于注意力的 sequence-to-sequence models (seq2seq) &#91;3, 49&#93;，通常也称为编码器-解码器（encoder-decoder）模型，就是这一趋势的范例。在很多诸如机器翻译、自然语言生成、图像描述以及总结的应用场景中，seq2Seq 模型都表现出了当前最优的效果。最新研究表明，这些模型能够在特定的重要场景下，实现人类级别的机器翻译效果。 seq2seq 模型的强大性来自于其为对序列的处理和预测提供了一个高效的监督方法，而无需对源序列和目标序列间的关系予以人工指明。在同一个模型中，系统能够学会对源序列句进行重排、转换、压缩或扩展，进而输出目标序列。上述变换是通过一个巨大的内在状态表征实现对源序列的编码及之后的解码工作的。只要数据量充足，seq2seq 模型就能为预测序列的学习提供一个通用的实现机制。 虽然 seq2seq 模型的影响已经很明确了，但深度学习模型导致的复杂程度和不确定性的增加也带来了问题。通常，在给出预测时，这些模型的表现都像是一个黑箱，使得追踪错误源头也变得困难。而内部的潜在表征也使人们难以分析这些模型，因为它们将数据转化成了和原始序列相差甚远的结果。虽然这些性质是很多深度学习技术所共有的，但对于人类读者而言，语言中的错误会非常明显。例如，由于 seq2seq 翻译系统将「早上好」错误的翻译为了「攻击他们」，导致了一次错误的逮捕，最终成为一起广为人知的事故 &#91;12&#93;。除此之外，seq2seq 模型中更常见却也值得担忧的失败包括：机器翻译系统完全曲解了一句话，图像描述系统生成了错误的描述，或语音识别系统给出了错误的文本。 在理想情况下，模型开发者希望部署能够完全理解、相信其产生结果是正确的系统。但目前对于深度学习模型而言，这个目标依然难以实现。同时研究者相信，在「以一种通用的、可复现的方式实现表象化、可视化 seq2seq 系统中的错误」这一重大挑战面前，可视化分析社区能够有所帮助。 研究者开发了 SEQ2SEQ-VIS：一个能够通过实现以下三个目标，进而满足上述要求的可视化分析工具。 检查模型决策：SEQ2SEQ-VIS 允许用户理解、描述并具体化 seq2seq 模型的错误，覆盖模型全部的五个阶段：编码器、解码器、注意力、预测、束搜索。- 连接样本和决策：SEQ2SEQ-VIS 展示了 seq2seq 模型基于潜在状态及其相关近邻，从训练数据中学到了什么。- 测试可选决策：SEQ2SEQ-VIS 提供了灵敏的交互方法，可以实现对模型内部进行操作。连接样本和决策：SEQ2SEQ-VIS 展示了 seq2seq 模型基于潜在状态及其相关近邻，从训练数据中学到了什么。 图 1（或更完整的图 7）展示了 SEQ2SEQ-VIS 的全貌。它整合了模型组件的可视化（图 1 左）、特定样本的内在表征（图 1 中），和在一个由预先计算好样本组成的巨大离线语料库上实现的最近邻搜索（nearest-neighbor lookup）。 图 2：seq2seq 模型通过五个阶段，将源序列翻译为目标序列：（S1）将源序列编码为潜在向量，（S2）将其解码为目标序列，（S3）编码器和解码器之间实现注意，（S4）在每个时间步骤中，预测单词概率，（S5）（通过束搜索）搜索最佳翻译。 图 7：Seq2Seq-Vis 概述。两个重要视图：（a）翻译视图（Translation View）和（b）近邻视图（Neighborhood View）分别推动了不同的分析模式。翻译视图提供了（c）注意力的可视化，（d）每个时间步骤中 top-k 个单词预测，以及（e）束搜索树。近邻视图通过（f，g）状态轨迹的投影以及（h）针对一个特定模型状态的最近邻列表，更进一步展示模型学到了什么。 使用案例 图 10：一个日期转换模型翻译效果的比较。输入序列「March 21, 2000」和「May 21, 2000」仅有几个字符不同。（顶部）用于预测正确月份「3」和「5」的注意力集中在了其差异「y」和「rc」上。（左下）轨迹视图展示了编码器状态变化中的这一差异。（右下）近邻列表显示，在输入 M 后，模型依然未作出决策。 图 11：抽象总结的使用案例。输入句子「Russian defense minister Ivanov called Sunday for the creation of a joint front for combating global terrorism（俄罗斯国防部长 Ivanov 于周日呼吁联合抵抗全球性的恐怖主义）」可以有不同的总结形式。图中黄色方格展示了不同的前缀解码（prefix decode）设置下的抽象结果。顶部：无约束抽象；中间：将预测从「for」改成「on」后，为保证语法正确，导致模型自动加上了「world leaders」；底部：将第一个单词从「Russian」改为「Moscow」或「Russia」，句子进一步压缩后，依然保留了句意。 图 12：利用 WMT』14 数据完成语言翻译的使用案例。（顶部）注意力图展示了目标单词「he」的注意力并非仅集中在解码器「er」部分，而是同时注意力了后面的单词，甚至注意了距离很远的动词「gesprochen（说）」。解码器的状态轨迹（左下）显示「he」和「spoke」的距离非常接近。近邻列表表明，模型设置了一个阶段，其中预测「spoke」为下一个单词。 图 13：一个欠训练的英语-德语模型。在欠训练或欠参数化模型中，重复是一个很常见的现象。轨迹象形图显示，在「in Stuttgart」的重复中，解码器状态在同一个区域内在「in」和「Stuttgart」交替变化，直到将它们分离出来。 论文：SEQ2SEQ-VIS &#58; A Visual Debugging Tool for Sequence-to-Sequence Models 论文地址：https&#58;//arxiv.org/abs/1804.09299 神经 Sequence-to-Sequence 模型已经通过许多序列预测任务证明了其具有准确、稳健的性质，也已经成为文本自动翻译的标准方法。Sequence-to-Sequence 模型的运行包含五个黑箱阶段，包括将源序列编码到一个向量空间中，再将其解码为新的目标序列。如今这是标准过程，但和许多深度学习方法一样，理解或调试 Sequence-to-Sequence 模型是很困难的。在本文中，研究者实现了一个可视化分析工具，使用户可以通过训练过程中的每个阶段，与训练好的 Sequence-to-Sequence 模型进行交互。其目标包含识别已被学到的模式，并发现模型中的错误。 转载来源：IBM、哈佛联合提出Seq2Seq-Vis：机器翻译模型的可视化调试工具]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>可视化</tag>
        <tag>哈佛大学</tag>
        <tag>IBM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用 FileManager 搭建个人网盘]]></title>
    <url>%2F2018%2F93dedd01%2F</url>
    <content type="text"><![CDATA[为什么需要自己搭建网盘目前网盘大部分不是限速就是限制容量，体验太差；分享不受限制。基于Go语言提供Web交互的文件管理程序，操作方便，轻量级搭建极其简单，多平台支持，可以运行在路由器中；多用户管理，可以共享系统给他人使用。 为什么需要自己搭建网盘 目前网盘大部分不是限速就是限制容量，体验太差；- 分享不受限制，高级功能不受会员限制；- 具有局域网最大速度访问优势，在线浏览图片、影音速度都可以慢速需求。分享不受限制，高级功能不受会员限制； FileManager 是什么？ 基于 Go 语言提供 Web 交互的文件管理程序，操作方便，轻量级搭建极其简单，多平台支持，可以运行在路由器中；- 多用户管理，可以共享系统给他人使用；- 文件上传、下载(支持打包下载)、预览、文档在线编辑功能、目录和文件管理创建。多用户管理，可以共享系统给他人使用； 我的使用场景 临时分享文件使用。如果搭建在服务器上，服务器空间昂贵，但是上传和下载速度比普通宽带快，分享临时文件方便快捷；- 搭建在路由上，然后路由器通过 frp 内网穿透，远程访问家中路由器上文件，相对 NAS 更加省电，浏览图片和音乐家里的上传带宽也够用；- 相对于 Smb、ftp、webdav 连接过程更简单，用于在公用电脑上下载自己常用的软件，不需要安装任何客户端软件。直接建立一个公共只读账户，放一些自己常用的工具软件，方便传输。搭建在路由上，然后路由器通过 frp 内网穿透，远程访问家中路由器上文件，相对 NAS 更加省电，浏览图片和音乐家里的上传带宽也够用； 如何搭建？ 或者 Windows 平台使用 PowerShell 配置 FileManager 简单配置 port：服务所用端口- database：数据库存放地址- scope：需要管理的文件夹路径- allowCommands：允许使用指令- allowEdit：允许进行文件编辑操作- allowNew：允许进行新建文件和文件夹操作- 更多配置请参考官方文档 &#91;配置文档&#93;(https&#58;//henriquedias.com/filemanager/configuration/)database：数据库存放地址 allowCommands：允许使用指令 allowNew：允许进行新建文件和文件夹操作 运行服务 加入 supervisor 使用 nginx 转发端口 访问：file.xxxx.com 或者 xxxx.com&#58;1250 即可，默认账户&#58;admin 默认密码：admin 登陆之后可以进行密码重置。 界面预览 基本功能 多用户管理 更多高级功能，请参考 FileManager 转载来源：利用 FileManager 搭建个人网盘]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>路由器</tag>
        <tag>文本编辑器</tag>
        <tag>Go语言</tag>
        <tag>Vim</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[陆奇举刀，百度第三次重组内阁]]></title>
    <url>%2F2018%2F2417c49b%2F</url>
    <content type="text"><![CDATA[2018年3月，百度贴吧事业部总经理胡玥、百度地图事业部总经理李东旻、90后副总裁李靖在一个月内陆续出走。 转载来源：陆奇举刀，百度第三次重组内阁]]></content>
  </entry>
  <entry>
    <title><![CDATA[史上最虐的《复联3》到底有多虐？]]></title>
    <url>%2F2018%2Fad69c8e0%2F</url>
    <content type="text"><![CDATA[因为即使最悲观的影迷走进影院，可能还是会发现，真实的结局比自己想象的还要悲观，这一次，超级英雄们集体失去了主角光环。 但我还是要提醒所有的影迷做好心理准备，因为即使最悲观的影迷走进影院，可能还是会发现，真实的结局比自己想象的还要悲观，这一次，超级英雄们集体失去了主角光环。 《帝国》影评人HelenO’Hara说的非常好：“无论觉得自己多么积极，你都还没有准备好灭霸的到来。我们的超级英雄也没有做好准备。” 虽然整部电影中，超级英雄的战斗力显得有些难以琢磨，过去几部电影中经常和钢铁侠绿巨人打个平手的锤哥，突然成为了整个漫威宇宙唯一可以和手握六颗钻石的灭霸正面刚的超级英雄，而灭霸只有两枚钻石的时候，还曾经虐得锤哥连喘气的机会都没有。 但总的来说，一切都可以概括为：所有的超级英雄，都被史上最有深度的反派灭霸给完爆了。 虽然这场悲剧史诗的过程依然充满着漫威式的欢乐，比如钢铁侠和奇异博士在宇宙偶遇星爵和毁灭者德拉克斯，两拨人还争论起谁的点子更好，后来小蜘蛛也加入到了这场套路中。又比如绿巨人变身的段子，都让这场悲剧在最后的结局到来之前依然热闹地欢天喜地，以至于最后的结局真的出现时，我简直不敢相信这是一部漫威电影。 必须告诉你的是，预告片中关于超级英雄领便当的剧透其实就是一系列炫目的假动作，有些是事实，有些是部分的事实，还有一些打乱了镜头的前后顺序，总之最好的办法是都别信。 比如里面有老神盾局长和钢铁侠最后一场对话，钢铁侠第一次泪如雨下的镜头，有雷神被灭霸单手爆头的画面，也有美队单挑灭霸的镜头，还有奇异博士被灭霸完虐的镜头。 可以告诉你的是，这其中肯定有真实的剧情，但也有很多是虚晃一枪。 有些人死了，其实还活着，有些人活着，其实已经死了。 总之我以后是再也不看漫威的预告片了，尤其是看着那些预告片中安然无恙说着段子的超级英雄被团灭时，那种感觉实在太扎心了。 我最后能剧透的一点是：按照设定，灭霸只要攒齐六颗无限宝石就能拥有毁灭宇宙的能力，这正是整部电影三条故事线的核心所在—— 149分钟，32位英雄齐齐亮相，从从银护外太空救人，到国奇异博士吹号，再到几个小队分别抵御灭霸，黑豹带队和灭霸百万大军血战瓦坎达，最后是灭霸“集宝石”，节奏如水银泄地一气呵成，三个小时几乎是直接飙到结局。 那么结局呢？ 结局是灭霸的确拥有了毁灭宇宙的能力。 由此你就能猜到超级英雄们的结局了。至于已经损兵折将、伤亡惨重的超级英雄们如何扳回一局？ 请看《复联4》。 罗素兄弟最令人惊叹的地方在于，他们终于为《复仇者联盟》系列，注入了过去少有的爆发式的情感。 我不知道你会被钢铁侠和小蜘蛛的亲情感动，还是被冬兵对着美队的最后一笑虐心，甚至是幻视和红女巫的生死相许，都有可能打动许多人。 我的建议是，所有的女孩都至少应该带一包纸巾，男人应该带两包，一包给女友，一包留给自己。 别抱有任何幻想，这是一部让超级英雄们集体绝望，而让爱他们的观众比他们更绝望的电影。 从某种意义上说，罗素导演甚至为了最大限度迁就每一位超级英雄和影片那个令人心碎的结局，放弃了影片的节奏，但这种放弃是值得的，正是这种放弃，让所有的角色都赢得了一次面对面和观众告别，虽然告别的时候，你可能不知道那就是告别。 这部电影甚至让我想起了《极限挑战3》的那座时光大桥，你和这些超级英雄们走着走着，仿佛永远没有尽头，可是当结局到了的时候，甚至不会提前通知你一声，上一秒还陪着你走的超级英雄，就这么停在那里了。 就仿佛你自己的心被剜掉一大块一样。我无法形容结局到来那一刻的感受。 我只能告诉你，这绝对是有史以来最欢快又最悲情的超级英雄电影。甚至很可能，这就是我有生之年，看过的最令人伤感的大结局了。也许对你也是如此。 《复联4》将是漫威老一辈英雄告别礼，可没有雷神钢铁侠美队的漫威还能火下去吗？ 但正如我们知道的那样，《复联3》和《复联4》是上下篇，这一部真正的结局，必须由明年上映的《复联4》给出。 从那部谁都不看好的《钢铁侠》开始，“漫威影业花费了十年时间，有条不紊的创造了一系列的人物、世界和故事，所有这些都创造了一个与众不同的事件。”现在，这一切正在走向一个历史性的中场结局。 和所有的赛事一样，比赛要继续，但所有的球员都会在某个时刻退场。 并且永不复还。 在《复联3》中，好莱坞的三位克里斯——克里斯·埃文斯、克里斯·海姆斯沃斯和克里斯·普拉特终于首次同框出现。从影片的情况看，这一幕很可能不会再有了。而小罗伯特·唐尼已经说过很可能不会有《钢铁侠4》了。克里斯·埃文斯也早就暗示过，《复4》肯定是他的终章。 某种意义上说，这是漫威的无奈之举，随着电影宇宙愈发庞大，倘若算上银河护卫队，单单超级英雄的人数便会达到两位数，如果无限扩容下去，总有一天观众会分不清谁是谁。 就算罗素兄弟的才华可以解决人多的问题，但从《美国队长3》启动的漫威第三阶段已经进行到此。好莱坞的游戏规则是：一切必须按计划行事。 漫画里的时间线可以修改，但电影不能轻易让角色死而复生，而一个失去了钢铁侠、美国队长和雷神的复仇者联盟会怎样，一切很难想象。 某种意义上说，《复联3》和《复联4》就是要把此前漫威电影宇宙积累的好牌都打出去，至于未来的事情，未来再说。 或许《雷神3》的片名才是对老一辈《复联》英雄们最好的形容——诸神黄昏。 需要说明的是，尽管漫威仍是超级英雄电影中的领军人物，但他们的对手越来越强了。福斯公司的“X战警”系列即将重启，《死侍》来势汹汹，而华纳兄弟已经开始凭借《神奇女侠》和《海王》找到感觉。 相比之下，一再重复“冷笑话+华丽特效+彩蛋”的漫威电影套路在被《复联3》《复联4》推到极致后，很可能会遭遇市场的物极必反。 十多年了，除了Netflix的《夜魔侠》《惩罚者》等超级英雄剧集，漫威几乎没有做出过改变，虽然“尾灯”已经离开了漫威宇宙，但他的《复联1》依然奠定了整个系列的风格，即便是充满悲情的《复联3》。 凯文·费奇在2014年时候说，漫威电影计划已经排到了2028年，除了新加入的2019年将推出独立电影的惊奇队长、毒液、渐渐老去的黑寡妇应该能坚持到那个时候，我们不确定雷神、美队和钢铁侠还能坚持多久。 我们也无法确定，《复联3》甚至整个漫威系列，在电影史上，到底将是一种怎样的存在？总有人对它嗤之以鼻，其中包括《阿凡达》导演詹姆斯卡梅隆。 但对更多的人来说，这些超级英雄甚至成为了生命中的一部分，他们构成了这个残酷世界的一抹亮色，即使是虚幻的，依然给人希望。 其中就包括死侍。在他申请加入复联后，收到了一封来自托尼·斯塔克的简短信件，最后一句是“你去烦X教授吧”。 你看，能够让这么多人把这个故事当真，不仅是因为好莱坞的大笔金钱，而是即使是爆米花，漫威也也是花费了十年用心打造出一个真实的世界，它就是漫威宇宙。 回到2009年，迪士尼联合主席鲍勃·艾格力排众议斥资40亿美元收购了漫威，尽管当时漫威的许多超级英雄角色都还没有获得票房的正名，现在看来，这40亿花得可真值！ 最后我的问题依然是：你是否已经准备好了，和这些陪伴了你十年的超级英雄挥手告别？ 转载来源：史上最虐的《复联3》到底有多虐？]]></content>
      <categories>
        <category>娱乐</category>
      </categories>
      <tags>
        <tag>复仇者联盟</tag>
        <tag>超级英雄</tag>
        <tag>漫威电影宇宙</tag>
        <tag>萨诺斯</tag>
        <tag>凯莉·罗素</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[刚刚，北京十一学校发布2018初中入学通知]]></title>
    <url>%2F2018%2F481814c5%2F</url>
    <content type="text"><![CDATA[十一学校2018初中入学通知正式发布，具体通知内容如下：2018年初中入学通知我校作为北京市综合教育改革实验学校，将面向应届小学毕业生招收初中入学综合素质优异及专项优异的学生。 “京城教育圈”今天（5月7日）获悉，十一学校2018初中入学通知正式发布，具体通知内容如下： 2018年初中入学通知 我校作为北京市综合教育改革实验学校，将面向应届小学毕业生招收初中入学综合素质优异及专项优异的学生。入学工作安排如下： 一、报名资格**：**具有初中入学资格的应届小学毕业生。 二、流程： 1.网上报名 （1）报名时间：5月7日早9&#58;00—5月10日中午12&#58;00 （2）报名网址：http&#58;//zs.bnds.cn （3）报名时须如实填写个人信息、综合素质指标、 相关附件。家长须记住自动生成的报名号。 报名类别可选择三种情况之一：综合素质优异；专项优异；兼报两类。 专项优异每人只选一个具体项目。 2.专项才艺展示和综合优异材料审阅 （1）接到学校通知的专项优异学生按要求到学校参加专项才艺展示。 （2）学校对综合素质优异学生的报名材料组织审阅。 3.录取 学校将在5月28日前通知录取学生。未录取学生不再另行通知。 2018.5.6 附：专项优异学生才艺展示具体项目及展示内容： 编辑| 江远 图片来源| 网络 内容来源| 十一学校官方网站 转载来源：刚刚，北京十一学校发布2018初中入学通知]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>教育</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[年度最戳心视频：焦虑的中国父母，正在废掉我们的下一代]]></title>
    <url>%2F2018%2Fb610df66%2F</url>
    <content type="text"><![CDATA[最近61岁的陈美龄在网上又火了。 这个曾在香港乐坛红极一时，与邓丽君齐名的女歌手，退隐歌坛30年后，又一次刷屏朋友圈。不过，这次是以妈妈的身份。 她把三个儿子，先后送进了美国排名第一的斯坦福大学。 最近，她接受了一个采访： 视频中侃侃而谈的陈妈妈的教育理念引起无数人深思：“不要让中国式焦虑，废掉了你的孩子”。 01 陈美龄在视频中提到了很多点… 最近61岁的陈美龄在网上又火了。 这个曾在香港乐坛红极一时，与邓丽君齐名的女歌手，退隐歌坛30年后，又一次刷屏朋友圈。不过，这次是以妈妈的身份。 她把三个儿子，先后送进了美国排名第一的斯坦福大学。 最近，她接受了一个采访： 视频中侃侃而谈的陈妈妈的教育理念引起无数人深思：“不要让中国式焦虑，废掉了你的孩子”。 01 陈美龄在视频中提到了很多点，都让无数父母瞠目结舌，比如：不要制定每天的时间表、不要给孩子报课外班、不要替孩子做选择…… 这种教育理念完全和我们背道而驰。要知道大多数中国父母唯恐孩子输在起跑线上，所以拼尽全力给孩子报最好的辅导班，送进最好的学校。 去年，有一篇《月薪三万，还是撑不起孩子的一个暑假》的文章更是扎了无数父母的心。广州一位高管妈妈，给孩子一个暑假的教育花费高达三万五，她连新衣服都不敢买。 与之类似的例子更是不胜枚举，无论是800万的学区房，还是吃着最贵的药，安着最贵的支架，鸡飞狗跳地陪娃写作业， 亦或是，无缝衔接的辅导班： 这些无一不体现着中国父母对孩子教育的重视。有研究指出：中国已经成为全世界教育花费最贵的地区，而且超过三分之一的家长已经把全部时间都花费在孩子身上。 可尽管如此，中国父母仍然担心自己做的不够。 这背后暴露出了一个残酷真相：中国式父母焦虑。我们害怕孩子考不上好学校，跟不了好老师，比别人成绩差……会输，会落后。 而陈美龄之所以爆红，就是因为她这一套崭新的教育方式，惊醒了无数深处焦虑之中的中国父母，让大家明白：不是孩子输不起，问题的本质在于中国父母害怕输。 就像马东说的，中国父母最可怕的地方就是把自己成长中的焦虑转移给了孩子。 &gt; 我们小时候没考上好大学，想让孩子考上985，211；我们小时侯成绩不如别人，想让孩子一定要争口气，超过别人家的孩子；我们没过上安稳的生活，催促孩子一定要过上理想生活…… 正是这种焦虑，让无数家长和孩子都处于连轴转的水深火热之中。 然而我们不知道的是：这种中国式父母焦虑，很有可能废掉我们的孩子。 02 电视剧《急诊科医生》中有一个桥段：一个小姑娘考试考砸了，扛不住妈妈的批评，喝农药自杀。虽然抢救醒了，但生命只剩下一个月的期限。 妈妈当时就崩溃了，悔不当初：我干吗要说她啊！没考好就没考吧…… 是啊，一次考不好就不好吧，输了一次成绩，并不能代表输了人生。为什么要如此苛责呢？然而，现在再后悔都晚了。 父母是孩子的镜子，父母有多少焦虑，孩子就会有多大的心理压力。2017年9月7日，香港教育局新任副局长蔡若莲的长子潘匡仁在家里跳楼，从40多层的高空坠下，不幸身亡。 潘匡仁&amp;蔡若莲 这位出身书香世家，毕业于海外名校的孩子，因为在一场单车比赛中受伤，无法继续参赛，不能为家族争光，患了抑郁症。 优秀教育者的后代，以自毁的方式表达“输不起”的绝望，多么令人唏嘘，这难道不是对中国式焦虑最大的讽刺吗？ 而这并不是个例，北京大学曾发布《中学生自杀现象调查分析报告》：中国每5个中学生中就有1人曾考虑过自杀。哪怕考上大学后，跳楼、卧轨、跳河的惨剧也是接二连三发生。 这里的每一个数据都足以让我们心惊胆战。 它让我们知道，中国式父母焦虑，对孩子造成了多大的伤害，家长的用力过猛，可能废掉的是孩子光明灿烂的一生。很喜欢白岩松说的一句话：不要教孩子如何赢，要教会他们如何漂亮的输。 是啊，社会本就那么多压力，为什么还要给孩子额外的负担呢？其实，中国父母最大的赢，就是让孩子学会如何输。 世界拳击冠军邹市明的儿子轩轩是一个好胜心极强的男孩子。在《爸爸去哪儿》第三季中比赛吃西瓜，边哭边吃“我不想输，谁来帮帮我呀”。 可是作为世界冠军的爸爸却说：你不能只想赢，也要学着输，输并不丢人。 于是，孩子知道了输赢才是人生常态。这个常常把“爸爸，你一定要赢哈”挂在嘴边的男孩，居然在爸爸失败的时候试着安慰他：输了没关系，重新来。 焦虑是没有用的，输了一次成绩，不代表输了以后的人生。人生漫长，一次跌倒并不可怕，重要的是能站起来，你只有不怕输，才能有机会赢。 03 父母永远无法为孩子抵挡一生风雨，我们能做的，就是抛却无用的中国式焦虑，引导他们正确面对人生。 不焦虑并不意味着，不让孩子吃苦，而是让孩子自己学会从容应对人生之苦。 表弟当年上小学时成绩不好，阿姨知道“逼”他学习不管用，就想了一个办法，大夏天的把他拉出去买西瓜。 近40度的高温下，阿姨蹲在摊前和西瓜贩拉起了家常，表弟催她快点，她也不听，就这样待了差不多一个小时。表弟看着来来往往的人，有的只挑不买，有的几毛钱还讨价还价，这1个小时里，西瓜贩赚的钱还没自己一个玩具贵。 回去的路上，阿姨装作不经意地问他：你以后是想坐办公室，还是在外面卖东西？表弟说：我当然要坐办公室，在外面又热又累。可是阿姨回答：你现在的成绩可能还坐不了办公室。 表弟若有所思没有说话，然而回到家，他竟然拿出曾经不屑一顾地卷子做了起来。 是啊，只有父母知道人生太苦是没用的，要让孩子自己明白：今天的你如果不吃苦，明天的世界会让你很苦；你吃不了读书的苦，以后也别想能走一条更容易的路。 04 很多家长都以为把孩子送进好的学校，就会有好的老师，好的教育。 然而，陈美龄在视频中说：我始终确信“教育的全部责任在于家长”，学校和老师只是重要的伙伴。孩子的教育，人格形成应该由家长承担。 她一直以来都尊重孩子的选择，告诉他们：如果迷茫的话，就听从自己的心，哪怕选择的是最难走的那条路。 当年，她大儿子考美国高中，不想考top1的学校，而想进排名第七的高中，因为学校会教授马术。陈美龄跟儿子讲：我尊重你的选择，但是这条路会很难，希望你不要辜负自己的努力。 于是大儿子非常用功，不仅把马术练得很好，成绩也一直排名第一。 无独有偶，在纪录片《成长单行道》里，一个母亲想让儿子进体制内，但儿子却喜欢体制外的工作。母亲说：我尊重你的选择，也请你做好吃苦的准备。 因为她们明白：孩子，不是一个“标配”的物品，不是流水线生产出来的同一化模版，最好的教育方式永远是因人而异的“私人订制”。 就像杜江在《爸爸去哪儿》送给嗯哼一段话： &gt; 你不是我的希望，不是的，你是你自己的希望，我那些没能实现的梦想，还是我的与你无关，就让它们与你无关吧你何妨做一个全新的梦那梦里，不必有我然而我爱你，我的孩子我爱你，仅此而已 你教育的孩子，终究不可能成为你想象的样子。 他只会成长为他眼中希望中的样子。 父母该给他的不是一条规划好的标配之路，而是教会他：如何吃下人生之苦，如何笑对未来的人生。 为人父母的我们是时候给自己降降温了，有时候不是孩子不优秀，是我们太着急了。 抛却无用的中国式焦虑，让孩子为自己而活，看清自己应该去向哪里，活出余生的新高度！ 人生路漫长，也希望每一个孩子能直面挫折，踏上星辰大海的征途，走向波澜壮阔的明天！ 转载来源：年度最戳心视频：焦虑的中国父母，正在废掉我们的下一代]]></content>
  </entry>
  <entry>
    <title><![CDATA[75%来自农村 外卖“骑手”是怎样一群新青年？]]></title>
    <url>%2F2018%2F6dca9e3d%2F</url>
    <content type="text"><![CDATA[摘要： 美团点评发布《2018年外卖骑手群体研究报告》。 钛媒体综合：短短几年间，外卖从一个新鲜事物已经成长为与城市生活密不可分的行业，而外卖骑手则是撑起这个新兴行业的基座。 5月4日，美团点评研究院经过对平台骑手的调查研究，发布了《新时代 新青年：2018年外卖骑手群体研究报告》，从人群特征、工作发展、生活追求等方面对骑手进行全景洞察，精准画像，全面分析了外卖骑手这一群体的工作生… 摘要： 美团点评发布《2018年外卖骑手群体研究报告》。 钛媒体综合：短短几年间，外卖从一个新鲜事物已经成长为与城市生活密不可分的行业，而外卖骑手则是撑起这个新兴行业的基座。 5月4日，美团点评研究院经过对平台骑手的调查研究，发布了《新时代 新青年：2018年外卖骑手群体研究报告》，从人群特征、工作发展、生活追求等方面对骑手进行全景洞察，精准画像，全面分析了外卖骑手这一群体的工作生活状况。 其中，从性别来看，90%的骑手为男性 , 10%为女性；从年龄来看，8090后为骑手群体的中坚力量，占比高达82%。 值得一提的是，2017年，尽管占比不多，但还是有22万女性在美团外卖获得收入。其中，86%的已婚女性骑手需要抚养1-2个子女，5%的女骑手是单亲妈妈，通过骑手收入所得补贴家用。 而从来源上看，75%的骑手来自农村，伴随着城市化的加快近7成的骑手选择离开家乡在外地打拼，大多来自河南、安徽、四川、江苏、广东等省份，有7成骑手选择奋斗在一二线城市；而城市的级别越低，本地骑手比例越高，说明外卖行业可有效吸纳三四线以下城市的当地剩余劳动力。 在收入层面，根据美团点评方面的调查，自营骑手的收入最为可观，收入多在6-8千；众包骑手多采用灵活就业方式，骑手收入多在4千元以内，基本和从事的其他工作收入相当。 以下是美团点评《2018年外卖骑手群体研究报告》的主要内容，由钛媒体编辑整理： 人群特征：城市新青年 数据显示，外卖骑手大多来自农村，在城市化的大潮中离开家乡在大城市打拼。《报告》指出，75%的骑手来自农村地区，大多来自河南、安徽、四川、江苏、广东等省份，近7成的骑手选择离开家乡在一二线城市打拼。从年龄结构来看，骑手多处在青年阶段，8090后为骑手群体的中坚力量，占比高达82%，将近一半人在目前的工作地居住了9年以上，深深地扎根在城市。 工作发展情况： 收入稳定，自我迭代 报告显示：骑手新青年特质明显，择业时不再单纯追求就业稳定。工作收入高、未来发展好成为骑手群体最看重的择业因素。骑手群体中，大学生的比例为16%，不断建立和完善知识结构，善于抓住机遇和整合资源实现持续的自我迭代。 高达24%的骑手保持着学习阅读的好习惯，工作之余注重自我提高，积极学习行业知识、跑单经验，打磨自己为梦想做好准备。 自营骑手的收入最为可观，收入多在6-8千。众包骑手多采用灵活就业方式，骑手收入多在4千元以内，基本和从事的其他工作收入相当。骑手群体中，大学生的比例为16%，不断建立和完善知识结构，善于抓住机遇和整合资源实现持续的自我迭代。 骑手的日常开支项目大多以生活日用，赡养双方父母、抚养和教育子女为主。 数据显示，42%的骑手是老骑手介绍而来，以“老乡带老乡”的方式在全国形成多个外卖兄弟连。 转载来源：75%来自农村 外卖“骑手”是怎样一群新青年？]]></content>
  </entry>
  <entry>
    <title><![CDATA[腾讯没有梦想]]></title>
    <url>%2F2018%2Fc1ee76ef%2F</url>
    <content type="text"><![CDATA[腾讯正在丧失内生增长能力，变成一家投资公司。 转载来源：腾讯没有梦想]]></content>
      <tags>
        <tag>乱翻书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图解巴菲特“帝国”：伯克希尔哈撒韦是这样赚钱的]]></title>
    <url>%2F2018%2F021e52a7%2F</url>
    <content type="text"><![CDATA[大多数人所了解的伯克希尔.哈撒韦公司只是一家专门做投资理财的公司，这为巴菲特创造了830亿美元的财富。 大多数人所了解的伯克希尔.哈撒韦公司只是一家专门做投资理财的公司，这为巴菲特创造了830亿美元的财富。然而很少人知道这家公司是怎么运作和赚钱的？ 认真观察全球富豪榜上的富豪就会发现，大部分富豪的财富都源自其创办的公司。 2018福布斯排行榜榜首的杰夫-贝佐斯于1994年创办了亚马逊；排在第二位的比尔-盖茨创办了微软公司；排在第四位的西班牙首富奥特加创办了Zara；扎克伯格创办了Facebook；拉里-埃里森创办了甲骨文公司。 巴菲特在2018福布斯排行榜上位居第三，他也与上述几位顶级富豪一样，通过创办公司积累了自己的财富。通过控股伯克希尔.哈撒韦收购、出售或者投资了数百家公司。这些公司遍布各大行业，包括可口可乐这样的消费型公司，《华盛顿邮报》这样的国家型新闻媒体， GEICO这样的保险公司。 伯克希尔.哈撒韦公司的起源 虽然如今的伯克希尔.哈撒韦公司与巴菲特以及查理.芒格联系密切，但这家公司最早却可以追溯到1839年。 伯克希尔.哈撒韦公司最初是一家位于罗丹岛的纺织厂，到了1948年这家公司的员工已经达到了11000人，公司的营收达到了2950万美元（相当于今天的3亿美元左右）。 在20世纪50年代末， 伯克希尔.哈撒韦公司股价开始下跌的时候，巴菲特看到了这家公司的价值，并通过机会大量买入这家公司的股票。 到了1964年，巴菲特想退出这家公司，伯克希尔.哈撒韦公司的首席执行官 Seabury Stanton想以每股11.37美元的价格收购巴菲特手中的股票，当时巴菲特购入伯克希尔.哈撒韦公司股票的价格还不到每股0.13美元。 伯克希尔.哈撒韦公司首席执行官给出的价格让巴菲特感到非常兴奋，他不仅没有卖出手中伯克希尔.哈撒韦公司的股票，反而大举继续买入。 结果是他控股了这家公司，并解雇了首席执行官Seabury Stanton。 从此之后伯克希尔.哈撒韦公司就变成了巴菲特的公司，并开始创造历史，创造奇迹。 伯克希尔.哈撒韦52年市值涨了2.4万倍 在与市场长期的赛跑过程中，市场被巴菲特远远地甩在了身后。 想要知道巴菲特是怎么赚钱的，就需要弄清楚伯克希尔.哈撒韦公司不同业务的营收状况。 通过对比伯克希尔.哈撒韦在不同行业的营收，我们可以清楚的看到这家公司是如何赚钱的。 伯克希尔.哈撒韦公司的投资组合 伯克希尔.哈撒韦公司的投资组合总体来讲可以结构为两大类： 1）拥有控股地位的股权； 2）用大量资金入股一家公司但没有控股地位 先看伯克希尔.哈撒韦所拥有的公司，伯克希尔.哈撒韦公司拥有众多知名的品牌，包括奶品皇后和金霸王电池等。 需要注意的一点是， 伯克希尔.哈撒韦本部公司的工作人员只有26位。出现这种现象有两种原因，一是巴菲特认为他所控股和投资的公司在原来高管的管理下会运行的更好；二是这种去中心化的策略是他成功的关键所在。 再看伯克希尔.哈撒韦投资但没控股的公司。 伯克希尔.哈撒韦公司的投资组合基本上就是美国整体经济体的缩影 ：这个投资组合中有银行、航空公司、日常消费公司，甚至也有像苹果这样的高科技巨头公司。 值得一提的是， 巴菲特并没有止步于此。伯克希尔.哈撒韦还拥有80家汽车经销商，美国第二大房产中介以及32家日报。 投资交易造就了如今的伯克希尔.哈撒韦帝国 如果巴菲特没有参与商业史上著名的几次交易，伯克希尔.哈撒韦公司根本不会有今天。 巴菲特参与的几项著名的交易： 1）投资ABC 巴菲特帮助Capital Cities融资收购ABC，在当时这是最大的一笔非石油行业的收购交易。最终合并后的Capital Cities和ABC被迪士尼吞并了。 2）文娱与体育节目电视网（ESPN） 在文娱与体育节目电视网成为美国家喻户晓的品牌之前，巴菲特就持有这家公司大量的股票。Capital Cities和ABC并购交易过程中，文娱与体育节目电视网也作为交易的一部分融合进去了。 3）亨氏 在2013年伯克希尔.哈撒韦和3G资本牵头收购了亨氏集团。这次收购让巴菲特获得了对HP Sauce、Lea &amp; Perrins等品牌的控制权。 4）《华盛顿邮报》 在小时候，巴菲特送过报纸，但是在他的人生后半场，他却成了这家报纸的大股东。 5）美国航空公司 在投资美国航空公司亏损3.58亿美元之后，巴菲特对外宣称，购入美国航空公司优先股是他犯下的最大的一次错误。 6）吉利公司 巴菲特在上世纪80年代就开始买入吉利公司的股票，在巴菲特把所持的吉利公司的股票卖给宝洁公司之前，他的账面盈利达到了44亿美元。（编译/雨辰） 本文来自财看见-腾讯财经，创业家系授权发布，略经编辑修改，版权归作者所有，内容仅代表作者独立观点。&#91; 下载创业家APP，读懂中国最赚钱的7000种生意 &#93; 转载来源：图解巴菲特“帝国”：伯克希尔哈撒韦是这样赚钱的]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>巴菲特</tag>
        <tag>巴郡公司</tag>
        <tag>投资</tag>
        <tag>拉里·埃里森</tag>
        <tag>亨氏食品</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[入门｜极致的优化：智能手机是如何处理大型神经网络的]]></title>
    <url>%2F2018%2F35c6d7f0%2F</url>
    <content type="text"><![CDATA[运行深度神经网络对计算能力、能耗及磁盘空间要求甚高，智能手机的计算资源十分有限，需要多种优化才能高效运行深度学习应用。 运行深度神经网络对计算能力、能耗及磁盘空间要求甚高，智能手机的计算资源十分有限，需要多种优化才能高效运行深度学习应用。本文介绍了如何在移动设备的各种指标之间取得平衡，在避免大幅度降低准确性的前提下构造更加轻便的神经网络，使得在移动设备上快速、准确地运行神经网络成为可能。 电脑拥有大容量硬盘和强大的 CPU 与 GPU，但智能手机没有。为了弥补这些硬件上的不足，智能手机需要一些特殊手段才能高效地运行深度学习应用。 智能手机有办法与这些强大的服务器集群竞争吗？还是完全没有希望？ 引言 深度学习是一种功能十分多样和强大的技术，但是运行神经网络对计算能力、能耗及磁盘空间要求甚高。这对于在具有大型硬盘和多个 GPU 的服务器上运行的云应用来说一般不是问题。 不幸的是，在移动设备上运行神经网络并非易事。事实上，尽管智能手机的功能越来越强大，它们的计算能力、电池寿命及可用的磁盘空间依然十分有限，特别是那些非常依赖轻便性的应用。把应用做得轻便可以加快下载速度，减少更新，并且延长电池寿命，而这些都是用户迫切需要的。 为了执行图像分类、人像模式摄影、文本预测以及其他几十项任务，智能手机需要使用特殊方法来快速、准确地运行神经网络，且不占用过多内存空间。 在这篇文章中，我们将会了解一些最有效的、能让神经网络在手机上实时运行的技术。 能使神经网络更小更快的技术 基本上来讲，我们只对三个指标感兴趣：模型的准确率、速度、在手机中占用的内存。天下没有免费的午餐，因此我们不得不在这些指标之间作出一些权衡。 对于大部分技术来说，我们一边要关注指标，一边还要寻找一个叫做「饱和点」（saturation point）的东西。达到这个点之后，利用其他指标的损失实现某个指标的增益将不再可行。在到达饱和点前保持优化值，可以在两个指标上取得最佳结果。 在这个例子中，我们可以在不增加误差的情况下显著减少代价昂贵的运算。但是，在超过饱和点之后，误差的严重程度高到不可接受。 记住这个方法，让我们开始吧！ 1. 避免全连接层 全连接层是神经网络中最常见的部分，它们通常能发挥很大作用。然而，由于每一个神经元都和前一层的所有神经元相连接，因此它们需要存储和更新大量参数，这对速度和磁盘空间都很不利。 卷积层是利用输入（通常是图像）中局部一致性的层。每一个神经元不再与前一层的所有神经元相连。这有助于网络在保持高度准确性的同时减少连接/权重的数量。 全连接层的连接/权重数量要远远多于卷积层。 使用少连接或非全连接的层能缩小模型的体积，同时保持其高准确性。这种方法可以提高速度，同时减少磁盘使用量。 在上面提到的构造中，一个拥有 1024 个输入、 512 个输出的全连接层大约有 500k 个参数。而一个拥有相同特征以及 32 个特征图的卷积层只需要大约 50k 个参数。这是一个 10 倍的提升。 2. 减少通道数量与卷积核大小 这一步展现了在模型复杂度与速度之间作出的一个非常直接的权衡。拥有大量通道的卷积层能使网络提取相关信息，但也要付出相应的代价。剔除一些特征图是一个节约空间、加速模型的简单方法。 我们可以运用卷积运算的感受野来做同样的事情。通过缩小卷积核大小，卷积对局部模式的感知减少，但涉及的参数也减少了。 缩小感受野/卷积核大小可以降低计算成本，但是传递的信息会变少。 在这两种情况下，我们通过找到饱和点来选择特征图的数量/卷积核大小，以保证准确性不会下降太多。 3. 优化降采样 对于固定数量的层和固定数量的池化操作，神经网络可能会表现得天差地别。这是由于数据的表征以及计算量大小取决于这些池化操作于何处完成。 如果池化操作较早完成，数据的维数会减少。维数越少，网络的处理速度越快，但信息量会减少，准确性也会降低。- 如果网络中的池化操作完成较晚，那么大部分信息会被保留下来，因此准确度高。然而这也意味着计算是在多维对象上完成的，这会导致计算成本的增加。- 于神经网络中均匀布置降采样是一种行之有效的结构（https&#58;//arxiv.org/pdf/1710.02759.pdf），而且能在准确性与速度之间保持良好的平衡。这也是一种饱和点。如果网络中的池化操作完成较晚，那么大部分信息会被保留下来，因此准确度高。然而这也意味着计算是在多维对象上完成的，这会导致计算成本的增加。 较早的池化速度快，延后的池化精确性高，均匀布置池化能兼具二者的一些优点。 4. 权重修剪 在一个经过训练的神经网络中，有些权重对于某个神经元单元的激活值至关重要，而其他的权重基本不影响结果。尽管如此，我们仍要对这些不那么重要的权重做一些计算。 修剪（pruning）是一个完全删除最小强度连接的过程，这样我们就可以跳过这些计算。这会降低准确性但是能让网络更快更精简。我们需要找出饱和点，然后在尽量不影响准确性的情况下删去尽可能多的连接。 删去最弱的连接来节省计算时间与空间。 5. 离散化权重 为了在磁盘中保存神经网络，我们需要记录网络中每一个权重的值。这意味着我们需要为每一个参数保存一个浮点数，同时也意味着大量磁盘空间的消耗。举例说明，在 C 中一个浮点数占据 4 个字节，即 32 位。一个有着上亿参数的网络（如 Google-Net 或 VGG-16）会轻易占据上百兆字节的空间，而这样的消耗在移动设备中是不可接受的。 为了尽量减小网络存储的量，一种方法是通过离散化权重来降低权重的精度。在这个过程当中，我们更改数字的表示使其不再表示具体值，而是限制其为数值的子集。这样我们只需要存储一次经过离散化的值，然后将它们映射到网络的权重上。 离散化权重存储索引而非浮点值。 我们再次需要通过找到饱和点来决定到底使用多少个值。使用更多数值意味着准确性的提高，但也意味着更大的表征空间。举个例子：如果使用 256 个经过离散化的值，每一个权重只需要使用 1 个字节（即 8 位）就能表示。相比之前（32 位），我们将其大小缩减了四倍！ 6. 模型表征的编码 我们已经对权重作了许多处理，但是还能进一步改进网络！这个特殊技巧源于权重分布不均的事实。一旦权重被离散化，我们就会失去相同数量的对应每一个离散化值的权重。这意味着在我们的模型表征中，某些索引的出现频率相对更高，我们可以利用这一点！ 哈夫曼编码（Huffman coding）能完美地解决这个问题。它通过给最常用的值分配最小索引以及给最不常用的值分配最大索引来解决这些问题。这有助于减小设备上模型的体积，最关键的是不会降低准确性。 访问次数最多的符号只使用 1 位的空间，而访问次数最少的符号使用 3 位的空间。这是因为后者在数据表示中出现的次数很少，并由此可以达到一种空间上的平衡。 这个简单的技巧使我们能够进一步缩小神经网络占用的空间，通常能减少 30％ 左右。 注意：每一层的离散化和编码可以是不同的，从而提供更大的灵活性。 修正准确率损失 通过我们使用的方法，神经网络已经十分精简了。我们删去了弱连接（修剪），甚至改变了一些权重（离散化）。在网络变得十分轻巧快速的同时，其准确率也不如以前了。 为了修正这一点，我们需要迭代地重新训练网络的每一步。这代表我们需要在修剪和离散化操作之后，再次训练网络使其可以拟合相应的变化，然后重复这一过程直到权重不再大幅变化为止。 结论 尽管智能手机没有优秀的台式机那样的磁盘空间、计算能力或者电池寿命，它们仍是深度学习应用程序的优秀实验对象。通过一系列方法，我们现在可以在这些多功能手持设备上运行强大的神经网络，准确性只是略有下降。这为数千个优秀的应用打开了大门。 如果有兴趣，你也可以了解一些面向移动设备的优秀神经网络，如 SqueezeNet（https&#58;//arxiv.org/abs/1602.07360）或 MobileNets（https&#58;//arxiv.org/abs/1704.04861）。 转载来源：入门｜极致的优化：智能手机是如何处理大型神经网络的]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>GPU</tag>
        <tag>智能手机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[业界 | 谷歌、百度等联合发布机器学习新基准MLPerf，旨在促进AI发展和公众参与]]></title>
    <url>%2F2018%2F0587e28d%2F</url>
    <content type="text"><![CDATA[选自hpcwire 作者：John Russell 机器之心编译 参与：刘晓坤、路 昨日，来自学界和业界的多个组织（包括谷歌、百度、英特尔、AMD、哈佛和斯坦福）共同发布了新型基准 MLPerf，「用于衡量机器学习软硬件的速度」。 长期以来，市场上的 AI 性能对比一直比较粗略，鱼龙混杂且通用性不足，难以作为参考，但 AI 基准之战即将开始。今天，… 选自hpcwire 作者：**John Russell** 机器之心编译 参与：刘晓坤、路 &gt; 昨日，来自学界和业界的多个组织（包括谷歌、百度、英特尔、AMD、哈佛和斯坦福）共同发布了新型基准 MLPerf，「用于衡量机器学习软硬件的速度」。 长期以来，市场上的 AI 性能对比一直比较粗略，鱼龙混杂且通用性不足，难以作为参考，但 AI 基准之战即将开始。今天，来自学界和业界的多个组织（包括谷歌、百度、英特尔、AMD、哈佛和斯坦福）共同发布了新型基准 MLPerf，「用于衡量机器学习软硬件的速度」。 上周，RiseML 发布博客，对比了谷歌的 TPUv2 和 Nvidia V100。今天，英特尔发布博客，展示了使用 RNN 执行机器翻译时选择软硬件的相关数据。 很长时间以来，围绕对有意义的 AI 基准出现大量讨论，支持者认为此类工具的缺乏限制了 AI 的应用。MLPerf 发布公告引用了 AI 领域先驱吴恩达的话：「AI 正在改变多个行业，但是要想完全发挥其潜力，我们仍然需要更快的硬件和软件。」我们希望更好、更标准化的基准能够帮助 AI 技术开发者创造出此类产品，允许采用者做出明智的 AI 技术选择。 MLPerf 称其主要目标是： 通过公平、有用的度量来加速 ML 的进展； 推动互相竞争的系统之间的公平对比，同时鼓励创新，以提升 ML 领域的当前最优水平； 使基准测试可负担，所有人都可以参与其中； 服务商业和研究社区； 强制要求复现性，以确保结果的可靠性。 AI 性能对比（h/w 和 s/w）目前主要由既得利益者发布，如英特尔近日的博客《Amazing Inference Performance with Intel Xeon Scalable Processors》。这并不是在针对英特尔。此类对比通常包含有用的见解，但是它们通常用于展示一方比另一方的优势。标准化基准可以缓解这一状况。 MLPerf 在模拟之前的一些尝试，比如 SPEC（标准性能评估组织）。「SPEC 基准加速了通用计算方面的进步。SPEC 于 1988 年由多个计算公司联合成立。接下来的 15 年中 CPU 性能提升 1.6X/年。MLPerf 将之前基准的最佳实践结合起来：SPEC 使用的一套程序；SORT 的一个部门来做性能对比，另一个部门负责创新；DeepBench 覆盖产品中的软件部署；DAWNBench 的 time-to-accuracy 度量。」MLPerf 称。 Intersect360 Research 的 CEO Addison Snell 称：「现在那么多公司在发展 AI，提供基准测试的尝试具备极高的重要性，尤其是对于大量互相竞争的技术。但是，AI 领域非常多样化，我怀疑是否会出现主导的单一基准。想想五年前所有围绕大数据和分析学的热情；尽管每个人都尝试定义它，行业并没有提供一个统一、常用的基准。我认为 AI 领域也会是这种情况。」 Hyperion Research 的高级研究副总裁 Steve Conway 称 MLPerf 是「很好、很有用的」一步，「因为多年来对于买方和卖方来说确实缺乏一个基准来展现不同 AI 产品和解决方案之间的区别。这个基准似乎是为了解决如今 AI 早期主要的受限问题（bounded problem）而创建的。之后随着 AI 开始出现未受限问题（unbounded problem，它们将是经济上最重要的问题），我们将需要额外的基准。受限问题相对简单，例如声音和图像识别或玩游戏等。未受限问题例如诊断癌症，其对应的受限问题可能是读取 MRI 图像；未受限问题能够在非常复杂的问题上推荐决策。」 MLPref 已经在 GitHub 上开源，但仍然处于非常早期的阶段，正如 MLPref 所强调的：「这次发布的更像是一个内部测试版，它仍可以从多个方面改进。该基准仍然在开发和精炼中，可以查看下方的 Suggestions 部分了解如何贡献该开源项目。我们期待在五月末能基于用户输入进行大幅更新。」 目前在 MLPerf 套装中的 7 个基准，每一个都有参考实现： 图像分类—ResNet-50 v1（ImageNet） 目标检测—Mask R-CNN（COCO） 语音识别—DeepSpeech2（Librispeech） 翻译—Transformer（WMT English—German） 推荐—Neural Collaborative Filtering（MovieLens 20 Million (ml-20m)） 情感分析—Seq-CNN（IMDB 数据集） 强化学习—Mini-go（预测 pro 游戏中的移动） 每个参考实现提供了：至少在一个框架中实现模型的代码；可用于在一个容器内运行基准的 Dockerfile；下载合适数据集的脚本；运行模型训练和计时的脚本；数据集、模型和机器设置的相关文档。 这些基准已经在以下的机器配置上进行了测试： 16 块 CPU、一块 Nvidia P100； Ubuntu 16.04，包含 docker 和 Nvidia 支持； 600GB 硬盘（虽然很多基准不需要这么多硬盘空间）。 业界选择结合几个 AI 基准还是让基准数量激增是很有趣的现象。在这样一个年轻的市场，大部分人选择提供基准测试工具和服务。例如，斯坦福（MLPerf 成员）近日发布了它的第一个 DAWNBench v1 Deep Learning 结果。 斯坦福报告称：「2018 年 4 月 20 日，我们发布了第一个衡量端到端性能的深度学习基准和竞赛，这些性能包括：在常见深度学习任务中达到当前最优准确率级别所需的时间/成本，以及在当前最优准确率级别上执行推断的延迟/成本。聚焦于端到端性能提供了标准化计算框架、硬件、优化算法、超参数设置和其它重要因素的区别的客观手段。」像 MLPerf 这样的项目可以在当前对比 AI 性能的时候，清除那些模糊不清的因素。 原文链接&#91;链接&#93;(https&#58;//www.hpcwire.com/2018/05/02/mlperf-will-new-machine-learning-benchmark-help-propel-ai-forward/) 本文为机器之心编译，转载请联系本公众号获得授权。 加入机器之心（全职记者/实习生）：hr&#64;jiqizhixin.com 广告&amp;商务合作：bd&#64;jiqizhixin.com 转载来源：业界 | 谷歌、百度等联合发布机器学习新基准MLPerf，旨在促进AI发展和公众参与]]></content>
  </entry>
  <entry>
    <title><![CDATA[大卫·哈维：读懂《资本论》，你对世界的困惑会减少一半]]></title>
    <url>%2F2018%2F9d72baa8%2F</url>
    <content type="text"><![CDATA[83岁的大卫·哈维胡子花白，但依然站在纽约城市大学讲台上。他的解读《资本论》课程深受年轻学生欢迎，课程视频放到网上后被翻译成100多种文字，在世界范围内广泛传播。 【编者按】 83岁的大卫·哈维胡子花白，但依然站在纽约城市大学讲台上。 大卫·哈维讲《资本论》，一直讲了50多年。在西方，他的粉丝越来越多。他的解读《资本论》课程深受年轻学生欢迎，课程视频放到网上后被翻译成100多种文字，在世界范围内广泛传播。这几年，他频频到访中国，他的好几本著作译成了中文，像《资本社会的17个矛盾》《世界的逻辑》等。2016年中国部分城市的房价暴涨，也让许多人开始广泛引用《资本社会的17个矛盾》中关于“房子是如何被资本化”的论断，发现马克思的理论在今天依然有强大的影响力。 2018年，恰逢马克思诞辰200周年。大卫·哈维在中国出版了他的新书《马克思与资本论》。哈维说，这本书是向马克思的致敬之作。 马克思为什么有穿越时空的影响力？ 1818年5月5日，卡尔·马克思诞生于德国特里尔。200年风云变幻，200年沧海桑田，今天，他的思想已经成为一种世界语言，指引着人类追寻理想社会的脚步。 马克思终其一生都在研究资本的规律。他的《资本论》无疑是近代世界重要的著作之一。三卷本《资本论》包含了马克思对资本主义特征和历史的深入思考。《资本论》在世界范围内对政治和经济产生了重要影响，至今依然有强烈的现实意义。 哈维发现，近年来有大量关于马克思个人情况、政治氛围和经济环境的研究问世。很多西方学者对马克思的生平和思想做了详尽的探究。在全世界最大的在线购物网站亚马逊输入“卡尔·马克思”的关键词，能够搜到将近1万种相关图书。马克思的经典著作特别是《资本论》的销售近年来更是创了纪录。据媒体报道，商业刊物和主要文学刊物出版了诸如《马克思最终是正确的吗？》等文章。美国《科学与社会》杂志主编、纽约城市大学名誉教授大卫·莱伯曼认为，人们不约而同地将重点放在马克思对资本积累和资本危机入木三分的描述上，是因为马克思第一个指出了资本主义时代的明确特征——资本主义社会的发展是扩张、两极化、不稳定及最终毁灭。 马克思的理论为什么有穿越时空的强大影响力？ 哈维认为，问题的关键在于，马克思《资本论》的研究对象是资本而不是19世纪的生活。资本依然在我们身边，依然鲜活，在某些时候资本出现病灶和失控现象，在某些时候则又显得膨胀而甚嚣尘上。 在马克思所处的时代，资本主义还仅仅占领了世界的一个小角落，但现在却是覆盖整个地球的主导经济体系。在马克思的年代，政治经济学是远比现在开放的争鸣领域。但现在，一个自封科学、高度数理化和数据驱动的经济学占据了正统地位，这是由各种自认为理性科学的知识组成的封闭体系，成为国家和资本力量掌控的私密领地。现在经济学又有了计算机的辅佐，人们越来越倾向于使用不断提升的计算机运算能力（每两年翻一番）来构建、解释和分析有关几乎一切事物的海量数据。哈维提醒我们，不能过度相信大数据，因为数据不可能穷尽所有未知的领域，不能解决社会关系恶化的问题。 相对而言，马克思关于资本运动规律及其内在矛盾、内在不合理性的深刻阐述，比宏观经济学理论更加尖锐深刻，更有解释力。 经济为什么会产生周期性危机？ 危机为什么会发生？危机会不会再次发生？2008年影响波及全球的国际金融危机至今让人心有余悸，各种关于金融危机产生原因的解释层出不穷，各派经济学家也是各显神通。从某种意义上说，很多西方主流经济学家，只是把一些经济学概念转化为数学模型进行演绎，而并没有任何新的思想和见解。经济学是经世致用之学，不是简单地在黑板上和实验室推算和证明自己的观点或理论。经济学理论的创新更不是依靠在学术期刊中用数学证明出来，实践才是检验真理的唯一标准。 马克思认为，资本运行有四个阶段：价值生产、价值实现、价值分配和价值增值。资本的运行，就是沿着这四个阶段循环不已。产品被生产出来，之后到市场上出售，把价值实现出来，价值实现的标志物是货币，于是就有如何分配这些货币的问题，最后，货币到了手里怎么用，货币少的人只能购买生活必需品，但货币多的人可以再行投资增值。于是，这些投资出去的货币又开始了下一个循环。只要资本主义在，这个循环就是无限的，而因为有上升的运动，便可图示为螺旋形状。 在前两卷《资本论》中，马克思用大量篇幅描述了资本的简单再生产。似乎他也想探索一种在非资本主义、无资本积累情况下有可能发生的良性循环再生产模式。但问题首先出现在剩余价值的生产以及永远扩张的必要性，这就要求从闭环式的无限循环转变到无止境的积累。正是这种转变迫使资本永远追求“不可实现的无限”。使用价值虽然明显受限于物质，但正如我们所见的，也难以避免受此疯狂的影响。现在人们试图“要使享乐达到想象中的无限的程度”，而另外许多地方则是无限的浪费，目前地球环境的日益恶化就清晰显示出人类的消费无度。 为了解释危机如何发生以及为什么会发生危机，哈维对不同区域价值体系的地缘经济史做深入的分析。2007-2008年美国发生金融危机，因为这场危机是起源于美国但又影响到了世界，所以这被视为一场全球性危机。 危机发生后，美国的消费市场开始冰冻。中国则是美国消费市场上的主要商品供应国。结果就是中国出口也开始暴跌。 2008年，中国出口暴跌30%，大量在华南的工厂关闭。但根据某些估测，大约有2000万到3000万人失业。 如何快速消化如此大量的剩余劳动力？答案是开足马力建设基础设施和大型项目。1900年至1999年期间，美国消耗了45亿吨水泥，但从2011年至2013年，中国消耗了65亿吨水泥。在两年多时间里，中国的水泥消耗量比美国在整个20世纪的水泥消耗量多出了近45%。 水泥用于建筑。这意味着在中国在建造环境、城市化和其他基础设施（交通设施、水利大坝、集装箱码头和机场）方面进行大量投资。被大量消耗的不仅仅是水泥。钢铁生产和消费也出现了明显扩张。近年来，中国占了全球钢铁产量和使用量的一半以上。为此中国需要进口大量的铁矿石来炼钢，铁矿石则来源于遥远的巴西和澳大利亚等地。 哈维认为，全球之所以能走出2007-2008年的危机，其中一个重要的原因就是生产性消费的持续增长，中国显然成了全球资本主义的救世主。 但中国应对经济困难的方式却并不是什么新鲜事。第二次世界大战后美国的情况也是如此。美国经济需要吸收战争期间创造的大量生产能力并为大批退伍军人创造就业机会。当时美国的决策者知道，如果退伍老兵从战场上退下来之后找不到工作，像是20世纪30年代时的情况，那肯定会造成严重的政治和经济动荡。 面对剩余资本和剩余劳动力供给的经济问题，通过美国帝国主义、冷战和军国主义扩张（“军工体系”）来做到的。与此同时，美国还对物质和社会基础设施（如高等教育）进行了大量的投资。州际公路系统将西海岸和南部以新的方式纳入美国经济。洛杉矶在1945年只是一个普通大小的城市，但到1970年它已经成为一个特大城市。 美国通过兴建房屋并在屋子里填满东西就摆脱了危机。但是正如2008年金融危机所显示的，这最终也让资本走入了危机。 如何看待人工智能和互联网技术？ 人工智能和互联网技术的突破，让这些技术成为当下最热门的议题。有些学者信誓旦旦地声称，可以通过大数据实现智慧城市，然后贫困、不平等、阶级和种族歧视以及剥夺式资本积累等一切城市病就会迎刃而解。 哈维认为，这种想法是极其天真的。马克思在关于机器的角色、关于资本和工业化的这些伟大的章节，引用了一个故事开篇：经济学家约翰·斯图尔特·穆勒感到非常困惑，他认为机器本应是为人类服务而生的，最后反而让工人们的工作变得更加繁重而辛苦。穆勒不理解为什么会发生这样的事。马克思在书中回答说，他当然不理解了，因为机器的使命本来就不是让工人得到轻松，而是让资本对劳动力的开发和利用达到最大化，因此也就不难理解为什么机器的发明让工人的工作处境变得更坏了。 事实上，资本始终幻想将工人变成资本流动的附属品。许多工业创新者都将此视为首要目标。工业时代法国实业家就公开宣称，在机床上的技术革新有三大目标：提高精度、提高生产率和替代工人。工厂制、泰勒主义、自动化、机器人以及最终用人工智能替代活劳动的设想本质上都是这一愿望的反应。除了在科幻小说里，机器人不会抱怨、不会顶撞、不会诉讼、不会生病、不会疲惫、不会分心、不会罢工、不会要求加薪、不会担心工作条件、不会要求茶歇、也不会旷工。资本始终幻想完全掌控劳动者或最终用技术替换掉所有活劳动，这种想法根植于不顾一切提高生产率的冲动。 马克思认为，技术问题是理解资本运动态势的基础。马克思对此问题有着尖锐和深刻的见解。整个资本主义对技术变革和经济发展都充满了迷恋。因此现在有人认为技术方案和科技创新可以解决所有社会问题，这种迷信有着深刻的思想根源，即认为技术是推动资本主义发展的原动力。这种技术迷信也不断被资本的不同部门培养，有人将科技创新变成大的咨询公司来为改善管理出谋划策；制药公司发明出针对不存在的疾病的药物；计算机专家坚持发明只有少数人才懂得操控的自动化系统，这些都是技术崇拜的表现。资本主义企业家和企业采取创新并不是因为他们想要创新，而是因为他们必须这样做才能获得或保住市场份额并确保其作为资本家的再生产。 &#91;本文整理自中信出版社2018年5月出版的马克思与《资本论》，作者：(美)大卫·哈维（David Harvey），译者：周大昕&#93; 转载来源：大卫·哈维：读懂《资本论》，你对世界的困惑会减少一半]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>经济</tag>
        <tag>资本论</tag>
        <tag>哈维</tag>
        <tag>卡尔·马克思</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[任志强和他的房价永远上涨（深度）]]></title>
    <url>%2F2018%2F5ff96c68%2F</url>
    <content type="text"><![CDATA[版权：来源 子木聊房（zimuliaofang） 任志强的战争 在房地产界，任志强是最火爆的热点，没有之一。 作为多军的鼻祖，任志强曾挂帅东南，一夫当关，战绩赫赫，一直坚持“中国房价永远上涨”的铁打理念。 其中最著名的战役就是和空军鼻祖房地产“三剑客”、资深经济专家谢国忠等人之间的世纪赌约。 为此，谢国忠在12年的时候还把自己在上海的豪宅变卖。以身立誓，“中国房价… 版权：来源 子木聊房（zimuliaofang） 任志强的战争 在房地产界，任志强是最火爆的热点，没有之一。 作为多军的鼻祖，任志强曾挂帅东南，一夫当关，战绩赫赫，一直坚持“中国房价永远上涨”的铁打理念。 其中最著名的战役就是和空军鼻祖房地产“三剑客”、资深经济专家谢国忠等人之间的世纪赌约。 为此，谢国忠在12年的时候还把自己在上海的豪宅变卖。以身立誓，“中国房价一定会崩盘”！ 然而，上帝站在了任志强这边，上海房价没降反升，而且紧接着全国房价就迎来了新一轮的上涨周期，三剑客和谢国忠等空军主力惨败沙场，无颜于众，此后匿名于江湖。 而任志强也因此一战成名，成了中国房地产的神话人物，行走的房价走势图。 其实在这场战役上是没有输家的。只是谢国忠等人太过年轻，低估了政府干预经济的能力和人性的贪婪。 在预测房价趋势上，有的专家在分析经济形式，有的在分析人口结构，甚至还有用算法给中国房价做精密数据模型。 但只有任志强在潜心研究「中国特色」，这就是不同之处。 在非完全交易市场中，只有「中国特色」才是房价最根本的天大变量！其他因素在它们面前又有什么用呢？ 一道政令下来，其他变量立刻归零，之前做的盘算和分析马上土崩瓦解。 譬如海南这次，本来房价已经处于高位，属于锁盘下调的走势，结果直接涉入封死了楼市，然后还天降了个大礼包。换句话讲就是“给了你一巴掌后，又掏出了一颗糖豆豆”，问你甜不甜？ 你却只能捂着嘴巴苦笑着说，这糖真好吃，嗡嗡作响的脑袋里只剩下了对未来的幻想。 最后大家也看到了，海南房价卡在那里动弹不得，不让你买也不让你卖，交易消失了，没了交易的市场还存在涨跌吗？这就是「中国特色」。 所以很多人坚信的「中国房价崩盘论」是完全错误的，假以时日，真有那么一天中国楼市在高房价中风雨飘摇，岌岌可危，这时候肯定会有人站出来给它打一针高效镇静剂，睡它个一年半载。 所以，在研究楼市的时候，不要单纯的只研究人口、土地、金融等等指标，更重要的是研究中国特色，看懂其背后的意图。 任志强是见证了中国改革开放的人，懂中国特色，了解它的逻辑，所以他在预测房价方面他人难以企及。但一个敢说真话的人，一生注定很坎坷。这也是我最佩服他的一点。 敢讲真话的任志强 其实，比说不说真话更严重一万倍的是能不能说真话，现在这个时代已经找不到像鲁迅那样敢说真话的人了。 “看懂了真相但没人敢说出来”，这是一个民族的悲哀。 就像历史上晚清闭关锁国一样，所有人都活在一片安逸之中，认为天朝是宇宙老大，无坚不摧。结果当洋枪洋炮轰开中国大门的时候，所有人都吓傻了。 同样的今天，芯片贸易战也给安逸的中国人深刻地上了一课。手机市场再大、销量再好，并不重要，重要的是自己能不能做出手机。 只可惜一直以来企业家中只有任正非看清了这个事实，但当年说出来这个真话时又有几个人听呢？大家只不过都是各忙各的，看谁赚的钱多，谁的份额市场第一而已。 任志强把中国房地产的真话讲出来了，这和学识认知没有任何关系，而是一段段艰苦岁月勾画的亲身经历。 他在《野心优雅》回忆录里，用五十万字记录了他的六十个春秋。从出身高干家庭的家世，到十一年的军旅生活。 从复员后贩卖兔皮起家，到进驻华远地产，并把华远做到上市。状告银行，被穷人扔鞋，被上面暗查，官与商，红与黑，坎坷六十载。 其实我对任老的评价就是，一直在体制中挣扎的“年轻人”！ 通读《野心优雅》你会发现任老人生中三个片段特别重要。一是参军表现非常突出，但因不听领导话，被称为“鸡肋”；二是在华远任职经理时，为了激励员工发了一大笔奖金，结果被以“贪污罪”下狱一年多；三是在把华远发展如日中天的时候，华润为了控股万科，活生生把他打下来的基业牺牲了。 他一生都在挑战体制和束缚，最后倒在了「虽败犹荣」的血泊中。最后他用一生明白了一个道理： 永远不要轻视政府对市场的干预能力，基于基础国情和体制看市场发展才是最正确的道理，所以那些海归派高级经济学家能看懂中国市场吗？ 中国需要的是针灸拔罐，不是胶囊药片。 但即使如此，爱说真话的任志强早期却被万众诟病。而且还荣获过一项大奖，就是“中国人最想骂的人”。为什么？ 为什么大家都爱骂任志强？ 真话难听，良言逆耳。 停车金融 全国收购、长租、联营、建设一二线城市大型停车场！！！详情平台内点击“他说”——&gt;“停车金融”了解！！！ 当他真正参透中国房地产市场后，提出了主要言论“房价永远涨！” 此言一出，直接刺痛了劳苦大众的神经。现在都买不起房了，还要涨？房价都是被你唱起来的！一呼百应，群而攻之。 所以一直以来，楼市几乎都被空军占领着，支持任志强的人微乎其微，当年房地产三剑客号令千万大军讨伐任志强时，称之为“狂妄至极，罪恶不赦，满嘴放炮”，这也是他“任大炮”绰号的来源。 但是研究空军特征的时候你会发现，70%的人是买不起房的，20%是舍不得买房，最后10%的人认为“房子是用来住的，不具备投资属性”，只能说这群人的思维超前了好些年，毕竟这个口号现在才喊出来。 所以空军在此思维导向下，不满于房价上涨，不满于靠房子发财的人和所有说房价要涨的人。这时候有背景的专家站出来了，大家欢呼雀跃，感觉专家终于把自己想表达的事情说明白了。 于是把精神寄托全部都转移到了他们身上，而对于和自己唱反调的人，恨之入骨。 所以楼市多空军之战其实就是中国阶级的斗争，底层老百姓对有高房价的不满其实就是对有钱人的不满。 这样看，任志强成为被炮轰的对象就很正常了。因为他不仅代表了买不起房的老百姓对房价上涨的恐惧，还代表了资本有钱人的利益。 当任志强对房价的预言几乎全部被应验，空军派主力悉数败下阵来之后，人们的精神寄托土崩瓦解，认清了买房是件遥不可及的事，明白了当年高喊无产阶级万岁本来就是一个弥天大谎。世界永远是有钱人的世界，有房有产才是王道，改不了的。 当年听了任志强的，搭上了顺风车，赚到盆满钵满，听了空军派的永远也没搭上车，到现在还是骂天骂地骂房价。 而且最重要的是，世界上有永远的多军，而没有永远的空军。买了房的空军，立马180度转为多军，比多军更期望房价上涨，人性如此。 其实说这些事情的，并不是让大家去看涨房价，而是要明白一个道理。 「如果想在楼市中寻找机会投资赚钱，就要尊重房价可以涨也可以跌的事实，而不是凭一己私利站在绝对的一面。」 我们务必看懂的真言 其实在2015年的时候，我每天都过得非常恐慌，因为低迷的市场、历史低谷的利率、超大的库存都是每次房价上涨周期来临的征兆。 于是疯狂的让身边的人买房成为了我的日常工作。不幸的是，只有少部分买了，大部分嫌贵没买。我亲眼见到朋友原本可以买北京二环的房，却一直在等房价下跌，从二环到三环，从三环到四环，结果最后买到了燕郊。 之后任老在发布“2015年不买房的人，就永远买不起房”的言论之后，又迎来了一波骂潮。可见，“买涨不买跌”的大众心态让多少人迷了心智。 现在还有人对任老的一些言论不太理解，所以针对未来中国房价走势，子木着重挑几点来解释说明。 1.**政策越出，房价越涨** 其实在出台的调控政策中，有些是好的，有些是不好的。例如限购和限价是恶性的，而限售和限贷是则是良性的。 限购一出，房子不让买了，大家一想，越不让买的地方肯定越好。这和谈恋爱一样，得不到的永远在骚动，得到的反而不珍惜了。 所以你看，所有人不会考虑未来是否会有人接盘，房子的增值属性如何。哪儿限购往哪儿买，找关系的，送茶水费的络绎不绝。有房子的还想买第二套、第三套，东西越少越要抢。 限价政策才是房价上涨的助燃剂，而且我认为限价政策一定会被写入史册的，用来警示后人。 限价的直接结果是导致新房二手房价格倒挂。一线城市因为该开发的都开发完了，市场发展饱和，二手房比新房多，倒挂是很正常的，但是你三四线城市倒挂是什么鬼？ 倒挂是什么意思？二手房卖3万块钱，政府给你批的一手房卖2万块钱。这说明什么？说明有人告诉你，你买了就有1万块钱的利润，那你还不去买？ 房价涨到现在其实很容易看出来，上面决心不够，下面贪图享受。有些城市炒房客早就脱身走了，劳苦大众却还在里面玩击鼓传花。 2、房地产未来还有二十年的红利期 价格来自于需求。如果没有需求就没有价格。而未来20年中国要把城市化完成率达到70%。意味着什么？ 意味着，城市化建设还在加剧进行。农村人口往城市迁移，小城市人口往大城市迁移，弱城市人口往强城市人口迁移。中国人口快速流动还有20年。 流动产生需求，需求产生价值。但流动的同时也会让市场分化，城市分化。分化后，强的城市会一直需求叠加，弱的城市需求减退，直至衰亡。 所以，中国未来的房价会一直涨，且还会存在大涨小跌的规律。但是弱的城市一定不会涨，需求没了还怎么涨？如果涨也是通货膨胀的字面意思，例如20年后小县城工资都2万出头了，房价6万有何不可？ 但是，作为买房的人一定要踩到这条大涨小跌曲线的谷底，这也就是房产半投资属性的重要之处。因为一个涨幅透支的可能就是你10多年的努力。 最后再说几句。 睿智的人会包容万物，而一个人格局的大小在于他所能接受事物发展的两个极端点之间撑起的空间**。** 换句话说，你可以接受房价涨到10万，也可以接受到房价跌到1000。最重要的是你可以理性看待房价，能听进去最难听的话。 任志强是中国房地产界的鼻祖，在这里尊称为一声，任老**。**他用自己的一生践行了他对房价的判断理论，这一点难能可贵，值得学习。但并不意味着其所有理论都是正确的，例如他之前总在为有钱人和开发商说话，对穷人有一种蔑视之情。 不过他后来也明白了，社会发展是以穷人为基础的。 从洛克菲勒的说法来说，当他们富起来的时候发现，穷人没有同时富起来的时候，会破坏他们富有的社会条件，比如说革命，比如说战争。因此他们一定要帮助穷人也富起来，才能让这个社会平和，至少让穷人有机会。 转载来源：任志强和他的房价永远上涨（深度）]]></content>
  </entry>
  <entry>
    <title><![CDATA[论文Express｜谷歌大脑：基于元学习的无监督学习更新规则]]></title>
    <url>%2F2018%2Fb8a998ea%2F</url>
    <content type="text"><![CDATA[大数据文摘作品编译：杨小咩是小怪兽、晓莉、小鱼这期论文Express，让文摘菌带大家来看看谷歌大脑和伯克利关于无监督学习的联合研究。 大数据文摘作品 编译：杨小咩是小怪兽、晓莉 、小鱼 这期论文Express，让文摘菌带大家来看看谷歌大脑和伯克利关于无监督学习的联合研究。 大数据文摘微信公众号后台对话框内回复“元学习”即可下载论文~ 无监督学习的一个主要目的是为了获得对后续任务有用的数据分布，从而避免在有监督训练过程中需要对数据进行标注的繁琐步骤。 通常，这个目标是通过定义一个代价函数（Cost Function）来最小化估计参数的方式实现的，例如negative log-likelihood（NLL）生成模型。 论文作者：Luke Metz、Niru Maheswaranathan、Brian Cheung、Jascha Sohl-Dickstein（谷歌大脑/加州大学伯克利分校） 本文提出了基于元学习的无监督学习更新规则，利用元学习技术对无监督权重的更新规则进行学习，在针对小样本分类任务上表现良好。 此外，我们将无监督学习更新规则约束为一个生物机制的局部神经元函数，从而推演一种全新的神经网络结构。 基于元学习的无监督学习更新规则可概括为训练不同宽度，深度和非线性的网络。它还可以训练具有随机排列输入维度的数据，甚至还可以从相对复杂的图像数据集泛化到一个文本任务。 相关工作 下表中列出了已经在论文中发表的元学习方法，从选择不同的任务类型、元学习结构、元架构和域等方面进行了全面的比较。 已发表的元学习方法比较 模型设计 我们将参数为∅t的多层感知机（MLP）f(·; ∅t)作为基础模型，元学习过程的内部循环通过迭代应用学习优化器来训练模型，下图是模型结构示意。 模型结构 在标准的监督学习中，“学习”优化过程就是随机梯度下降(SGD)。有监督损失函数l (x, y)与这个模型相关，其中x是小样本输入，y是相对应的标签。通过使用梯度∂l(x,y)/ ∂φ_t执行SGD，迭代更新基础模型的参数φ_t至收敛。有监督更新规则可以被写成： 其中θ是优化器的参数（例如学习速率），我们称其为元参数（通常也叫做超参数）。 本文中的学习优化器是一个参数更新过程，它并不依赖于标签信息， 在传统的无监督学习算法中，专家知识或者一个简单的超参数搜索决定了θ，其中包括一些元参数，例如学习率和正则化常数。相比之下，我们的更新规则有更多数量级的元参数，例如神经网络的权重。我们在元目标上执行SGD来训练这些元参数，以便找到最佳参数θ∗，将一组训练任务的元目标最小化。 训练更新规则 近似梯度训练 考虑到θ的高维性质，本文通过截断BP算法评估∂&#91;MetaObjective&#93;/ ∂θ对参数θ进行优化，采样每次截断的步数和无监督训练步数的总数以限制由截断引入的潜在偏差。 梯度稳定训练 限制最大内环步长对于优化器的稳定性至关重要。如果不限制学习率，优化器的学习速度会迅速提高并进入混沌区域。 当使用学习优化器时，特别是在学习优化器的元训练的初期，学习优化器很容易在基础模型中产生高方差权重，批标准化（Batch Norm）通过增加权重空间可以解决上述问题。 元训练的分布与泛化 本文中学习优化器的泛化来自于无监督更新（UnsupervisedUpdate）的形式和元训练分布。此外对数据集和基础模型架构上的分布也进行了训练。 本文构建了一套由CIFAR10、来自ImageNet的子集的多类识别和一个由渲染字体组成的数据集组成的训练任务。 我们发现增加训练数据集的变化有助于优化过程。为了减少计算量，我们将输入数据大小限制为小于16x16像素，并相应地调整所有数据集的大小。 在预处理中，我们根据特征维度对所有输入进行转置，以便无监督更新能够学习到一个置换不变性学习规则。 为了增加数据集的变化，我们还通过移位，旋转和噪声来扩大数据集，并将这些增强系数作为元目标的附加回归目标，例如旋转图像并预测旋转角度以及图像类别。 实验结果 本文研究了现有的无监督学习和元学习方法的局限性，然后展示了我们提出的学习优化器的元训练（meta-training）和泛化特性，最后对学习优化器的运行原理进行说明。 目标函数失配 尽管变分自编码器（variational auto-encoder，VAE）分类准确率在一定范围内会随着训练步数的增加而提高，但在训练后期，其分类准确率会所下降。这种结果是由于目标函数失配引起的，例如下图中小样本分类结果。 半监督学习算法的失效模式 上图中，左图是目标函数失配曲线。右图是原型网络在随机输入下的分类准确率。 元优化（Meta-Optimization） 在训练过程中，通过平均所有数据集、模型结构和算法展开执行步骤，监测了元目标（meta-objective）的移动平均数，如下图所示。 训练和评估任务分布的训练曲线 上图中，经过200小时的训练后，训练损失在不断下降，表明近似的训练算法都可以进行有效的学习。为了获得全局参数，我们在多种训练集和测试集上运行了学习优化器，如右图所示。其中，像imagenet、MNIST和Fashion Mnist等数据集的评估损失都有所下降。在训练像IMDB等数据集，就出现了过拟合现象。因此，在200小时后的元训练中，我们用元参数θ进行无监督更新。 泛化 我们最先泛化的对象就是数据集。在下图中，通过在学习模型中嵌入了针对像素的后验分布的变分自编码器，并通过有监督学习比较了小样本分类（每一类有10个样本）的性能，如下图所示。 学习优化器泛化到不可见的数据集 上图中，在同一标签数据集上，我们学习的更新规则产生的表达能力比随机初始化或变分自编码器的输出结果更适合小样本分类。 为了进一步探索优化器的泛化能力，我们利用二进制文本分类数据集：IMDB电影评论，训练了学习优化器，该数据集通过计算一个包含1000个单词的词袋进行编码。 我们分别使用训练了30个小时和200个小时的模型来评估元训练的效果。尽管只利用了图像数据进行训练，训练了30个小时的学习优化器比随机初始化的识别准确率提高了近10%。 我们要泛化下一个的属性是神经网络结构。我们使用学习优化器训练不同深度和单位计数的模型，并比较了在不同时间点的结果，如下图所示。结果表明，尽管只训练了2-5层的网络和每层64-512个单元，学习规则可泛化到11层，每层10000个单元。 接下来我们将考察模型在不同激活函数上的泛化。我们将学习优化器应用于具有多种不同激活功能的基础模型上。在训练过程中不同点上的性能评估可以在下图中看到。 尽管训练中只使用了ReLU激活函数，但我们的学习优化器在所有情况下的表现都优于随机初始化。 探索学习优化器的学习过程 为了理解算法的学习过程，我们在学习优化器中输入了两个moon数据集。尽管是二维数据集，与元训练中使用的图像数据集不同，但学习模型仍然能够识别出以一种完全无监督的方式生成的数据集，如下图所示。 上图是经过学习优化器分类后的可视化结果。输入数据集分别为moon和MNIST，学习算法能对无标签的数据进行分类。可视化结果显示了从基本网络结构利主成份分析（PCA）降维后的结果，并选取了前三个主成分的进行展示。 此外，学习算法能够沿着不同的主成分方向分离出各类数据。 结论 本文提出了一种基于元学习的无监督学习更新规则，实验结果表明算法的性能优于与现有的无监督学习算法。此外，更新规则可以训练不同宽度、深度和激活函数的模型。 大数据文摘微信后台后台对话框内回复“元学习”即可下载论文~ 论文地址： https&#58;//arxiv.org/pdf/1804.00222.pdf 转载来源：论文Express｜谷歌大脑：基于元学习的无监督学习更新规则]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>大数据</tag>
        <tag>许嵩</tag>
        <tag>加州大学伯克利分校</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[社交关系的裂变不止于电商，「淘淘课」想用它做知识付费]]></title>
    <url>%2F2018%2Fb6e6e083%2F</url>
    <content type="text"><![CDATA[一些有知识生产能力但社会话题度并没有那么高的人被天然排除在了这些大平台之外；此外，对于一些内容生产者来说，平台的确为他们提供了内容运营和流量的支持。 得到、喜马拉雅等知识付费平台的崛起、小鹅通、荔枝微课的火爆又让知识付费从大平台“烧”到了微信生态内，一个肉眼可见的变化是，内容的生产和获取门槛越来越低。 36氪最近接触到淘淘课的创始人及 CEO 周杰认为，中心化、平台化的运行模式下，知识付费更多是一些已经拥有大众影响力的“大V”们对自己的流量的内容变现，一些有知识生产能力但社会话题度并没有那么高的人被天然排除在了这些大平台之外；此外，对于一些内容生产者来说，平台的确为他们提供了内容运营和流量的支持，但综合流量的玩法其实并不适用于内容产品。 淘淘课在做的事情简单来说就是为知识付费产品提供一个出口，帮助一些中小V甚至我们所认为的生活中的普通人将自己的知识进行变现，可以分两方面来看： 内容运营的去中心化：淘淘课选择让知识生产者自己就变成内容营销方，为他们提供“知识店铺”的服务。前面提到，电商领域的综合流量平台玩法其实并不适用于内容产品，主要因为，内容产品（或者说泛教育产品）更多的是供给端主导。在产品一侧，用户更愿意基于口碑、对于内容生产方的品牌认知进行购买，因此，在这一逻辑下，如果要提高课时完成率和复购，就需要内容提供方（机构或个人）来维系用户，沉淀流量，让用户留存下来。 周杰认为，大部分有内容变现动机的 CP 方其实已经有了自己的粉丝用户群体，可以看做是一个“私域流量”，怎么将这部分流量的价值最大化才是最主要的。 通过自己运营“知识店铺”，对于内容生产方而言，一个最为直接的变化体现在收入上，另外一个变化则是，透过知识店铺的运营反馈，对于内容生产方能够直接了解到自己粉丝群体对于内容的需求，进而在新的内容制作当中进行调整，是一个 C2M 的逻辑。 小鹅通、荔枝微课等做的也是类似的事情，但淘淘课的一个区别在于，“知识店铺”除了可以作为自己内容的销售场景外，内容生产方也能够选择淘淘课自己的“精选商城”上的其他内容上架售卖，通过多维度的内容去满足用户对于不同内容的需求，另一方面，也可以理解为“流量共享”。 内容分发及营销的去中心化：做内容领域的“社交电商”。除了用内容生产者本身将平台去中心化外，“知识大使”也是淘淘课在内容营销渠道上的一个重要角色。 创始人周杰曾任蚂蚁-国泰产险 CTO ，参考保险领域的代理人机制，他认为分销不在于线上，而是线上和线下都要保证，“线上”是内容生产者本身的影响力，“线下”则是指的是社交关系。 36氪曾经对社交电商进行过详细的分析和报道，这些“知识大使”可以类比为个人店主，他们有自己的“流量池”，同时也具有一定的将这些流量变现的能力，而淘淘课给到这些知识大使的“供应链”就是精选商城内的知识内容。 我比较好奇的是”知识大使“都是怎样的人群？周杰提到，现阶段，淘淘课主要在宝妈、大学生群体内进行推广。这些群体以“宝妈群”为例，这些群体首先有相对“封闭”的社交关系场景，妈妈群之间的口碑传播效应特别明显。 除了以个人形式运营“知识店铺”外，淘淘课也支持二级分销，用社交关系裂变的模式来促成内容教研。今年 3 月刷屏的新世相已经验证了， 至于淘淘课在线商城中所售卖的课程，主要有两大块来源 ，首先是团，此外，淘淘课的也可以作为大的内容分发渠道存在，对于可能存在的盗版问题，周杰提到，团队下一阶段计划通过区块链的技术来规避。 相对于“有赞”模式，从 SaaS 工具切入到营销侧的服务，淘淘课的服务更加直接，即营销层面的辅助，36氪注意到，小鹅通在营销解决方案上也推出了“知识店铺”的功能。我们认为，当“知识/内容”越来越成为一种商品时，社交电商的模式或许会成为知识付费的新姿势。 团队方面， 淘淘课的创始团队均来自阿里巴巴（蚂蚁金服），参与了余额宝、招财宝、娱乐宝等多项互金领域产品搭建。其中创始人及CEO周杰历任蚂蚁金服总监（M4），蚂蚁-招财宝 CTO、蚂蚁财富事业群创始团队成员，曾负责商户事业线、财富事业线的技术和业务体系搭建。 ———————— 我是36氪作者思齐，教育、消费电商类项目报道交流请联系微信 HannahHQ723 转载来源：社交关系的裂变不止于电商，「淘淘课」想用它做知识付费]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>市场营销</tag>
        <tag>电子商务</tag>
        <tag>产品运营</tag>
        <tag>周杰</tag>
        <tag>蚂蚁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNN和LSTM弱！爆！了！注意力模型才是王道]]></title>
    <url>%2F2018%2Fa71e3994%2F</url>
    <content type="text"><![CDATA[大数据文摘作品编译：晚君、笪洁琼、钱天培循环神经网络。LSTM和RNN被发明于上世纪80、90年代，于2014年死而复生。 大数据文摘作品 编译：晚君、笪洁琼、钱天培 循环神经网络（RNN），长短期记忆（LSTM），这些红得发紫的神经网络——是时候抛弃它们了！ LSTM和RNN被发明于上世纪80、90年代，于2014年死而复生。接下来的几年里，它们成为了解决序列学习、序列转换（seq2seq）的方式，这也使得语音到文本识别和Siri、Cortana、Google语音助理、Alexa的能力得到惊人的提升。 另外，不要忘了机器翻译，包括将文档翻译成不同的语言，或者是神经网络机器翻译还可以将图像翻译为文本，文字到图像和字幕视频等等。 在接下来的几年里，ResNet出现了。ResNet是残差网络，意为训练更深的模型。2016年，微软亚洲研究院的一组研究员在ImageNet图像识别挑战赛中凭借惊人的152层深层残差网络（deep residual networks），以绝对优势获得图像分类、图像定位以及图像检测全部三个主要项目的冠军。之后，Attention（注意力）模型出现了。 虽然仅仅过去两年，但今天我们可以肯定地说： “不要再用RNN和LSTM了，它们已经不行了！” 让我们用事实说话。Google、Facebook、Salesforce等企业越来越多地使用了基于注意力模型（Attention）的网络。 所有这些企业已经将RNN及其变种替换为基于注意力的模型，而这仅仅是个开始。比起基于注意力的模型，RNN需要更多的资源来训练和运行。RNN命不久矣。 为什么 记住RNN和LSTM及其衍生主要是随着时间推移进行顺序处理。请参阅下图中的水平箭头： RNN中的顺序处理 水平箭头的意思是长期信息需在进入当前处理单元前顺序遍历所有单元。这意味着其能轻易被乘以很多次&lt;0的小数而损坏。这是导致vanishing gradients（梯度消失）问题的原因。 为此，今天被视为救星的LSTM模型出现了，有点像ResNet模型，可以绕过单元从而记住更长的时间步骤。因此，LSTM可以消除一些梯度消失的问题。 LSTM中的顺序处理 从上图可以看出，这并没有解决全部问题。我们仍然有一条从过去单元到当前单元的顺序路径。事实上，这条路现在更复杂了，因为它有附加物，并且忽略了隶属于它上面的分支。 毫无疑问LSTM和GRU（Gated Recurrent Uni，是LSTM的衍生）及其衍生能够记住大量更长期的信息！但是它们只能记住100个量级的序列，而不是1000个量级，或者更长的序列。 还有一个RNN的问题是，训练它们对硬件的要求非常高。另外，在我们不需要训练这些网络快速的情况下，它仍需要大量资源。同样在云中运行这些模型也需要很多资源。 考虑到语音到文本的需求正在迅速增长，云是不可扩展的。我们需要在边缘处进行处理，比如Amazon Echo上处理数据。 该做什么？ 如果要避免顺序处理，那么我们可以找到“前进”或更好“回溯”单元，因为大部分时间我们处理实时因果数据，我们“回顾过去”并想知道其对未来决定的影响（“影响未来”）。在翻译句子或分析录制的视频时并非如此，例如，我们拥有完整的数据，并有足够的处理时间。这样的回溯/前进单元是神经网络注意力(Neural Attention)模型组。 为此，通过结合多个神经网络注意力模型，“分层神经网络注意力编码器”出现了，如下图所示： 分层神经网络注意力编码器 “回顾过去”的更好方式是使用注意力模型将过去编码向量汇总到语境矢量 CT中。 请注意上面有一个注意力模型层次结构，它和神经网络层次结构非常相似。这也类似于下面的备注3中的时间卷积网络（TCN）。 在分层神经网络注意力编码器中，多个注意力分层可以查看最近过去的一小部分，比如说100个向量，而上面的层可以查看这100个注意力模块，有效地整合100 x 100个向量的信息。这将分层神经网络注意力编码器的能力扩展到10,000个过去的向量。 这才是“回顾过去”并能够“影响未来”的正确方式！ 但更重要的是查看表示向量传播到网络输出所需的路径长度：在分层网络中，它与log（N）成正比，其中N是层次结构层数。这与RNN需要做的T步骤形成对比，其中T是要记住的序列的最大长度，并且T &gt;&gt; N。 跳过3-4步追溯信息比跳过100步要简单多了！ 这种体系结构跟神经网络图灵机很相似，但可以让神经网络通过注意力决定从内存中读出什么。这意味着一个实际的神经网络将决定哪些过去的向量对未来决策有重要性。 但是存储到内存怎么样呢？上述体系结构将所有先前的表示存储在内存中，这与神经网络图灵机（NTM）不同。这可能是相当低效的：考虑将每帧的表示存储在视频中——大多数情况下，表示向量不会改变帧到帧，所以我们确实存储了太多相同的内容！ 我们可以做的是添加另一个单元来防止相关数据被存储。例如，不存储与以前存储的向量太相似的向量。但这确实只是一种破解的方法，最好的方法是让应用程序指导哪些向量应该保存或不保存。这是当前研究的重点。 看到如此多的公司仍然使用RNN/LSTM进行语音到文本的转换，我真的十分惊讶。许多人不知道这些网络是如此低效和不可扩展。 训练RNN和LSTM的噩梦 RNN和LSTM的训练是困难的，因为它们需要存储带宽绑定计算，这是硬件设计者最糟糕的噩梦，最终限制了神经网络解决方案的适用性。简而言之，LSTM需要每个单元4个线性层（MLP层）在每个序列时间步骤中运行。 线性层需要大量的存储带宽来计算，事实上，它们不能使用许多计算单元，通常是因为系统没有足够的存储带宽来满足计算单元。而且很容易添加更多的计算单元，但是很难增加更多的存储带宽（注意芯片上有足够的线，从处理器到存储的长电线等）。 因此，RNN/LSTM及其变种不是硬件加速的良好匹配，我们在这里之前和这里都讨论过这个问题。一个解决方案将在存储设备中计算出来，就像我们在FWDNXT上工作的一样。 总而言之，抛弃RNN吧。注意力模型真的就是你需要的一切！ 相关报道： https&#58;//towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0 转载来源：RNN和LSTM弱！爆！了！注意力模型才是王道]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>大数据</tag>
        <tag>王道</tag>
        <tag>亚洲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红杉资本刘星：新零售未来5年的“五化”趋势]]></title>
    <url>%2F2018%2F4f8923b2%2F</url>
    <content type="text"><![CDATA[《零售老板内参》联合36氪举办的新零售创新创投峰会在深圳金蝶软件园隆重举行。专注消费零售领域的顶级投资机构、投资人，深耕新零售一线实践创业精英。 文 | 红杉资本中国基金合伙人刘星 零售老板内参独家专稿 未经许可不得转载 4月24日，《零售老板内参》联合36氪举办的新零售创新创投峰会在深圳金蝶软件园隆重举行。专注消费零售领域的顶级投资机构、投资人，深耕新零售一线实践创业精英，新消费新零售领域备受追捧的现象级产品和项目，零售行业的权威大咖、意见领袖，以及500多名零售行业精英齐聚，围绕“新消费、新零售、新机遇”展开丰富多样的主题演讲、圆桌对话，深入探讨消费零售行业2018年的新趋势以及新消费、新零售赛道的新机遇。 在峰会上，红杉资本中国基金合伙人刘星发表了精彩演讲。以下为演讲速记整理： 感谢36氪和《零售老板内参》的邀请，让我有机会跟大家分享。我是一个不合格的学生，我刚才知道老师给我出的题是无人零售，我自作主张给自己出了一个新题“探索消费新时代”。 之所以用“探索”这个词，大家说2017年是新零售的元年，2017年在新零售领域风风火火，主持人提到2018年会更加活跃。我同意以上的说法，但我们应该把眼光和思考放在更长的时间维度。所以客观来说我们还在探索阶段，很多新模式、新业态，我们看到的很好的市场反映和特别好的业内媒体的报道，相信他们探索的创新处于早期发展阶段，包括无人零售、无人货架、自助售货机、无人便利店。 在休息室有两位创业者跟我讨论“无人”是否重要。我们应该有探索的心态，既然是探索，我们不能太着急，没什么东西可以一口吃成大胖子。零售消费行业需要一段时间的沉淀，既然是探索，给自己犯错的空间。在创业探索的过程中可能会遇到挫折、交一点学费，这都是正常的，所以我特别想谈谈“探索”。 消费新时代，在接下来5-10年展现在我们面前的，是一个很壮观的画面。这是我们心目中的消费新时代，我们今天刚好走上探索之路。 这是我去年分享过的PPT，当中有什么迭代，在此基础上有什么新想法。2017年4月，我在一个小型会议上做分享——《新零售究竟新在哪里》。去年我第一个讲的是新业态，今天我把新业态放在最右边，这是我认知的改变。我们开始接触新零售时，发现由于新业态的出现，让我们感觉有新东西出现。实际上新业态是一个结果，因为人们在前三个维度上展开探索，最后像一盘菜似的端到别人面前。最后是新人群、新品牌、新技术。收入能达到中产水平的人显著增加，这些人群背后是我们消费新时代的主力，这些人更个性、更识货。他通过海淘、旅行更会辨别好商品，“更会花”意味着他更有钱、更懂得怎么花钱，他知道如何选择好的商品，如何为好的商品买单。这些人群的特征推动新零售、新消费的发展。 前几天一个朋友在群里提出一个很好的问题，“技术为新零售提供什么价值”，有成功的案例让我们看到应用后，便有明显的业绩提升吗？大家能不能脱口而出告诉大家某一个特别成功的案例，在我们跟很多创业者、消费零售企业的接触过程中，可以清晰的看到潮流的涌动。 在新技术的问题上要有一定的信仰，看看快手、拼多多的崛起，这是纯线上的企业，这两家是非常好的代表，两个创始人都是理工男，都是工程师，他们对技术有天生的信仰，事实上结果证明其信仰是正确的。快手内容的推荐不通过编辑，决定哪些内容在前面出现，哪些内容在后面出现。拼多多的老总并没有商品团队，由算法驱动什么商品卖得好。如果有机会看到这两家公司的图表，如拼多多，拼多多和阿里、淘宝、唯品会相比，他达到2亿用户的时间比前几家公司短非常多，证明数据和算法驱动是有效的。行业和公司要有信仰，相信数据和技术的力量，并不是你今天使用工具，明天便能看到效果，这需要一定的时间沉淀和积累。 新零售的目标是什么，带给客户美好的新的体验。我希望大家在用户体验上花更多的时间打磨和思考，我是否带给客户美好的体验，这个体验是否让客户感受到舒服、顺畅、贴心，这个体验是否有新鲜感。作为企业的领导者，我是否考虑降低成本，提高效率。作为零售行业，最终不能达到效率和成本，无法形成经济模型。虽然你给客户新的体验，但生意可能做不下去。我认为这是从业者需要考虑的点，凡是都有一个最根本的立足点，最根本的立足点在于给客户提供美好的新的体验。如果能为客户提供美好的新的体验，你的经济模型理论上是成立的。我们不能为了新零售而新零售，技术很重要，对数据要有信仰，非得为了应用和数据做技术，有点离开初心了。 新零售也离不开新品牌，在未来5-8年会有大批的新兴品牌出现，这些品牌从何而来，除了从品类创新入手外，更多的会源于品质提升，同时也会出现一些在品味上带来新体验的。有多少人看过《品类杀手》这本书，从新品类入手创建一个新品牌，这是被历史和世界各国验证过的创立品牌的方式。中国经过过去二三十年经济大发展，很多品类被品牌占据了，是否有新的品类作为基础构建新品牌，我认为有。 前两天买了一双鞋，这个品牌说你穿这个鞋子到野外跑步，可以在野外比较软的地上跑步。中国人特别多，哪怕你做的是小众产品，事实上小众不小，因为中国人口基数非常大。前5-10年中国品牌从品类诞生，我认为未来新品牌诞生的基础是更高的品质。 有几条简单而朴素的原理，你是不是用更好的材料，可能由于技术的创新导致你的品质提升。你的确用了更多的匠心精神在产品品牌上，品味有调性，就像诚品说“我们不是卖书的，我们是推广阅读的”。无印良品推崇的是“我们购买商品不看品牌，不看包装”。可品味，让用户一方面感觉到有品味，另一方面是可以跟你互动、把玩，我可以细细的咀嚼感受，这是可品味。我认为新品牌未来会有大量的机会，我认为未来5-10年更大的机会是以品质为根基创建品牌，最后以品味为根基创建品牌。 品牌零售化和零售品牌化。原来品牌商在传统的央视广告、门店，对消费者每个个体，对商品每个SKU在什么场景下被谁购买，被谁使用，零售终端并不了解。在现在新技术时代下，有新零售互联网的传播，通过营销传达给客户，通过直营门店了解市场的脉搏，品牌商把自己变得更加零售化，让自己更懂零售，让自己更有机会直接面对消费者。零售在品牌化，一些新兴零售企业非常注重本身的品牌打造，不像以前的零售企业只是提供一个场所，在合适的时间把合适的商品卖给合适的用户。现在新零售企业非常重视本身的品牌塑造，同时很多开始做自有品牌，自有品牌的比例在拉升。零售品牌化是非常明显的趋势。 在新技术上，大家应该更勇敢、更积极的拥抱创业公司提供的解决方案。国际解决方案的企业和软件企业不能很好的了解中国市场的变化，中国本土企业和创业企业更了解市场结构，更接地气，更能为消费零售企业提供合适的解决方案。 展望未来5年，我总结为“五化”：体验化、智能化、品牌化、细分化和集中化。在增量市场里，出现更多细分化的特色零售业态。在存量市场上，商超、便利店、水果零售等现有业态里出现整合，形成更集中化。祝愿大家在接下来的会议过程中有更多的收获和分享，谢谢！ 转载来源：红杉资本刘星：新零售未来5年的“五化”趋势]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>经济</tag>
        <tag>创业</tag>
        <tag>风投</tag>
        <tag>红杉资本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“排序”机制：区块链原生应用独有的创新设计]]></title>
    <url>%2F2018%2Fa9e75d89%2F</url>
    <content type="text"><![CDATA[具有不同于古典互联网社区产品的设计细节和产品机制，它的“排序”方式使内容第一次有了另一种更公平的筛选算法和发现机制。 区块链付费问答产品 ：Cent ，具有不同于古典互联网社区产品的设计细节和产品机制，它的“排序”方式使内容第一次有了另一种更公平的筛选算法和发现机制。 橙皮书之前介绍了一款区块链付费问答产品 ：Cent 。 最近我仔细看了看这款产品的一些设计，越发感觉：Cent 有不同于古典互联网社区产品的设计细节和产品机制。 我认为Cent代表了区块链原生应用的一个独有的创新设计，这个创新之处就在于“排序”机制。 一、“排序”是一种新的产品设计 从上一次的报道里，我们大概知道了 Cent 是个什么样的产品： 它可以被看作付费问答版的“知乎”（实际上因为是付费的，你也可以上面发布“任务”，而不仅仅只是“问题”，但为了方便讨论，我们还是以问答为主）： 提问者可以在上面发布问题，每个问题绑定一笔征集答案的悬赏金，以 eth 币的形式；1. 答题的人发布答案后，则有机会参与瓜分赏金，赚取 eth 币；1. 最后Cent还有另一个独特的用户角色：排序者。排序者不回答问题，但同样有机会获得 eth 币。我们重点来说说最后一点。 排序者是介于提问者和答题者之间的投票人，系统首先会把每个问题下面的所有答案通过算法分配成两两一组，这个算法会确保每组的两个答案质量相对接近、没有太大的差距，然后排序者需要对所有成对的答案进行投票筛选，在每组中选出最好的那个。 上面把问题下的所有答案分成了 12 对，排序者需要从每一对中挑选出最好的那个答案。 每对包括两个答案，通过左右两个按钮让两个答案进行PK，挑出最好的那个。 被选中的那个答案会变成绿色的。 所有答案排序完成之后，在问题到期限关闭之后，就可以坐等分钱了。 可以看到，排序者每排一次，其实就是对所有答案进行一次整理，最终所有排序者的结果会转化成：根据回答内容的质量，把问题的答案从高到低一一进行了排序，最终让高质量的内容可以浮现出来。 我认为：排序者这种用户角色是之前的互联网产品所没有的。 对内容进行排序、在每组两个答案之间“PK”选出最好的那一个，这种类型的交互，对用户来说也是完全陌生新鲜的产品体验。而且，这种交互最终还会产生不同的投票算法，让优质内容以另一种机制浮现出来。 因此，从各个方面来看，排序都算得上是产品设计上的一个创新。 二、跟知乎点赞同／反对的机制有什么本质不同？ 对社区类产品来说，控制好社区内容的信噪比、让高质量的内容被更多人看到、让有潜力的内容有更多曝光的机会，这些都是产品机制的重点。 在之前的社区产品里（天涯论坛、百度贴吧），采取的方式是让用户尽可能低门槛的发布内容，在主页中以时间排序作为信息流呈现的逻辑，然后通过“版主加精”、给权重的方式让好的内容置顶浮现出来，同时通过删帖等强制管理，消灭垃圾内容。 到了知乎，这种方式就变了。知乎是通过更民主的投票方式，让其他用户对答案点赞同／反对，从而让优质内容浮现出来，让垃圾内容逐渐消失。 表面上看，知乎的赞同／反对也会对答案的排序产生影响。那么，Cent 和知乎本质上还有区别吗？ 答案是：有区别。而且区别很大。 主要有三点： 1.从用户角度来看，点赞同／反对其实是用户一种自我表达的出口。 换句话说，用户在知乎上通过对某个答案点赞同／反对，来表达自己的某种观点和判断的，从而形成自己的社交形象，这是用户肯为内容投票的动机之一；但在 Cent 上，用户愿意成为排序者是出于利益因素——他可以获得实际的经济回报，这更像是一份“工作”，排序者和提问者之间是一种隐性的雇佣关系。 2.知乎采用赞同／反对，最终沉淀出来的是具备热度的头部内容。 知乎的目标，是让每个问题下面都能呈现出一批精彩的答案，这批答案将带来最主要的头部流量，至于 10 赞以下的长尾内容，他们彼此之间的质量和排名是怎样的？知乎并不关心。 而 Cent 不同， Cent 是答案与答案两两进行 PK ，它是对所有答案的一次质量排序，每一个答案具体的排名都是根据用户的操作得出来的，每个排位都是严格的、不可替换的、有迹可循的，不管这个排位是前几名还是倒数后几名。 3.第三点跟第二点是强相关的。 因为知乎点赞同／反对最终是要找出具备热度的头部内容，而点赞数同时也在潜移默化地告诉用户“这个答案是优质”的，是一种心理暗示，因此知乎的头部内容存在马太效应，也就是“赞越多的答案越有可能被后来的用户点赞”；相反，Cent 就不会有这个问题。 首先，Cent 把答案配对分组时，根据此前不同的投票情况，系统就可以对不同的用户展示不同的配对组合，这样总的来说会使得投票过程更加公平；然后——也是和知乎最大的不同点，Cent 每组答案进行 PK 的时候，用户是看不到之前其他用户投票的结果的。每个用户每次投票都是在黑箱中进行，因此不会被其他用户干扰。 这三点，同时也是 Cent 在产品设计上最主要的创新点。社区类产品里，内容第一次有了另一种更公平的筛选算法和发现机制。 三、为什么在区块链之前没有“排序”的设计？ 搞清楚了排序的创新之处，很自然的会想到另一个问题：为什么排序机制一直等到区块链出现之后才诞生？ 最主要的原因是：区块链技术给予了社区类产品更直接的支付能力和交易透明度。之前，要完成 Cent 这样一款产品，借助人民币充值悬赏金、通过微信支付、支付宝这样的工具也可以实现付费问答或者任务认领，但是唯独不能实现的是排序者这个角色的设计。 中心化平台，在这类产品中，大部分的商业模式是中介抽成。中心化平台往往会倾向于自己包办买卖交易双方的撮合和协调，这样才能从提问者的悬赏金中提取一定的中介费。 因此，由中心化平台决定“哪些答案是优质的”是很自然的做法——滴滴总是“宣称”会帮你叫到距离最近的、速度最快的、服务最好的司机，即使事实并非如此，它也会一直这样宣称。因为只有这样，它才具备价值。 那么，既然规则是由中心化平台制定的，显然排序者这样的用户角色就是多余的——最重要的是，你如何确保平台会真的会为排序者分一部分酬劳，以此作为他们辛苦排序的劳动成果？特别是当这部分钱完全可以通过平台内部操作节省下来的时候。 而区块链技术可以确保这一切都是透明的，排序者可以得到规则里承诺的、应有的 token 和报酬。这是一个自动运转的系统，不需要人工运营。提问者、答题者、排序者，只要这三类用户都对平台的规则达成共识，愿意参与进来，那么，智能合约就会自动执行接下来各个环节的资金分配，每个用户都能皆大欢喜。 四、最后 上面主要是我从产品经理的角度分享了对 Cent 排序产品设计的思考。 这是一个非常小的产品细节，也是一个非常具象的例子。从小的细节和具体的例子里，人们更容易感受到区块链技术创新对产品所带来的一些影响。 但实际上，如果你跳出产品经理的视角来看这个问题，“排序”其实不仅是一种产品设计上的创新，它背后代表的是另一块属于区块链的新生的市场。排序代表的是对内容的一种整理和组织，更进一步，我们不仅可以利用区块链和 token 激励用户对答案进行排序，我们还可以激励他们对答案进行补充完善、重新整理（比如，把维基百科代币化）等等。 而这种在社区内借助 token 让用户对内容进行维护的方式，在国外已经有一个统一的称呼了，叫“curation markets”。但在国内，对这种类型的认知还很初期，网上几乎很难找到相关的讨论。橙皮书希望借助这篇产品经理角度的文章，让大家对 curation markets 有一个初步的认识。 作者：橙皮书，微信公众号：橙皮书（ID：taixu_huanjing），关注区块链技术和产品 本文由 &#64;橙皮书 原创发布于人人都是产品经理。未经许可，禁止转载 题图来自 unsplash，基于 CC0 协议 转载来源：“排序”机制：区块链原生应用独有的创新设计]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>经济</tag>
        <tag>区块链</tag>
        <tag>产品经理</tag>
        <tag>苏黎世高工</tag>
        <tag>民主</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[36氪领读 | luckin coffee 侵占你朋友圈的秘密，裂变拉新]]></title>
    <url>%2F2018%2F5029d5f0%2F</url>
    <content type="text"><![CDATA[36氪专门为读书设立了栏目，筛选一些值得读的书，并提供一些书摘。内容简介移动互联网时代，信息日益冗余，新闻速朽；整体流量增长速度放缓，而竞争者数量高速增加；流量呈现变少、变贵、欺诈频繁的现状。 36氪专门为读书设立了【36氪领读】栏目，筛选一些值得读的书，并提供一些书摘。希望你手边有一本称心的书，让读书这场运动继续下去。 内容简介移动互联网时代，信息日益冗余，新闻速朽；整体流量增长速度放缓，而竞争者数量高速增加；流量呈现变少、变贵、欺诈频繁的现状。品效合一的营销策略成为共识，而实现路径成为痛点。 多次开创各营销渠道效果之最的营销人、各种刷屏级营销事件操盘手、神州专车CMO杨飞，这一次倾囊相授，诚恳讲述如何实现流量获取、营销转化以及流量的运营和再挖掘。 作者简介杨飞，2017年广告门年度CMO，“流量池营销”理论提出者，传播学硕士；曾创办移动营销机构氢互动，获得国内外各类营销奖项近200次；2015年出任神州优车集团CMO，操盘神州专车、神州买买车等多次营销战役。现任luckin coffee营销操盘者。 书籍摘录裂变营销，最低成本的获客之道先讲一个刚刚发生的故事。我所操盘的luckin coﬀee 营销第一 仗最近启动了。虽然这是一杯典型的网络新零售咖啡（App 下单， 可自提可外卖，高品质咖啡），但由于获客第一步是App 下载，推 广难度还是不小的。你想想：谁会为了喝一杯咖啡，愿意下一个10 多兆的 App ？ 之前内部讨论时，luckin coﬀee 的 CEO 问我：“你认为最重要 的 App 获客方式会是什么？”我毫不犹豫地回答：“裂变拉新。” 是的，相比于传统广告的品牌曝光、饱和式投放、内容营销、 公关事件等手段，我心里清楚，咖啡作为一种典型的社交饮品，将大部分广告费用拿来作为用户补贴，激发老用户分享好友拉新，将是最核心的获客手段。 事实也证明如此。2018 年 1 月 5 日，我们正式上线拉新赠杯活 动，当天新增用户注册量环比翻番，订单环比增长了40%，而且相 比于之前精准的微信LBS 商圈定投，该形式获客成本大幅度降低。 神奇的裂变！ 不夸张地说，今天一个企业如果没有太多预算做广告并投放到 媒体，我不会特别在意，但如果它的App 或者微信中没有裂变营销，那是不可接受的。 社交流量：移动互联网上最重要的免费流量 移动互联网时代最贵的是什么？是流量吗？是，也不是。流量只是结果，移动互联网时代最贵的是用户关系和关系链。 人是社会中的个体，离不开各种人际交往，而移动互联网让这种人际关系变得更紧密、更具交互性。在复杂的人际交往中，信息的流动构成了源源不断的流量，这些流量对企业而言就是巨大的、可发掘的金矿。 我们知道，腾讯之所以能够稳坐互联网三巨头之一的位置，靠 的不是工具应用的垄断，而是通过QQ、微信等社交产品，打通和绑定用户关系链。这种绑定带来的最大的商业价值，就是不需要通过传统的广告和营销模式去告知用户，只需要通过充分的“社交挑逗”（我喜欢用这个词）就能让用户追随朋友的喜好，比如“你的朋友正在干吗，你要不要跟他一起来？”从而去接受一个新鲜产品（想想很多人是怎么开始玩《王者荣耀》的）。 关系链成本是锁定用户行为和忠诚度的一个指标，如果没有社交关系的绑定，很多功能强大的产品就很容易被用户放弃，而注入了社交因素的产品，使用频次会明显增多，口碑推荐会提高用户信任，消费购买完毕朋友间还可以相互比较。而当用户要放弃产品时，也要慎重考虑脱离圈子的影响。你可以很轻易地离开一个书店或者商场，却很难轻易地离开一个朋友和一个朋友圈。 社交关系链是任何企业、任何产品在移动互联网上最强大的护城河。低成本社交流量的获取关键就在于社交关系链的打通。企业要想办法持续输出内容来刺激用户，使其从用户转为“粉丝”，再主动将企业的品牌或产品信息传播出去，成为企业在移动互联网时网状用户结构中的重要连接点。 以上就是裂变的理论基础。 今天的企业，一定要善于借助社交平台（微信公众号、微信群、朋友圈）的力量，在内容和福利的驱动下，触发用户身边的连接点，进而将用户的整个关系网络打通。当企业自有用户流量达到一定量级时，裂变的效果也就喷薄而出。 AARRR：从拉新到裂变 AARRR 是近几年兴起的增长黑客中提到的App 运营增长 模型。AARRR 分别是指：获取用户（acquisition）、提高活跃度 （activation）、提高留存率（retention）、收入获取变现（revenue）、 自传播（refer）。 AARRR 模型不仅适用于App，企业在营销的过程中也可以按 照这 5 步来检验营销效果。 第一步，获取用户：获取用户是运营一款应用的第一步，所有企业建立品牌、推广、营销的目的都是获客拉新。 第二步，提高活跃度：很多用户第一次使用产品的场景其实很被动。有些品牌，用户可能只用一次就离开了，那么这个用户就没有成为产品真正的用户。究其原因，有可能是注册流程太烦琐，或者产品功能同质化，或者产品没有达到用户的期望值而且不能满足其需求，抑或第一次使用完全是利益驱动。 种种原因都能影响到用户后续的体验和消费。但显而易见的是，一个用户在App 中的活跃频次，决定了该用户是否是此产品的真正用户。所以企业要通过运营或者有趣的营销手段，快速提高用户的消费频次，将初次用户转化成忠实用户。 第三步，提高留存率：“用户来得快，走得也快”是企业产品面临的另一大难题。在 当下，一个产品获客100 人能够留存10% 就已经很厉害了，如果能留存二三十人，那就是爆品。用户来了之后，用完你的产品就走了，这是一个很不好的现象，证明你的产品用户体验不太好。更糟糕的情况是，你的产品教育了市场，说明用户知道了市场还有你这样的产品，一旦他们发现更好的竞争对手的产品，就会投奔到竞争对手那儿，等于你帮竞争对手打了广告。 第四步，收入获取变现：变现是产品最核心的部分，也是企业最关心的部分。有些互联网产品前期采用补贴策略，获取收入很少甚至无收入（比如共享单车）。产品本身就能获取一些收入，让企业盈利为正，这是企业希望达到的理想状态。而收入直接或间接来自用户，所以前三个步骤是应用获取收入的基础，只有付费用户多了，或者补贴减少，收入才可能实现规模化正向盈利。 第五步，自传播：自传播这一环节在社交网络兴起的当下至关重要。如果用户觉得好玩儿、有趣，或者有利益驱动，就会自发性地将产品社交媒体中。然后，通过老用户找新用户，产品获得更大的扩散。自传播也就是产品的流量裂变。 自传播的核心是，产品本身是否真正满足了用户的需求且产生了价值。从自传播到获取新用户，产品形成了一个螺旋式的上升轨道，用户群体可能会产生爆发式的增长。 可以看出，在AARRR 模型中，获取用户就是流量入口，提高活跃度就是惊喜时刻，提高留存率就是产品价值，收入获取变现是单位价值，而自传播就是放大传播效应。 从以上营销的角度来解读AARRR 模型，我认为有三点尤其重要。 第一，获得第一批种子用户。只有有了第一批用户，才可能完成后续其他行为。尤其是本章推荐的裂变营销，其实质是用老用户带新用户，所以第一批用户非常关键，是营销的基础。 第二，提高留存率。想要提高留存率，在网络营销中可以不断试验，这是增长黑客和传统市场营销的本质区别。增长黑客提出的 A/B 测试、MVT （最小化测试）都是为了提高留存转化率。当然，社交关系链也是提高留存率的重要手段之一。 例如，Facebook 早期发现用户流失非常严重，为了避免用户 流失进一步扩大，Facebook 在注销流程后面新增了一个页面。当用 户要离开的时候，系统会读出好友列表中互动最亲密的5 个人，询问：“你真的确定要离开吗？”很多本来要注销的用户担心再也见不到这些朋友，看不到他们的状态，心一软就留下了。这个页面上线后，在没花一分钱的情况下，一年之内为Facebook 减少了2% 的 损失，留下了 300 万用户。 第三，裂变，也就是老用户如何通过技术手段，将应用产品病毒式推荐给新用户。 增长黑客会取代市场总监吗？ 由于裂变型增长更多地采用技术和数据来驱动，也让增长黑客的概念在近两年很流行。有必要在这里做一个知识补充。 增长黑客的概念最早起源于美国硅谷。2010 年，肖恩·埃利斯在自己的博客上首次提出了“增长黑客”的概念，他也被称为“增长黑客之父”。 肖恩对增长黑客有一个有趣的定义：增长黑客的唯一使命就是增长，因为公司的估值是与增长息息相关的，增长是所有公司的核心指针。在“技术控”眼里，品牌、创意、媒介、公关等这些传统市场手段是效率并不高的增长方式，甚至需要被增长黑客所取代。 近几年，增长黑客这个概念从美国延伸到中国，并且在国内十分火热，很大一个原因在于，现今国内的公司获取流量的压力太大，同时市场遇冷，导致竞争增强，传统营销方式收效甚微。每个企业都希望在各个环节提升效率，而不论是工程效率、金钱效率还是用户获取效率，增长黑客都能带来低成本、快速的提高。 同时，越来越多的企业不仅仅关注获客，也开始关注用户的整个生命周期，开始通过数据驱动的方法，不断地对产品进行迭代，这些都是导致增长可能成为新一代营销命题的重要原因。 2017 年 3 月，可口可乐宣布取消设立24 年之久的CMO 一职， 取而代之的是一个新角色——首席增长官（Chief Growth Oﬃcer）。 可口可乐的整体战略也向“以增长为导向，以消费者为中心”持续转型。增设首席增长官并非可口可乐一家公司的特例。高露洁、亿滋等快消品巨头都聘请了首席增长官，以实现品牌的快速增长，提升增长在品牌战略中的地位。 这一现象的背后，带来的一个明显趋势是AdTech 和 MarTech的对决。 AdTech 从字面上理解就是把广告和品牌内容送达消费者的技术 和手段。在AdTech 中，付费媒介、网页广告、SEM 付费搜索、原生广告、程序化购买、DSP 等都是经常使用的方式。 MarTech 主要是指利用即时服务、优化消费者体验流程、优化顾客转化技术等技术手段，借助大数据标签、客户关系管理、营销自动化等管理系统而实现的技术化营销。 AdTech 比较像营销人员的“外功”，有预算和出街创意就能实 现；而 MarTech 更像“内功”，可以为企业数字化转型和商业转型提供整体解决方案。 现实情况是，MarTech 在增长驱动和获客成本上明显要优于 AdTech，也越来越成为企业的核心增长手段。 我曾参加国内的GrowingIO（一家数据分析公司）增长大会，作为一个营销人，在场下听到一帮程序员在台上的用词，居然也有“创意”“热点”“事件营销”“自媒体”等，确实很有感慨。黑客增长与营销的边界正在模糊，甚至对传统的营销观念正产生巨大的冲击。 但在这样的趋势下，回到我们最开始的问题：增长黑客真的会取代市场总监吗？我的答案是，不会代替，但会融合。新一代市场总监一定要突破原有的营销知识短板，掌握更多的产品、技术、数据等驱动增长手段，而增长黑客也会成为企业市场核心组织，成为与传统品牌、外部广告等共同存在的“三极”之一。 初创公司没有庞大资金来选择优质的推广渠道以及头部内容合作，在这样的情况下可依靠大数据驱动和增长黑客，使之成为助力增长机制。成熟品牌虽然有了市场份额和大批忠诚用户，但仍将面对持续 增长的难题。用市场团队补充增长黑客团队，通过技术和数据的方式，来指导营销广告、创意、投放，也很有必要。 我们看到，无论是传统市场部门还是增长黑客技术部门，必然的趋势都是：企业要想实现流量获取和变现，就必须从自身流量出发寻找控制变量的方法，以存量找增量，以精细化运营获取更多的增长结果。 微信社会化营销的流量改造微信日活跃用户超9 亿，其中55% 的用户每天要打开微信10次以上。这两年，微信的巨大流量让所有人都心动不已，大家都想从这空气级的巨型应用流量池中分一杯羹，企业纷纷自建微信账号，数千万的微信公众号因此诞生。 微信去中心化的体系，让流量变得更直接，同时依托于社交口碑属性，这些流量也更加真实、更有价值。 时至今日，微信营销的基础教育已经完成，几乎每家企业都会开通官方微信公众号，并且有频次地更新内容运营。但这并不代表每个微信营销企业都会合理、有效地利用微信，通过好的手段实现流量改造，使其发挥最大转化效率。 90% 的官方微信都在自嗨 官方微信的“自嗨”是当下微信营销普遍存在的现象。很多企业看似赶在潮流上，实则仍然在用传统广告理念运营微信。比如，注册一个微信公众号（相当于买断一个长久的低价广告位或新闻位），然后雇一位小编定期发图文贴维护（等于雇了一位企业专属的广告投放编辑）。简单两步就解决了常规的广告投放、企业内刊、品牌公关等多种市场传播形式。 网感较强的企业，会紧跟事件热点，借助热点和受众完成一些简单的海报互动，虽然阅读量并不会增加太多；网感不强的企业，微信公众号就会完全沦落为自身的新闻中心，成为企业动态、领导人讲话、企业文化活动的宣传阵地，然后鼓动全员转发朋友圈，以为这样做就能达到传播刷屏的效果。但结果往往是阅读量过千都困难，“粉丝”量不增反降，用户活跃度也没有提升。 “无趣”“无效”“无聊”是当下企业在微信运营时的三个普遍问题。 无趣：由于属性限制，企业微信在一开始就具有天然商业化内容的定位，但受众对于这类内容的接受度和容忍度是有限的。缺少人格化的微信内容定位，没有意思的内容输出，企业和受众之间没有深层互动，这些都是由于无趣导致企业微信关注度不高的直接原因。 无效：即使很多企业微信有了关注度、有了阅读量，却依然无法将阅读量成功转化，让流量成为销量。这是由于企业在移动营销的过程中，仍然保持着传统的广告公关心态来对待微信营销 无聊：由于一些企业微信编辑人员的专业度不够，操作门槛较低，导致产出的内容没有营养价值。无聊的内容最终无法达到获取流量的目标。 微信营销如何才能快速引流并转换，以下将展开讨论。 把微信服务号做成超级 App 请注意，微信服务号不是公关号，也不只是内容号，而是一个 还原 App 功能的服务号。这是微信服务号的基本定位。 微信升级5.0 版本之时，不仅带来了全民上下沉迷的打飞机游戏，更带来了服务号和订阅号拆分。企业如果想要完善建立移动端的营销服务体系，服务号势必成为最佳选项。企业需要通过申请自 定义菜单，开通更多的后台接口，把微信服务号当成轻量级的App来使用，从而完成微信运营的核心思想转化。 对于一款企业 App 产品来说，它至少承载着三大功能。 第一，要承载业务的基本产品功能。 这一点很好理解。比如，神州专车作为移动出行的App，主要功能就是给用户提供出行专车服务。淘宝、天猫、京东App 的基本 产品功能是线上购物平台，饿了么、美团外卖、百度外卖App 的基本功能是线上外卖订餐平台，等等。这些产品功能本身是要关联用户数据和消费数据的。 第二，要承载客服咨询反馈的功能。 App 是企业与用户的主要接触点和沟通平台。企业要想及时获 得用户反馈信息，就必须让自己的产品具备和用户沟通的功能，也就是客服咨询功能。 第三，要承载营销信息的展示告知功能。 当一个App 具备一定的用户基数时，其本身的开屏页、弹窗、轮转图等就是企业免费的广告展示、信息告知的重要渠道。 同理，如果企业微信账号要做成超级App，就得满足以下几个基础功能。 广告信息的展示告知 我一直建议企业做好微信服务号，而不是订阅号。服务号和订阅号的不同之处在于，订阅号每天可推送一条图文信息，会被折叠 在订阅号窗口；而服务号是每月推送4条图文信息，但不会被折叠，可以直达用户。 或许会有企业认为一个月推送4 次，频次不够，内容太少，达不到效果，但其实恰恰相反。当下用户的时间太过碎片化，如果每天的推送内容不够出彩，就很难打动用户，甚至会被认为是一种骚扰而取消关注。 2017 年以来，微信平台本身的订阅号打开率一直在持续下降。如果企业资源有限、人员有限，建议只做好服务号就够了。订阅号可以注册下来，用于企业发布一些紧急性、临时性的信息，以及与用户沟通交流，不做日常更新。 企业在做服务号的推送内容时要珍惜每一次的推送，把内容做成精品，通过一次次的累积叠加最终实现用户的增长。 客服咨询功能 显然，微信的生态环境比App 更适合说明企业服务和管理用户，微信公众平台新版的客服功能提供了即时回复用户咨询、自动回复、客服数据统计等功能，并支持多人同时为一个公众号提供服务，让企业和用户的连接更为方便和快捷。 企业可以利用微信公众平台极大地减少客服人员的工作量，让 用户在微信里自主完成咨询、查询等操作。随着AI（人工智能）客服、语音机器人等技术的成熟，微信客服功能会进一步优质高效。 微信一定要实现企业产品功能微信开发者模式是一个开放式的接口，可以通过产品后台的编写进行后台改造，完成消费数据的接口对接，从而实现产品在微信里的业务转化。 比如，很多连锁餐饮企业就是微信服务号的受益群体。他们将微信服务号进行技术开发和数据对接，增设了订餐、排位、查看菜单、预订外卖等菜单功能，或者添加微信卡券功能，绑定会员卡、发放优惠券等，效果相当不错，能够提高用户消费频次和消费额度。 餐饮企业，尤其是快餐，一个共同特点就是即兴消费，满足“频发”“多选”“短决策”的特性。三者共同作用时，微信在消费者快速做出消费决策时的作用就尤为明显。每一次的推送，再辅助优惠券等福利刺激，都可能立刻转化为消费购买决策。 不仅是餐饮企业，所有具有即兴消费属性的企业，如出行行业、 快消行业、商超便利店等，都适合把微信服务号打造成超级 App。 讲几个实际案例。 肯德基：手机自助点餐 2016 年 3 月 7 日，肯德基与微信支付达成合作，在全国超过 4700 家门店同时上线微信支付，同时在全国30 多个城市超 过 2300 家餐厅开通手机自助点餐。以微信支付为起点，完成微信体内的闭环式营销，打造数字化用餐体验。 用户在肯德基的微信公众号上就能体验“手机自助点餐”的服务功能。这一功能不仅能让顾客不用排队点餐，甚至不用进店就能完成点餐、支付的系列环节。而门店一方只需按照订单准备好菜品，等待用户到店领取即可，大幅度缓解了高峰时段的客流压力。 FlowerPlus 花加：微信大流量带来的留存转化 FlowerPlus 花加（以下简称“花加”）的模式很简单，用 户通过微信下单，每月支付不到100 元就能收到一盒时令鲜花，收花地点选择在办公室或者家中。 就是这样一家关注都市白领日常鲜花消费市场、提出“日常鲜花”概念的公司，借助 微信的巨型流量优势，在短短的一年零4 个月的时间里，公众 号“粉丝”就完成了从0 到 129 万的增长，规模从起步到营收 3000 万元，迅速占领了鲜花 O2O 领域的第一梯队位置。 从传播的角度来说，鲜花消费处在一个受众需求大、消费频次高、自传播触发点广的优势基础上，微信正好为花加提供了传播优势。花加采用的模式是先付款、后发货的订阅模式，这解决了资金流转问题。 微信也为花加的用户留存起到了很大的帮助作用。企业可以通过公众号留下用户的信息和数据，分析客户需求，给不同客户进行用户画像，提供不同的产品和服务送达，从而实现比 自有官网或App 更高的留存率。 比如，花加会给新客户配送比较容易养的或者常见的鲜花，给老客户配送一些有养护难度的花，为孕妇配送鲜花时会避开对胎儿有影响的花种等。 据报道，花加目前的用户来源有 90% 以上都是微信用户的 口碑传播结果，10% 来自微信朋友圈的广告投放。 转载来源：36氪领读 | luckin coffee 侵占你朋友圈的秘密，裂变拉新]]></content>
      <categories>
        <category>传媒</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>市场营销</tag>
        <tag>移动互联网</tag>
        <tag>黑客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[F8大动作：PyTorch 1.0现身（Logo也换了），围棋AI开源]]></title>
    <url>%2F2018%2Fcb052d87%2F</url>
    <content type="text"><![CDATA[Caffe2和PyTorch合体事件有了清晰的发展方向，同样服务于深度学习开发者的ONNX也宣布支持更多的框架。 夏乙 若朴 发自 凹非寺量子位 出品 | 公众号 QbitAI F8开发者大会第二天，Facebook亮出了一系列AI大动作。 Caffe2和PyTorch合体事件有了清晰的发展方向，同样服务于深度学习开发者的ONNX也宣布支持更多的框架。 另外，Facebook开源了视频理解、自然语言处理的模型，开源了围棋AI ELF OpenGo，还展示了一个打星际的AI。 PyTorchv0.4.0正式版发布没几天，Facebook在F8开发者大会第二天宣布将发布PyTorch 1.0，还提前展示了这款新框架的特性。 这个框架，还换了LOGO： 深度学习框架Caffe2的作者贾扬清，在知乎上将这一版本的发布总结为Caffe2 + PyTorch = PyTorch 1.0。 也就是将原本两款框架面向研究的和面向生产的特性结合了起来。 Facebook介绍说，PyTorch 1.0结合了Caffe2和ONNX模块化、面向生产的特性，和PyTorch自身灵活、面向研究的特性结合起来，为广泛的AI项目提供了一个从科研原型到生产部署的快速、无缝途径，让用户可以快速实验，通过一个能在强制执行模式和声明执行模式之间无缝切花的混合前端优化性能。 除了将研究和生产特性结合起来，PyTorch 1.0还将ONNX（开放神经网络交换）包含进来。ONNX是Facebook去年联合多家软硬件公司发布的神经网络模型转换协议，现在，它新增了对苹果的Core ML、百度PaddlePaddle、高通SNPE的支持，再加上原本支持的MXNet、Caffe2、PyTorch、TensorFlow、CNTK等框架，实现了神经网络模型在各种主流框架之间的转换。 PyTorch 1.0 beta版将在今年夏天和用户见面。 不过，Facebook内部已经用上了。官方称，Facebook多款产品和服务都在大规模应用这个新框架，它每天要处理60亿次文本翻译任务。 PyTorch最初亮相于1年多以前，Facebook的另一款深度学习框架Caffe2，则在去年的F8大会上正式发布。 不过今年4月，Caffe2已经宣布全部代码并入PyTorch。接下来的几个月里，两款框架原本的组件将深度结合，成为一个单独的软件包。 就在上周，PyTorch发布了v0.4.0版本，将Tensors（张量）和Variables（变量）合并，新增了零维张量，还开始了对Windows系统的官方支持。 展示PyTorch 1.0的同时，Facebook还开源了一部分研究成果。比如用于视频理解的ResNext3D模型将于6月发布，视频行为识别模型Res 2+1今天就已经开源，PyTorch中的自然语言理解库Translate也将开源。 发布了这么多资源和工具，去哪找呢？Facebook还为旗下所有的AI资源推出了一个网站： https&#58;//facebook.ai/developers 围棋AI开源下载在F8大会上，还开源了一个围棋AI：ELF OpenGo。 这个AI是Facebook团队对DeepMind技术的一个重现，最近他们选择与四名排名世界前30的人类高手对战，取得了14-0的胜利。 和AlphaGo一样，这个AI的重点也并不只是下围棋，而是想要更好的解决问题。现在ELF OpenGo已经可以开源下载。 对此，田渊栋在知乎上有更详细的解答： 我们最近改进了ELF框架，并且在上面实现了DeepMind的AlphaGoZero及AlphaZero的算法。用两千块GPU训练约两到三周后得到的围棋AI，基本上超过了强职业的水平。我们和韩国棋院合作进行了一次测试，给这个AI单卡每步50秒搜索时间（每步搜索8万个局面），给人类棋手任意长时间思考，结果AI以14比0完胜。参与测试的棋手包括金志锡，申真谞，朴永训及崔哲瀚，在这里我们非常感谢他们的合作，大家都很尽力，一些棋局下了三四个小时极其精彩。应棋手们的要求，这14局棋谱中的12局不久将公开。另外我们也和现在著名的LeelaZero比较了下。我们采用了LeelaZero除ponder外的缺省配置（约一分钟一步），及4月25日的公开权重(192x15, 158603eb)，结果我们的AI以200比0获胜。在此我们非常感谢Leela团队的工作，对于他们的开源精神，我们表示由衷的敬意。这次我们将训练代码，测试代码及训练出来的模型（224x20）全部公开，首要目的是贯彻我们一直以来坚持的开源方针，让AI为全世界服务。其次是对于AlphaGoZero及AlphaZero这样非常优秀的算法，我们想要提供一个可重复的参考实现，让全球的研究者们能在这上面继续改进，充分发挥自己的创造力。最后是借此机会推广一下我们的ELF平台和PyTorch深度学习框架，希望更多的人能使用和完善它。感谢大家的支持！田渊栋，龚渠成&amp;马子嫯（Jerry Ma）, Shubho Sengupta, 陈卓远，Larry Zitnick ELF OpenGo代码及模型的地址： https&#58;//github.com/pytorch/ELF 其他在F8大会上，还展示了一个可以打《星际争霸》的AI，Facebook也计划随后开源这一项目。星际争霸和围棋一直也都是Facebook团队研究的方向。 还有一项突破研究。基于35亿张用户已打标签（17000个）的公开图像，Facebook成功训练了一个图像识别系统，这比之前只能用手动打标签的5000万张图片训练相比，提高了系统的识别能力，在ImageNet上获得了创纪录的高分（准确率85.4%）。 更多信息，可以参考这个页面： https&#58;//code.facebook.com/posts/1700437286678763/ 此外，F8大会上还展示了AR和VR方面的进步。 Facebook已经创建了一个原型系统，可以生成效果惊人的三围重建画面。下面这个链接最后的视频，展示了正常的视频与3D重建画面的比较，几乎难以分辨左右哪个画面为真。（友情提示：左边露出操作员脚部的是真实世界） https&#58;//mp.weixin.qq.com/s/iFe6y5rzM2EqV02aNVqZfA — 完 — 诚挚招聘 量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。 量子位 QbitAI · 头条号签约作者 վ’ᴗ’ ի 追踪AI技术和产品新动态 转载来源：F8大动作：PyTorch 1.0现身（Logo也换了），围棋AI开源]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>Facebook</tag>
        <tag>围棋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python调用百度接口，实现ocr识别]]></title>
    <url>%2F2018%2F50f14f9e%2F</url>
    <content type="text"><![CDATA[1.文本识别：2.身份证识别：3.银行卡识别：4.行驶证识别：5.营业执照识别： 1.文本识别： 2.身份证识别： 3.银行卡识别： 4.行驶证识别： 5.营业执照识别： 转载来源：Python调用百度接口，实现ocr识别]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Python</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小米申请在香港上市，将成2014年以来全球最大IPO]]></title>
    <url>%2F2018%2F4f09df33%2F</url>
    <content type="text"><![CDATA[5月3日，港交所官网显示，小米已正式提交IPO申请文件，小米有望成为港交所“同股不同权”第一股。 5月3日，港交所官网显示，小米已正式提交IPO申请文件，小米有望成为港交所“同股不同权”第一股，将成2014年以来全球最大IPO。 5月3日早间，小米向港交所递交招股书，2017年收入1146亿元，经营利润122.16亿元。2015年、2016年及2017年，小米集团分别产生亏损人民币76亿元、利润人民币4.916亿元及亏损人民币439亿元。 招股书中小米董事长雷军发布公开信。雷军称，小米不是单纯的硬件公司，而是创新驱动的互联网公司。小米的商业模式经历了考验，得到了充分验证。今天，小米走到了历史性的重要节点。面向未来，小米建立的全球化商业生态有著 极具想像力的远大前景。 以下为雷军公开信原文： 您好！感谢您对小米的关注和支持。当您打开这份文件时，看到的不仅仅是一家风华正茂、勃勃向上的公司，更是一份由勇气和信任所支撑的新商业蓝图。 在此，我想向您说明，小米是谁，小米为什麽而奋斗。 小米不是单纯的硬件公司，而是创新驱动的互联网公司 具体而言，小米是一家以手机、智能硬件和IoT平台为核心的互联网公司。我们的使命是，始终坚持做“感动人心、价格厚道”的好产品，让全球每个人都能享受科技带来的美 好生活。 8年来的每一天里，“和用户交朋友，做用户心中最酷的公司”的愿景都在驱动著我们努力创新，不断追求极致的产品和效率，成就了一个不断缔造成长奇蹟的小米。 2010年4月成立小米时，我和我的合伙人们只有一个简单的想法：做一款让我们自己 喜欢、觉得够酷的智能手机。我们8个联合创始人中，6人是工程师，另外2人是设计师，都是消费电子设备狂热的“发烧友”。 “感动人心、价格厚道”这八个字是一体两面、密不可分的整体，远超用户预期的极致产品，还能做到“价格厚道”，才能真正“感动人心”。创新科技和顶尖设计是小米基因中的追求，我们的工程师们醉心于探究前人从未尝试的技术与产品，在每一处细节都反覆雕琢，立志拿出的每一款产品都远超用户预期。我们相信打破陈规的勇气和精益求精的信念 才是我们能一直赢得用户欣赏、拥戴的关键。 不止于技术，我们推崇大胆创新的文化。从手机工艺、屏幕和芯片等技术的前沿探索，到数年赢得的200多项全球设计大奖；从“铁人三项”商业模式，到通过“生态链”公司集群；从“用户参与的互联网开发模式”，到小米线上线下一体的高效新零售创新精神，在小 米蓬勃发展并渗透到每个角落，推动我们不断加快探索的步伐。 目前，我们是全球第四大智能手机製造商，并且创造出众多智能硬件产品，其中多个品类销量第一。我们还建成了全球最大消费类IoT平台，连接超过1亿台智能设备。与此同时，我们还拥有1.9亿MIUI月活跃用户，并为他们提供一系列创新的互联网服务。 真正让我们更加自豪的并非是这些数字，而是中国智能手机和智能设备等一系列行业的面貌因为我们的出现而彻底改变。 我们推动了智能手机在中国的快速普及和品质提升，这为中国移动互联网的快速爆发打下坚实基础。移动支付、电商、社交网络、短视频等行业在中国的蓬勃发展都有赖于移动互联网涌入了数以亿计的庞大人口。中国这一全球最大市场中，移动互联网行业的跨越式发展、成熟的背后，我们也被公认作出了不少贡献。 优秀的公司赚的是利润，卓越的公司赢的是人心。更让我们自豪的是，我们是一家少见的拥有“粉丝文化”的高科技公司。被称为“米粉”的热情的用户不但遍及全球、数量巨 大，而且非常忠诚于我们的品牌、并积极参与我们产品的开发和改进。 浴火重生，小米商业模式被充分验证 作为一家年轻的互联网公司，小米的发展并非一路坦途。2016年，我们的市场占有率曾有过下滑。我们清醒地认识到早先几年过于迅猛的发展背后还有很多基础没有夯实， 因此我们主动减速、积极补课。2017年，小米顺利完成“创新+质量+交付”的三大补课任务， 迅速重回世界前列。 据我们了解，除了小米，还没有任何一家手机公司，销量下滑之后能够成功逆转。 浴火重生，小米经历了一家能够长期稳定发展的公司所必需的修炼。我们的管理更加有序，我们的人才储备更加充实，我们的技术积累更加深厚，我们的供应链能力和产能 管理能力更加强大。 更重要的是，我们的商业模式经历了考验，得到了充分验证。 小米不是单纯的硬件公司，而是创新驱动的互联网公司。尽管硬件是我们重要的用户入口，但我们并不期望它成为我们利润的主要来源。我们把设计精良、性能品质出众的产品紧贴硬件成本定价，通过自有或直供的高效线上线下新零售渠道直接交付到用户手中， 然后持续为用户提供丰富的互联网服务。 这就是我们独创的“铁人三项”商业模式：硬件+新零售+互联网服务。小米至今的成就说明了这一模式强大的生命力。创业仅7年时间，我们年收入就突破了千亿元人民币，这 一成长速度是许多传统公司无法企及的。 效率的提升来自于运营成本，尤其是交付产品给用户时的交易成本的极大降低。小米独特的商业模式使得商品既好又便宜得以实现，造就了用户信任的基础。 （文 | AI财经社 鲁智高） 转载来源：小米申请在香港上市，将成2014年以来全球最大IPO]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>IPO</tag>
        <tag>小米科技</tag>
        <tag>移动互联网</tag>
        <tag>智能手机</tag>
        <tag>智能硬件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Facebook两大深度学习框架正式合体，开源了击败14名高手的围棋AI]]></title>
    <url>%2F2018%2F46956228%2F</url>
    <content type="text"><![CDATA[Caffe2和PyTorch合体事件有了清晰的发展方向，同样服务于深度学习开发者的ONNX也宣布支持更多的框架。 夏乙 若朴 发自 凹非寺量子位 出品 | 公众号 QbitAI F8开发者大会第二天，Facebook亮出了一系列AI大动作。 Caffe2和PyTorch合体事件有了清晰的发展方向，同样服务于深度学习开发者的ONNX也宣布支持更多的框架。 另外，Facebook开源了视频理解、自然语言处理的模型，开源了围棋AI ELF OpenGo，还展示了一个打星际的AI。 PyTorchv0.4.0正式版发布没几天，Facebook在F8开发者大会第二天宣布将发布PyTorch 1.0，还提前展示了这款新框架的特性。 这个框架，还换了LOGO： 深度学习框架Caffe2的作者贾扬清，在知乎上将这一版本的发布总结为Caffe2 + PyTorch = PyTorch 1.0。 也就是将原本两款框架面向研究的和面向生产的特性结合了起来。 Facebook介绍说，PyTorch 1.0结合了Caffe2和ONNX模块化、面向生产的特性，和PyTorch自身灵活、面向研究的特性结合起来，为广泛的AI项目提供了一个从科研原型到生产部署的快速、无缝途径，让用户可以快速实验，通过一个能在强制执行模式和声明执行模式之间无缝切花的混合前端优化性能。 除了将研究和生产特性结合起来，PyTorch 1.0还将ONNX（开放神经网络交换）包含进来。ONNX是Facebook去年联合多家软硬件公司发布的神经网络模型转换协议，现在，它新增了对苹果的Core ML、百度PaddlePaddle、高通SNPE的支持，再加上原本支持的MXNet、Caffe2、PyTorch、TensorFlow、CNTK等框架，实现了神经网络模型在各种主流框架之间的转换。 PyTorch 1.0 beta版将在今年夏天和用户见面。 不过，Facebook内部已经用上了。官方称，Facebook多款产品和服务都在大规模应用这个新框架，它每天要处理60亿次文本翻译任务。 PyTorch最初亮相于1年多以前，Facebook的另一款深度学习框架Caffe2，则在去年的F8大会上正式发布。 不过今年4月，Caffe2已经宣布全部代码并入PyTorch。接下来的几个月里，两款框架原本的组件将深度结合，成为一个单独的软件包。 就在上周，PyTorch发布了v0.4.0版本，将Tensors（张量）和Variables（变量）合并，新增了零维张量，还开始了对Windows系统的官方支持。 展示PyTorch 1.0的同时，Facebook还开源了一部分研究成果。比如用于视频理解的ResNext3D模型将于6月发布，视频行为识别模型Res 2+1今天就已经开源，PyTorch中的自然语言理解库Translate也将开源。 发布了这么多资源和工具，去哪找呢？Facebook还为旗下所有的AI资源推出了一个网站： https&#58;//facebook.ai/developers 围棋AI开源下载在F8大会上，还开源了一个围棋AI：ELF OpenGo。 这个AI是Facebook团队对DeepMind技术的一个重现，最近他们选择与四名排名世界前30的人类高手对战，取得了14-0的胜利。 和AlphaGo一样，这个AI的重点也并不只是下围棋，而是想要更好的解决问题。现在ELF OpenGo已经可以开源下载。 对此，田渊栋在知乎上有更详细的解答： 我们最近改进了ELF框架，并且在上面实现了DeepMind的AlphaGoZero及AlphaZero的算法。用两千块GPU训练约两到三周后得到的围棋AI，基本上超过了强职业的水平。我们和韩国棋院合作进行了一次测试，给这个AI单卡每步50秒搜索时间（每步搜索8万个局面），给人类棋手任意长时间思考，结果AI以14比0完胜。参与测试的棋手包括金志锡，申真谞，朴永训及崔哲瀚，在这里我们非常感谢他们的合作，大家都很尽力，一些棋局下了三四个小时极其精彩。应棋手们的要求，这14局棋谱中的12局不久将公开。另外我们也和现在著名的LeelaZero比较了下。我们采用了LeelaZero除ponder外的缺省配置（约一分钟一步），及4月25日的公开权重(192x15, 158603eb)，结果我们的AI以200比0获胜。在此我们非常感谢Leela团队的工作，对于他们的开源精神，我们表示由衷的敬意。这次我们将训练代码，测试代码及训练出来的模型（224x20）全部公开，首要目的是贯彻我们一直以来坚持的开源方针，让AI为全世界服务。其次是对于AlphaGoZero及AlphaZero这样非常优秀的算法，我们想要提供一个可重复的参考实现，让全球的研究者们能在这上面继续改进，充分发挥自己的创造力。最后是借此机会推广一下我们的ELF平台和PyTorch深度学习框架，希望更多的人能使用和完善它。感谢大家的支持！田渊栋，龚渠成&amp;马子嫯（Jerry Ma）, Shubho Sengupta, 陈卓远，Larry Zitnick ELF OpenGo代码及模型的地址： https&#58;//github.com/pytorch/ELF 其他在F8大会上，还展示了一个可以打《星际争霸》的AI，Facebook也计划随后开源这一项目。星际争霸和围棋一直也都是Facebook团队研究的方向。 还有一项突破研究。基于35亿张用户已打标签（17000个）的公开图像，Facebook成功训练了一个图像识别系统，这比之前只能用手动打标签的5000万张图片训练相比，提高了系统的识别能力，在ImageNet上获得了创纪录的高分（准确率85.4%）。 更多信息，可以参考这个页面： https&#58;//code.facebook.com/posts/1700437286678763/ 此外，F8大会上还展示了AR和VR方面的进步。 Facebook已经创建了一个原型系统，可以生成效果惊人的三围重建画面。下面这个链接最后的视频，展示了正常的视频与3D重建画面的比较，几乎难以分辨左右哪个画面为真。（友情提示：左边露出操作员脚部的是真实世界） https&#58;//mp.weixin.qq.com/s/iFe6y5rzM2EqV02aNVqZfA — 完 — 诚挚招聘 量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。 量子位 QbitAI · 头条号签约作者 վ’ᴗ’ ի 追踪AI技术和产品新动态 转载来源：Facebook两大深度学习框架正式合体，开源了击败14名高手的围棋AI]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>Facebook</tag>
        <tag>围棋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[海通证券姜超评资管新规：货币超发的时代结束了]]></title>
    <url>%2F2018%2F78a6cd7d%2F</url>
    <content type="text"><![CDATA[海通证券姜超1日观点认为，资管新规的出台确认一个时代的结束，中国货币超发的时代正式结束。如果未来中国的货币不再超发，那么我们的财富创造模式将会发生巨大的变化。靠涨价赚钱将成为过去，靠买房发财的时代就要结束了。而未来只有创造实际增长才能创造财富，这意味着创新才能创造价值，与此同时货币低增将抑制通胀预期，那么债市也会充满机会。 以下为原文： 在上周，央行等四部委联合发布了《关于规范金融… 海通证券姜超1日观点认为，资管新规的出台确认一个时代的结束，中国货币超发的时代正式结束。如果未来中国的货币不再超发，那么我们的财富创造模式将会发生巨大的变化。靠涨价赚钱将成为过去，靠买房发财的时代就要结束了。而未来只有创造实际增长才能创造财富，这意味着创新才能创造价值，与此同时货币低增将抑制通胀预期，那么债市也会充满机会。 以下为原文： 在上周，央行等四部委联合发布了《关于规范金融机构资产管理业务的指导意见》，其中严格规定资产管理机构不得承诺保本保收益、打破刚性兑付；禁止资金池，消除多层嵌套，抑制通道业务，防范影子银行风险；同时按照“新老划断”原则设置过渡期至2020年底，确保平稳过渡。 在我们看来，资管新规的出台确认了一个时代的结束，中国货币超发的时代正式结束了！与此相应，我们的财富创造模式也将发生翻天覆地的变化。 过去发财靠涨价。过去两年，国内的财富创造来源是涨价。比如说大家曾经热捧的茅台，其实主要就是涨价的故事，2016年时53度飞天茅台的零售价只有800多元/瓶，而现在已经涨到了1500元/瓶。而周期行业在过去两年成功逆袭，也在于商品价格大幅上涨，以煤炭、粗钢为代表的商品价格几乎都翻了一倍。 而在过去十年，国内最为成功的财富模式无疑就是买房。从08年到现在，官方统计的全国商品新房的平均售价涨了一倍多，但这个价格其实不可比，因为新房越盖越远，比如10年以前上海卖的新房都在内环内，现在几乎都在外环。按照可比价格来测算，几乎所有一二线城市的房价涨幅都在3倍以上，折算成年化涨幅超过15%。 根本原因货币超发。但是大家有没有想过，凭什么买房可以赚这么多钱？要知道，房子还是那个房子，从房子本身来看其实还有折旧，一套房子放十年以后从质量来看跟以前肯定没法比，但是价格贵了好几倍，这说明房价上涨跟房子本身没有多大关系。 其实，最本质的原因是货币超发，钱不值钱了！在十年以前，中国的广义货币M2总量只有47万亿，而现在的货币总量已经达到了174万亿，货币总量就增加了近3倍，这也是过去10年全国房价实际涨幅平均达到3倍以上的主要原因。 而且，中国的货币统计其实还有遗漏，因为广义货币M2主要统计了银行的存款，也就是银行的表内负债。但是过去几年银行理财大发展，到目前为止的余额接近30万亿，而很大一部分银行理财不统计为银行存款，是以表外影子银行的形式来体现，这意味着包含影子银行以后的中国货币超发情况更严重。 但货币超发并非常态。但是大家有没有想过，其实在经济发展的过程当中，货币超发并非常态现象。发展中的经济体货币增速通常比较高，比如说印度的广义货币M2增速高达30%。但是对于发达经济体，比如美国、欧元区、日本当前的广义货币M2增速都只有3-4%，韩国高一点也就在6%。 而对于这些发达经济体，在历史上其货币增速其实也曾经高过，比如日本70年代货币增速平均是16%，韩国80年代货币增速平均是30%，美国70年代的M2平均增速也有10%，但是到目前为止发达经济体的货币增速几乎无一例外都降到了个位数增长。 为什么货币增速有高有低，如何理解货币增速的变化？ 美国货币史：货币增速先升后降。要理解货币增速的变化，我们可以研究一下美国的货币史，因为美国是全球经济的龙头，而且其拥有最长的经济历史数据，因此其货币增速的变化可以帮我们理解中国货币增速的未来。 金本位时代，货币长期低增。在美国19世纪的100年当中，货币平均增速只有4.5%，远低于20世纪平均7%的货币增速。为什么19世纪美国的货币增速那么低？其实原因非常简单，因为当时处于金本位时代，货币没法超发。 纸币时代，货币增速先升后降。在1933年，美国正式废除了金本位，从此进入了纸币时代。如果观察美国过去80年的货币增速，可以发现前50年货币增速上升，货币平均增速高达9%，但是后30年货币增速下降，货币平均增速仅为6%。 也就是从美国的历史数据来看，货币高增并非常态，其过去200多年的货币增速起初100多年长期在低位，之后50年货币增速上升，但是最近30年货币增速重新下降。 货币作用：从增长到通胀，再从通胀到增长。要理解美国货币增速的历史变化，我们需要思考的是货币的作用。 从宏观来看，货币是经济交换的媒介，因此货币增长主要是满足经济总量增长的需要。而无论是通胀，还是经济的实际增长，都会增加经济名义总量，同时带来对货币的新增需求。因此，货币的增长主要是满足通胀或者经济增长的需要。 金本位时代没有通胀，货币的作用是满足经济增长。在19世纪的100年当中，美国的通胀为零，这意味着100年内美国也没有通胀。19世纪美国GDP实际增速平均约为4.1%，与4.5%的货币增速大致相当，这意味着当时的货币增长主要是满足经济增长的需要。 纸币时代，货币超发导致通胀。但是进入20世纪以后，金本位的缺陷开始显现，因为黄金的产量是有限的，没法满足经济飞速发展的需要，所以主要国家相继都废除了金本位，美国也在1933年进入了纸币时代。 而美国的通胀也在1933年以后产生，其20世纪的平均通胀达到3%，远高于上一个世纪的0%。但从经济增长来看，其20世纪的GDP实际增速平均为3.3%，反而还低于19世纪的4.1%。 这意味着，在进入纸币时代以后，货币增速上升的主要作用只是推高了通胀，但是并没有带来更高的经济增长。20世纪美国的货币增速从4.5%上升到7%，只是把美国的通胀从0推升至3%，而实际经济增速反而还有下降。而这一现象在1970年代达到顶峰，这10年美国的货币增速高达10%，但是GDP实际增速仅为3.2%，而CPI高达7.8%。 在美国20世纪70年代，诞生了著名的货币主义，弗里德曼的名言是“一切通胀都是货币现象”，而这一认识最终改变了美国央行的行为。 央行抑制通胀，货币增速回落。1980年以后，美联储开始转向通胀目标制，把抑制通胀作为最核心的政策目标。1979年沃克尔成为美联储主席，而他持续提高利率紧缩货币也成为里根经济学的重要标志。从那以后30年，美国的通胀大幅回落至2.7%，与之相应美国的货币增速也降至了6%左右水平，但是这一过程当中美国GDP实际增速并没有大幅下降，而是稳定在3%左右。 货币超发，只对涨价有意义。美国的货币史，其实充分证明了一个结论：就是货币超发除了涨价，不创造任何价值。在金本位时代，货币没法超发，其实只是导致了长期通缩、没法涨价，但不影响经济增长。而在纸币时代，货币超发只是带来了通胀的上升，而抑制货币超发也只是降低了通胀，并不影响经济增速。 中国央行：抑制货币超发、货币低增新常态。而美国的历史经验其实也适用于中国。在过去10年，由于美国次贷危机的冲击，我们开始采用刺激需求的方式稳增长，其实本质是采用了货币超发的方式刺激增长。 从08年到17年，中国的GDP实际增速从10%降至了8%，但是这10年当中我们的广义货币增速依然维持在15%左右高位，而且考虑到影子银行的发展，这意味着这10年的实际货币增速还要更高，这期间就不时出现各种价格飞涨，尤其是房价持续上涨导致资产泡沫日益严重。 但是从美国的历史来看，央行的行为是会变的，因为央行会发现货币超发长期没有意义，所以最终会改变货币超发的行为。而在过去两年，中国央行的改变非常明显：首先是政府把打赢防范金融风险作为三大攻坚战的首要任务，与此相应我们建立了金融稳定委员会，实施了资管新规，全力推进金融去杠杆，压缩影子银行。其次是18年的政府工作目标，不再设定任何货币增速，而以往我们每年都有12%以上的货币增速目标。而央行在18年初明确提出，未来货币低增或是新常态。 货币低增时代，创新和债市为王。观察美国过去30年，在美联储下定决心抑制货币超发之后，我们可以发现，靠涨价其实几乎不赚钱。别看最近油价涨的欢，其实过去30年的油价也就涨了一倍。而美国的房价好像创出了历史新高，其实也就回到了08年的高点。也就是无论是商品、还是房子，其实就是涨涨跌跌，长期看每年平均涨幅都非常有限。真正在美国过去30年真正创造财富的是两类资产，一类是创新类资产，美国纳斯达克指数过去30年涨了30倍，另一类是固定收益类资产，因为在控制了货币增速之后，美国利率出现了持续的下降。 今年年初，我们明确提出看好两类资产，一类是创新类资产，另一类是债市为代表的稳定收益资产，到目前为止的表现都非常不错。其实这背后的原因非常简单，如果未来中国的货币不再超发，那么我们的财富创造模式将会发生巨大的变化。靠涨价赚钱将成为过去，靠买房发财的时代就要结束了。而未来只有创造实际增长才能创造财富，这意味着创新才能创造价值，与此同时货币低增将抑制通胀预期，那么债市也会充满机会。 转载来源：海通证券姜超评资管新规：货币超发的时代结束了]]></content>
  </entry>
  <entry>
    <title><![CDATA[专访数学家舒其望：若整天忙着填表评杰青，哪有时间做学问？]]></title>
    <url>%2F2018%2F0543fa4b%2F</url>
    <content type="text"><![CDATA[舒其望资料图“反正聪明人总是很多的，你提供一个好的环境，他们就会冒出来”。美国布朗大学应用数学教授舒其望曾是改革开放以来担任美国名校数学系主任的第一位大陆留学生。 舒其望 资料图 “反正聪明人总是很多的，你提供一个好的环境，他们就会冒出来。” 美国布朗大学应用数学教授舒其望曾是改革开放以来担任美国名校数学系主任的第一位大陆留学生，当澎湃新闻记者问起学科建设的经验，他轻松地回答道。 舒其望衡量一个好环境的最重要标准，就是能让科研工作者不分心。比起竞争数量限定的职位、统计琐碎繁冗的指标、评选层层压身的称号，他相信，同行评议护航下的终身教职制度，能让学者在专心学问的同时，自然而然获得与其水平相称的待遇。 这也许是舒其望今年欣然加入未来科学大奖科学委员会的原因之一。这个由大中华区民间资本设立的科学奖开出单项百万美元奖金，奖励那些由同行评议选出的大中华地区原创基础科学研究。 舒其望参与评选的奖项为“数学与计算机科学奖”，去年刚刚颁发出第一届，得主是时任北京国际数学研究中心教授许晨阳。 数学家向往的“世界顶尖”境界，或许离不开舒其望所说的不分心。 有些孩子就喜欢数学 舒其望现为美国布朗大学讲座教授、美国工业与应用数学学会会士及美国数学学会会士。常春藤盟校之一的布朗大学，是一所古老的顶级私立研究型学府。 他的研究领域包括用于求解双曲方程和对流占优偏微分方程的高精度WENO有限差分及有限体积方法、间断有限元方法和谱方法等。这些方法被广泛应用于计算流体力学、半导体元件模拟及计算宇宙学等领域。 简单来说，微分方程等数学模型可以通过计算机算法应用到上述领域。而舒其望所做的研究，就是用数学方法去检验、提高这些算法的可靠性、准确性和工作效率。 比如，如果对飞机形状做出一些特定的调整，飞机是否能飞得更加平稳呢？在传统上，航空工程师可以在风洞实验中测试气流阻力、噪音等。舒其望与工程师一起设计、分析算法，将风洞实验在计算机上模拟出来。这些数学模型，又往往与天体模拟、半导体元件模拟有相通之处。 现年61岁的舒其望祖籍安徽黟县，他在文革期间度过了中小学，所以也很难说得上有过任何当数学家的童年理想。在这条他个人形容为 “按部就班”的道路上，没有浓重的浪漫主义笔墨，只有数学沿途随意播下兴趣的种子，在多年后竟蔚然成林。 在“胡闹”的上学阶段凭兴趣多看了几本数理化方面的书籍、在恢复高考时报考了相对准备得比较好的数学，1978年，舒其望“按部就班”地进入了中国科学技术大学，开始接受系统性的数学教育。 在舒其望的回忆中，那时的中科大的师生都充满干劲，他在“尝到甜头”后越来越觉得，做数学研究是一件挺好玩的事情。 “但那时候是不是就一定认准了要当数学家呢？好像也不敢说这个话。”舒其望保持着轻松而低调的叙述语气。甚至当被问起后来赴美取得一些研究成果的成功经验时，他也只是笑着说道：“可能是我运气比较好，找老师很顺利，老师也很好，给我的题目也很好，找工作也顺利，可以说是一切都顺利。也许是因为数学比较容易吧，不用牵扯到做实验或其他很多技能。” 舒其望的同辈人在“胡闹”中凭着兴趣自学成长，舒其望下一代的许多孩子，却在奥数班中度过了无数周末。他希望，奥数能褪去高考加分等功利性因素，单纯作为课外活动存在：“有些孩子喜欢画画，有些孩子喜欢打篮球，而有些孩子就喜欢数学。” 分心的事多了，学问就做不好 在美国加州大学洛杉矶分校获博士学位后，1987年，舒其望开始在布朗大学任职。其中1999年至2005年间，他担任应用数学系系主任，为改革开放后中国留学生中第一人。 谈起学科建设，舒其望反复强调不能让科研工作者有太多分心的事情：“要让大家一心一意做自己想做的研究，不需要成天担心自己的教职保不保得住，或是去想是不是可以拿到‘杰青’之类的称号。” 相比国内通常为科研人员设置阶段性的考核指标，由此被一些行政程序和人事关系牵绊精力，他认为美国的终身教职制度能更好地提供专心的研究环境。 “一天到晚填表，说今年发了多少一区文章、二区文章，哪有时间干这种事？我最多花5%的时间在这些对科研毫无用处的事情上。”舒其望直言道。 “一个人的精力有限，分心的事多了，学问就做不好。”他简单直白的逻辑，令人想起苏轼“长恨此身非我有，何时忘却营营”的感慨。 舒其望看到一些中国高校也在尝试终身教职制度，但实际操作中设置了诸多行政性指标：“比如说今年能申两个（职位），五个人都够格申请。一定要从五个人里面评出两个人，这个做法就非常要命。这五个人又不是都做一个研究方向的，你怎么判断淘汰哪三个人呢？” 他担心的情况是，也许五个人都很优秀，却因为学术外的人为因素，无法都拿到职位。 相比起来，美国的终身教职制度始终着眼于考量个人素质是否足够优秀，“你申不上是因为你不太符合这个位置所要求的标准，而不是因为没有位置给你了。”舒其望概括了一下内在的逻辑差异。 终身教职这个科研铁饭碗，会不会存在诱使科研人员混日子的隐患呢？舒其望说道，根据他的个人见闻，这样的制度能保绝大多数的优秀人才在专心科研的同时拿到相应水平的职位，混日子的隐患是必然存在的代价。从现实情况看，这代价已经极小。 数学不需要跟着热点走 不过，即使在实施终身教职的大洋彼岸，足够 “分心”的理由也还有很多。如今舒其望门下有着很多中国学生，保持着用功而成绩优秀的传统，但比起老一辈留学生，他们的七巧玲珑心也许有了更多的疑问，比如，“我是不是应该去赚大钱？” 他门下的桃李绝大部分仍选择了继续做研究，去工业界的不到四分之一。但不可否认，金融和计算机产业的火热，足以令许多数学系学生心动侧目。 有意思的是，舒其望进入未来科学大奖科学委员会参与评选的 “数学与计算机科学奖”，其奖项名称本身就点出了，数学这门古老神圣的基础学科，和计算机科学这门炙手可热的产业新贵，已被紧密地联系在一起。 站在应用数学家的角度，舒其望对计算机科学眼下的人工智能热看得较为平淡。这并不是人工智能第一次掀起热潮：“上世纪60年代就搞过一次，最后发现计算机还没达到那个能力，走不通。现在数学上取得了一些革命性的突破，计算机当然也有很大的进步，两相结合，大家就看到了希望，又说这个东西可以做出来。有热点就会有炒作，现在的人工智能可能存在炒作的情况，到底能坚持多久我也不敢说。” 潮来潮去间，人工智能仍在等待数学世界里的斗转星移。“热点可能几年一换。只要你把数学基础做好了，不管什么来了都能用得上。所以我觉得，数学不是特别需要跟着热点走。”舒其望总结道。 转载来源：专访数学家舒其望：若整天忙着填表评杰青，哪有时间做学问？]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>布朗大学</tag>
        <tag>工程师</tag>
        <tag>UCLA</tag>
        <tag>高考</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谷歌发布迄今最大注释图像数据集，190万图像目标检测挑战赛启动]]></title>
    <url>%2F2018%2F90c473b2%2F</url>
    <content type="text"><![CDATA[包含190万张图片，共计600个类别，共标记了1540万个边界框，这是迄今的有对象位置注释的最大数据集。 新智元编译 来源：research.googleblog.com 编译：小潘 【新智元导读】今天，谷歌宣布开放Open Images V4数据集，包含190万张图片，共计600个类别，共标记了1540万个边界框，这是迄今的有对象位置注释的最大数据集。基于此数据集，谷歌将在ECCV 2018举办大型图像挑战赛。 2016年，谷歌推出一个包含900万张图片的联合发布数据库：Open Images，其中标注了成千上万个对象类别。从它发布以来，谷歌的工程师一直在努力更新和重新整理数据集，以为计算机视觉研究领域提供有用的资源来开发新的模型。 今天，谷歌宣布开放Open Images V4，其中包含190万张图片，共计600个类别，共标记了1540万个边界框。这个数据集成为现有的带有对象位置注释的最大数据集。这些边界框大部分是由专业的注释人员手工绘制的，以确保准确性和一致性。这些图像非常多样，通常包含有几个对象的复杂场景（平均每个图像包含8个边界框）。 谷歌发起大型开放图像挑战赛与此同时，谷歌还推出Open Image Challenge（开放图像挑战赛），这是一项新的目标检测挑战，将在2018年欧洲计算机视觉会议（ECCV 2018）上举行。Open Image Challenge遵循了PASCAL VOC、ImageNet和COCO的传统，但规模空前： 在170万张训练图片中，有1220万个有框注释，共500个类别。- 比以前的检测挑战更广泛，包括诸如“fedora”和“snowman”之类的新对象。- 除了对象检测这个任务之外，挑战还包括一个视觉关系检测跟踪人物，即在特定关系中检测对象的配对情况，例如“女人弹吉他”。比以前的检测挑战更广泛，包括诸如“fedora”和“snowman”之类的新对象。 训练集现在已经可以使用了。一组包含10万个图像的测试集将于2018年7月1日由Kaggle发布。提交结果的截止日期是2018年9月1日。我们希望这些大型的训练集能够激发对更精密的探测模型的研究，这些模型将超过目前最先进的性能，并且500个类别将能够更精确地评估不同的探测器在哪里表现得最好。此外，有大量的图像和许多对象的注释使我们能够探索视觉关系检测，这是一个正在发展的分支领域的热门话题。 除此之外，Open Images V4还包含3010万的人工验证的图像级标签，共计19794个类别，这并不是挑战的一部分。该数据集包括550万个图像级标签，由来自世界各地的成千上万的用户在crowdsource.google.com上生成。 Open Images V4数据集Open Images是一个由900万张图片组成的数据集，这些图像被标注为图像级标签和对象边界框。V4的训练集包含了600对象类的1460万个图像，其中共标记了174万个标记目标，这使得它成为现有的最大包含对象位置注释的数据集。这些物体的边界框大部分是由专业的注释器手工绘制的，以确保准确性和一致性。这些图像非常多样，通常包含有多个对象的复杂场景（平均每个图像有8.4个标记）。此外，数据集还带有数千个类的图像级标签。 数据组织结构 数据集被分割为一个训练集（9,011,219图像），一个验证集（41620个图像）和一个测试集（125,436张图片）。这些图像被标注了图像级标签和边界框，如下所述。 表1 表1显示了数据集的所有子集中的图像级标签的概述。所有的图像都有机器生成的图像级标签，这些标签是由类似于Google Cloud Vision API的计算机视觉模型自动生成的。这些自动生成的标签有一个很大的假正率。 此外，验证和测试集，以及部分训练集都包含经过人工验证的图像级标签。大多数验证都是由Google内部的注释者完成的。更小的部分是通过图片标签软件来完成的，如Crowdsource app, g.co/imagelabeler。这个验证过程实际上消除了假阳性（但不是传统意义上的假阴性，这种方式会导致一些标签可能在图像中丢失）。由此产生的标签在很大程度上是正确的，我们建议使用这些标签来训练计算机视觉模型。使用多个计算机视觉模型来生成样本，这样做是保证在训练时不仅仅用机器生成的标签数据，这就是为什么词汇表被显著扩展的原因，如表一所示。 总的来说，有19995个不同的类和图像级标签。请注意，这个数字略高于上表中人工验证的标签的数量。原因是在机器生成的数据集中有少量的标签并没有出现在人工验证的集合中。可训练的类是那些在V4训练集中至少有100个正例的人工验证类。基于这个定义，7186个类被认为是可训练的。 边界框 表2 表2显示了数据集的所有分割中边界框注释的概述，它包含了600个对象类。这些服务提供的范围比ILSVRC和COCO探测挑战的范围更广，包括诸如“fedora”和“snowman”之类的新对象。 对于训练集，我们在174 万的图像中标注了方框，用于可用的阳性人工标记的图像级标签。我们关注最具体的标签。例如，如果一个图像包含汽车、豪华轿车、螺丝刀，我们为豪华轿车和螺丝刀提供带注释的标注方框。对于图像中的每一个标签，我们详尽地注释了图像中的对象类的每个实例。数据集共包含1460万个的边界框。平均每个图像有8.4个标记对象。 对于验证和测试集，针对所有可用的正图像级标签，我们提供了所有对象实例详尽的边界框注释。所有的边界框都是手工绘制的。我们有意地尝试在语义层次结构中尽可能详尽地标注注释框。平均来说，在验证和测试集中，每个图像标记了5个边界框。 在所有的子集中，包括训练集、验证集和测试集中，注释器还为每个边界框标记了一组属性，例如指出该对象是否被遮挡。 类定义（Class definitions） 类别由MIDs（机器生成的id）标识，可以在Freebase或Google知识图的API中找到。每个类的简短描述都可以在类中CSV中找到。 统计和数据分析 600个可标记类的层次结构 Open Images数据集&amp;挑战赛地址： https&#58;//storage.googleapis.com/openimages/web/index.html 【加入社群】 新智元 AI 技术 + 产业社群招募中，欢迎对 AI 技术 + 产业落地感兴趣的同学，加小助手微信号&#58; aiera2015_1 入群；通过审核后我们将邀请进群，加入社群后务必修改群备注（姓名 - 公司 - 职位；专业群审核较严，敬请谅解）。 转载来源：谷歌发布迄今最大注释图像数据集，190万图像目标检测挑战赛启动]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>Kaggle</tag>
        <tag>Fedora</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[36氪领读 | 零售进化，适者生存]]></title>
    <url>%2F2018%2F248337fc%2F</url>
    <content type="text"><![CDATA[36氪专门为读书设立了栏目，筛选一些值得读的书，并提供一些书摘。内容简介马云说：“纯电商的时代很快就会结束，未来的十年、二十年将没有电子商务，取而代之的是‘新零售’。 36氪专门为读书设立了【36氪领读】栏目，筛选一些值得读的书，并提供一些书摘。希望你手边有一本称心的书，让读书这场运动继续下去。 内容简介马云说：“纯电商的时代很快就会结束，未来的十年、二十年将没有电子商务，取而代之的是‘新零售’。线上线下和物流、大数据结合在一起，才是真正的新零售！” 亚马逊说：“Amazon Go的无须排队、无须结账、无须售货、无收银员才是未来新零售门店该有的样子……” VMC说：“新零售=传统零售业务+新技术+新金融，VMC Anywhere新零售系统是最适合商品流通行业的新零售！” 新零售到底是什么，未来的零售业又是何种形态？我们能否实现人货场重构、消费场景无处不在？大数据、智能化能得到怎样的运用，AR/VR又能带来怎样的虚实消费体验？ 新零售绝不是简单的线上线下融合相通，在零售营销的技术变革中，顾客洞察－身份识别、位置识别、个性化服务，构成了关键驱动要素。 作者简介上海六韬三略咨询机构创始人，上海九逸科技有限公司CEO，曾任联想零售执行委员会专家委员，常年从事零售研究与实践。从2013年起相继出版了《中国为什么没有优衣库》《零售4.0时代，互联网＋零售》等书籍。同时，他及他的团队也为诸多企业提供系统的咨询服务，在新零售带来了无限可能的机遇下，帮助传统企业重新回到同一起跑线上，赋予他们更多的思维和创新能力，谋求以通过商品、服务、渠道、商业模式等方面的创新来重构零售竞争力。 书籍摘录第一章 新零售的号角吹响——新零售时代已经到来 零售是一座桥梁，它搭建的基础是消费者与零售商；零售是一个通道，零售商通过它向消费者传递美好的生活；零售还是一个愿景，在这里将构建一个理想中的生活蓝图。零售自诞生之日起，就与消费者的生活密不可分，只要有消费者的需求，零售就会永远存在。 历史的车轮不断滚滚向前，周边的人与事都发生了诸多变化，城市更加现代，生活更加便捷，通信更加方便，购物方式也更加多元。不知不觉中，零售随着历史的演进渐渐旧貌换新颜。 零售的改变是被历史进程裹挟着前行的，这里有自觉也有不自觉，但每次改变，不管大与小、强与弱，都是为了让生活更美好。消费者乐在其中，他们发现，零售与自己生活的融合度越来越高，零售变得无可替代。 零售是一种表达方式，是一种生活方式，抑或是一种基本法则？ 零售是一个常见词，提到它，几乎每个人都知道，但却少有人深究零售的真实含义是什么。 在给出正式答案之前，我们还是先按照大众的理解来分析一下零售的意义。 零售是零售商把商品与服务卖给消费者，消费者愿意为此买单。零售需要有一个地方出售商品，不管是在一个看得见的地方还是在看不见的网络上，它都需要一个依托，来进行展示和销售。零售的含金量就是把商品与服务卖给那些认同它价值的人。 零售是简单的，也是复杂的交易。简单在于了解它不需要太深奥的道理，直白地说，就是赚取差价。这有点像买股票，低价入，高价出。低价购进的商品，通过零售商的努力，提升其内在价值，再流转到消费者手中。以出售服务为内容的零售商看似是零成本的，但其隐含的成本其实很多，也很复杂。 零售的复杂在于，这么一件看似简单的事情，做得久的人却并不多。世界上最大的零售商之一沃尔玛仅有50余年的历史，而亚马逊、阿里这些后起之秀的历史更是短暂。阿里要做102年的企业，时间将证明一切。 零售是供应链条的最后一个环节，零售商与消费者的距离最近，零售与生活密切相关。 零售物种大爆发 新零售的概念一经提出，与其有关的话题就从未停止过。在争论的同时，更多的零售商投入实践之中。当下的零售业出现了前所未有的活跃状态，几乎每天都能听到新的资讯，也能看到新的零售实践形式，许多零售商试图用实践的结果来回答什么是新零售。新零售还未有一定之规，有的只是对创新的探求。 在线上与线下加速融合的当下，从概念的探讨回归到实践的创新，新零售不是停留于文字表面的静止，而是不断前行、不断添加新内容的实践。 所以，对新零售的认知终归要回归到实践之中。 “忽如一夜春风来，千树万树梨花开”，层出不穷的新的零售形式让人应接不暇。这些零售形式有从线上到线下的落地，也有横空出世的创造，还有线下的探索。每种零售形式都被赋予了不同的理解与卖点，让同行眼前一亮，让消费者相见恨晚。 但这些新的零售形式的内容不管怎样变化，其核心都是为了效率的提升、成本的降低、与消费者更好的互动与体验。这些对新的零售探索像开足马力的马达，轰隆隆地向前驶去。 家乐福关注于“邻家业态”，在上海开出29家“Easy家乐福”后，在无锡开出第30家实体店。家乐福的这个新业态，更贴近于社区，SKU（库存量单位）在4000左右，而面积在300~400平方米，给消费者提供了比便利店更为宽敞的空间。在新业态的探索上，家乐福把找到可持续盈利模式作为关键点，这是业态生存的基础。 大润发也在探索，近期在上海开出飞牛优鲜的第一家实体店，这是依托原有卖场基础进行的改造，后期实体店会独立运营。飞牛优鲜首先借助了大润发的现有资源，线上与线下联动，实现在配送范围之内，1小时送到客户手中。在这个比速度的时代，消费者的耐心被一点点消磨，只有更快，才有可能争夺到机会。 永辉一改传统的形象定位，频频试水新的业态形式，这样的尝试，无疑是在抢夺不同层次的消费者。BRAVOYH是永辉精致超市品牌，主要以经营高端产品和时尚用品为主，这一定位与民生超市永辉已经有了天壤之别。除此之外，永辉还开出了“超级物种”。店如其名，在“超级物种”店内，一个个小物种，如健康有机生活馆、生活厨坊、花坊、鲑鱼工坊、波龙工坊、盒牛工坊、麦子工坊、外卖工坊、择物工坊等组合成了一个大物种。 商圈不同，“超级物种”里的小物种组合方式也略有差异。值得一提的是，与其他零售商过分依赖外来力量助力发展不同，“超级物种”全部是永辉的知识产权，这保证了一定时间内永辉在这个业态形式上拥有更多的自主权。与BRAVOYH相同的是，“超级物种”聚焦的也是高端客群。这两种新兴业态显然与原来的永辉卖场有了很大区别。 老牌零售商也在摸索新的业态形式，可谓老树开出新花。百联集团于近期开出了RISO首店，这家实体店同样无法用传统的零售视角来解读，百联集团把它定义为新零售发现店，是集生鲜、餐饮、书店为一体的新的融合模式，这种前所未有的组合方式，不光给零售业带来了想象空间，还让消费者体验到了各种看似的不可能的情景。 在店内，顾客不用专门到收银台排队结账，只要找到戴着特殊标识的员工就可以实现现场收银，免去了排队的烦恼。顾客用App下单，在配送范围内1个小时就可送达。 各大零售商的业态探索有相同之处，也有不同之处。相同之处是，所有零售商都顾及了消费者的跨渠道体验，将线上与线下融为一体，实现了线上下单、线下快速配送。线上与线下的连接成为一项必备技能，如果缺失，根本无法与消费者达成共识；所有零售商都不约而同地强调了配送的及时性，承诺在配送范围内可以快速到达。 3公里商圈客户，成为线上与线下争夺的重点。这些大品牌零售商开出的小业态都把商圈压缩到触手可及的范围。商圈的缩小，让目标消费者更为集中，同时还能把零售商的运营效率发挥到极致。 不同之处在于，每个零售商的新业态都极具想象力，这考验的是零售商的智慧，他们都在尽量地避免与竞争伙伴重合。这些新推出的实体店业态，每家零售商都有独家秘籍，这表明他们不甘心与他人雷同，残酷的竞争也不允许他们与别人雷同。 业态探索最终探索的是效率与成本，缓行的零售商可能因为一时的迟疑而错过最佳的发展机会。在发展的紧要关头，机会的错失将无法弥补。柯达在由胶卷成像到数码相机的转变进程中，因为迟疑而把最好的机会拱手让人，从而走向了破产的命运；诺基亚自1996年开始，连续14年保持了手机行业的市场份额第一，但面对智能手机崛起，诺基亚未做出及时的转变，终被苹果和三星超越，最后不得不把手机业务卖给微软，从此退出手机市场。 行业的转变带来机会的同时，也暗潮涌动。与风浪同行的人可能会获得机会，但远离风浪的人最终交出的必然是竞争资格，如果资格都失去了，还谈什么竞争？现实如此残酷，这也让各大零售商不敢停下脚步，就算付出资金成本和时间成本，也要坚持探索；就算是一个试错过程，也要不惜代价，坚持前行。 零售第一阶段：有什么买什么 大多数人，对1.0时代的印象极为模糊。翻开历史，那时零售没有形成体系与规模，都是单打独斗，零售形式单一，售卖方式传统古老，单品还不像现在这样极大丰富。零售商大多依附于体制而生存。因为没有竞争，消费者的需求未被充分挖掘出来，紧俏的商品让消费者趋之若鹜。 在1.0时代，零售仅是买与卖的代名词。较为正规的零售商用三尺柜台隔开消费者与营业人员，双方有距离地交流，营业人员不冷不热，消费者也没有太大热情，完成简单的交易后，零售商的使命基本结束。 许多人的记忆中还残存着一些印象：在物资匮乏的年代一物难求，大家都想尽办法买一台电视机，谁家要是有了电视，那就成了邻居们眼中的红人。商品短缺让零售成为毋庸置疑的卖方市场，消费者的需求根本得不到满足。 但随着经济的发展，零售市场斗转星移，消费者很快又要回了主动权。 零售第二阶段：连锁扩张 渐渐地，零售商开始以新姿态示人，最令人印象深刻的是柜台的消失。撤掉柜台，消费者可以自由进出品牌区、超市，不再受遮挡物的干扰。营业人员也变得热情，他们不再对消费者不冷不热、冷眼相对，而是想尽办法“讨好”消费者，消费者由被动变为主动；商品不再供不应求，而是供大于求。于是，零售步入另一个轨道，买方市场来临。 在收集零售2.0时代的资料时，我发现了一个有趣的巧合，那就是“95、96、97元年”现象。在这三年里，中国大地上成立了大量的零售实体，有国资发起的，也有个人创立的，还有国外零售品牌的涌入，现在耳熟能详的零售品牌大多是在那时成立或进入中国市场的。步步高成立于1995年，永辉的前身也成立于1995年，胖东来同样是在这一年开出了前身：望月楼胖子店，家乐福在1995年进入中国市场。 1996年，同样诞生了许多零售商，人人乐和银座都是在1996年开出了第一家实体店，在这一年，沃尔玛和麦德龙进入中国市场。1997年仍很精彩，大润发和银泰分别在上海和北京成立。翻看这些集团的历史就会发现，他们在成立后，并没有满足于现状，都在两三年内迅速开设了分店，由同城到异地，他们凭借最初积累的经验与人气，跑马圈地，渐渐扩大疆域。在他们的引领下，零售市场迎来了2.0时代。 从此，零售商不再单枪匹马，而是树立了集团化战略策略，零售发展呈现连锁化的态势。零售商凭借自身的资源优势，迅速掌握了渠道的话语权。渠道为王，生产商除了传统渠道之外并没有另外的渠道可以销售，必须完全仰仗于零售渠道的分销。这真是传统零售商的“黄金时代”。但是好景不长，剧情很快就发生了逆转，传统零售商不再是“唯一”。 零售第三阶段：电商发展 电商的兴起，让零售市场不再是传统零售商的一枝独秀。电脑的普及、互联网的发展，为电商成立打下了物质基础。同样是巧合，目前电商的两大巨头都在同一个年份涉足电子商务领域，淘宝于2003年上线，同一年京东商城因为“非典”的影响由线下转向线上发展。两大电商的上线，初时并没有引起过多的关注，也未引起实体零售商的警惕。但是其影响力很快就显现出来，渐渐地，线上开始抢占线下的市场，双方虽未呈势均力敌之势，但电商的威力已不能让人小觑。 因为上网需要借助电脑等固定设备，这为购买带来一定障碍，PC时代的网购还没有现在那么疯狂。传统零售商在电商的PC时代并未做出回击之势，只是像对待普通的新事物那样，不屑、好奇，还有些无动于衷。 渐渐地，消费者的购物范围开始扩大，消费者也在线上与线下不停地来回转换；传统生产商的销售渠道也不再单一，而是有了更多的选择。传统零售商此时发现，他们的独有优势正在消失。 随着售卖渠道的增多，消费者开始疯狂地比价。他们潜在的价格敏感度被挖掘出来，谁的价格更低，他们就更愿意到哪个渠道购物。电商凭借价格的优势建立了稳定的客流，更为意义深远的是，他们培养了消费者的购物习惯，消费者对网络购物越来越信任和依赖，这为未来的竞争积累了更多资本。 此时传统零售商依然浑然不觉，大多数零售商还沉浸在“黄金时代”的自鸣得意里，未把消费者购物习惯潜移默化的转变太当回事，从而错过了研究消费者习惯转变的最佳时期。 零售第四阶段：开放与包容、多元与个性并存 这一阶段，线上线下突然变得泾渭分明，线上零售的发展让人不敢小觑，而线下的市场份额一步步被蚕食。线上的发展如果非要用一个标志性事件来总结的话，可以把阿里巴巴的“双11”当成一面旗帜，这面旗帜是电商发展的一个缩影。从2009年初创到2016年，“双11”走过了8个年头，而这8年是电商崛起的一个重要时段。2009年天猫“双11”的销售额仅为5200万元，2017年就达到了1682亿元，几何级数的增长速度让人惊叹不已。 在这些数据中，我们发现了一个有趣的现象。2012年“双11”销售额达到了191亿元，首次突破百亿。查看历年“双11”数据同比值，可以发现2012年是同比销售增长最多的年份，达到了468%；而2012年还有一个数据也不容忽视，那就是移动支付的兴起。移动支付数量达到了900万笔，占到总销售额的6%，与2011年同比增长426%。销售增长与移动支付增长，两个比值竟如此相近，说明消费者正在从PC端悄悄地向手机等移动设备端转移。 过了2012年，移动支付势如破竹，一发不可收拾，到了2016年，无线端支付占到了“双11”全天销售额的近82%。如果说2012年是移动支付迁移的开始，那么到了2016年，就基本完成了转移。消费者从PC端一下跃到了无线端。 这是一次质的飞跃，消费者已然不是昨天的消费者。这看似是使用工具的转移，但背后却是消费者购物习惯、选购方式、需求满足方式的变化。这些变化，让消费者不再具有传统零售模式下的消费习性。他们更善于使用工具，也更善于通过不同渠道满足自己的购买欲望。 消费者成为真正意义上的中心。风云突变，传统零售商仿佛是一夜之间才感知到“春光如此灿烂”，但大多传统零售商根本无暇欣赏这春光如画的美景，因为他们才想起前期忘记种树了。春天没有花赏，秋天没有果吃，那如何“过冬”呢？ 互联网时代的来临，消费的主动权又交还给了消费者，电商在拼命地争取流量，传统零售商正在找回客流，消费者成为各方争夺的焦点。有了流量和客流，就不怕没有销量，这是各方达成的共识。 这个阶段是一个开放和包容的时代，零售商不再拘泥于线上或线下，线上与线下正在快速融合；也不再拘泥于某种形式，大到购物中心，小到一个人的微店，零售的舞台更加多元，也更加精彩。 以上简单梳理了零售的发展进程，这一路走来，每个人都参与其中。不管是商家还是一名普通的消费者，在回顾时才发现自己竟走了这么远的路，一路上的变化是如此之大。而正在经历变化的零售商和消费者竟浑然不觉，真是“只缘身在此山中”。 从近乎原始的第一阶段，到开放包容、个性多元的第四阶段，再到今天提出“新零售”的概念，这是一部零售行业的进化简史。在新零售时代，我们拥有了新的机遇点，同样也会面临新的挑战。 新零售时代：新时代的好零售 评判零售商有两个重要的指标，这两项指标也是上市公司年报上常见的。零售商在日常管理中，也把这两项指标作为重要的参数，公司的经营业绩通过这两项指标就能一下子跃然纸上，而且直观、一目了然，它们就是销售额与利润。但数据仅是结果的表现，只代表前一阶段或当前的状态，并不能全面反映零售商的发展状况。曾有一家上市公司的年报数据显示在上一财年不管是利润还是销售额，公司都取得了令人满意的成绩。但时隔一年，数据就出现了断崖式下降。数字不能代表一切，但也能代表一切。 为什么这么说？ 说数字不能代表一切，是因为尽管上一财务年度的数据还很亮眼，但零售商的内在核心其实早就发生了变化。不过是因为有经营的惯性，数据其实是在缓慢走低的，所以掩盖了深层次的问题。说数字代表一切，是因为核心失去后，直接的体现就是数据严重下跌。 一家好的零售商不仅要做到满足消费者的愿望，提升消费者体验，同时还要建立稳固的专业化市场，保证业绩持续稳定的增长。零售商需要建立长期的市场计划和明确的战略目标，而不能用杀鸡取卵的方式只顾眼前的苟且。得过且过的零售商肯定无法实现长期的盈利。 好的零售商不能患上“数字近视症”，一味强调和追求数据的漂亮，并对数字过分重视与夸大，而不去建立和耕耘长效机制，不主动深入研究数字背后隐藏的问题与原因。长此以往，必定忧患重重。比如有些零售商的员工经常在一个专业论坛里曝光内部管理问题和发泄心中的不满，但因为数据指标表现还算不错，并未引起外界的重视。而当数据不能再掩盖问题的时候，员工的声音又被无限放大。其实问题不是刚刚出现或发生的，“千里之堤，毁于蚁穴”，大厦的倒塌其实早就有了前兆，只是未引起管理层的重视而已。 好的零售商要时刻记得研究顾客的需求与体验，这是零售商立足的根本，在任何时候做任何决定，都不能忘了站在顾客的角度做出思考与选择。马化腾在接受《哈佛商业评论》专访时说，用户需求和用户体验是腾讯研究的重中之重，用户需求与喜好瞬息万变，腾讯每天都在研究。腾讯最早的一个产品是QQ，许多人都有10年以上的“Q龄”，一路相伴走来，会发现QQ也在随时发生着变化，QQ的许多功能与时俱进，与潮流接轨。如果不去改进与变化，QQ可能早就进了历史博物馆。 好的零售就如同慢火煮汤，火势不激进，细工慢火才能打磨出食材深层的味道，并历久弥新，久久让人难忘。 经营深处的拷问，变与不变 突出重围，找到立足地，占领行业或区域行业的制高点，这是许多零售商的梦想。然而现实的残酷与竞争的激烈，却把梦想击得粉碎。 拨开云雾见明月。云雾重重，究竟用什么力量可以把云雾拔开，见到那轮最美的明月？看看零售的发展史，一路走来，做得好的零售商其实是有共性的，不管时代如何演进，消费者怎样变化，表现好的零售商都与这两个字有关。 变 一个主动求变的零售商保持了进取的姿态，不管在思维方式上还是经营策略上都愿意与消费者的需求相磨合。主动求变意味着要或小或大地改变过去的自己，甚至否定自己，这个过程相当痛苦与难熬，像凤凰涅槃，再造一个自己。无印良品当年遇到业绩滑坡时，时任社长松井忠三走访了许多实体店，与员工们座谈，专注于问题的解决。 他还理顺了岗位职责，建立了工作标准手册，并处理了大量滞销商品库存。新制度的建立、与旧有观念的博弈、不良库存的清理与利润损失的阵痛，都让求变之路步履艰难。求变的过程不轻松，但求变后旧貌换新颜，无印良品走上了快速发展之路。如果没有当时的变，就没有今天的无印良品。 主动寻求变化意味着要走出舒适区，时刻挑战自己。不管是线上还是线下，不管是龙头还是草芥，敢于挑战的零售商不是在变化就是在变化的路上。这厢阿里的支付宝刚刚推了VR红包，那厢微信就推出了小程序，让消费者应接不暇。虽然变化无处不在，但也要看到，有的变化长久地生存了下来，有的变化如滑过天际的流星，一闪而过。 变化的根本是洞察顾客的变化，满足顾客的需求，这是所有变化的宗旨。 顺 此处的“顺”可理解为“顺势而为”。零售的发展如一条绵延悠长的水路，消费者和时代的发展、竞争环境的变化是河流里的水，零售商是船，逆水行舟，不进则退。只有顺势而行，才能与消费者、时代、外部环境融合起来，才能有取胜的机会。 零售商如果想做到顺水行舟，首先要顺应消费者的需求，不管是零售商暗合消费者的需求，还是引领他们的需求，消费者的需求始终是零售商前行的方向与目标。只有与消费者的需求合拍，消费者才愿意买单。 还要顺应技术的发展。凯文·凯利说，“技术是世间至强之功”。技术是零售商的内在功夫，拥有先进的技术犹如学会了世界上最高强的武功，靠它行走江湖，就多了份自信。对传统零售商来说，习惯了买货—卖货的简单操作模式和思维模式，在各项新技术不断推出的今天，许多实体零售商显得笨拙和不知所措，显然他们还没有做好学习新技术和应用新技术的准备。 马云提出了“五新”的概念，把新技术也列为重要一项。互联网企业对新技术的热衷有其天然的基因，而实体企业稍显迟钝，在新技术面前要拿出十分的热情热烈拥抱，才能与时代同步。 近期亚马逊实体店Amazon Go利用AI技术真正实现了无人结账。顾客在店里选购商品后可以直接拿回家，他的亚马逊账户随后会收到账单，消费者只要在网上支付即可。亚马逊利用计算机视觉和机器学习技术真正解决了顾客购物后需要等待结账的难题。这种体验在过去几乎闻所未闻，没想到现在梦想很快就变成了现实。 与竞争环境变化相协调，是零售商顺应时代发展的重要体现。零售是一个包容的行业，任何有作为、有想法的企业，都可以在这里大展拳脚。但竞争环境的瞬息万变，又让人不敢有半点松懈。在激烈的竞争中创造优势、突出优势、保持优势，这是与竞争协调发展的必由之路，而竞争是推动进步的发动机。 “顺势而为”还包含另外一层意思，那就是零售商的自我调整。一位有着多年零售经验的前辈曾感叹，每一年的发展变化太快，今年与去年就是天壤之别，去年可能还在犹豫是否引进第三方支付，而今年第三方支付就成了必备之物。零售商要时刻警觉外界的变化，还要警醒自身的不足，这样才能争取更大的机会。 转载来源：36氪领读 | 零售进化，适者生存]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>电子商务</tag>
        <tag>家乐福</tag>
        <tag>亚马逊公司</tag>
        <tag>大润发</tag>
        <tag>沃尔玛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[美债破3%！中国经济会走剌激房地产老路吗?]]></title>
    <url>%2F2018%2F7fc9456b%2F</url>
    <content type="text"><![CDATA[近日，美国10年期国债收益率涨破了3%，这是自2014年1月以来的首次。受此影响，美国三大股指随后暴跌。标普跌1.37%，纳斯达克跌1.7%，道指跌1.74%；欧洲和亚太股市开盘后，也悉数下跌。而多位华尔街大佬则为此发出警告，如果国债数据超过3%，美股八年大牛市势必会终结。 可能有人会问，美债收益率走高、美元指数升值、全球资本回流美国，就算能够终结美国大牛市，那跟我们中国经济有啥关系呢？… 近日，美国10年期国债收益率涨破了3%，这是自2014年1月以来的首次。受此影响，美国三大股指随后暴跌。标普跌1.37%，纳斯达克跌1.7%，道指跌1.74%；欧洲和亚太股市开盘后，也悉数下跌。而多位华尔街大佬则为此发出警告，如果国债数据超过3%，美股八年大牛市势必会终结。 可能有人会问，美债收益率走高、美元指数升值、全球资本回流美国，就算能够终结美国大牛市，那跟我们中国经济有啥关系呢？对此，我们认为，美国10年期国债收益率突破3%，主要是对中国经济影响还是很大的。 一方面，美债利率走高，意味着中美两国利差会进一步收窄。目前中国10年期收益率为3.6%，利差已从高峰时的150个BP，缩减为现在的60BP，而中美两国长期利差的缩小，会导致国内外资金回流美国本土，这会给人民币汇率造成较大贬值压力。 另一方面，美国社会的通胀率正在逐步上升。由于减税剌激（增加投资）+基建投资+油价飙升，都会推升美国的通胀水平。而因通胀水平上升，导致美联储加快加息和缩表步伐。受此影响，全球资金会加快流向美国的进程，而以人民币计价的资产泡沫就会首当其冲。 就在国内外资金流出已成趋势，人民币蒙受对外贬值压力。同时，中美贸易摩擦持续不断，国内经济转型面临压力，中国经济将往何处去？就值得我们去思考了。 如果中国货币在当下时点选择宽松，这就会导致中国国国债的收益率曲线下移，那么中美两国的利差会进一步被压缩，人民币汇率将遭受空前的贬值压力。 但是如果跟着美国一起收紧货币，人民币汇率稳定住了，而货币收紧之后会导致国内的中小企业生存环境，生存环境更趋恶化。同时，由于中国跟着美国加息之后，房地产将负担不起如此高的利率水平，进而有了方向性下跌的选择。从而引发一系列的系统性金融危机。 从目前情况看，中美贸易摩擦已经对中国经济造成了负面影响，而对这种负面的影响过程，如果再搞货币紧缩肯定是雪上加霜。但如果推出宽松政策，恐怕也不符合当前的“降杠杆，控风险”的目标。所以，未来中国不可能再搞货币剌激政策，更可能的是偏向于中性，就是对于实体经济偏向于宽松，而对于房地产、股市等虚拟经济更倾向性的紧缩。 现在外有美国等西方贸易保护主义的抬头，未来依赖出口来拉动GDP增加更加困难，所以这次中央政治局会议提出了二点重要指示：一是扩大内需。二是要推动信贷、股市、债市、汇市、楼市健康发展，及时跟进监督，守住金融底线，并且消除潜在隐患。 那么，中国该如何扩大内需呢？内需主要包括投资和消费。而投资却又分为制造业、基建与房地产三块。现在情况是，房地产市场是最容易启动的，但加杠杆的空间有限，居民部门的杠杆水平已经非常高，GDP占比已经达到50%！居民债务率从20%到50%，美国花了40年的时间，中国只用了10年。 剩下的还有制造业和基建投资。制造业投资也受到房地产的挤压，而唯有基建投资才勉强的能做点贡献。也就是说在投资方面，只要房地产投资一直过热下去，制造业投资肯定是无法担当助力经济增长大任，只有基建投资尚有可能，只是要中央政府要允许地方政府暂时再扩大一下债务规模，但这也并非长久之计。 讲完了投资之外，还有就是消费，我国居民的消费恐怕也根本拉动不起来，原因是很多购房者把每月收入的大部分都交给了房企和银行，甚至把未来几十年的收入都透支掉了。随着国内房价越来越高，居民消费增加幅度也会大幅放缓。所以，如果要想让民间消费拉动经济，就必须把房地产泡沫给去除掉。 在当前复杂的国际经济和贸易环境之下，中国只能选择扩内需，但是要想把内需真正扩大起来，基础建设投资是托底，而民间投资和消费才是唱主角，但是房地产业对民间投资和消费起到了挤出效应。所以，只有把房地产去掉泡沫，中国经济才能更加平稳、安全的发展。 平说财经 （ID&#58; BZZCAIJING )原创时评 转载来源：美债破3%！中国经济会走剌激房地产老路吗?]]></content>
  </entry>
  <entry>
    <title><![CDATA[小程序风口已至，国家队投资微盟是为名、为利还是为民？]]></title>
    <url>%2F2018%2F3b98a697%2F</url>
    <content type="text"><![CDATA[第一条，是4月20日，“allin小程序”的第三方Saas服务商微盟，完成了高达10.09亿元的D1轮融资。 这两天被小程序刷屏了，而且都是爆炸式的消息。 第一条，是4月20日，“all in 小程序”的第三方Saas服务商微盟，完成了高达10.09亿元的D1轮融资，据说D2轮融资也即将完成，而且金额不低于1.5亿美元。 第二条，在昨天的“小程序&amp;大商业”商业峰会上，明星投资人朱啸虎又放出了炸弹，他认为“小程序流量红利就是今年一年，如果没抓住，那么机会与你无关。” 与这两件大事同样刺激观众眼球的，是小程序在流量萧条时代的逆天数据： 推出一年，1.7亿日活用户、58万个小程序上线、100万个开发者、2300个第三发开放平台，连接微信生态的10亿用户和200多个类目的商家。 如此庞大的商业势能，难怪国家队基金也坐不住了，赶快集体投个第三方服务商微盟“压压惊”。不过互联网行业从来不缺钱，与其说是看中了微信生态庞大的商业跑道，其象征意义其实更值得深思。今天我们就来八一八。 【国家队入局，为利or为名or为民？】 我们不妨先来细数一下微盟10.09亿D1轮融资背后，都有哪些商业大佬： 公开资料显示，微盟10.09亿D1轮融资由上海自贸区基金、国和投资、一村资本、天堂硅谷领投，腾讯双百、东方富海、渤海产业基金、辰韬资本、优势资本等跟投。 其中领投方上海自贸区股权投资基金、国和投资都是国家队级的基金。上海自贸区股权投资基金的身份更有些特殊：它是全国首支自贸区主题投资基金，主要服务于自贸试验区重点产业及‘四新’产业的发展，以及上海全球科创中心建设。 那么，国家队基金对微盟的青眼有加，到底是为名还是为利，亦或是为民？我认为三者兼而有之。 首先，本质上还是金融机构，冲着“国家队”的金字招牌也要做好一个价值投资者。去年就有至少7亿资金押注小程序，今年更是在资本市场所向披靡。据说有投资人放言“没有小程序的电商平台我已经不看了”。小程序如此火爆，其上下游产业链自然也开始蓬勃发展。现象级社交电商拼多多融资30亿美元，朱啸虎6000万投资小程序数据统计平台阿拉丁，第三方Saas服务商微盟受青睐就不足为奇了。 值得注意的是，国家队还是微盟D1轮融资的主力军，这已经不是单纯地看好微盟背后微信生态的大跑道，而是押注微盟在垂直领域的绝对优势。2018年Q1财报显示，微盟2017年全年毛收入近11亿，并且收入、付费客户数、净利润等关键数据都远超于同业者，是货真价实的垂直领域超级入口，未来投资回报不会低。 可以肯定的是，微盟被国家队翻了牌子，这是一次国家战略与市场经济相得益彰的融合，不仅会得到经济和政策上的支持，更有助于其发挥第三方服务商的连接和赋能作用，让微信生态的庞大经济价值惠及各个零售企业和10亿消费者。 【all in 小程序之前，企业首先要解决三大难题】 QuestMobile的报告显示，从2017年1月至2018年3月，微信小程序的月活规模超过4亿，在上个月，小程序日活用户达1.4亿左右，渗透率达43.9%，还有很大的上升空间。 相信已经没有人会质疑，小程序的春天真的来了。 但商家在此时“all in”小程序，恐怕要闯过至少三道关：第一，尽管小程序拥有超过50个流量入口（微信群、朋友圈、公众号、搜索、社交广告、二维码等等），但流量依然集中，精准推广是第一道门槛； 第二道门槛则是场景落地。小程序在内容、社交、门店、工具等多个场景都可以广泛应用，但不同场景下的交易流程和交互体验需求不同。比如零售、餐饮、美业、休闲娱乐等不同行业对应的小程序产品逻辑肯定也各不一样，如何开发出符合自身业务逻辑的小程序就成为当务之急。 第三则是流量转化难。小程序需要下载，又不能像公众号那样主动推送，因此尽管与用户的连接半径最短，但留存成本更大，试错成本高昂，据说新客转化率只有 1%。提升转化率成为攫取红利的第三大门槛。 将业务模式迁移到小程序上，成了所有零售业者头上的达摩克利斯之剑。怎么破？ 最大的关键在于管道。在微信生态中，微信提供的是基础能力。而第三方服务通过互联网技术，为企业提供连接新流量和数据服务的支撑，正是促进微信生态走向繁荣的重要管道。 如果说管道，“all in 小程序”的第三方服务商微盟应该最有优势。去年发布的“新云计划”，微盟小程序矩阵集中亮相，落点在小程序，但眼里盯着的其实是整个企业级服务。SaaS服务体系覆盖了电商、门店、餐厅、外卖、会务、官网、美业、休闲娱乐等多个场景，提供智能化解决方案。 显然，微盟要做的是重度的大连接，以CRM系统为入口，卡位整个智能服务生态。从美国的SalesForce到中国的EC等，CRM都是SaaS最成功的品类。Salesforce市值预计在未来三年将达到1000亿美元。所以，微盟只要执行到位，可以迸发出惊人的商业潜力。 【小程序+公众号+社交广告：微盟跑赢行业的“金三角”】 公平的说，目前企业级Saas服务商各占山头，但许多人更看好微盟。一方面是其先发优势和规模效应所带来的行业护城河极深，另一方面则通过“小程序+公众号+社交广告”所构成的流量“金三角”，为企业级Saas服务在电商在营销上提供一体化解决方案，建立了差异化竞争优势。 一对一的小程序，一对多的公众号、多对多的社交网络（朋友圈），这些都是社交电商的天然渠道。三浪叠加的流量组合，让商家离消费者的距离无限拉近。 社交广告实现流量引入，解决获客难题；公众号助力用户沉淀，解决留存难题；小程序提供服务，帮助提升转化。而最新上线的“分销”功能，是升级，也是裂变，依托微信的社交属性实现裂变传播，激活微信生态的10亿流量，贯穿到“拉新-促活-转化-交易-忠诚”这一社交电商完整链路的始终。 “金三角”的流量闭环和背后巨大的业务推力，正是微盟能够吸引众多电商、零售等合作伙伴的核心原因。 当然，要用好流量“金三角”，前提是要有精准画像。微盟基于微信庞大的社交行为数据和自身平台的消费行为数据，为商家提供更为精准的目标群体画像和丰富的触达通道，助力商家实现更加有效的精准营销。 在挖掘微信生态溢出价值这件事上，微盟下的是苦功夫，更是真干。因为这是他的根本，当然不遗余力。所以，这波小程序流量红利的蛋糕，最先吃到的自然还是微盟。 【结束语】 企业级 SaaS 市场是一个 U 型曲线，前期需要耗费巨大的成本研发产品、培育用户，然后才能迎来增长。 小程序的流量红利释放也才刚刚开始，国家队基金强势参战，领头羊微盟持续赋能并教育市场，也会进一步推动微信生态的繁荣。 相信，小程序会在今后一两年进入大爆发期，企业级Saas也会获得应有的荣光，属于微盟们的舞台很大，加油！ 王冠雄，著名观察家，中国十大自媒体（见各大权威榜单）。主持和参与4次IPO，传统企业“互联网+”转型教练。每日一篇深度文章，发布于微信、微博、搜索引擎，各大门户、科技博客等近30个主流平台，覆盖400万中国核心商业、科技人群。为金融时报、福布斯等世界级媒体撰稿人，观点被媒体广泛转载引用，影响力极大，详情可百度。 转载来源：小程序风口已至，国家队投资微盟是为名、为利还是为民？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>电子商务</tag>
        <tag>风投</tag>
        <tag>基金</tag>
        <tag>移动互联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“五环外”的拼多多，如何打破圈层壁？]]></title>
    <url>%2F2018%2Fff642dc7%2F</url>
    <content type="text"><![CDATA[连日活 10 亿的微信打破圈层壁都难，拼多多怎么做到的？ 转载来源：“五环外”的拼多多，如何打破圈层壁？]]></content>
      <tags>
        <tag>i黑马</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与产品：抖音、快手的“气质”成因]]></title>
    <url>%2F2018%2F03a04b30%2F</url>
    <content type="text"><![CDATA[同一类型的两款产品，从功能上看，似乎没有明显差别，但为什么给人的“感觉”却是完全不同呢？ 算法快抖的视频内容分为推荐（发现）、附近（同城）和关注三个模块，这里主要说明推荐模块的算法机制。 视频与用户画像的匹配程度1. 热度（赞、评论、转发等）1. 发布时间根据用户数据和内容标签计算两者的匹配程度，是每个内容产品的算法核心，已经被总结很多次了，其理论大体一致，在本社区搜索“算法”关键词就能找到，这里就不再赘述了，下面主要介绍热度和发布时间两点。 打开你的抖音，你会看到系统已经为你推荐好了一系列内容，再仔细观察一下，你会发现这些视频的获赞数量基本都在50万以上，中位数大概在100万（刷多了会减少）。 而打开快手呢？ 你会发现视频获赞数量基本维持在1万到10万这个区间，有的甚至会出现几千几百，但很难找到过10万的视频。 出现这种差距，难道是因为快手用户少吗？ 显然不是，快手的用户已经是其他短视频产品的用户之和了。之所以出现这种状况，其实是因为快手算法特有的“热度权重“。 视频发布初期，随着其热度提高，曝光机会也会跟着提高，此时，“热度权重”起到“择优去劣”的作用。而在视频热度达到一定阈值后，它的曝光机会将不断降低，此时，“热度权重”起到“择新去旧”的作用（其实是为了给用户平等的展示机会，后面会讲到）。 与此同时，快抖对于“发布时间”的看法也是不一样的。 在抖音，你会发现很多视频其实几个月前就发布了（验证这一点，只需要在评论区不断下翻即可，可根据早期评论的发布时间进行推断）。因为用户一般不会在乎短视频是不是最新的，只要足够精彩即可。 而在快手，大部分视频都是近期发布的，再远的视频也是一个月内（在视频界面右下方有时间标注）。 那么，前面提到的“热度权重”和“发布时间权重”对于用户来讲又会有怎样的影响呢？ 首先，短视频的用户大体分两种：一种是“看视频”的看官，一种是“拍视频”的制作方。这里，我们把看官的注意力比作一个蛋糕，而制作方比作分蛋糕的人。 首先，我们来看分蛋糕的人。在抖音，分到大量蛋糕的用户还会继续加快分蛋糕的速度（高热度会不断提高曝光机会），头部用户集中了大量的用户注意力资源，这种中心化会让普通制作者、草根制作者难以被关注（这与微博颇为类似）。 而在快手，头部用户分到的蛋糕被设了上限（高热度和旧视频曝光机会会大大降低），因此会有更多的人分到蛋糕，这也体现了快手的理念——希望所有用户都能展示自我，任何一位普通用户都有被关注的权利。 对于看官来说，抖音给了他们大量的优质资源，这些都是经过大量用户检验，而放到推荐模块的内容池的视频。而快手只是经过初步检验就根据用户喜好开始推荐了，所以会有很多小众和“乡土”的内容。 抖音和快手，一个是精致的台上表演，一个是平凡的街边才艺。 相对来说，抖音是看官导向的，而快手则更偏向于制作方，尤其是草根用户。这也就不难理解为什么快手会沦落到被整改的尴尬境地，因为“三俗”生产者总能找到自己的市场。 产品除了算法，我认为以下两点也是快抖气质差异的诱因。 录制功能1. 交互设计 1. 先音乐后录制的妙处与其他短视频不同，抖音的录制功能别具一格，先选音乐再根据音乐录视频，而不只是充当背景音乐。 每当视频的动感与音频的调子相重合时，会大大刺激观众的感官，带来不一样的体验。同时，也产生了更多玩法，比如：对口型、拍同款等，增加了趣味性、可看性。因此，抖音会给人一种“酷炫”的感觉（但是拍摄门槛也抬高了）。 2. 不断上滑的“沉浸式体验”一打开抖音，便进入了播放界面，接着依靠上下滑动来更换视频，嗯 … 这种状态可以维持一个多小时 … 这种懒人式交互大大提升了用户粘性，不过也削弱了用户改变“状态”的意愿，即附近模块、关注模块的使用几率将会降低。由此，用户的注意力又被“粘”在了头部用户的优质内容上，中心化进一步加剧。 与之相反的，快手的推荐（发现）对用户并没有那么大的粘性，三个模块的交互方式相当，都是瀑布流布局，并且快手的启动页是用户上一次退出的页面。 比如：上一次在同城离开，下一次启动页会是同城模块，关注模块也是如此，这样，用户选择的自由度“无形”地增加了。同时，快手也因其同城和关注的高使用频率，而在社交属性上更胜一筹，而不仅仅是一个娱乐软件。 其实快抖的算法与交互设计是相辅相成的，抖音的算法决定了它的视频更加优质，因此不需要用户做太多的选择，适合逐个播放，也减少了用户操作负担和选择负担。而快手视频的优质密度没有那么大，需要用户选择播放，在操作上会繁琐一些。 回忆一下我们使用抖音的时候，是不是一般会看完整个视频再播放下一个，很少掠过。而使用快手的时候，我们通常要掠过几个，才能选出自己想看的视频。 因此，“滚动播放”更适合抖音，而瀑布流适用于快手（其实快手也可以尝试美拍的“瀑布流+滚动播放相关视频”的交互设计，或者抖音附近模块的“瀑布流+滚动播放下一个视频”的交互设计）。 结尾除了算法和产品设计，还有着其他因素导致快抖的风格差异，比如：运营和品牌公关。 不过从效果上看，算法和产品设计更像是产品的“基因”，从最开始就影响着“两个宝宝”的未来走向（抖音的精致范和快手的平民化）。 如何设计出我们想要的产品，让“宝宝”长成我们想要的样子，抖音和快手的实例值得我们借鉴。 本文由 @ 信管专业学生 原创发布于人人都是产品经理。未经许可，禁止转载 题图来自网络 转载来源：算法与产品：抖音、快手的“气质”成因]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>软件</tag>
        <tag>蛋糕</tag>
        <tag>甜品</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消费机器人今年爆发！四大品类瓜分百亿蛋糕]]></title>
    <url>%2F2018%2F9d7ed269%2F</url>
    <content type="text"><![CDATA[特别是视听觉语义理解、自然语言处理、神经网络、情感识别算法等的发展，使得扫地机器人、智能音箱等消费级机器人产品逐渐走入消费者视野。 近两年，人工智能技术的迅猛发展。特别是视听觉语义理解、自然语言处理、神经网络、情感识别算法等的发展，使得扫地机器人、智能音箱等消费级机器人产品逐渐走入消费者视野。根据捷孚凯（GfK）最新报告，中国消费级机器人2018年零售规模将超100亿元。 本期的智能内参，我们推荐来自捷孚凯的中国消费级机器人分析报告，就扫地机器人、智能音箱、民用机器人和智能服务机器人的零售数据出发，盘点市场的消费偏好以及各类产品作为智能家居入口的潜力。如果想收藏本文的报告全文（捷孚凯：中国消费级机器人分析报告），可以在智东西头条号回复关键词“**nc248**”下载。 以下为智能内参整理呈现的干货： 机器人市场都在卖什么 ▲中国机器人市场规模（2015-2020年） 机器人市场主要分为工业机器人、商用服务机器人，以及消费级机器人。 其中，工业机器人主要用于制造业， 包括离散制造和流程制造，在政策和资本的支持下正蓬勃发展，预计市场规模在2020年将达到1110亿美元（IDC数据）。 而商用服务机器人，覆盖医疗、零售批发、公共事业和交通领域等领域，面临着巨大的发展机遇和市场空间，已经处于爆发的临界点。 ▲中国消费级机器人零售规模（2018年将超100亿元） 消费级机器人方面，前两年的产品功能和价格上，与用户的期望还有一定的差距，导致厂商变现困难。但随着智能化技术的发展，产品与需求逐渐匹配，加上多家科技巨头的入局，市场大门正在打开。 目前，市场上消费级服务机器人的主要应用场景包括幼儿教育、助老助残、智能家居、数字娱乐、情感陪护等。在现有的技术成熟度和市场接受度下，扫地机器人、智能音箱、民用无人机、智能服务机器人这四大品类成为主流产品。 ▲消费级机器人的四大主流品类 扫地机器人即帮助消费者从繁琐的家庭劳务中解脱出来，负责清扫、吸尘、拖地的智能化清洁类产品，因需求明确、任务单一，因此发展较为成熟。 智能音箱则是2017年的爆款产品，可以通过语音交互控制智能家居和其他智能设备，并且实现内容搜索、上网购物等第三方服务，成为智能家居的新入口。 民用无人机目前主要用途以航拍摄影为主，兼顾一些商业用途，如电力巡检、环境监测、快递送货等。目前，国内普通民众对无人机的认可程度和需求度逐渐攀升。 智能服务机器人搭载了语音交互、远程视频、本地服务、家居控制等功能，以早教和娱乐为卖点，从而快速地打入消费级市场。 细分市场详析随着人工智能的发展，以及居民可支配收入增加，消费级机器人市场潜力巨大，青年群体（15-49岁的消费人群）的热衷程度与兴奋态度，直接带动了智能音箱、智能服务机器人、无人机、扫地机器人等新物种的跨越式进步。 扫地机器人：智能家居入门级产品 ▲中国扫地机器人市场规模 随着科技的进步和社会发展，特别是受生活节奏加快和工作压力增大的影响，消费者希望从繁琐的家庭日常清洁事务中解脱出来。扫地机器人在这样的背景下应运而生，并且正以惊人的速度普及。 捷孚凯数据显示：扫地机器人零售量五年复合增速高达51%，2017年零售额同比增长率23%；至2017年，扫地机器人零售额已达44.1亿元（零售量332.5万台），预计2018年市场规模将达53.8亿元（435万台）。 ▲中国扫地机器人以线上市场为主 从销售渠道来看，扫地机器人自进入中国市场以来，主要以在线销售为主要销售渠道。2017年，扫地机器人在线零售量占比91%，且零售额中在线市场的占比也达到89%。 在线市场最大的优势就是可以带来巨大的流量，且契合了主要受众（青年群体）的消费习惯，但是通过在线市场了解产品信息和体验产品功能还是具有局限性。捷孚凯指出，在线市场与线下市场融合，是今后整个扫地机器人厂商在渠道布局的重点策略。 ▲扫地机器人带来全智能清扫模式 扫地机器人在不断改善清洁效果的同时，其智能化也在不断发展，包括机器人与智能手机的智能连接和自主导航定位，后者可以实现定位-构图-规划-清扫一站式的智能清扫方案。 智能连接方面，2017年，具有智能连接功能的扫地机器人零售额占比已达50.4%，而这一数字在两年前仅有11.4%；自主导航定位方面，随着越来越多高性价比导航技术的发展与应用，导航系统扫地机器人的零售额占比从2016年的3.3%显著增长到2017年的16.6%。 智能音箱：AI赋能 ▲借助语音交互技术的优势，智能音箱有望成为智能家居入口 2017年，随着苹果等科技巨头加入战局，智能音箱市场规模达到了质的飞跃。 智能音箱具备天然语音属性，指向更为自然的人机交互模式，能够整合多类第三方服务，因此也更容易成为智能家居的入口。 亚马逊市场化的成功尝试，让很多大佬从长远的角度看到了智能音箱作为智慧生活入口的可能性，也让很多内容方看到了语音交互作为服务整合平台的机会。 捷孚凯数据显示：2017年中国智能音箱市场零售量达到165万台，零售额3.1亿元；考虑到百度、阿里、小米这三位玩家在3月分别发布了自家的战略产品，预计2018年销量将持续增长达到588万台（11.8亿元）。 ▲中国智能音箱零售市场 销售渠道方面， 依托规模爆发的智能体验店，智能硬件产业突破了缺乏线下渠道体验的瓶颈，垂直链路全面打通，用户触达、认知、体验机会几何级增长，拉动用户需求，智能音箱行业迎来新机遇。 ▲智能音箱撞上新零售 捷孚凯分析指出，智能音箱从玩具变成真正的智能家居入口，到形成强大的用户群体，势必会经过3个阶段的发展：完善基本功能→集成服务丰富度→建立家居控制体系。除了3个阶段各自的比拼因素之外，在发展过程中都需要渠道，用户基数及资金三大因素加持。 ▲智能音箱发展的三大阶段 我国智能音箱目前还处在第二阶段的初期，产品的体验还有较大的提升空间，且由于我国目前智能家居的环境尚不成熟，进入到第三阶段的比拼还需要几年的时间。 目前，语音交互体验的提升是目前智能音箱领域亟需解决的问题，用户基数是实现该体验优化的核心。 民用无人机：落点户外娱乐 ▲中国消费级民用无人机零售市场始终保持高速增长 随着无人机技术逐渐成熟，制造成本和进入门槛降低（移动终端的兴起，芯片、传感器、电池等硬件产业链成熟），消费级无人机市场已经爆发。 前瞻产业研究院分析指出，2022年我国军用和民用无人机将达22.8亿美元，十年（2013-2022年）需求总额将超过134亿美元，复合增长15.57%。 根据捷孚凯零售追踪数据，2018年无人机的需求量虽持续增长，但涨幅较之前将有所下降，预测2018年全国消费级无人机零售市场同比增长21%，规模将达到34亿人民币。 ▲无人机线上售价趋势 与其他智能硬件相同的是，民用无人机的主要销售渠道为线上。通过价格亲民的入门型号，无人机厂商降低消费门槛，推动消费者普及。 从产品类别来看，民用无人机目前主要用途还是以航拍摄影为主，消费者对于产品的科技感，包括防碰撞性能、4K、VR等，以及便携性的要求逐年上升。起飞重量已经从2016年初的1282克降至2017年末的821克。 除了航拍，诸如电力巡检（预计2020年电力巡检无人机市场规模在不放量的情况下约为58.45亿元）、环境监测（2017年秋冬以来，至少有四川、陕西、安徽等6省都使用了无人机这一“武器”协助监测大气情况）、快递送货（京东、苏宁、顺丰等众多企业纷纷加入无人机送快递的行列）等应用也是民用无人机市场的增长点。 ▲科技感与便携性推动无人机产品升级迭代 智能服务机器人 智能服务机器人搭载语音交互、远程视频、本地服务、家居控制等功能，以教育陪伴、养老助老、生活娱乐和安防为卖点，目前正处在发展期，代表性产品包括软银的Pepper，优必选的Cruzr等。 ▲服务机器人市场前景 根据IFR的数据，服务机器人正处在一个快速上升的应用阶段，到2020年有望达到1322万台的销售量，整个规模可能达到200多个亿。捷孚凯预测，2018年，我国生活陪伴机器人市场规模将超5.2亿元。 ▲智能服务机器人的四大应用场景 2015年的服务机器人风口期，有一大批公司涌入这一行业，他们的产品大同小异。然而经历了两年的发展，服务机器人在落地应用上始终找不到大规模领域，交互仍需迭代改进，成本和售价过高等问题亟待解决。可以说，目前服务机器人领域的当务之急就是寻找落地应用或走定制化路线。 对此，捷孚凯从智能家居的角度指出了一种可行性：基于AI，智能服务机器人有望完成智能化家居控制（门窗管理、照明管理、门禁联动、节能管理等）、家电控制（电视、音响、电饭煲、空调、热水器等控制）和安防保护（防盗监控、防煤气泄漏、紧急报警等），从而成为智能家居的控制终端之一。 智东西认为，青年群体，特别是数字土著（15-19岁消费者）对于新型家庭电子产品热衷的态度为机器人的早期发展提供了良好的消费市场环境，随着这两年来相关技术，特别是人工智能（模式识别、语音交互等）技术的发展，消费级机器人不再局限于数字土著市场：扫地机器人真正的开始解放家务，智能音箱整合了丰富的第三方服务，无人机成为户外娱乐利器，家庭机器人也逐步落点早教和娱乐… 转载来源：消费机器人今年爆发！四大品类瓜分百亿蛋糕]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>机器人</tag>
        <tag>扫地机器人</tag>
        <tag>音箱</tag>
        <tag>智能家居</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从实体去产能到金融去产能：拿走酒杯的人回来了]]></title>
    <url>%2F2018%2Fab4485e9%2F</url>
    <content type="text"><![CDATA[从实体去产能到金融去产能：拿走酒杯的人回来了文／朱振鑫如是金融研究院首席研究员、执行总裁前美联储主席马丁曾说过，金融监管者的职责就是“在盛宴渐入佳境时拿走酒杯”。 从实体去产能到金融去产能：**拿走酒杯的人回来了** （宏观研究猿讲故事第6集） 文／朱振鑫 如是金融研究院首席研究员、执行总裁 前美联储主席马丁曾说过，金融监管者的职责就是“在盛宴渐入佳境时拿走酒杯”。中国的这场金融盛宴嗨了太多年，监管者早已错过了最佳的介入时机，不过庆幸的是，在中国发生金融危机之前，敢于“拿走酒杯的人”终于回来了。这次他们要做的不是拿走酒杯那么简单，因为很多客人已经酩酊大醉，甚至不省人事，他们要做的是拖走那些喝醉的人 如果说2015-2016年是供给侧改革的第一阶段，重点是实体去产能。那么2017年后供给侧改革已进入第二阶段，重点是金融去产能。实体去产能的后果是农民工和企业家受损，产业向龙头企业集中，金融去产能的后果是金融民工和所谓的金融大鳄受损，资本、资源、资金向头部机构集中。 过去十几年，金融跑的太快，实体被彻底甩在身后。从存量看，金融资产规模年均增长15%以上，远远超过同期GDP增速，2009年四万亿时期金融资产增速曾一度达到24.1%。2016年我国金融资产规模约为553万亿元左右，占GDP比率大幅攀升到740%。从增量看，中国金融业增加值占GDP的比重从2005年开始逐年上升，截至2016年已经达到8.4%，不仅远远超出韩国（2.3%）、德国（4.1%）等发展中国家，甚至超过了美国（7.2%）、日本（4.4%）等传统的金融强国。 金融繁荣的后果是泡沫横生。借着泡沫的东风，金融产能快速膨胀。从从业人数来看，金融业队伍不断扩大，2012年-2016年仅仅五年的时间就增加了132万人，达到640万人，金融从业人数占全部就业人数的比例也由0.69%提升到0.82%。从金融机构数量来看，2011到2016年间我国金融机构从3691家增长至10171家。尤其是2014年新一轮宽松以来，金融机构平均每年增长2500家，增速接近50%，其中非银行金融机构增长尤为迅猛。从资产规模来看，我国五大类金融机构的总资产规模在从2010到2016年平均每年增长24万亿元，年均增速高达24%。 2015年是一个拐点，繁荣的金融大厦出现了第一道裂痕：股灾。金融大厦迅速搭建的时候，上层是金融资产泡沫的膨胀，底层是金融机构和人员的产能扩张。反过来，当金融大厦垮塌的时候，先是上层的金融泡沫出清，然后是底层的金融产能去化。 第一阶段是从2015年到2017年，核心是金融去杠杆，挤出金融资产泡沫。从股市来看，2015年的股灾使其成为第一个被戳破的金融泡沫，上证综指从5178点最低跌到2638点，1000多只股票跌幅超过50%，接近100只股票跌幅超过70%。从债市来看，泡沫破分两步，第一步是2014年出现个体的债券违约，这比股灾还早，但真正到大规模债灾是在2016年四季度。由于央行货币政策收紧，10年期国债收益率从2.6%一路反弹到4.0%，跌幅达140bp。与此同时，信用违约事件也愈发频繁，自2015到2018年，债券市场共发生162起违约事件，2016-2017年共有127只债券违约，当中不乏债项评级和主体评级AA+的债券，而2014年只有6只债券违约。 2017年之后进入第二阶段，主要是金融去产能，消灭冗余的金融机构和金融民工。道理很简单，有泡沫的时候蛋糕大了，金融机构都有钱赚，冒险经营的机构也不会踩雷。但泡沫破了就惨了，根本不需要那么多金融机构和金融民工了。举个最简单的例子，比如有机构打着理财的名义非法集资，承诺20%固定收益，然后拿去投股市，当股市大幅上涨的时候，不仅可以兑现高收益，还能赚一大笔，养活一批伪金融家，但当股市暴跌的时候，不仅兑现不了客户的本金和收益，连自己也要破产，机构和人员都要缩编。 实际上，这种去产能在金融的外围圈层已经比较彻底，比如P2P。根据网贷之家的统计，从2015年开始，P2P平台的问题开始集中爆发，仅2015年一年就有1294家平台跑路或出现问题，2016年更是多达1731家，截至2017年多达4000多家P2P平台都爆出问题。不仅数量多，而且很多大平台的资金规模惊人。e租宝涉案581亿，波及90万人，泛亚涉案430亿，波及22万人。这些平台跑路有主观诈骗因素，但也和金融去产能的客观环境有关，泡沫没了，他们的生存失去了根基，最后只能跑路，完成了一种变相的去产能。 下一步金融去产能的重点有两个：一是行业逐步拓展到金融机构的核心圈层，包括一些大家认为很优质的行业，比如基金、券商等。二是形式逐步从温和去产能升级到激进去产能。很多人觉得金融机构是铁饭碗，不可能去产能。但历史告诉我们，覆巢之下无完卵，任何行业在激情之后都逃不了出清的厄运，只是出清的方式不同而已。结合历史经验，金融去产能的方式不外乎四种： 第一，最温和的方式是降薪。金融业和工业最大的不同在于轻资产、重人力，在业绩下滑的时候，工业企业可以出卖固定资产，而金融业只能压缩人力成本。对于很多国有机构来说，不能直接裁员，只能通过降薪来降成本，变相去产能。根据世界银行的统计数据，2016年我国金融业私人报酬支付及公司雇员报酬总体由2015年的445亿美元下降到352亿美元。而2016年四大类金融机构从业人数却由2015年的607万人上升至640万人，表明虽然很多机构还在由于惯性扩张人员，但人均薪酬其实已经下降很多了。 以最早暴露问题的银行业为例，不管是高管还是基层，薪酬都明显下降，尤其是一些股份制银行和中小型银行，过去那种躺着赚钱的日子早就结束了。比如浦发银行人均年薪从2012年的20.6万元一路下降到2016年的12.6万元，每年下降3.1万元。光大银行前些年还不错，但2016年也开始大幅下降，人均年薪较2015年下降将近10万元。中信银行人均年薪在2015年之前稳定在20-25万之间，但2015和2016两年仅有13.5和13.9万元。受限薪影响，高管薪酬的下降更为明显。再加上2015年“限薪令”的影响，大部分银行高管年薪几乎“腰斩”。比如工行董事长总薪酬从2013年的113.9万降到54.68万，中行、建行、交行等一把手的税前总薪酬均从七八十万降到50万元以下。浦发银行董事长吉晓辉2015年的税前总薪酬更是较2013年、2014年下降50%以上。 第二，相对温和的方式是减员。比降薪更有效的方式是减员。中国虽然是一个不太能容忍裁员和失业的国家，但中国式的减员并非没有先例。最激进的就是90年代的下岗潮，在几年的时间里，国企在职人数从1997年的1亿人以上骤降到7000万以下，几千万人被“减员”。对金融业来说，由于机制相对市场化，减员更为激进。目前减员比较多的集中在证券公司，因为证券业在扩张之后最早暴露了风险，2015年的股灾让很多券商遭受重创。从2016年5月方正证券内部宣布裁员之后，有几十家券商都在内部做出裁员预警或通知。 我原来所在的券商分析师行业是一个最典型的例子。持牌分析师都需要在证券业协会备案，根据证券业协会的统计，2011到2014年间，持牌分析师从不到2000人增长到2866人，但现在这个数字已经掉到了2621人。大量卖方分析师离开这个行业，有的去上市公司做实业，有的去创业，就是因为感受到了和过去传统工业那样的产能过剩。 第三，相对激进的方式是重组。多兼并重组、少破产清算不仅适用于实业去产能，也适用于金融去产能。一种是兼并，比如现在的申万宏源，就是三家证券公司重组来的，“申”是申银证券，“万”是万国证券，“宏源”就是宏源证券。90年代末，申银证券和万国证券先合并。2014年，申银万国证券又与宏源证券合并，这是券商里最大的联姻了。还有一种选择是重组，比如当年的南方证券。2004年，因挪用80亿元客户准备金和巨额亏损，证监会、深圳市政府宣布对南方证券实施行政接管。2005年，南方证券重组成为中国建银投资证券，从此退出历史舞台。 第四，最极端的方式是破产倒闭。央行原副行长吴晓灵老师说过一句话，“消灭风险最好的办法是让风险暴露，允许金融机构破产。”很多人可能对金融机构破产没有概念，尤其是觉得银行根本不可能倒闭，但事实上，不管是证券公司、信托公司还是商业银行，都曾经发生过破产倒闭的惨剧。 倒闭的非银机构里最有名的是君安证券和广国投。1999年1月，广东国际信托投资公司由于资不抵债向申请破产，成为中国第一例非银金融机构破产案。当时主要是受亚洲金融危机的影响，导致一大波信托公司倒闭。我看了下数据，1997年的时候中国有242家信托公司，现在只有68家，其他大部分都破产或者被叫停了。 证券公司的情况也差不多，90年代中国的证券公司数量比现在多得多，但那一轮金融去产能之后很多都倒闭了。最有名的就是君安证券，君安号称“创新之王”，是证券业里的“巨无霸”。1998年，因MBO、转移巨资炒作港股等事件而被关闭，董事长张国庆入狱四年，一年后该公司被国泰证券接管，形成现在的国泰君安证券公司。其他一些倒闭的证券公司估计很多人都没听过，比如富友证券、珠海证券、汉唐证券、德恒证券、中富证券、大鹏证券、闽发证券等等。 倒闭的银行大家应该都听过，就是当年的海南发展银行。90年代海南房地产泡沫，多家信用社通过高息揽存的方式开展业务，资不抵债。1997年，28家信用社并入海发行，但海发行宣布不再付高息，于是一些投机者纷纷选择撤资退出，引发其他储户挤兑，储户连续两个月在海发行网点排队取款，兑付压力加上当时房地产泡沫破灭带来的贷款坏账压力最终把海发行压垮。1998 年6 月 21 日，海南发展银行成为国内第一家由于支付危机而倒闭的商业银行。这恐怕是中国最真实的一次金融危机，好在海南是个孤岛，没有让危机扩散，否则后果不堪设想。 图：那些年倒闭的金融机构 数据来源：如是金融研究院 繁荣的时候鸡犬升天，泥沙俱下，危难的时候大浪淘沙，优胜劣汰，天下大势不过如此。过去两年的实体去产能带来了实体产业的集中，比如钢铁行业的集中度（CR5）从22%提升到25%左右。未来两年的金融去产能也必将带来金融业集中度的提升。 第一，从股权的角度看，资本会向大机构集中。从金融机构的股权层面来看，大机构并购小机构、小机构减少会成为趋势。回顾全球金融业的历史，每一次金融去产能都会带来金融业并购的浪潮。上世纪70-80年代滞胀时期，西方国家曾出现过一波并购潮。在美国，仅1979年一年就有217家银行被大银行收购。在英国，60年代还有100家证券机构，到1980年代仅剩下17家。90年代末到21世纪初危机频发，也出现了资本集中的趋势。在美国，弗丽特银行收购波士顿银行，第一银行与第一芝加哥银行联姻，国民银行与美洲银行合并，都是强者愈强的著名案例。在日本，90年代三菱银行与东京银行合并也是经典案例。 在我国，金融行业的兼并也不是新鲜事。就像前面说的，这几年银行业已经出现小型商业银行抱团合并的现象（比如河南13家地方性银行组建成中原银行），期货业已出现兼并重组浪潮，十年内机构数量下降近30家，证券业也已涌现出申万和宏源合并的案例，未来几年这种情况会越来越多。 金融监管的强化可能会加速金融资本集中的趋势。举个最典型的例子，证监会前段时间发了一个关于证券公司股权管理的文件，要求证券公司的控股股东净资产不低于1000亿元。先不说现有的证券公司股东没几家能满足，即便是放眼全中国，能达到这个标准的企业也没几家。显然，政策层希望用严格的牌照管理和资本门槛，把一些不规范的小机构清理出局，资本将加速向大机构集中。 第二，从业务的角度看，资源会向大机构集中。从金融机构的业务层面来看，大机构会享受更多的业务资源，而小机构会受到严重的挤压。以券商为例，近三年IPO数量激增，尤其是2017年IPO数量创下新高，但小券商日子并不好过，大部分项目都被大券商拿走了。广发、中信、海通这前三家保荐了近100个IPO项目，占总量的五分之一。相比之下，很多小券商要么没有项目做，要么只做了一个项目。从IPO主承销收入来看，前十大券商的市场份额2015年是47%，2016年升至51%，到2017年已经达到58%。 为什么业务会越来越集中？一方面是因为监管强化，很多小机构过去业务不规范，靠野路子拉起来的架子肯定要散。典型的就是很多小券商用“包干制”在体外养了很多业务团队，原来监管不严的时候能贡献不少利润，现在恐怕做不到了。另一方面是因为人才流失。小机构的业绩稳定性不如大机构，薪酬水平可能会明显下降，人才失去薪酬激励的时候自然更愿意去大机构，便于积累学习和选择新的工作。 第三，从融资的角度看，资金会向大机构集中。金融机构更愿意给大企业融资，反过来，金融机构自己融资的时候大机构也有明显优势。在监管强化和金融紧缩的过程中，大型金融机构的信用优势会体现出来，客户更愿意把钱交给有坚强后盾的大平台，这使得大机构能享受到更低的负债成本，间接推高了小机构的负债成本。典型的例子就是银行，大银行的资金成本会比中小银行低，导致大银行对企业的贷款成本也会低。如此，便会形成银行找大企业，企业找大银行的循环，大银行融资越来越容易，小银行融资越来越难。 总结来说，过去几年是小金融机构的天下，谁机制活谁就赚得多，未来几年是大机构的天下，谁家底最扎实谁才能活得久。 合作、加群请添加微信：RushiFinance，务必注明机构职务姓名。 转载来源：从实体去产能到金融去产能：拿走酒杯的人回来了]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>金融</tag>
        <tag>光大银行</tag>
        <tag>P2P理财</tag>
        <tag>宏源证券</tag>
        <tag>方正证券</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[麦肯锡：软件驱动重写汽车行业竞争法则]]></title>
    <url>%2F2018%2F1df07ebe%2F</url>
    <content type="text"><![CDATA[当汽车逐渐从一个硬件驱动的机器逐渐进化成软件驱动的电子产品，汽车行业的竞争法则将被重新书写。发动机是整个 20 世纪汽车的技术核心和工程核心，而今天，强大的算力、高级的传感器们正越来越多的扮演着这样的角色：从效率、到互联、到无人驾驶、到电动化、到新型出行解决方案… 当汽车逐渐从一个硬件驱动的机器逐渐进化成软件驱动的电子产品，汽车行业的竞争法则将被重新书写。 发动机是整个 20 世纪汽车的技术核心和工程核心，而今天，强大的算力、高级的传感器们正越来越多的扮演着这样的角色：从效率、到互联、到无人驾驶、到电动化、到新型出行解决方案……它们让更多这样的时代创新成为可能。 可是，随着电子和软件的重要性变强，复杂度也升高了。举个例子就是现在汽车内部暴增的软件代码行数 SLOC（Software Lines of Code，译者注）。2010 年时有些车里的 SLOC 就有千万行，2016 年时这个数字就增长了 15 倍达到大概 1.5 亿行。这样滚雪球似的复杂度上升造成了严重的软件质量问题——有近期数百万级的汽车召回为证。 汽车向提供越来越高级的自动化在定位，汽车厂商们也把车内软件的质量和安防当作确保车辆安全的关键必要条件。行业也因此需要重新对现今的车内软件和电子电气架构进行构思。 说一个较为迫切的行业问题整个行业正在经历一个车从硬件定义到软件定义的转换，每个车平均的软件和电子电气相关内构快速增长。 软件，在今天，能占到一辆 D 级车或说一辆大型车全部内构的 10%（约 $1,200 美元），而这一占比的增速将达到每年 11% 的复合增长率：2030 年将达到 30%（约 $5,200 美元）。 于是也毫不奇怪整个数字汽车价值链上的每个参与者都想在这些软件和电子技术带来的创新中分一杯羹（图 1）。软件公司和其他数字技术公司开始从他们原有的二三级供应商位置跳脱，成为汽车厂商的一级供应商。他们开始在汽车技术的“堆栈”（stack）里扩大自己的参与感，从提供功能、app 进化到操作系统。 与此同时，传统的一级电子系统供应商则大胆踏入由科技巨头们占领的功能、app 地盘；高端车厂们则正进入这“堆栈” 下层，比如操作系统、硬件简化、信号处理等等——他们须要捍卫他们的技术独特性和优势。 图1 这样战略动作带来的后果之一是车辆架构将变为基于广义计算平台的面向服务的SOA（Service-Oriented Architecture，译者注）。开发者们可以加入新的互联解决方案、应用、人工智能元素、高级分析和操作系统。所以未来差异化将不像传统车那样在于硬件，而在于软件和高级电子赋能的 UI、体验部分。 明日之车将转向搭载全新差异化因子的平台（图 2 ）。这些因子要素可能包含信息娱乐创新、自动驾驶能力、以及那些基于“运行失败” 的智能安全功能（例如，系统可以在部分失灵的情况下仍完成关键任务）。软件将在数字技术的分层里逐渐下移，以智能传感器的形式与硬件相互集成。“堆栈”将横向集成，形成让车辆架构向 SOA 转变的新层级。 图 2 最终，新的软件和电子架构会带来多项改变游戏规则的新趋势，驱动复杂度和相互依赖程度的提升。 比如，这些新的智能传感器和应用就会给车辆带来“数据爆炸” ，厂商们若想保持竞争力，就得能更有效率的处理并分析这些数据； 模块化 SOA 和 OTA 更新将成为管理车队复杂软件和功能按需（function-on-demand）商业模式可行的关键条件； 信息娱乐以及低级别 ADAS 在越来越多第三方开发者提供内容的情况下将进一步被“app化”； 对数据安全的要求从聚焦纯访问控制策略向一个可以预测、避免、检测并防御网络攻击的集成安防概念转向； 高级别自动驾驶能力（HAD，Highly automated driving）的来临对功能的融合、高算力以及高集成度都提出了要求。 探寻未来电子电气架构的十个假设技术与商业模式的前路未定，我们还是基于广泛的研究和专家见解对未来的汽车电子电气架构做了十个假设并分析了他们对行业的意义。 一、多 ECU 将被整合 汽车行业将转向整合的 ECU 架构而非与特定功能对应的一大堆特定ECU（即现在这种“加个功能就加个盒子”的模式）。 第一步中，大多数功能将开始被集中在主要车辆域（domain）的集成域控制器上，这些控制器会部分代替当下在不同分布式 ECU 中运行的功能。 这样的发展业已开始且将在两三年内打入市场，这种整合特别适用于跟 ADAS 和 HAD 功能相关的技术层级，基本的车辆功能则可能会继续保持去中心化的状态。 在向自动驾驶的进化过程中，软件功能的虚拟化和硬件的抽象化将变得更加迫切，而这种新的手段可以通过不同几种形式实现。 情况其一是将硬件合并为针对延迟和可靠性提出不同要求的“堆栈” ，比如支持 HAD 和 ADAS 功能的高性能堆栈以及用于基本安全功能的一个独立的、时间驱动的低延迟堆栈。 另一种情况，ECU 被一个冗余的“超级计算机” 替代. 而第三种情况，控制单元概念被彻底放弃以支持一个智能节点计算网络（smart-node computing network）。 这一变化驱动因素有三：成本、市场新入者、通过 HAD 实现的需求。首先无论对于功能开发还是计算硬件，也包括通信硬件，成本减少都会加速上述整合；新入玩家来到汽车领域，通过软件导向的车辆架构对整个行业造成的破坏力也是同样效果；对 HAD 功能以及冗余性日益增长的需求也需要更高集成化 ECU。 几家高端车厂和他们的供应商已经在 ECU 整合问题上积极行动，先行一步升级电子架构，尽管明确的行业定式还未出现。 二、汽车行业将限制特定硬件所用的堆栈数量 伴随整合的将是堆栈限制的规范化，实现车辆功能和 ECU 硬件的分离，提升虚拟化。硬件和嵌入式固件（包括操作系统）将依赖关键非车辆功能条件而非被分配到车辆功能域的一部分。要实现这样的分离和 SOA 架构，以下四个堆栈可能成为未来五到十年内下一代汽车的基本： ·时间（Time-driven）堆栈。在此域中，控制器直接与传感器、执行器连接，系统须支持严格的实时要求和低延迟时间；资源调度基于时间。此堆栈包括达到最高汽车安全完整性等级的系统，比如经典汽车开放系统架构域（AUTOSAR, Automotive Open System Architecture, 译者注）。·事件-时间（Event/time-driven）堆栈。此混合型堆栈将高性能安全应用相连结，比如和支持ADAS和HAD的功能相接。应用程序和外设通过操作系统分离，应用程序按时间进行调度，应用程序内的资源调度则既可以根据时间或是优先级。操作环境确保重要安全应用在独立的容器（container）运行并与其他车内应用明确分隔，现有的例子就是自适应AUTOSAR。·事件堆栈（Event-driven）。这以堆栈以信息娱乐系统为中心，对安全性来说并不关键。应用程序与外设将明确分离，资源和调度遵循最优化或基于事件的调度策略。此堆栈中包含用户可见的、常用的功能且是用户与车辆形成交互的介质，比如像安卓（Android），Automotive Grade Linux， GENIVI 和 QNX。·云堆栈（非板载堆栈）（Cloud-based，off-board）。最后一种堆栈负责和协调从车外获取车内数据和使用车内功能。于是此堆栈负责沟通，同时还负责对应用的安全性和保护性检测（即认证），由它建立一个已定义的车的接口（interface），包括远程诊断。 供应商和技术提供商已经开始在以上堆栈中建立自己的专长，举个值得注意的例子就是信息娱乐系统（事件堆栈），公司们已经在推动人车沟通能力的拓展，如3D或增强现实式导航。另一个例子就是人工智能和传感器在高性能应用程序上的引入，关键供应商在此领域已经和主要的汽车厂家进行合作开发计算平台。 在时驱域，AUTOSAR 和 JASPAR 则在支持着时间堆栈的标准化，而扩展后的中间件层（middlewarelayer）将从硬件中将应用进行抽象。 车不断进化为移动的计算平台，中间件将让车辆的重新配置成为可能，同时允许软件的安装和升级。不像今天在每个不同 ECU 里的中间件只是负责单元间的通讯，下一代汽车中的中间件将是域控制器访问功能的链接，在 ECU 硬件之上运行的中间件层将实现抽象和虚拟化、SOA 和分布式计算。 已有证据表明，汽车厂商正向柔性架构努力，这也包括一个总体的中间件。比如 AUTOSAR 的自适应平台，它是一个动态的系统，包括中间件、对复杂操作系统的支持和最先进的多核微处理器。但是目前这类发展只限制在单个 ECU 中。 三、中期看，车载传感器个数将迅速升高 后面两到三代汽车产品上，厂商们将通过安装多个有相似功能的传感器以确保足够的安全性冗余（图 3）。然而从长远角度，汽车行业将必然开发特有传感器以减少传感器数量以及相关成本。 我们认为接下来的五到八年雷达和摄像头相结合的方案将占据主流，而当自动驾驶能力逐渐提升，激光雷达的引入对于确保物体分析（object analysis）和本地化（localization）的冗余成为必要。 以 SAE 的 L4（高级自动）自动驾驶为例，实现 L4 的初期可能需要 4 到 5 颗激光雷达，包括以城市运营和近 360 度可视为目的的固定在车后方的后置激光雷达。 图 3 长期来看，车辆传感器个数问题将会出现不同的情况：继续增加、数量稳定或数量减少。到底哪一种情况将真正到来则依赖法规要求、不同解决方案的技术成熟度以及在不同用例中使用多个传感器的能力。法规方面，如若要求加强驾驶员监控，则车内传感器必然增多。 可以预见的是汽车内饰中消费电子传感器将会开始应用。动作传感器和用于测心率和困倦成都的健康检测、面部识别、虹膜追踪，这些只是多种潜在用例中的一小部分。当然，随传感器数量上升或稳定，相应的物料成本也将上升，不只是传感器本身的成本，还有车内网络，所以减少传感器数量能带来的成本节约也一定可观。 在高级自动驾驶或完全自动驾驶时代到来，未来的高级算法和机器学习技术将增强传感器的性能和可靠性，结合更强大、性能更高的传感器技术，多余传感器的数量将有希望减少。今天在用的这些传感器可能由于其功能被高性能传感器淘汰而变得过时（例如，一个基于摄像头或激光雷达的停车辅助功能将可能取代超声传感器）。 四、传感器将更加智能 系统架构的需求，决定了智能、集成的传感器们需要为管理和处理高级自动驾驶所需的海量数据而存在。如传感器融合或 3D 定位等高级别功能将需要在中心化计算平台上运行，但数据的预处理、过滤、快速反应等则将更多在传感器周边或直接在传感器内完成。 有估计称对于一辆自动驾驶汽车每小时产生的数据量将达到 4TB，因此，智能化将从 ECU 们逐渐转移至传感器，靠传感器进行基础的、要求低延迟、只要求低算力的预处理，尤其是当权衡数据处理成本时，在传感器内处理数据对比将海量数据在车内传来传去相比更应把这些工作交给传感器。 而且 HAD 下驾驶决策冗余无论如何也需要集成的中心化算力，这更可能是基于已经过预处理的数据。智能传感器将对自身功能进行监督而传感器冗余则将提升传感器网络的可靠性、可用性和安全性。另外，为确保不同情况下传感器的正确运行，需要新一类传感器清洁方案和应用——如需要除冰能力、除尘除垢能力等。 五、全电力和数据网络冗余成为必须 高可靠性要求的关键安全应用和其他类似应用，将充分利用整个冗余圈来实现与安全操控相关的那些关乎巨大的一切内容，比如数据传输和电力供应。 电动车技术、中央计算机以及对电力要求较高的分布式计算网络都会对新的冗余电量管理网络提出要求。支持线控转向和其他 HAD 功能的故障运行系统将需要冗余的系统设计，这也是对现今的故障安全监控实施的巨大架构改进。 六、“汽车以太网”将崛起并成为车的中坚 今天的车辆网络不足以满足未来车辆的需求。 HAD 数据速率和冗余要求的提高，连接环境中的安全性和保障性以及对行业内标准化协议的需求将极可能导致汽车以太网成为关键推动因素，特别是对于冗余中央数据总线。 以太网解决方案将需要通过添加像音频 - 视频桥接（AVB）和时间敏感网络（ TSN ）等以太网扩展来确保可靠的域间通信并满足实时要求。行业参与者和 OPEN 联盟支持采用以太网技术，许多汽车制造商已经取得了这样的飞跃进展。 传统网络（如本地互联网络和控制器区域网络）将继续用于车辆内，但仅用于封闭的低级网络，例如传感器和执行器位置。 FlexRay 和 MOST等技术很可能会被汽车以太网及其扩展，AVB 和 TSN，所取代。 继续发展的话，我们预计汽车行业也同样会拥抱未来以太网技术，比如高延迟宽带产品（HDBP）和 10 千兆位技术。 七、OEM 将始终严格控制用于功能安全和 HAD 的数据连接，但会为第三方访问数据开发界面 发送和接收安全关键数据的中央连接网关将始终直接连接到 OEM 后端，除规定的要求外，第三方可以通过这些进行数据访问。但在信息娱乐方面，受车辆“ APP 化”的驱动，出现新的开放接口来允许内容和应用程序提供商部署内容，而 OEM 将尽可能保持相应的标准。 今天的车载诊断端口将被车联网解决方案取代。将不再需要对车辆网络的物理维护但可以通过 OEM 的后端进行维护。 OEM 们将在其车辆后端提供数据端口用于特定用例，如遗失车辆跟踪或个体保险。但是，售后市场设备对车辆内部数据网络的访问会越来越少。 大型车队（fleet）运营将在用户体验中发挥更强大的作用，并将为终端客户创造价值，例如通过在一套服务（例如周末或每日通勤）中为不同目的提供不同的车辆。这要求他们利用不同 OEM 的后端并开始整合其车队的数据。之后更大型的数据库将允许车队运营商在 OEM 级别无法获取的数据集成和分析上变现。 八、汽车通过云将车载信息与车外数据结合 虽然 OEM 以外的其他厂商可用的数据将取决于未来的监管和相关磋商，但对云计算中不断增加的非敏感数据（即非个人数据或安全相关数据）的处理将可以得到更多深入洞察结果。 随数据量增长，数据分析对于处理信息并将其转化为可操作的知识将变得至关重要。利用数据以实现自动驾驶和其他数字化创新的有效果取决于多个玩家之间的数据共享。目前虽然还不清楚这将如何、由谁完成，但主要传统供应商和技术供应商已经在构建能够处理这种新数据的集成汽车平台。 九、汽车将引入双向通信的可更新组件 车载测试系统将允许汽车自动检查功能和集成更新，从而实现生命周期管理以及增强或解锁售后的产品功能。所有 ECU 将向传感器和执行器发送和接收数据，检索数据集以支持创新用例，例如基于车辆参数的路线计算。 OTA 更新是 HAD 的先决条件; 同时还将因为 OTA 出现新的功能、确保网络安全、并使汽车制造商能够更快地部署功能和软件。实际上 OTA 更新功能是前面介绍的许多车辆体系结构重大变化背后的驱动。 此外，OTA 还需要在从车辆外部堆栈每层到车辆中 ECU 们的端到端的安防解决方案。这种安防解决方案仍有待设计，而由谁做、怎么做都将会是非常有趣的观察。 要实现像智能手机那样的可升级性，业界需要克服限制性经销商合同、监管要求以及安全和隐私问题。这里各种汽车厂商也公布了部署 OTA 服务的计划，其中包括对它们的车辆的无线更新。 OEM 将在 OTA 平台上对其车队进行标准化，并与该领域的技术提供商密切合作。 由于车的互联性和 OTA 平台变得越来越重要，我们可以认为 OEM 将在这个细分市场中占据更多的所有权。 车辆将获得软件和功能升级，同时也会收到针对设计使用寿命的安防更新。监管机构可能会强制要求软件维护以确保车辆设计的安全完整性。这种更新和维护软件的任务将引出关于车辆维护和运营的新商业模式。 十、评估汽车软件和电子体系结构的未来影响 影响当今汽车行业的趋势们为硬件相关的内容带来很多大的不确定性，对软件和电子体系结构来说，看来未来的破坏性可能也不会少多少。 许多战略举措都有可能：汽车厂商可以选择建起行业联盟来规范和标准化车辆架构、数字行业巨头可以引入车载云平台、出行服务商可以自己自己造车或开发开源车辆堆栈和软件功能，汽车厂商则可以引入日渐复杂的互联、自动驾驶汽车。 对于传统的汽车公司来说，从以硬件为中心的产品向以软件为导向的服务驱动型行业的转变尤其有挑战性。然而考虑到本文所述的趋势和变化，汽车行业内的任何人都没有其他选择，只能做好准备。我们能看到几大战略推力： ·解耦车辆和车辆功能的开发周期。 OEM 和一级供应商需要从技术和组织两个角度确定如何开发、提供和部署功能，而且是大部分在车辆开发周期之外。鉴于目前的汽车开发周期，企业需要找到一种管理软件创新的方法。此外，也应该思考如何为现有车队创建改造和升级解决方案（例如计算单元）。·定义软件和电子产品开发工作的目标增值（ value added ）。 OEM 必须确定他们能够建立控制点的差异化特征。另外，明确定义自己软件和电子产品开发的目标附加价值非常重要，同样的还有，找到可以形成商品或话题的区域且仅一家供应商或合作伙伴能够实现。·给软件贴上一个明确的价签。将软件与硬件分离意味着需要 OEM 重新考虑其单独购买软件的内部流程和机制。除了传统已有的设定之外，分析采购过程中如何将敏捷的软件开发方法固定下来也很重要。这里指的供应商（一级，二级和三级）也发挥着至关重要的作用，因为他们需要为其软件和系统产品提供明确的商业价值，以使其获得更大的收入份额。·围绕新的电子架构设计一个特定的组织（包括相关的后端）。除了改变内部流程以交付及销售先进的电子和软件之外，行业玩家们（ OEM 和供应商）还应该考虑针对车辆电子相关的主题设置一个新的不同的组织。主要是，新的“分层”架构要求有可能打破目前的“垂直”流程并引入新的“横向”组织单元。再说一句就是，他们也需要为自己的软件和电子开发团队提升专门的能力和技能。·围绕作为产品的汽车特征设计商业模式（特别是对汽车供应商来说）。为了保持竞争力并在汽车电子领域分一杯羹，分析哪些功能才是为未来架构增添实际价值并可以变现是致关重要的。随后，玩家需要为软件和电子系统的销售推出新的商业模式，无论当时是作为产品、服务或者全新的东西。 随着汽车软件和汽车电子新纪元的开始，它正在彻底改变各种业务模式，客户需求以及竞争性质的行业既有的确定性。我们对将建起来的收入和利润池感到乐观。但要从转变中受益，业内所有参与者都需要重新思考并在新环境中仔细定位（或重新定位）其价值主张。 转载来源：麦肯锡：软件驱动重写汽车行业竞争法则]]></content>
      <categories>
        <category>汽车</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>人工智能</tag>
        <tag>麦肯锡公司</tag>
        <tag>电子技术</tag>
        <tag>汽车产业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[今日头条一季度教育榜：K12教育新规关注飙升，留学政策大变革]]></title>
    <url>%2F2018%2F93d32ac1%2F</url>
    <content type="text"><![CDATA[发布教育行业季度榜单，透过数据解读教育资讯热点，洞察教育行业目标用户兴趣偏好，用数据带你了解教育的那些事儿。 对于每个有孩子的家庭来说，教育绝对是头等大事。从孩子出生到长大成人，正确的价值观及良好的技能学习都依赖于良好的家庭教育观念，家长是在孩子成长过程中非常重要的角色。 头条指数从早教、K12教育、留学三大领域资讯入手，发布教育行业季度榜单，透过数据解读教育资讯热点，洞察教育行业目标用户兴趣偏好，用数据带你了解教育的那些事儿！ 早教领域关注飙升榜：“压岁钱”成早教热议话题，“双语”教育备受关注。一季度中，“压岁钱”涨幅登顶榜首，相信不少家长在春节也遇到如何让孩子正确面对压岁钱的问题。红包虽小，但背后折射的是一个家庭的教育观念。有的家长直接收走孩子的红包，有的会追问孩子红包金额，聪明的父母会借红包让孩子了解传统文化，也引导孩子正确地对待红包与金钱的关系。 值得一提的是，“双语”教育资讯本季度飙涨877%。3-6岁不仅是孩子性格养成的关键时期，还是学习外语的最佳时期，越来越多的家长意识到从小培养孩子“双语”能力对往后语言学习的重要性，从家庭英语交流到选择双语早教机构，家长们在“双语”教育这件事上可谓是费尽了心思。 早教领域热搜榜：简笔画荣登热搜榜首，德智体美全面发展在早教热搜版块，很多家长不仅搜索简笔画，还经常转发简笔画教程。对于平时工作忙碌的家长来说，简笔画可现学现用确实方便，看完教程可以马上和孩子一起协作画画，这既培养了孩子的想象力及速记能力，也有利于孩子未来的兴趣发展。睡前时间是与孩子交流的宝贵时机，家长们在头条搜索睡前故事，借此与孩子沟通，让孩子在有益的故事中学到知识，促进智力发育，也增进了孩子与家长之间的感情。此外，“手工”、“跆拳道”等培养孩子运动能力的教育方式也受到家长们的关注，德智体美全面发展要从娃娃抓起的教育理念已经深入到家长心中。 K12教育各线城市关注榜：三四线市场潜力大，教培巨头积极布局本季度三四五线城市用户在K12教育领域资讯关注度有所上升，三四线教培市场近年来需求不断增加，家长也有较强的付费意愿，但目前三四线教育仍存在着优质教育资源稀缺，以中小机构为主的教培市场质量参差不齐等痛点。正是如此，得益于互联网及视频直播技术的发展，新东方、好未来两大K12教培巨头借助“双师课堂”模式，改变了以往渠道下沉成本过高、师资人员紧缺等难题，迅速布局三四线教培市场。 K12教育领域热门学科榜：数学登顶关注榜首，三大主科仍最受关注本季度“数学”类教育资讯关注度最高，关于“数学”的资讯更多地集中于数学课的学习方法及技巧，“语文”类资讯则更加集中于作文写作类的案例分享，而语法笔记在“英语”类资讯中也受到用户关注。总体来说，语数英三大主科关注度依旧高于其他科目，从内容看，学习笔记及技巧型的资讯更受用户欢迎。 K12教育领域关注飙升榜：整顿培训机构“超纲教学”，一系列教育新规引关注总体上看，一季度关注度涨幅较高的“超纲”、“托管”、“教师队伍”等关键词源于一系列教育新规的发布。2月22日，教育部办公厅等四部门发布的纠正校外培训机构开展“超纲教学”培训不良行为的通知。2月24日，黑龙江省教育厅首次下发关于推后中小学生早晨到校时间的通知。3月16日，教育部长陈宝生提出今年17个省份将启动新高考改革规划等教育新规的发布迅速引起众多家长关注。此外，本季度用户也十分关注“3点半放学”托管服务问题、促进“教师队伍素质建设”、招聘“特岗教师”等教育资讯。 留学资讯各省用户关注榜：上海北京关注度远超其他省市据教育部发布的2017年中国学生出国留学相关数据显示，2017年我国各类出国留学人员总数首次突破60万，达到达60.84万人，同比增长11.74%，持续保持世界最大留学生生源国地位。从头条指数TGI兴趣偏好数据来看，国内一流大学云集的上海、北京指数均超200，两地用户对留学资讯消费需求大。此外，湖北、海南、广东等省市用户对留学资讯的偏好度也位居全国前列。 热门留学国家关注榜：美澳加三国留学最受关注美国、澳大利亚、加拿大等国拥有多所世界一流大学，发达的教育资源吸引国内学生不断前往留学深造。2017年底，美国大使馆发布的《2017年门户开放报告》数据显示，超过24%的国际留学生把美国选为留学目的国，而中国留学生占在美国际学生总数的32.5％，连续第八年位居榜首。而在澳大利亚，中国留学生占比依旧最高，约占31%，国人依旧热衷着出国留学这件事儿。 留学教育领域关注飙升榜：川普或限发留美签证，加拿大留学政策大变革美国总统川普作为话题人物，在留学资讯领域的影响力也毫不逊色。据美国《华尔街日报》3月17日报道，美国政府正考虑限制给中国留学生发放签证、H-1B工作签证、以及停发10年赴美旅游签证，这则消息迅速引起留学圈的关注。 “GIC”本季度关注度飙升1636%，该计划是加拿大留学政策中的银行投资证明。3月13日，加拿大大使馆微博发布了即将新推出的4大类加拿大留学签证申请类别介绍，新政中强制要求几乎所有的学习许可申请计划都需购买1万加元的担保投资证明。此外，“SDS”作为加拿大签证中的另一重要计划也在本次新政中有所调整，新SDS要求雅思总分与各项分数不低于6分。 本季度教育类热门问答中，家庭教育方式及孩子性格培养类咨询被重点关注，而文理科选择、大学排名等教育类疑问也引发用户热议。 头条指数借助今日头条平台每天百亿级的阅读数据，捕捉行业热点，洞察阅读行为背后的兴趣表达。每个季度，头条指数将发布行业热度榜单，帮你看清行业动态，用户关心的，才是你真正需要的，欢迎关注&#64;头条指数！ 转载来源：今日头条一季度教育榜：K12教育新规关注飙升，留学政策大变革]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>在线教育</tag>
        <tag>移动互联网</tag>
        <tag>今日头条</tag>
        <tag>加拿大</tag>
        <tag>家庭教育</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[被催熟的平安好医生！]]></title>
    <url>%2F2018%2F87907134%2F</url>
    <content type="text"><![CDATA[平安好医生凭借资本力量获取大量客户，主要营收仍来自平安，目前还处于烧钱阶段，此时上市似乎有被催熟的意味。 培育“独角兽”企业，一向都是风投和互联网公司干的活，不过，平安集团仿佛是个例外，一口气培育了四个独角兽企业——平安好医生、陆金所、平安一账通和平安医保科技。4月22日，平安好医生就召开了全球发售会，拟于5月4日登陆香港联交所。平安好医生凭借资本力量获取大量客户，主要营收仍来自平安，目前还处于烧钱阶段，此时上市似乎有被催熟的意味。 4月22日，平安好医生在香港召开全球发售会，公司预期将于5月4日登陆香港联交所。此次共发售1.6亿股，每股发售股份50.80-54.80港元。据知情人士透露，定价在每股54.80港元的最高区间，照此计算，平安好医生拟募资规模87.7亿港元（约合人民币70亿元）。而平安好医生估值也达到75亿美元，折合约588亿港元。 平安好医生自2015年4月正式发布产品至今，仅仅发展了3年时间，估值达到了75亿美元，发展速度着实令人惊叹。不过，探究平安好医生财报，似乎有种被催熟的感觉，营收好看，但是很大一部分来自母公司平安集团的输血，此外仍处于巨额亏损之中。尽管客户数字好看，变现能力堪忧。 根据招股书显示，平安好医生2015年-2017年收入分别为2.79亿元、6.02亿元、18.68亿元，但持续亏损，近三年亏损额分别为3.24亿元、7.58亿元、10.02亿元。近三年经营性现金流也均为负数，分别为-0.45亿元、-2.63亿元、-4.84亿元。 烧钱买来的用户？尽管连续3年亏损，平安好医生仍然受到了投资者的青睐。招股说明书显示，此次平安好医生与多家国际基石投资者签订协议，前十大基石投资者将出资5.5亿美元，认购份额约为53%，占已发行股本8%左右。 或许，这些基石投资者看中的，便是平安好医生迅速增长的用户量以及营收数据。作为一个互联网独角兽，用户数据尤其值得关注。 如上图所示，2015年-2017年，平安好医生月活跃客户分别为560万、2180万和3290万人，而付费客户仅有10万人、40万人和90万人。这样的数据，既可以解读为付费空间巨大，同样可以解读为变现能力差，空有用户量。 有趣的是，打开平安好医生APP，首先看到关键词搜索推荐的是“步步夺金”，首页显眼位置推荐的，也是“步步夺金”。而所谓的“步步夺金”，就是平安好医生2015年12月推出的引流工具，用户通过使用APP，比如第一次参加，走满5步可送1金，作为起步基金。以后每天走路1000步，奖励0.3金，之后每走2000步，奖励0.1金，而这些“现金券”可以在用户商城兑换礼品，比如洗发液、剃须刀、厨具以及牙膏之类的生活用品。 从招股股数据中可以看出，“步步夺金”项目推出后，平安好医生月活量显著提高，直接从2015年560万月活，提升至2016年2180万月活。 根据招股书显示，2015年-2017年，平安好医生推广费用分别为0.07亿元、3.84亿元和2.13亿元。由此可见，2015年12月“步步夺金”项目推出后，平安好医生推广费用剧增。 互联网企业通过补贴拉客户似乎无可厚非，但医疗需求在生活中远没有“衣食住行”那样高频，给用户送钱的方式固然可以粉饰用户数据，如何把这些客户转化为真正关注健康，关注医疗，而非挣钱而来，似乎仍需要平安好医生继续努力。 背靠平安好乘凉事实上，背靠平安这颗大树，平安好医生不仅可以任性地烧钱，也可以通过丰富的集团资源，撑起公司营收。2015年-2017年，平安好医生提供给平安集团业务，占营收比例分别为80.9%、41.4%和46.4%，由此可见，平安好医生的发展，离不了平安集团的扶持。 此外，平安集团对平安好医生的扶持，不仅仅是购买其服务，也包括资本支持和强营销。招股书显示，平安好医生主营业务分为家庭医生服务、消费型医疗、健康商城和健康管理和互动，2017年占营收比例分别为13.0%、35.0%、48.0%和4.0%。 其中，家庭医生服务为平安好医生主打的在线诊疗；而消费型医疗主要是出售体检卡，事实上，很多平安保险经纪人，在推销保险的同时，顺带推销体检卡，从而拉动平安好医生营收。 根据招股书显示，消费型医疗43.8%提供给公司客户，平安集团就占了41.8%，其他56.2%提供给个人客户，而54.5%又通过平安集团的销售代理完成的。平安集团购买的服务加上平安集团代理的，共计96.3%，通过平安好医生自有销售团队和健康商城完成销售的，只占2.9%。可以说，平安好医生的消费型医疗业务，全部靠着平安集团撑着。 健康商城则是一个电商平台，在网上销售养生、居家百货、宝宝用品、健康食品等，有趣的是，平安好医生健康商城还出售电视、手机等家电数码产品。 从招股书可以看出，健康商城为平安好医生发展最为迅速的业务，2015年-2017年，营收分别为190万元、6.31亿元和8.96亿元。扣除提供给平安集团的营收，提供给其他客户的营收分别为190万元、5.66亿元和4.67亿元。 不过，提供给其他客户真实的销售数据，似乎还要扣掉用平安好医生对用户的补贴。上图可知，平安好医生健康商城的付款方式中，有“使用我们奖励计划的优惠券支付”，这便是上文提到的“步步夺金”项目。2016年、2017年“步步夺金”推广费用分别为3.85亿元和2.14亿元，扣除后，提供给其他客户的营收数据分别为1.81亿元和2.53亿元。 2017年，平安好医生营收18.68亿元，其中8.65亿元提供给平安集团。此外，仍有7.72亿元消费型医疗业务来自平安集团代理销售，2.14亿元推广费用也很大程度计入了健康商城收入。 而平安好医生一直宣传和主打的家庭医生业务，则从2015年占比42.6%降至2017年13.0%。为了平安好医生的业绩，平安集团似乎注入了太多的资源，导致平安好医生早熟的假象。 被催熟的平安好医生平安好医生虽然是平安系的，高管却主要来自阿里巴巴。或许，平安好医生的成立，也是源自平安集团董事长马明哲的一次挖角行为。2013年，马明哲从阿里巴巴挖来了王涛，其原为阿里巴巴资深副总裁兼阿里软件总裁，来到平安后，就任平安健康险董事长兼CEO。 健康险在保险品种里并非大类，王涛就任健康险总裁后，便很快干起了老本行软件。2014年1月，他开始在上海组建团队，2015年4月正式发布平安好医生APP。平安好医生的高管团队中，首席产品官吴宗逊、首席技术官王齐和首席运营官白雪均来自阿里巴巴。可以说，平安好医生是拿着平安的渠道和资金，依靠挖角阿里的人才做起来的。 一直以来，看病难和看病贵，是国内患者诟病两大问题。为了解决这些问题，2011年以来兴起了很多互联网医疗公司，比如好大夫在线、春雨医生等。不过，这些互联网公司的都是轻资产运营的，比如在线问诊，它们的作用，就是把医生与患者在网上有效链接起来。 事实上，国内互联网医疗行业发展并不乐观，医疗服务通常需要高素质人才和医疗检查，这些是互联网医疗欠缺的。目前，大部分互联网医疗企业都集中在挂号、在线信息查询等。而平安好医生之所以崛起，主要从医院挖角医师，依靠全职医师给患者提供诊疗服务。 据招股书显示，截至2015年、2016年及2017年，平安好医生的医疗团队人数分别为585名、797名及888名。需要注意的是，截至2017年底，888名的医疗人员中仅有172人为医生（约占总数的19%），其余的是医务助理。 平安好医生的营收主要由消费型医疗和健康商城提供，这些收入绝大部分来自平安集团的购买服务以及资源支持，而公司主打的家庭医生业务，也是靠“重资产”取得竞争优势的，而这些同样离不开平安集团的资金支持。 短短三年，平安集团用资金和平台资源砸起来平安好医生。这样的平安好医生，似乎是被催熟的。不像其他互联网公司，是在市场的腥风血雨中杀出来的，没有得到市场的检验，若离开平安集团的扶持，平安好医生能否正常运营仍值得商榷。 转载来源：被催熟的平安好医生！]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>电子商务</tag>
        <tag>风投</tag>
        <tag>IPO</tag>
        <tag>平安保险</tag>
        <tag>马明哲</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[聚类分析之k-means算法(SSE、轮廓分析）]]></title>
    <url>%2F2018%2F59ab7715%2F</url>
    <content type="text"><![CDATA[在前面我们介绍过了很多的监督学习算法，分类和回归。这篇文章主要介绍无监督算法，通过聚类分析来处理无类标数据。 在前面我们介绍过了很多的监督学习算法，分类和回归。这篇文章主要介绍无监督算法，通过聚类分析来处理无类标数据。我们事先并不知道数据的正确结果(类标)，通过聚类算法来发现和挖掘数据本身的结构信息，对数据进行分簇(分类)。聚类算法的目标是，簇内相似度高，簇间相似度低。有点像LDA降维算法，类内方差最小，类间方差最大。这篇文章主要包括： 1、K-Means算法 2、K-Means++ 3、硬聚类和软聚类 4、聚类算法的性能评价指标 一、K-Means算法在聚类算法中K-Means算法是一种最流行的、使用最广泛的一种聚类算法，因为它的易于实现且计算效率也高。聚类算法的应用领域也是非常广泛的，包括不同类型的文档分类、音乐、电影、基于用户购买行为的分类、基于用户兴趣爱好来构建推荐系统等。 K-Means算法的实现步骤，主要分为四个步骤： 1、从样本集合中随机抽取k个样本点作为初始簇的中心。 2、将每个样本点划分到距离它最近的中心点所代表的簇中。 3、用各个簇中所有样本点的中心点代表簇的中心点。 4、重复2和3，直到簇的中心点不变或达到设定的迭代次数或达到设定的容错范围。 常用的距离度量标准是欧几里得距离的平方： 其中x和y表示不同的两个样本，n表示样本的维度(特征的数量)。基于欧几里得距离，K-Means算法需要优化的问题就是，使得簇内误差平方和(within-cluster sum of squared errors,SSE)最小，也叫簇惯性(cluster intertia)。 下面利用sklearn来实现一个k-means算法的应用，使用sklearn的数据集，数据集中包含150个随机生成的点，样本点分为三个不同的簇 150个样本点的分布如上图所示。下面使用sklearn内置的KMeans算法来实现对上面样本点的聚类分析 二、K-Means++K-Means算法需要随机选择初始化的中心点，如果中心点选择不合适，可能会导致簇的效果不好或产生收敛速度慢等问题。解决这个问题一个比较合适的方法就是，在数据集上多次运行K-Means算法，根据簇内误差平方和(SSE)来选择性能最好的模型。除此之外，还可以通过K-Means++算法，让初始的中心点彼此的距离尽可能的远，相比K-Means算法，它能够产生更好的模型。 K-Means++有下面几个步骤组成： 1、初始化一个空的集合M，用于存储选定的k个中心点 2、从输入的样本中随机选择第一个中心点μ，并将其加入到集合M中 3、对于集合M之外的任意样本点x，通过计算找到与其距离最小的样本d(x,M) 4、使用加权概率分布来随机来随机选择下一个中心点μ 5、重复步骤2和3，直到选定k个中心点 6、基于选定的中心点执行k-means算法 使用sklearn来实现K-Means++，只需要将init参数设置为”k-means++”，默认设置是”k-means++”。下面利用k-means++算法来实现上面三个簇的聚类 通过上面图可以发现k-means++的聚类效果还不错，簇的中心点，基本位于球心。在实际情况中使用k-means++算法可能会遇到，由于样本的维度太高无法可视化，从而无法设定样本的簇数。k-means算法的簇不可重叠，也不可分层，并且假定每个簇至少会出现一个样本。 注意：由于k-means算法是基于欧式距离来计算的，所以k-means算法对于数据的范围比较敏感，所以在使用k-means算法之前，需要先对数据进行标准化，保证k-means算法不受特征量纲的影响。 三、硬聚类和软聚类硬聚类(hard clustering)是指数据集中的样本只能划分到一个簇中，如k-means算法。软聚类(soft clustering)或模糊聚类(fuzzy clustering)可以将一个样本划分到多个不同的簇中，如C-means(FCM)算法。 FCM的计算步骤与k-means相似，只是FCM是使用样本属于不同簇的概率来代替k-means中的类标。样本属于不同簇的概率之和为1。 FCM的计算步骤如下： 1、指定k个中心点，并随机将每个样本点划分到某个簇中 2、计算各簇的中心μ 3、更新每个样本点所属簇的概率(隶属度) 4、重复步骤2和3直至，样本点所属簇的概率不变或是达到容错范围或最大迭代次数 隶属度的计算公式如下： 其中，ω表示的就是样本所属簇的概率，上式表示的簇的个数为3。样本属于簇j的概率。m大于1，一般取2，被称为模糊系数。 FCM算法的单次迭代计算成本要高于k-means算法，但FCM的收敛速度比较快。 四、聚类算法的性能指标1、簇内误方差(SSE) 在对簇的划分中，我们就使用了SSE作为目标函数来划分簇。当KMeans算法训练完成后，我们可以通过使用inertia属性来获取簇内的误方差，不需要再次进行计算。 可以使用图形工具肘方法，根据簇的数量来可视化簇内误方差。通过图形可以直观的观察到k对于簇内误方差的影响。 通过上图可以发现，当簇数量为3的时候出现了肘型，这说明k取3是一个不错的选择。 2、轮廓图定量分析聚类质量轮廓分析(silhouette analysis)，使用图形工具来度量簇中样本的聚集程度，除k-means之外也适用于其他的聚类算法。通过三个步骤可以计算出当个样本的轮廓系数(silhouette coefficient)： 1、将样本x与簇内的其他点之间的平均距离作为簇内的内聚度a 2、将样本x与最近簇中所有点之间的平均距离看作是与最近簇的分离度b 3、将簇的分离度与簇内聚度之差除以二者中比较大的数得到轮廓系数，计算公式如下 轮廓系数的取值在-1到1之间。当簇内聚度与分度离相等时，轮廓系数为0。当b&gt;&gt;a时，轮廓系数近似取到1，此时模型的性能最佳。 通过轮廓图，我们能够看出样本的簇数以及判断样本中是否包含异常值。为了评价聚类模型的性能，可以通过评价轮廓系数，也就是图中的红色虚线进行评价。 转载来源：聚类分析之k-means算法(SSE、轮廓分析）]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>可视化</tag>
        <tag>技术</tag>
        <tag>欧几里得</tag>
        <tag>推荐技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[亚马逊成功的秘密：贝佐斯的决策方法论与“两个披萨原则”]]></title>
    <url>%2F2018%2Facb36bf9%2F</url>
    <content type="text"><![CDATA[同时，我们也注意到，FarnamStreet发表的一篇文章，介绍了亚马逊创始人&amp;首席执行官杰夫·贝佐斯的决策方法论。 转载来源：亚马逊成功的秘密：贝佐斯的决策方法论与“两个披萨原则”]]></content>
  </entry>
  <entry>
    <title><![CDATA[酷码编程完成天使轮融资，将搭建在线编程平台]]></title>
    <url>%2F2018%2Fda43d115%2F</url>
    <content type="text"><![CDATA[由头头是道基金领投、第四象限基金跟投，具体金额尚未透露。据悉，本轮融资将主要用于课程研发、在线编程平台搭建以及线下直营校区扩张等方面。 图片来源：摄图网芥末堆4月27日讯，近日，少儿编程教育品牌酷码编程宣布完成天使轮融资，由头头是道基金领投、第四象限基金跟投，具体金额尚未透露。据悉，本轮融资将主要用于课程研发、在线编程平台搭建以及线下直营校区扩张等方面。 酷码编程成立于2016年，主要面向4到18岁的青少年，为其提供趣味编程、初级至高级算法的编程课程，可供学员完成3到5年的学习。分别涵盖图形化编程、机器人编程、手工代码JS/H5、Python、C++等课程。 酷码编程采用线下小班课（不超过8人）的教学模式，重点关注青少年思维模式的培养和相互之间的合作竞争。酷码编程创始人马丛认为，青少年编程教育从课程设计、教学流程等都没有足够成熟的资源可直接复制，为此酷码编程前期采用线下面对面授课的形式，获取不同城市、不同家庭对编程教育的需求，并根据市场反馈完善其课程产品和教学服务。 马丛表示，“未来，少儿编程教育将会成为像英语一样的必备技能，其市场规模将会和英语培训比肩。此次和头头是道基金将展开多层次的合作，发挥其在教育领域、媒体、科技板块的资源，帮助酷码编程完成高效运营。” 目前，酷码编程拥有8家直营校区。后续酷码编程将提升运营速度，计划在2018年末完成10到15家直营校区的扩张。同时，为了方便学生对于课程的体验，酷码编程也在积极寻找社区型的加盟商。 酷码编程计划将于今年8月推出自主研发的在线编程平台，为学生提供在线教学服务，与线下教学形成互补，完成“线上+线下”的业务布局。 转载来源：酷码编程完成天使轮融资，将搭建在线编程平台]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>英语</tag>
        <tag>基金</tag>
        <tag>科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[下一个千亿级财富金矿？IPFS挖矿到底有何魔力！]]></title>
    <url>%2F2018%2F4f900001%2F</url>
    <content type="text"><![CDATA[想起前段时间比特币市场行情一片低迷，矿工及矿机经销商更是叫苦不迭，能不赔就已经非常幸运了。在这种大环境下，不少矿工选择退场，或者寻找新的机会，比如IPFS。 正文 最近小编在群里或者币友圈都有听到很多人讨论IPFS。想起前段时间比特币市场行情一片低迷，矿工及矿机经销商更是叫苦不迭，能不赔就已经非常幸运了，在这种大环境下，不少矿工选择退场，或者寻找新的机会，比如IPFS。 可能是IPFS主网即将在6月份上线，越来越多的人开始关注IPFS，矿工们的呼声早已在各大论坛、社群炸开了锅，提前屯硬盘、矿机的人比比皆是，大家都相信2018年将是IPFS矿工获取最大收益的一年，并且第一批矿工将会是收益最大的人。 那么这个让矿工朋友如此兴奋的IPFS，到底是个啥！为何这么多人为之疯狂？IPFS到底是概念模式的炒作，还是真的能给世界带来什么样的改变？ IPFS是什么？ 星际文件系统IPFS（InterPlanetary File System）是一个面向全球的、点对点的分布式版本文件系统，目标是为了补充（甚至是取代）目前统治互联网的超文本传输协议（HTTP），将所有具有相同文件系统的计算设备连接在一起。 原理是用基于内容的地址替代基于域名的地址，也就是用户寻找的不是某个地址而是储存在某个地方的内容，不需要验证发送者的身份，而只需要验证内容的哈希，通过这样可以让网页的速度更快、更安全、更健壮、更持久。 它是一个协议也是一个网络，已经运行了2年半，并非虚无缥缈的空气。它就像比特币网络一样，并没有发明什么新技术，他只是将很多种技术(P2P网络技术、BitTorrent传输技术、Git版本控制，自证明文件系统的数据传输协议等等)加以结合，并在这些技术上改进创新，集成了一个去中心化的，IPFS网络。 接下来是IPFS最为引人瞩目，最被大家炒作的概念：IPFS要补充甚至取代过去20年里使用的超文本媒体传输协议(HTTP)。要知道，咱们现在使用的互联网协议，全都是http，而且已经用了20多年了，从HTTP1.0 到现在的HTTP5，网页的展示越来越美观丰富，但它背后的Browser/Server 模式是从来没变的。 如果，我说的是如果，IPFS能做到更改这项模式，无疑会是颠覆性的，甚至是重构性而存在的：网络将会更快、更安全、更开放；隐私将得到极大的保护，人人都可以成为服务器，IPFS，可以从本质上改变网络数据的分发机制，这一切，是在是太amazing了！ IPFS的挖矿方式，其实很简单，IPFS矿工通过检索或贡献存储空间来得到奖励（FileCoin），再将FileCoin兑换成比特币或者以太币套现，这就是IPFS挖矿的基本流程。 IPFS为何如此火爆？ 天下熙熙皆为利来，天下攘攘皆为利往！已经说了，区块链最大的共识就是赚钱，IPFS这里显然有了极好的概念，极好的模式，咱们可以赚一笔啊，为何不来。IPFS的中国热，其实是由由新矿工群体和新矿机商群体带动的。 1、IPFS市场之所以如此被看好，重要的一个原因就是其奖励机制，70%的募资基金将奖励FileCoin 矿工（挖矿奖励），这么有诚意的分配比例当然会被大家看好。这样高份额的奖励自然吸引着矿工们前来挖矿。 2、大部分矿工觉得购买比特币和以太坊矿机，价格太高而且还订不到，电费价格也奇贵无比，所以只能退而求其次，买个”IPFS“矿机咱先挖着玩玩，说不定这个概念一起来，猪都起飞了呢。 3、IPFS，说句实话，现在突然热的要命，主要还是因为这个概念真他么的好圈钱。怎么圈？搞个盒子卖矿机，加上IPFS的概念，高价卖货你懂得！光卖矿机就能发大财你能信？ IPFS是一个开源版+增强版的玩客云 1.去中心的云存储不会随时关停 金山快盘、酷盘、360云盘、快传、各种云盘，当你在上面存满自己私人东西，然后公司说关就关的时候，是多么的痛苦啊。 而IPFS是一个去中心的云存储，不会有哪个公司可以「因业务调整」而关停。 2.挖矿不再是消耗人类能源的浪费 比特币的挖矿，其实是算一个lucky number，使得这个lucky number跟一堆转账记录的hash值符合特殊规律（比如前10位都是0）。 这个挖矿算法很优雅，解决了区块链历史记录极难被更改的问题。但它有个致命的缺点，算lucky number本身毫无社会贡献，只是增加了大量的电费。 而IPFS的挖矿更优雅，矿机硬盘的文件被别人使用了（比如一次下载或一次视频播放），可以收获一点点filecoin（文件币）的奖励。如果你想获得很多很多的filecoin，那么你就要准备很大很大的磁盘空间和很多很多的带宽。而你的这些存储和带宽，是别人上网冲浪需要访问的文件。 所以IPFS的挖矿其实就是BT做种的过程，我为人人，人人为我。 3.集成了Git版本控制功能，文件的历史版本都有保存 区块链的一个超级帅的概念，就是可以追溯历史，之前干了什么是无法抵赖的。集成了Git概念的IPFS，一个文件的任何改动都有版本可查，做了坏事想抹掉可是很难的了。 4.你的数字资产真正被你所拥有 在http的互联网里面，你在网络上留下的痕迹、产生的数据、保存的文件，其实都是存在「别人公司」的服务器上的，数据的所有权其实是数据商业公司的。 举个例子，你想销毁在Facebook上传的照片，或者是想把微信好友的关系保存起来，都没办法。因为这些数据虽然是你产生的，所有权是「公司」的。这些数据很有价值，但是你却没办法把它带走。 而在IPFS里面，你拥有一把数据的私钥。需要给哪个应用开启，不想给哪个应用使用，掌控权都属于你自己。 转载来源：下一个千亿级财富金矿？IPFS挖矿到底有何魔力！]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
        <tag>比特币</tag>
        <tag>区块链</tag>
        <tag>Git</tag>
        <tag>360云盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018中国新一线城市排名出炉！成都稳居第一！]]></title>
    <url>%2F2018%2F94a512a0%2F</url>
    <content type="text"><![CDATA[近年来，无数文字和图片，试图解构这一网络热点。昨日，2018中国城市商业魅力排行榜出炉。四个一线城市在各自的两个梯次中调换了位置——由“北上广深”变为“上北深广”；15个“新一线”城市中成都排位第一，依次是成都、杭州、重庆、武汉、苏州、西安、天津、南京、郑州、长沙、沈阳、青岛、宁 什么是成都？ 什么是成都魅力？ 近年来，无数文字和图片，试图解构这一网络热点。 实实在在的 数据痕迹，更能说明。 昨日，2018中国城市商业魅力排行榜出炉，依据最新一年的170个品牌商业数据、19家互联网公司的用户行为数据及数据机构的城市大数据，第一财经·新一线城市研究所对中国338个地级以上城市再次排名。 最引人瞩目的，是一线城市和“新一线”城市两个榜单。 根据最新排行榜，四个一线城市在各自的两个梯次中调换了位置——由“北上广深”变为“上北深广”； 15个“新一线”城市中成都排位第一，依次是成都、杭州、重庆、武汉、苏州、西安、天津、南京、郑州、长沙、沈阳、青岛、宁波、东莞和无锡。 用数据描绘成都 ↓↓↓↓↓ 商业资源集聚度·排名第一 消费品牌门店总数连续三年超过广州 在第一财经·新一线城市研究所看来，门店选址是商业社会中最为精明且谨慎的逻辑。今年，这套方法得到了进一步升级。 在今年的商业资源集聚度中，考察大品牌青睐度——大品牌如何选择城市，代表着品牌对城市商业品质氛围的认可。成都依然是西南地区大品牌进驻的首选城市，成都的消费品牌门店总数连续三年超过广州及其他“新一线”城市。 城市枢纽性·排名第一 交通是联通城市的物质基础 若是把城市之间的关联比喻成一张网，那么每一座城市都是网络中的节点。强辐射力的城市向周边城市输送更多的商品、资源与人才，弱辐射力的城市往往处于被动接收辐射的地位。这种输送的能力——即枢纽性，是城市重要的竞争力之一。 交通是联通城市的物质基础，在这个维度，榜单既考虑了城市的高铁站数量、民航可直达城市数、经过高速公路条数等城际交通基础设施类数据，也用城市之间通过铁路、民航与高速公路等交通工具的城际往来矩阵分别计算了城市在交通网络中的枢纽性。 今年的物流通达度指数在物流网点数量之外，新增了各城市收寄包裹的数据。 商业资源区域中心度指数计算的是城市中各商业品牌与其所在区域内其它城市联系度的总和。华南的广州和深圳、西南的成都和重庆、东北的沈阳和大连商业资源分配相对“均势”，而上海、北京、武汉和西安在各自区域内则具有绝对优势。 城市人活跃度·排名第一 成都是日均观影规模最大的新一线城市之一 消费活跃度指数是衡量城市人是否活跃的基础指标，也意味着城市人的支付能力以及整座城市在线上线下同步提供商业服务的能力。成都、武汉和重庆等中西部城市是日均观影规模最大的新一线城市，足够的人口规模为当地的观影消费市场提供了充足的潜在客源。 不安分指数衡量的是城市向上生长更新的欲望，它代表了一种积极的生活状态。成都是不安分指数最高的新一线城市。成都人乐于在旅行平台上分享自己的旅游记录，也迅速接纳了新生的共享单车，并保持着很高的日常骑行活跃度数据。 生活方式多样性·排名第一 成都等城市更愿意在音乐上投入资金 今年榜单建构了生活方式多样性指数的算法框架，从出门新鲜度、休闲丰富度和消费多样性三方面更聚焦地衡量这个与城市人生活感知密切相关的指数。 更多的人开始跑步、健身、阅读、听音乐和旅行，这些休闲活动类数据都可以用来衡量城市人的休闲丰富度。 通过电影票房、音乐App的付费意愿、淘宝线上消费商品的多样性、对星级酒店的偏好与旅游产品的购买意愿，能观察到城市人多样的消费类型。从数据看，成都、南京和杭州相比其他城市更愿意在音乐上投入资金。 未来可塑性·排名第一 成都是创业环境最好的“新一线”城市 创新能力是城市可塑潜力的重要一环，初创公司是最主要的创新主体之一。数据显示，杭州、成都创业平台数量和融资规模仅次于一线城市，是创业环境最好的新一线城市。 这一指数还考虑了城市人消费行为中的商品信息关注度、会员用户情况。越来越多追求理性与品质的消费行为，会给城市商业带来新的升级空间。 城市的GDP和人口数据也纳入考量。在考虑规模基数的前提下，不同级别的城市突破各自增长瓶颈的能力多少给了人们对未来的信心，也让人们相信自己的选择。成都商报记者 叶燕 相关： 一套评估体系包含五大指标 在最新的中国城市商业魅力排行榜中，记者看到，四个一线城市为上海、北京、深圳、广州。15个“新一线”城市依次是成都、杭州、重庆、武汉、苏州、西安、天津、南京、郑州、长沙、沈阳、青岛、宁波、东莞和无锡。 第一财经·新一线城市研究所说明，这是利用城市数据建立一套评估体系，依据最新一年的170个品牌商业数据、19家互联网公司的用户行为数据及数据机构的城市大数据，对中国338个地级以上城市再次排名。 为保证榜单的延续性与可比性，这份2018年最新的城市商业魅力排行榜沿用了上一年的商业资源集聚度、城市枢纽性、城市人活跃度、生活方式多样性和未来可塑性五大指标，并维持了原有的算法框架：一级指数的权重以新一线城市研究所专家委员会打分的方式计入，二级指数以下的数据则采用主成分分析法。 中国城市格局悄然发生变化。在新一线城市中，成都排名第一，在多个维度成绩亮眼；无锡经过一年的蛰伏重返新一线；重庆、苏州、郑州是位次连续3年上升的3个城市。 越来越多城市都充分意识到，人才是城市发展的核心。今年年初，南京、杭州、成都、西安和武汉等新一线城市都相继出台人才新政，吸引高校学生和专业技术人员落户。这是一场“人才争夺战”，更是城市发展核心要素的抢滩。 转载来源：2018中国新一线城市排名出炉！成都稳居第一！]]></content>
      <categories>
        <category>房产</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>创业</tag>
        <tag>大数据</tag>
        <tag>中国联通</tag>
        <tag>酒店</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K12社群运营容易忽视的几个细节和思考]]></title>
    <url>%2F2018%2Fbcfe4894%2F</url>
    <content type="text"><![CDATA[社群邀请了教育行业专家、学者、创始人、老师等人，不定期对当下的热点话题、细分领域、教育现象进行探讨和分享。 【智囊分享】是“芥末堆｜教育智囊团”组织的社群活动。社群邀请了教育行业专家、学者、创始人、老师等人，不定期对当下的热点话题、细分领域、教育现象进行探讨和分享。 在教育行业，社群运营也被视为招生获客的最佳路径。很多教育公司也一早锁准了这条低成本的获客之道。比如传智博客、好未来的家长帮、宝宝玩英语的微信生态等。在本期中，国内某知名K12公司的小明老师（化名）分享了大家在社群运营过程中容易忽视的几个细节和思考。 以下是分享实录，供大家参阅。 对于社群运营，今年我们看到了很多刷屏级的活动，大家很兴奋，想复制这种模式，很多做社群的小伙伴貌似又看到了做社群的希望。我个人觉得虽然社群运营操作门槛低，我不讲如何能做出现象级刷屏的活动，第一，我觉得毕竟还是少数人可以操盘，我们更多的是吃瓜群众，应该脚踏实地做好每一步的运营；第二。我们多一些最基本的思考，如何设计属于适合自己的增长模型，如何在每一个环节达到最大的转化，从而实现营收。 现在做社群相信市面也有很多很成熟的体系，大家也听过很多社群营销的课程，接下来我的分享，仅限于自己对于K12社群运营的简单思考。 一、对于K12社群运营的理解科学、系统、高效是我对K12用户的社群运营结构最基本的理解。科学是指社群依据在线教育产品如何利用内容、模式以及产品实现增长和转化；系统是指社群运营如何解决从用户参与到转化的过程达到系统化运转；高效是指如何利用工具、团队以及内容实现社群的高效运转。 用户结构根据中小学生对于学习有着长期、稳定、刚性需求这三个特点：学生作为直接参与者以及效果的反馈者，家长作为产品选择者和付费决策者，老师作为内容生产者，根据不同的角色，社群运营出现了不同的运营策略。 二、关于社群运营基本思维、工具、技巧（一）社群运营最基本的思维：势 1.运营和推广：比如早前几年朋友圈推出的各种测试、H5以及近期的何种刷屏活动，裂变手段，好友互动、成绩比拼、微信群PK、朋友圈晒成绩，如果你第一时间掌握了，将瞬间实现流量的爆发。 2.热点和爆款：综艺节目类似与朗读的节目、政策的红利（高考改革）、内容（稀缺性资料以及课程）等等，如何策划出爆款活动，懂得势在哪里。 3。工具和产品：现在技术的发展远远比我们想象的快，对于社群裂变、个人号裂变、公众号裂变等，每一个细分的领域都会有更先进的工具出现，在第一时间掌握最新的工具，结合自己的优势，实现高效的增长。 （二）出现的社群模式 群裂变模式 对于7天搞定xx、21天xx训练营,领取xx课程等等活动，借助活码群裂变工具，成为很多做社群运营忠实的方式，看起来能获得一大批对于某项福利感兴趣的用户，但是这些群变现的转化率较低，用户很难产生黏性，一旦入群发现是推广课程、公众号，用户产生了抵触情绪，使得变现和留存成为最大的难题。 2、打卡模式 相信很多做在线教育的小伙伴并不会陌生，利用学习训练营打卡模式，打卡的平台有小程序、公众号、H5等产品。形式有点击打卡（小程序、H5）、分享链接、海报等打卡方式，分享的渠道多集中于朋友圈。打卡在社群中意味着一种态度还有短时间养成一种好习惯，根据打卡的格式、时间以及规则，要求的是对于社群高效组织。 例如：对于刷屏的薄荷阅读，薄荷阅读通过微信公众号打卡、带班老师每日讲解+答疑、社群成员督促等多种机制来确保用户完成每日的学习任务。 在“社群老师”的引导下，群成员每天完成“每日一句”、“今日词表”、“边听边读”、“课后习题”、“答疑讲课”等学习环节,在最后一天完成所有阅读的成员可获得本次课程笔记的永久阅读权限，未完成者无法再查看阅读内容，通过激励/惩罚措施来提高群成员达成目标的完成率。 （三）社群需要掌握的工具：托 1、整合资源 比如在举办某些大会或者课程时，我们需要一些大咖或者嘉宾出面，如果我们没有太多的经费和资源，这个时候，我们可能会先联系最有可能搞定的嘉宾，同时我们会联系和他同样级别的嘉宾，然后分别对双方说都会出席同一场活动，这种通过对方当托，实现资源协调的方式利用好，实现事半功倍的效果，再比如大家熟知的吃火锅的案例。 2、旁敲侧击 用户在群内发出一些不利于群规的链接和信息等，出于对用户意识到问题的目的，我们在群内让托犯同样的错误，予以警告或者剔除，通过旁敲侧击，让用户意识到问题，不再犯类似的错误。所以当我们不想直接处理，但又不得不这么做的时候，我们可以用“托”的方式去旁敲侧击一下。 3、以假乱真 对于一个社群刚刚建立的时候，用户有很强的戒备心，如何破冰和解决信任度的问题。 这个时候我们就要利用托的身份假扮成用户，主要目的就是以用户的身份产生互动，产生交流，增强彼此的信赖度，用户的心理防线就会慢慢降低，我们在进行宣传和推广。 4、以身作则 针对福利活动，出现了运营流程的错误或者由于参与人数太少，导致用户怀疑能不能按照预期获得他应该得到的东西。流程上由于一些特殊原因没能及时准备。这种时候如果不及时处理的话，会造成大面积的用户反抗行为。对于活动如果由于参加的用户较少，用户对活动的奖励也存在着半信半疑的态度。 此时，我们可以利用托进行澄清说明，声称自己已经拿到了奖品。同时要说明奖品是依据规则获得，会陆续发放，请大家耐心等待。用户看到了其他人已经拿到，而自己只是时间上稍微晚一点的话，会比较容易接受。这不是为了骗人，而是为了给我们争取时间来弥补过失。 （四）社群需要掌握的分享技巧 利用内容和福利刺激用户实现转发分享，对于增强用户的接受程度，目前常见的几种方式如下： 1、前置分享 A、对于用户要获取福利就必须按照要求转发，通过审核之后才可以获取利益。需要工具的支持和人工不阶段的审核。 缺点在于，随着群内人群的增多，对利益的需求就会越来越大。比如增送小礼品，人数增多，成本增大，最好的选择就是我们能够提供复制不产生成本的利益，比如工具、视频、电子书、网络教程、人脉资源等等。 B、用户自己参与条件不够，需获得更大的利益，需要邀请让人分享获得抽奖机会或者免费名额，比如小米的一分抢购助力。利用了人贪便宜和赌博的心理实现裂变。 2、后置分享 A、大部分用户为了获得福利，朋友圈觉得对于其他的好友来说不合适，比如集赞、助力等，所以在这个时候我们让转发的人和被吸引人的人同时获取福利，就会打消转发者的心理顾虑，这也是满足了社交中的利他属性。比如：报一次课需要100，但是双人同时报每人只要60元，用户的接受程度就比较高了。 转载来源：K12社群运营容易忽视的几个细节和思考]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>市场营销</tag>
        <tag>在线教育</tag>
        <tag>移动互联网</tag>
        <tag>朋友圈</tag>
        <tag>薄荷</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[焦点解读 | 大疆10亿美元融资样本：三大关键点存疑，投资者分歧加剧]]></title>
    <url>%2F2018%2F14467c74%2F</url>
    <content type="text"><![CDATA[科技独角兽的高溢价时代 焦点解毒 | 大疆10亿美元融资样本：三大关键点存疑，投资者分歧加剧_36氪 转载来源：焦点解读 | 大疆10亿美元融资样本：三大关键点存疑，投资者分歧加剧]]></content>
  </entry>
  <entry>
    <title><![CDATA[1分钟知识锦囊 | 听说开发者都喜欢用游戏来训练AI，为什么？]]></title>
    <url>%2F2018%2F870b0c9e%2F</url>
    <content type="text"><![CDATA[AI 在训练场中可以学习如何跟人类一起合作。 1分钟知识锦囊 | 听说开发者都喜欢用游戏来训练AI，为什么？ _36氪 转载来源：1分钟知识锦囊 | 听说开发者都喜欢用游戏来训练AI，为什么？]]></content>
  </entry>
  <entry>
    <title><![CDATA[从无监督构建词库看「最小熵原理」，套路是如何炼成的]]></title>
    <url>%2F2018%2Fb8f4fc62%2F</url>
    <content type="text"><![CDATA[在深度学习等端到端方案已经逐步席卷NLP的今天，你是否还愿意去思考自然语言背后的基本原理？ 转载来源：从无监督构建词库看「最小熵原理」，套路是如何炼成的]]></content>
      <tags>
        <tag>PaperWeekly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小学一年级语文题碾轧家长智商 专家：小学生作业不宜太难]]></title>
    <url>%2F2018%2F862625ba%2F</url>
    <content type="text"><![CDATA[一道小学一年级的语文作业题，不仅难倒了大学本科毕业的小学生爸妈及众多家长，还在一个从事文字工作的编辑群里引发了热烈讨论，说法不一。 来源&#58;燕赵晚报 小学一年级语文题碾轧家长智商 专家：小学生作业不宜太难，应少些标准多给空间，培养开阔思维 “人多，什么游戏都能玩，拔河，老鹰捉小鸡，打排球，打篮球，踢足球……连开运动会也可以。”请问，这段选文一共有几句话？一道小学一年级的语文作业题，不仅难倒了大学本科毕业的小学生爸妈及众多家长，还在一个从事文字工作的编辑群里引发了热烈讨论，说法不一。 近来，关于小学生作业频频碾轧爸妈智商的案例屡见不鲜，不少父母发帖吐槽，是小学生作业太难了，还是家长们知识落伍了？相关教育专家认为，小学生作业不宜太难，也不宜标准太僵化，在答案上应该多给空间，才不致于把孩子的思维“圈”得太死。 家长们每天讨论孩子们的作业题 梁女士和爱人都是大学毕业，儿子上小学一年级，平时梁女士负责给孩子辅导作业。按常理，小学一年级的作业是最简单的，但是却经常让她感到挠头，比如一道数学题：“数字按从小到大的顺序排列，7的前面有几个数？”梁女士就弄不清是“7”还是“6”，因为不知道是不是包括“0”。还有一道数学题：32-6=？答案肯定是26，但是试卷要求写出做题分解过程，儿子分解的是32拆分成30和2，30-6=24，24+2=26，被判错了；正确答案是32拆分成20和12，12-6=6，20+6=26。这叫梁女士很是不解：“为什么32只能分解成20和12才算对？这个标准也太僵化了！” 在梁女士儿子所在班的家长群里，家长们每天都在为孩子们的作业题而讨论，哪道题怎么做，正确答案应该是什么？为什么正确答案是这样的…… 最近，一道语文题让梁女士和家长们颇费脑筋，是老师发的期中模拟卷上的题：“人多，什么游戏都能玩，拔河，老鹰捉小鸡，打排球，打篮球，踢足球……连开运动会也可以。”请问，这段选文一共有几句话？梁女士是中文系毕业，从事的也是文字工作，她认为这段选文应该是一句话，因为通篇表达了一个意思，但是她又不确定。到底应该是几句话，家长们在群里集思广益后也没有讨论出结果。梁女士又发到了朋友圈，朋友们给出的答案也不一样，有的说是一句话，有的说是两句话，还有的说是三句话。昨日，梁女士又把这道题发到了一个编辑工作群里，群里都是从事文字工作的专业人士，大家议论纷纷，仍然没讨论清楚到底是几句话，有人说是一句话，理由是通篇表达了一个意思；有人说是两句话，因为中间出现了省略号，省略号代表一句终结。在讨论中，大家纷纷感慨，现在的小学生语文题竟然让专业的文字工作者都“拿不准”，是成年人知识结构过时了？还是小学生的题出得太难了？ 小学生作业频频碾轧爸妈智商 梁女士的作业难题一抛出，引来了一片共鸣声，很多爸妈吐槽孩子作业太难了，智商受到无情碾轧，甚至开始怀疑所受的教育。 在一家事业单位工作的黄女士说，她的儿子上小学二年级，前一阵子试卷上的题也把她难住了，是卷子里拓展题中的图型填字题，上面是“车”、左边是“齿”、右边是“流”、下面是“班”，要求在中间填个字，使上下左右的字均可组成词语，她想了很长时间，想出来一个“轮”字；后一道题型类似：上边是“大”、下边是“风”、左边是“日”、右边是“思”，中间要求填个字，使上下左右的字都能组成词语，她就怎么也想不出来了。只能告诉儿子，等老师公布答案吧。黄女士说，她最怕的还是数学题，比如“一堆桃子，5个5个地数余3个，7个7个地数也余3个，这堆桃子至少多少个？”还有填字游戏，要求把1-10这几个数填入图中，使图型每条线上的四个数之和都相等……这些题都让自己很蒙，觉得学过的数学完全不够用。 同为小学生家长的王女士则主要依赖作业帮和百度，每有不会的题，就上网搜索答案，再给孩子讲，但即使如此，也经常会有弄不明白的题，只能向老师求助。 在网上，因为孩子作业难而吐槽、求助的帖子更是数不胜数。一个叫“红火火”的网友发帖说：“求各位大神帮帮忙，一道小学三年级的题目把我们难倒了，我和她爸爸都是大学本科毕业，现在大学生被小学题难住了，感觉自己辅导孩子学习没有信心了”。这个帖子很火，后面跟帖一片，一些网友给出自己的答案，更多的网友则发出共鸣，讲述自己遇到的各种奇葩的小学题，想去网上搜索答案都搜不到，很无奈很崩溃。网友纷纷感慨：“感觉这些小学生作业是对自己智商的无情碾轧”“想想自己上了十几年学都白上了”…… 专家： 小学生作业应弱化标准 让梁女士挠头多日的语文题究竟答案是什么？她终于忍不住给老师发短信询问，老师的回复是：两句，因为省略号代表一句话。 石家庄市教育科学研究所高中组的李慎老师则做了更详细的解释。她说，这道题考的其实是学生对标点符号的认知，在标点符号使用规范中，标点符号分为“标号”和“点号”，“点号”又分“句中点号”和“句末点号”，“句中点号”包括顿号、逗号、分号等，“句末点号”包括句号、问号、叹号、省略号等。在这段话里，出现了省略号和句号两个“句末点号”，就是两句话。如果再细分一下省略号的归属，用于一串名词后面表示列举的不能单独成句，用于带有动词、形容词的句子后面的可单独成句，这段话中省略号列举的正是可单独成句的动词组。 李慎老师说，这样的题应该是小学三、四年级的题型，如果是小学一年级，还是有些难了。一段文字包括几句话应该是标点符号和内容结合来判断，小学一年级的孩子很难做到这一点。小学生的理解能力有限，一些题目超出他们的理解能力后就很难讲解，经常有小学的教研员来请教她，如何对学生解释明白一道题的答案，她也很为难。她认为现在小学生的作业题、考试题很多是形式大于内容，过于追求形式上的标准，而不是内容上的实用，同样的一段话，与其让孩子们回答这是几句话，不如让孩子们去体会这段话的意思，体会文字的美感。在答案上也该多给些空间，只要是合理的能够自圆其说的都该鼓励，不能用过于僵化的标准来“圈”住孩子们的思维。 老师： 家长可与老师多交流 针对家长们经常被小学题目难住的困惑，在省会一所重点中学任教的刘老师也提出了自己的看法。她说，小学生的作业题多数是根据课程教材来出的，考量的是课堂上学过的某个知识点，家长们虽然受过高等教育，但很可能已经忘记小学学过的知识了，又对教材不熟悉的话，有时候的确会蒙。她建议家长多跟孩子交流，只有熟悉小学生的课本才能更好地帮助他们，如果家长的确觉得难，还可以跟老师交流，要求降低作业难度。而且，尽量鼓励小学生自己动脑动手解决问题，家长不要包办太多。 此前，石家庄市教育局还专门出台了《关于进一步加强小学生作业管理工作的通知》，要求学校不得布置超越学生能力的作业，以尽力解决小学生作业方面的困扰。文件还明确提出，小学生作业布置数量要适当，难易要适度。加强作业形式的灵活性和情趣性，调动学生的学习积极性和创造力。（记者 刘文静） 转载来源：小学一年级语文题碾轧家长智商 专家：小学生作业不宜太难]]></content>
      <categories>
        <category>教育</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>大学</tag>
        <tag>语文</tag>
        <tag>排球</tag>
        <tag>升学考试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国教育O2O服务行业白皮书]]></title>
    <url>%2F2018%2Fb6a554fb%2F</url>
    <content type="text"><![CDATA[市场特征：中国教育培训市场整体呈现潜力大、机会多、创新性强且竞争激烈的特点，未来市场整体将走向深度融合之态。 核心结论 教育培训行业 发展驱动力：中国教育培训行业的发展受频发的利好政策、不断更新迭代的技术和越发多元的市场需求共同驱动。- 市场特征：中国教育培训市场整体呈现潜力大、机会多、创新性强且竞争激烈的特点，未来市场整体将走向深度融合之态。- 营销痛点：市场营销渠道不断丰富，但企业面临获客成本高、市场竞争强和用户转移成本高的不足，而用户缺乏一个具有公信力的、用户信任的第三方渠道来为用户筛选信息、做决策等活动提供参考。市场特征：中国教育培训市场整体呈现潜力大、机会多、创新性强且竞争激烈的特点，未来市场整体将走向深度融合之态。 教育O2O平台 核心价值：教育O2O模式提升了用户选择培训机构的效率，增加了机构/教师的曝光度，为“互联网+”与教育的结合提供了宝贵的经验和借鉴意义。- 发展趋势：未来，教育O2O平台将优化升级平台服务能力，平台功能向重量级方向发展；平台整体上将会重构教学流程和服务模式，线上线下业务走向深度融合的OMO形态。发展趋势：未来，教育O2O平台将优化升级平台服务能力，平台功能向重量级方向发展；平台整体上将会重构教学流程和服务模式，线上线下业务走向深度融合的OMO形态。 中国教育培训行业的特征 线下教育市场步入理性思考，并积极拥抱互联网 中国教育培训行业始于20世纪80年代，改革开放使得国门打开，外企得以入驻，人才变得紧缺且复合化，职业培训市场开始兴起。随后市场逐步开化，留学培训市场开始繁荣。进入2000年，中国加入WTO，社会对人才的要求越来越高，终生学习的理念开始盛行，家庭经济的好转也催生出”不让孩子输在起跑线”的意识，一大批中小学教育辅导机构开始涌现，市场迎来高速发展。2013年以后，线下培训市场竞争趋于白热化，一方面，为吸引生源“保分保效果”等代名词开始出现，但实际效果不佳；另一方面，市场门槛低，一大批人入行掘金，行业赛道混乱、口碑下滑，因此用户对市场的信任度下降，倒逼企业反思。同期，随着互联网元年的到来，受新兴科技与互联网的影响，教育+互联网的新业态开始形成，在线教育浪潮开始兴起。 利好政策频发，市场秩序不断规范，助力市场健康有序发展 中国教育培训市场的发展无法脱离国家政策的保驾护航。新修订的《民办教育促进法》明确了对民办学校举办者合法权益的保护，同时“负面清单”和联合监管机制规范了校外教育培训机构，市场将在迎来一轮清洗后进入良性的健康发展期。针对新兴技术与教育的结合，国家大力推行教育信息化，以将优质教育资源输出，同时在学习行为数据化的基础上利用人工智能技术实现智能教育、个性化教育，促进教育公平而有质量。在人才引进/输出方面，一方面，减少留学流程，优化回国人员服务；另一方面，促进中外合作办学，学习借鉴各国教育发展成功经验，取长补短，互利互补，提高办学质量。 技术创新更迭快，不断与教育融合，提升教与学的效率 技术进步是中国教育培训发展的基础，每一次技术的变革都是提升教学效率和教学体验升级的催化剂。互联网的普及与完善使得多媒体教学得以推广，让部分教学活动从粉笔板书中解放出来，提升了教与学的效率，同时也为大范围在线教育提供可能，降低了用户知识获取的成本；语音图像识别、在线测评、互动直播，不仅覆盖了教学活动中的教-学-练-测-评各个环节，丰富了学习场景，而且将用户学习行为记录下来，为个性化教学、自适应学习提供了数据支撑。未来，当人工智能技术深度融合于教育教学环节时，教学活动各个环节的时间成本将有效释放，高质量的、有效的智能化教学时代将开启。 生活水平逐步提升，催生市场各类需求，推动市场发展 改革开放后经济复苏，人们生活水平得到极大提升，人们在人均文教娱乐方面的支出持续增长，自2010年开始，全国人均教育文化娱乐支出保持年均10%左右的增速，市场消费意愿持续高涨。经济基础和时代环境的变化催生着教育需求的变化，为满足市场需求，教育培训市场的企业数量和品类逐渐丰富，并且随着人工智能等新兴技术的发展，用户对个性化、定制化的需求急剧显现，对减少重复学习提升学习效率的自适应学习等智能化的学习期望也越来越强烈，表现为资本市场和创业市场对线上教育的不断深耕，教育培训市场以新兴科技为基础的新科技萌芽时代已经开启。 音乐、外语、兴趣等领域的需求大于供给，市场可拓性强 从美团点评平台的机构和用户分布来看，音乐、外语、兴趣生活和留学培训等市场领域目前需求大于供给，市场的可拓性强，市场机会也相对较多。但从市场的更替来看，目前兴趣生活、驾校、外语培训的市场淘汰率相对较高，其中兴趣生活的替换率最高。 资本和技术推动教育培训市场不断创新，市场潜力大、机会多、创新性强且竞争激烈，市场整体将走向深度融合之态 从整体来看，教育培训的需求市场不断变化进而推动整个教育培训市场的繁荣发展。现阶段，中国教育培训市场潜力巨大，而且基于国内互联网的快速发展，新兴技术与教育的不断融合，教育培训市场不断有新的基因注入。同时在资本的推动下，新的商业模式、深度垂直细分的赛道以及创新教学及管理等频频引领市场新的竞争热点，整个教育培训市场呈现资本热、机会多、创新性强、竞争激烈的特点，未来提升教学效率和效果将是永恒的主题，市场整体将走向深度融合。 营销方式随时代变迁而丰富，营销的本质是利用多种运营手段让用户产生消费，并在此过程中建立企业品牌形象 营销的本质在于让用户产生消费，AIDA模式（“爱达”公式）是一个经典的营销模型，它将销售阶段化，即吸引用户注意—引起用户兴趣和认同—激发用户购买欲望—产生购买行为。但让用户产生购买行为并非营销终点，用户的重复购买和推荐不仅能够引导潜在用户池的有效转化，而且能促进企业品牌形象的树立，进而形成用户认知-转化-推荐的闭环。现阶段基于互联网，营销的手段越发丰富，营销方式也变得更加灵活多变，传统的营销方式如发传单、广播、电视等，与线上的搜索、弹窗广告、社群运营等网络营销手段相结合，企业将有更多渠道和机会接触达用户进而完成转化，营销将在企业运营和品牌建立中发挥越来越大的价值。 获客成本高、市场竞争强和用户转移成本高是企业运营痛点 中国教育培训行业发展至今，其市场营销的本质虽然未变，但随着市场的成熟和行业宏观环境的变化，市场营销面临着越来越多的挑战。目前获客成本高是各培训机构普遍面临的挑战，一方面是用户常用的营销渠道（如百度）竞争格局相对单一，为寡头垄断型，故用户的导流作用受营销成本影响大；另一方面，不同教育领域或同一教育领域不同角色的用户做决策时侧重点不同，如家长用户对品牌知名度、名师的要求高，看重服务的权威性，而学生则对营销内容的娱乐性等更为敏感，且存在家长与学生意见相左的情况，营销成本无形增加。从市场竞争角度来看，拥有口碑的机构已形成较强的竞争壁垒，在市场竞争中占据强势地位；而同品类的长尾机构同质化明显，让用户无从抉择。同时教育培训市场的营销也受行业本身的慢所限，当用户选择了合适的老师时，再次更换机构/老师的可能性较低，即市场的客户转移成本高。 一个具有公信力的、用户信任的第三方渠道可为用户筛选信息、做决策等提供有效参考 目前中国教育培训市场企业林立且在教学内容、师资力量和产品服务上同质化已十分明显，而用户通过专业的与教育相关的途径去了解相关信息的可行性低，大部分用户做决策时都是随大流。除了从众心理，从诸多繁杂的培训机构中做出决策的未知性本身就会给用户带来一定焦虑感，而该种焦虑感容易被利用。此外，互联网时代营销无处不在，用户身处各种营销触点之下，市场上常见的能够为用户提供信息的媒介大部分都是企业营销的途径，一定程度上带有目的和导向性。因此市场急需一个具有公信力的、权威的、用户信任的第三方渠道为用户筛选培训机构时提供参考，以降低用户与培训机构信息的不对称，节省用户的时间成本和试错成本。 提升了教学及管理效率，降低了运营成本 互联网+教育打破了空间限制，优化了资源配置，缓解了教育资源分布不均的问题。在提升效率方面，互联网+教育使得用户学习行为和机构管理可线上化、数据化，一方面，为用户精准推荐学习内容逐步成为可能；另一方面，教育SaaS的应用提升了企业的运营管理效率。在营销推广方面，互联网丰富了企业的推广渠道，增加了企业触达用户的途径，降低了企业的推广成本，同时也倒逼企业优化服务、寻找差异性，从而增加用户转化。 中国教育O2O服务平台的特征 平台主要负责提供教育培训的相关信息，并在线下完成上课 普遍意义的教育O2O模式是指教育培训企业在各种互联网技术的基础上，通过不断整合线上线下学生资源和教育资源，实现学生线上支付课程费用而在线下完成学习活动的一种教育模式。本报告所定义的教育O2O服务平台的主要特点是平台以提供教育培训信息为主，而不生产或不主要负责对外生产教学内容，并且相关学习活动是在线下进行，它既包括疯狂老师、轻轻家教、艺好学等垂直类教育领域平台，也包括决胜网、美团点评这样的综合类教育导购平台。 纵观教育O2O模式的发展历程，其繁荣发展阶段和市场洗牌阶段出现的都很快，没有长时间的跨度，主要是因为互联网思维模式的快与教育行业的慢相结合时产生了极大的不对等，因此在未来的一段时间，教育O2O赛道上的玩家将处于思变期，蓄势待发，谋求破局。 教育O2O平台基于线下教学，平台主要是将信息聚集并分发给用户，而其他平台则发挥着聚合或自营主体的作用 教育O2O平台与其他在线教育平台相比，主要是在教学形式和平台作用方面有很大的差别。在教学形式上，教育O2O平台的学习场景主要在线下进行，而其他在线教育平台按照自己的业务或课程特色可以选择线上教学、线下教学或线上线下相结合的方式，具有自主性。在平台作用方面，教育O2O平台主要是将机构/教师信息集中起来，然后分发给用户，提升用户筛选效率和选择空间，并且为中小机构带来流量；而B2B2C和B2C教育平台则分别承担着教育载体的角色和自营主体的角色。 教育O2O模式提升了用户的选择效率，增加了机构/教师的曝光度，是“互联网+教育” 的先行者 教育O2O平台充分挖掘线下资源，将具有不同教学特色、不同教学方式的教师信息及用户评论通过平台展现给用户，不仅拓展了用户的选择空间，降低了市场信息的不对称，而且为用户做决策时提供了参考评论，增加了用户对业内企业/机构的了解。从机构/教师角度来讲，教育O2O增加了机构/教师的曝光度，降低了运营成本，并为中小机构和个体教师在大的教育机构垄断大部分市场的前提下增加了机会。从行业整体来讲，教育O2O模式不仅丰富了在线教育的商业模式，更重要的是教育O2O平台的不断试错为互联网与教育的不断融合与深度发展提供了宝贵的借鉴意义，将引导教育+互联网正向发展。 教育客观环境的不足以及产品端在服务体系和服务能力等方面的缺陷是教育O2O平台所面临的主要挑战 教育O2O平台发展之初创业市场和资本市场纷纷急于抢占赛道而缺少对教育与互联网结合的思考，故教育O2O平台的不足快速显现。从客观环境来讲，教育O2O平台既无法脱离教育本身的特性，又无法摆脱互联网的要求，对师资、内容和流量的要求都很高。从产品模式来看，平台的用户粘性不高，平台对用户提供的服务更像一次性买卖，用户一旦与教师建立联系后完全可以脱离平台，而且平台在用户想要找到最适合的老师的这项需求上发力不足，产品无论是在服务体系上还是在服务能力等方面都亟待升级，以提升用户粘性，增加行业竞争壁垒。 教育O2O平台功能持续优化，升级服务能力，提升竞争壁垒 现阶段大部分教育O2O平台对用户的服务止于找到适合的老师，而未将服务延伸至找到老师后，并且用户普遍认为平台评价内容的参考价值有待提升，平台整体技术竞争壁垒也不高。随着业内企业的不断反思与用户对信息有效性的需求越发旺盛，教育O2O平台将持续优化并完善平台的功能和服务体系，从而为用户提供更有效的、更精准的、更个性化的信息和教学活动服务，而平台的功能和服务也势必向重量级方向发展。目前美团点评在平台的服务能力和服务体系方面不断优化并升级，一方面平台为用户提供了海量的信息供给，而且针对评价体系和评价真伪性两方面双管齐下，增加了用户信任度的同时也提升了用户的筛选效率。另一方面，平台还致力于打通机构间的合作，试图为用户提供更多的增值服务，以向用户传递可持续的服务价值。 未来教育O2O平台将是线上线下深度融合的OMO形态 教育O2O平台的用户具有低频且对平台低依赖性的特点，究其原因在于平台无法将用户从购买服务-享受服务-服务后的各个环节形成闭环。经过市场经验的总结及摸索，以美团点评学习培训为例，作为教育O2O服务行业的头部平台，不断向打通教学活动各环节、对接上下游企业等方向发力，试图将企业线上线下数据进行深度融合，进而形成用户、教师、平台的共生价值：一方面，平台通过打通各个企业间的合作实现教学流程的重构，既为用户提供基本信息服务，又满足了用户对优质师资和教育资源的需求；另一方面，完善的服务体系将吸引师生重返平台，平台得以再次掌握用户的学习行为数据，进一步提升推荐精准度，实现教师和用户之间的良性反馈。艾瑞认为平台全量信息的聚集将使得平台服务能力和服务体系向更加稳定而成熟的服务闭环发展。 中国教育O2O服务平台用户洞察 升学考试类用户重视预约且下单较为慎重 从美团点评平台的用户购买行为来看，升学考试类用户与兴趣技能类用户的购买行为有较大差异。升学考试类用户面临较大的升学及考试压力，重视教学效果，故做决策时更加慎重，他们往往通过平台获取培训机构信息后预约到培训机构了解完具体情况后再判断是否交易，占比为74.3%。而兴趣技能类用户相对而言压力小，更多的是为了发展自己的兴趣或者提升自己的素养，并且该类产品需要通过试听体验来判断产品/服务是否适合自己，故用户对试听的性价比要求较高，因此用户除了通过平台预约外，更喜欢在平台团购体验课。 师资力量是用户预约试听时考虑的首要因素 从用户预约试听时考虑的因素来看，“师资力量”是家长用户和成人用户预约试听时考虑的首要因素，占比分别为63.0%和50.1%，紧随其后的就是“机构知名度”，占比分别为53.1%和41.9%。 相比于家长用户，成人用户更加看重“培训体系/教材”和“资料完整程度”等因素，这可能是由于成人用户的学习自主性和目的性强，故对所学教材类型和资料的完整度有更高的要求。 家长用户更重课程体系设置，成人用户更重试听课体验 从用户判断产品/服务质量好坏的标准来看，家长用户更加重视“课程体系设置”，占比为63.8%，其次为“试听课体验”、“教学方法”和“学习环境/氛围”。而成人用户最为注重“试听课体验”，其占比最高为50.5%，“课程体系设置”和“学习环境/氛围”紧随其后，分别为48.8%和45.1%。这或许是由于家长用户的孩子处于K12阶段，更需要系统的教学，故更重视课程设置，而成人用户则更多的是有目的性的学习，试听课有助于他们判断课程或服务是否符合他们的需求，故试听体验对他们的影响更大。在这个过程中，教育O2O平台既可以让商户提供更优质的服务，满足单次体验的标准化，又可以让用户高效获取信息，降低用户的时间成本和决策成本。 师资力量是用户做出付费决定的最主要的因素 从用户付费的决定因素来看，家长用户和成人用户在付费前的考虑因素大致相似，“师资力量”从诸多因素中脱颖而出成为最主要的因素，其占比分别为57.0%和48.8%，紧随其后的就是“品牌知名度”和“教学方法”这两方面。 整体来看，家长用户考虑的因素更加宽泛，而成人用户则相对集中在“师资力量”方面。家长用户和成人用户对“价格”和“地理位置”的敏感度均较低。 用户在购买产品/服务前均会货比“三”家 根据本次调查，用户在购买产品/服务前均会对比其他家的同类产品/服务，无论是家长用户还是成人用户，其对比的平均机构数为3家。 15人以内的小班课是用户最偏爱的班型 从用户班型的偏好来看，2-15人的小班课备受用户偏爱，其中，6-10人的班型最受家长用户和成人用户欢迎，其占比分别为38.5%和31.5%。一方面，小班课的容量易让每个学生受到老师的关注，从心里产生对学习的积极性；另一方面，小班课的费用较一对一教学要低，性价比高。 平台信息丰富选择空间大是用户使用教育O2O平台的主因 从用户使用教育O2O服务平台的原因来看，“平台信息丰富，可选择的企业/机构多”是家长用户和成人用户使用该类平台的主要原因，其占比分别为66.1%和51.3%。除此之外，家长用户对平台的“可对比不同机构的价位、师资等”、“可参考其他用户评价”等功能比较注重；而成人用户则相对更加关注平台的“可免费或低价试听”及“可对比不同机构的价位、师资等”功能。选择被广告导流进入或随手点击进入的用户占比较少，这说明用户对教育O2O平台的使用具有主动性。 平台信息丰富全面但存在教师刷课时、刷评论等现象 从用户对教育O2O服务平台的直观印象来看，“平台信息丰富全面”是家长用户和成人用户最为直观的印象，用户平均评分分别为4.42和4.49（满分为5分制），紧随其后的则是平台基于教师性格和地理位置的匹配。但用户普遍认为平台存在教师刷课时、刷评论等现象，这说明教育O2O服务平台在教师管理规范上还有很大的提升空间。 超过九成的用户对教育O2O平台整体持满意的态度 从用户对教育O2O服务平台整体评价来看，用户整体对教育O2O服务平台的满意度都较高，其中家长用户和成人用户对教育O2O服务平台满意度的TOP2（非常满意+比较满意）值分别为92.0%和90.4%。这可能源于教育O2O平台不仅能够给用户提供较为丰富的企业/机构/教师的选择，而且用户的评价和购买量能够给用户带来一定的参考，降低用户决策时对机/教师的认知盲点和试错成本。 超九成的用户对从教育O2O平台上所购的产品/服务满意 从用户对通过教育O2O服务平台上购买的产品/服务的满意度来看，家长用户和成人用户对其所购买的产品/服务持满意的态度，其TOP2（非常满意+比较满意）值分别为92.9%和90.4%。 严审老师资质、精准推荐适配机构/教师以及简化筛选条件是用户对教育O2O平台的三大期望 从本次调研结果来看，家长用户整体对教育O2O服务平台的期望较为迫切，这可能是由于家长用户的孩子处于K12阶段，整体上升学压力比较大，因此对能够提高孩子与机构/教师的适配度、提升筛选优质师资的几率的各项功能有迫切的需求。而成人用户可自由支配的时间较少，因此对教学的有效性要求较高，故对机构/教师的适配性要求也随之提升。 转载来源：中国教育O2O服务行业白皮书]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>市场营销</tag>
        <tag>在线教育</tag>
        <tag>移动互联网</tag>
        <tag>O2O</tag>
        <tag>美团网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[资源｜DMLC团队发布GluonCV和GluonNLP：两种简单易用的DL工具箱]]></title>
    <url>%2F2018%2Fea9b9244%2F</url>
    <content type="text"><![CDATA[GluonCV文档地址：http&#58;//gluon-cv.mxnet.ioGluonNLP文档地址：http&#58;//gluon-nlp.mxnet.io/自去年以来，MXNet的动态图接口Gluon凭借着它的简单易用、并行效率高和节省显存等特点，成为了非常受欢迎的一个开源工具。 近日，DMLC 发布了简单易用的深度学习工具箱 GluonCV 和 GluonNLP，它们分别为计算机视觉和自然语言处理提供了顶级的算法实现与基本运算。本文简要介绍了这两个工具箱，并提供了基本的使用示例，更多详细的内容请查看它们的原文档。 GluonCV 文档地址：http&#58;//gluon-cv.mxnet.io - GluonNLP 文档地址：http&#58;//gluon-nlp.mxnet.io/GluonNLP 文档地址：http&#58;//gluon-nlp.mxnet.io/ 自去年以来，MXNet 的动态图接口 Gluon 凭借着它的简单易用、并行效率高和节省显存等特点，成为了非常受欢迎的一个开源工具。此外，Gluon 最大的特点就是文档和教程齐全，李沐及 MXNet 团队还发布了一系列「动手学深度学习」的公开课。 GluonCV 和 GluonNLP 继承了 Gluon 的优良传统，它们都能使用简单易用的 API 构建复杂的深度神经网络。此外，这两个项目目前都处于开发的早期阶段，它们的更新频率会比较高。因此，各位读者对该项目的贡献将极大地完善用户体验和工具性能。 GluonCV 项目地址：https&#58;//github.com/dmlc/gluon-cv- GluonNLP 项目地址：https&#58;//github.com/dmlc/gluon-nlpGluonNLP 项目地址：https&#58;//github.com/dmlc/gluon-nlp GluonCV 提供了计算机视觉领域顶级深度学习算法的实现。设计上，GluonCV 是为了帮助工程师、研究人员、学生快速的做出产品原型、验证新思路、学习计算机视觉。 训练脚本从而重现最新论文中的顶级结果； 大量的预训练模型； 细心设计的 API，便于理解实现； 社区支持。 GluonNLP 提供了 NLP 领域顶级深度学习模型的实现，且建立了文本数据管道和模型的模块。设计上，它同样也是为了让工程师、研究员和学生能快速的实现研究思路，做出产品原型。该工具箱提供以下四大特征： 训练脚本来重现研究论文中的顶级结果； 通用 NLP 任务的预训练模型； 仔细设计的 API，极大的减少了实现的复杂性； 社区支持。 安装 安装 MXNET GluonCV 和 GluonNLP 都依赖最新版的 MXNet，最简单的方式是通过 pip 安装 MXNet，运行下面的命令行将安装 CPU 版本的 MXNet。 安装 GluonCV 使用 pip 是安装 GluonCV 最简单的方式： 当然，我们也可以使用 Git 复制 GluonCV 项目并在本地安装： 安装 GluonNLP 同样，通过以下 pip 命令安装 GluonNLP 也是最简单的： 这两个工具目前都提供了案例或教程，但 GluonNLP 假定了用户对深度学习与 NLP 有基础理解，GluonCV 的教程假定用户对深度学习与计算机视觉有基础了解。以下简要展示了这两个工具的使用案例。 以下的案例将使用 20 层的残差网络在 CIFAR10 上从头开始训练，我们这里只展示了模型架构和最优化方法。使用 GluonCV 首先需要导入这个库： 选择模型架构可以简单地从已有模型中导入，以下将从 GluonCV 的模型库中导入用于 CIFAR10 的 20 层残差网络： 而剩下的优化方法及损失函数的配置就可以通过一般的 Gluon 接口完成，这同样也是非常简明和高效的使用方法。 对于 GluonNLP 来说，一般的任务都可以分为加载数据、构建词表、搭建模型和加载词嵌入等。以下将针对这些步骤展示该自然语言处理库的简单使用过程。 首先，以下代码将导入 GluonNLP，并加载 Wikitext-2 数据集： 随后，我们可以根据上面导入的数据集创建词表： 创建词表后，我们就能继续构建神经网络模型。如下将从模型仓库中导入一个标准的 RNN 语言模型，并将其应用到上面加载的数据集上： 最后，加载词嵌入表征就能馈送到模型并进行训练。如下将加载 GloVe 词嵌入表征，它是一种顶级的英语词嵌入方法： 转载来源：资源｜DMLC团队发布GluonCV和GluonNLP：两种简单易用的DL工具箱]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Word</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以史为镜 『中兴之困』 与三星半导体30年崛起之路]]></title>
    <url>%2F2018%2Ff0862c95%2F</url>
    <content type="text"><![CDATA[如何避免下一次中兴事件？ 转载来源：以史为镜 『中兴之困』 与三星半导体30年崛起之路]]></content>
      <tags>
        <tag>爱否科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[作业盒子完成C轮1亿美元融资 自适应学习受资本青睐]]></title>
    <url>%2F2018%2F2ab007b1%2F</url>
    <content type="text"><![CDATA[4月25日，作业盒子正式对外宣布，已于今年2月份完成C轮共计1亿美元融资。本轮融资由云锋基金领投，好未来等机构跟投，泰合资本担任独家财务顾问。 本报讯 记者喻剑报道：4月25日，作业盒子正式对外宣布，已于今年2月份完成C轮共计1亿美元融资，本轮融资由云锋基金领投，好未来等机构跟投，泰合资本担任独家财务顾问。这是作业盒子四个月内完成的第2轮融资，创造了在线教育领域最快的连续融资纪录。此前的2017年10月，作业盒子刚刚宣布完成由贝塔斯曼亚洲投资基金领投，新世界集团、好未来、BV百度风投跟投的2亿元人民币B+轮融资。 120天内完成两轮融资，一方面表明资本对作业盒子AIOC战略的认可和加持，另一方面也印证了教育行业的持续升温。作业盒子创始人兼CEO刘夜表示，“教育”一直是引发社会普遍焦虑的高频话题，国家提倡减负、学校要保证效率效果、家长渴求优质教育资源，这些矛盾背后的根源是“优质教育资源供需之间的不平衡”。作业盒子成立于2014年7月，最早从作业工具切入K12公立学校教学场景，2015年正式面向公立学校师生推出了“作业盒子”系列产品，目前已经构建了从工具到数据再到内容的“教—研—学—辅”完整教育生态。根据作业盒子公布的最新数据显示，截至2018年4月，作业盒子累计注册学生用户已经超过2700万，教师用户超过200万，覆盖了全国31个省市自治区、400多座城市的70000所学校，日均采集学习行为数据超过1亿条，每天活跃用户超过370万。在小学数学领域，作业盒子拥有全网最大规模、最全维度的学生学习数据库，构建了超过30维的学生数据肖像，这也是作业盒子实施其“AIOC战略”最具行业优势的场景和数据基础。 “教育的终局是创造供给，而非搬运供给”，这是作业盒子此前在B+轮融资发布会上提出“AIOC”战略时想要推动解决的问题，即：借助AI等技术手段来大规模地创造教育供给，让每个老师都有他个人的AI助教，也让每个家庭拥有专属的AI老师，把相对重复、繁琐的知识“传递”的工作交由更智慧的机器来完成，解放老师和家长，让他们更专注教育当中情感和精神的传达，让孩子的学习更高效，成长更科学——这也是教育的本质。在作业盒子构建的未来教育场景中，“机器将成为最好的‘老师’，为尽可能多的群体提供优质教育资源”。 记者了解到，自适应算法如今在教育创业领域被广为采用，如论答公司开发了国内第一个以国际顶尖算法为核心的自适应学习系统，主持了国内第一个有关自适应学习有效性的实证研究。为客户提供最前沿的个性化学习解决方案。论答创始人王枫博士说，论答的人工智能学习引擎，相当于名师的大脑。“就像AlphaGo，围棋棋盘有361个格子，每个格子有黑子、白子和不落子三种可能，围棋就有3的361次方种可能，这个量级无法用深蓝那种穷举的方法算出来，只能通过算法优化，这个跟K12解读阶段的知识点是类似的，中考数学有181个知识点，每个知识点有掌握、未掌握两种状态，中考数学就有2的181次方种可能，也必须通过算法来优化。”王枫说，“科技能够在差异化、个性化、精准化方面，为教育提供新动力。比如算法和知识图谱的配合，规划出一条最优学习路径”。 德联资本合伙人贾静表示，中国是一个教育大国，在教育产品选择中，经济成本只占一小部分，更重要的是时间成本、机会成本的考量。如何因材施教，作业、练习题、课程内容根据每个受教育者的特点而设计，是现在教育产品的一个趋势。 转载来源：作业盒子完成C轮1亿美元融资 自适应学习受资本青睐]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>人工智能</tag>
        <tag>在线教育</tag>
        <tag>好未来</tag>
        <tag>云锋基金</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教你用PyTorch实现“看图说话”（附代码、学习资源）]]></title>
    <url>%2F2018%2Fa36020f3%2F</url>
    <content type="text"><![CDATA[作者：FAIZANSHAIKH翻译：和中华校对：白静本文共2200字，建议阅读10分钟。本文用浅显易懂的方式解释了什么是“看图说话”。 作者：FAIZAN SHAIKH 翻译：和中华 校对：白静 本文共2200**字，建议阅读10分钟**。 本文用浅显易懂的方式解释了什么是“看图说话”(Image Captioning)，借助github上的PyTorch代码带领大家自己做一个模型，并附带了很多相关的学习资源。介绍 深度学习目前是一个非常活跃的领域—每天都会有许多应用出现。进一步学习Deep Learning最好的方法就是亲自动手。尽可能多的接触项目并且尝试自己去做。这将会帮助你更深刻地掌握各个主题，成为一名更好的Deep Learning实践者。 这篇文章将和大家一起看一个有趣的多模态主题，我们将结合图像和文本处理技术来构建一个有用的深度学习应用，即看图说话(Image Captioning)。看图说话是指从一个图像中基于其中的对象和动作生成文本描述的过程。例如： 这种过程在现实生活中有很多潜在的应用场景。一个明显的应用比如保存图片的描述字幕，以便该图片随后可以根据这个描述轻松地被检索出来。 我们开始吧！ 注意： 本文假定你了解深度学习的基础知识，以前曾使用CNN处理过图像问题。如果想复习这些概念，可以先阅读下面的文章： Fundamentals of Deep Learning – Starting with Artificial Neural Network- Architecture of Convolutional Neural Networks (CNNs) demystified- Tutorial&#58; Optimizing Neural Networks using Keras (with Image recognition case study)- Essentials of Deep Learning – Sequence to Sequence modelling with Attention (using python)Architecture of Convolutional Neural Networks (CNNs) demystified Essentials of Deep Learning – Sequence to Sequence modelling with Attention (using python) 目录 什么是Image Captioning问题？- 解决任务的方法- 应用演练- 下一步工作解决任务的方法 下一步工作 什么是Image Captioning问题？ 设想你看到了这张图： 你首先想到的是什么？下面是一些人们可以想到的句子： A man and a girl sit on the ground and eat . （一个男人和一个女孩坐在地上吃东西）A man and a little girl are sitting on a sidewalk near a blue bag eating . （一个男人和一个小女孩坐在蓝色包旁边的人行道上吃东西）A man wearing a black shirt and a little girl wearing an orange dress share a treat .（一个穿黑色衬衣的男人和一个穿橘色连衣裙的小女孩分享美食） 快速看一眼就足以让你理解和描述图片中发生的事情。从一个人造系统中自动生成这种文字描述就是Image Captioning的任务。 该任务很明确，即产生的输出是用一句话来描述这幅图片中的内容—存在的对象，属性，正在发生的动作以及对象之间的互动等。但是与其他图像处理问题一样，在人造系统中再现这种行为也是一项艰巨的任务。因此需要使用像Deep Learning这样先进复杂的技术来解决该任务。 在继续下文之前，我想特别感谢Andrej Kartpathy等学者，他们富有洞察力的课程CS231n帮助我理解了这个主题。 解决任务的方法 可以把image captioning任务在逻辑上分为两个模块——一个是基于图像的模型，从图像中提取特征和细微的差别， 另一个是基于语言的模型，将第一个模型给出的特征和对象翻译成自然的语句。 对于基于图像的模型而言（即编码器）我们通常依靠CNN网络。对于基于语言的模型而言（即解码器），我们依赖RNN网络。下图总结了前面提到的方法： 通常，一个预先训练好的CNN网络从输入图像中提取特征。特征向量被线性转换成与RNN/LSTM网络的输入具有相同的维度。这个网络被训练作为我们特征向量的语言模型。 为了训练LSTM模型，我们预先定义了标签和目标文本。比如，如果字幕是A man and a girl sit on the ground and eat .（一个男人和一个女孩坐在地上吃东西），则我们的标签和目标文本如下&#58; 这样做是为了让模型理解我们标记序列的开始和结束。 具体实现案例 让我们看一个Pytorch中image captioning的简单实现。我们将以一幅图作为输入，然后使用深度学习模型来预测它的描述。 例子的代码可以在GitHub上找到。代码的原始作者是Yunjey Choi 向他杰出的pytorch例子致敬。 在本例中，一个预先训练好的ResNet-152被用作编码器，而解码器是一个LSTM网络。 要运行本例中的代码，你需要安装必备软件，确保有一个可以工作的python环境，最好使用anaconda。然后运行以下命令来安装其他所需要的库。 git clone https&#58;//github.com/pdollar/coco.gitcd coco/PythonAPI/makepython setup.py buildpython setup.py installcd ../../git clone https&#58;//github.com/yunjey/pytorch-tutorial.gitcd pytorch-tutorial/tutorials/03-advanced/image_captioning/pip install -r requirements.txt 设置完系统后，就该下载所需的数据集并且训练模型了。这里我们使用的是MS-COCO数据集。可以运行如下命令来自动下载数据集： chmod +x download.sh./download.sh 现在可以继续并开始模型的构建过程了。首先，你需要处理输入： Search for all the possible words in the dataset and# build a vocabulary listpython build_vocab.py # resize all the images to bring them to shape 224x224python resize.py 现在，运行下面的命令来训练模型： python train.py –num_epochs 10 –learning_rate 0.01 来看一下被封装好的代码中是如何定义模型的，可以在model.py文件中找到： import torchimport torch.nn as nnimport torchvision.models as modelsfrom torch.nn.utils.rnn import pack_padded_sequencefrom torch.autograd import Variable class EncoderCNN(nn.Module)&#58; def init(self, embed_size)&#58; “””Load the pretrained ResNet-152 and replace top fc layer.””” super(EncoderCNN, self).init() resnet = models.resnet152(pretrained=True) modules = list(resnet.children())&#91;&#58;-1&#93; # delete the last fc layer. self.resnet = nn.Sequential(*modules) self.linear = nn.Linear(resnet.fc.in_features, embed_size) self.bn = nn.BatchNorm1d(embed_size, momentum=0.01) self.init_weights() def init_weights(self)&#58; “””Initialize the weights.””” self.linear.weight.data.normal_(0.0, 0.02) self.linear.bias.data.fill_(0) def forward(self, images)&#58; “””Extract the image feature vectors.””” features = self.resnet(images) features = Variable(features.data) features = features.view(features.size(0), -1) features = self.bn(self.linear(features)) return featuresclass DecoderRNN(nn.Module)&#58; def init(self, embed_size, hidden_size, vocab_size, num_layers)&#58; “””Set the hyper-parameters and build the layers.””” super(DecoderRNN, self).init() self.embed = nn.Embedding(vocab_size, embed_size) self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True) self.linear = nn.Linear(hidden_size, vocab_size) self.init_weights() def init_weights(self)&#58; “””Initialize weights.””” self.embed.weight.data.uniform_(-0.1, 0.1) self.linear.weight.data.uniform_(-0.1, 0.1) self.linear.bias.data.fill_(0) def forward(self, features, captions, lengths)&#58; “””Decode image feature vectors and generates captions.””” embeddings = self.embed(captions) embeddings = torch.cat((features.unsqueeze(1), embeddings), 1) packed = pack_padded_sequence(embeddings, lengths, batch_first=True) hiddens, _ = self.lstm(packed) outputs = self.linear(hiddens&#91;0&#93;) return outputs def sample(self, features, states=None)&#58; “””Samples captions for given image features (Greedy search).””” sampled_ids = &#91;&#93; inputs = features.unsqueeze(1) for i in range(20)&#58; # maximum sampling length hiddens, states = self.lstm(inputs, states) # (batch_size, 1, hidden_size), outputs = self.linear(hiddens.squeeze(1)) # (batch_size, vocab_size) predicted = outputs.max(1)&#91;1&#93; sampled_ids.append(predicted) inputs = self.embed(predicted) inputs = inputs.unsqueeze(1) # (batch_size, 1, embed_size) sampled_ids = torch.cat(sampled_ids, 1) # (batch_size, 20) return sampled_ids.squeeze() 现在测试我们的模型： python sample.py –image=’png/example.png’ 对于样例图片，我们的模型给出了这样的输出： a group of giraffes standing in a grassy area . 一群长颈鹿站在草地上 以上就是如何建立一个用于image captioning的深度学习模型。 下一步工作 以上模型只是冰山一角。关于这个主题已经有很多的研究。目前在image captioning领域最先进的模型是微软的CaptionBot。可以在他们的官网上看一个系统的demo. 我列举一些可以用来构建更好的image captioning模型的想法： 加入更多数据当然这也是深度学习模型通常的趋势。提供的数据越多，模型效果越好。可以在这里找到其他的数据集： http&#58;//www.cs.toronto.edu/~fidler/slides/2017/CSC2539/Kaustav_slides.pdf- 使用Attention模型正如这篇文章所述(Essentials of Deep Learning – Sequence to Sequence modelling with Attention),使用attention模型有助于微调模型的性能- 转向更大更好的技术研究人员一直在研究一些技术，比如使用强化学习来构建端到端的深度学习系统，或者使用新颖的attention模型用于“视觉哨兵（visual sentinel）”。使用Attention模型正如这篇文章所述(Essentials of Deep Learning – Sequence to Sequence modelling with Attention),使用attention模型有助于微调模型的性能 结语 这篇文章中，我介绍了image captioning,这是一个多模态任务，它由解密图片和用自然语句描述图片两部分组成。然后我解释了解决该任务用到的方法并给出了一个应用演练。 对于好奇心强的读者，我还列举了几条可以改进模型性能的方法。 希望这篇文章可以激励你去发现更多可以用深度学习解决的任务，从而在工业中出现越来越多的突破和创新。如果有任何建议/反馈，欢迎在下面的评论中留言！ 原文标题：Automatic Image Captioning using Deep Learning (CNN and LSTM) in PyTorch 原文链接：https&#58;//www.analyticsvidhya.com/blog/2018/04/solving-an-image-captioning-task-using-deep-learning/ 译者简介 和中华，留德软件工程硕士。由于对机器学习感兴趣，硕士论文选择了利用遗传算法思想改进传统kmeans。目前在杭州进行大数据相关实践。加入数据派THU希望为IT同行们尽自己一份绵薄之力，也希望结交许多志趣相投的小伙伴。 转载来源：教你用PyTorch实现“看图说话”（附代码、学习资源）]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>GitHub</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小程序：BAT的下一个新战场]]></title>
    <url>%2F2018%2Fcf711999%2F</url>
    <content type="text"><![CDATA[自从张小龙把应用号改为“小程序”后，关于小程序的产品动向一直令开发者和创业者心驰神往。连独角兽捕手朱啸虎在不同场合表态，“别看区块链了，赶紧去小程序创业啊！ 自从张小龙把应用号改为“小程序”后，关于小程序的产品动向一直令开发者和创业者心驰神往，当前的小程序开发热逐渐有了七年多前的安卓开发的盛况。从做一个App走上人生巅峰，到做一个公众号估值千万，到如今已有爆款小程序、小程序服务平台等拿到一线VC的巨额融资，连独角兽捕手朱啸虎在不同场合表态，“别看区块链了，赶紧去小程序创业啊！” 当我们谈起“小程序”时，在语境一般指代的是“微信小程序”，这有点儿不公允，支付宝在去年也做了小程序，淘宝会员码店铺也像小程序；百度才是最早的小程序鼻祖，从轻应用（lightApp）到直达号再到今年4月重新上线部分企业的小程序，现实很残酷，与用户称呼公众号一般特指微信订阅号一样正常。 微信在基本完成连接“人”（社交）、连接“内容”（社媒）任务之后，已把重心放在连接“产品”（小程序）上，尽管目前主流产品形态还是App，但微信小程序增速非常亮眼，根据QuestMobile报告显示，从2017年1月至2018年3月微信小程序的月活规模超过4亿，在上个月小程序日活用户达1.4亿左右，渗透率达43.9%，还有很大的上升空间。越来越多App开发了小程序版，以致于以后移动产品评测机构做用户数据得做“双份”对比了。 那么，BAT三家之中，为何只有微信小程序具有强大的用户流量以及生态场景能力？在微信生态之中，小程序如何才能存活下来？ 阿里**小程序、百度小程序为什么没有那么火？**本质上说，小程序是以超级App为母App不断孵化出无数多的子App，使得超级App成为新的移动互联网基础设施，当各种需求被不同的小程序满足之后，很容易长出类似苹果应用市场（App Store）那样的生态。所以从微信小程序诞生起，巨头们就很焦虑，阿里担心小程序的社交电商在腾讯体系内形成闭环，百度担心人们搜索需求被小程序搜索满足。 1.阿里**小程序押注“新零售”，**拓展线下场景 马云曾这样评价微信，刚出来时“被吓了一跳”，再后来觉得“仅此而已”，而这几年，微信支付在碎片化支付场景之中对支付宝的冲击显而易见；微信小程序在下很大一盘棋，仅从小程序之中孵化的一个拼多多，就成了腾讯战略冲击淘宝电商垄断地位的又一王牌。 阿里做小程序的孵化基地是支付宝和淘宝，支付宝的小程序更多是在便民属性上工具应用，属于“用完即走”性质。今年淘宝的一个显著变化是不再是纯粹的电商平台，而是线上新零售基地。当前淘宝中已经整合了“淘宝外卖”、“飞猪旅游”等O2O业务，挨着淘宝搜索框的“会员码”实际上是一个向用户附近位置线下门店导流的本地生活服务业务。 在淘宝平台模式之中，要实现复杂的、非标的到店或到家服务场景，就得采用免下载安装包的“小程序”产品形态以更好实现流量闭环，由于淘宝本身就是阿里系产品导流基地，做轻应用有比较强的技术积淀，产品体验并不差。但阿里做小程序也只能打通在小程序上的电商场景，而没有办法丰富其他业态，阿里电商的盈利模式决定了商户依然需要自购广告买平台流量或者返佣。 （淘宝首页本地生活服务类增多，会员码实际上是门店小程序，目前支付宝使用较为高频的共享单车小程序） 2.百度小程序的出路是做信息流广告落地页 百度链接信息的强项更准确的说是链接官网或者站长，这种优势在微信生态之中被公众号和自媒体削弱，接下来企业做官网的趋势可能就是做一个小程序（开发App的成本相对较高），毕竟以前PC端4亿用户每个企业都有官网，和现在微信小程序用户量级差不多。所以，百度再不推小程序，确实就有点晚了。 此前的轻应用没有做起来是由于百度在移动端没有拳头级App带，过去2年百度移动端转型已经完成，2017年手百信息流广告业务以环比20%增速发展，与大搜业务并驾齐驱，是百度长期投入AI技术研发的现金流业务。后续在百度移动端的信息流之中，有望接入一些体验较好的小程序站点，首页向用户Push（推荐）时呈现，无需跳转到至客户的App，使用体验要比H5式的广告落地页要好很多。 笔者发现4月12日百度App的“常用服务”中上线了“优信二手车”小程序，还没有介入首页。 百度小程序的缺憾在于其移动支付市场份额较小，没有办法在自身生态体系内完全打通支付场景；并且或许只有与百度合作的小程序商家才能得到类似“品牌专区”的推荐以及首页的流量推荐，这将制约很多企业开发者进驻的兴致。 （百度小程序目前仅作为常用服务，优信二手车作为样板，体验App化，暂无支付功能） 长尾小程序如何在微信“去中心化的产品生态”中生存？目前阿里小程序、百度小程序均无法与微信小程序相抗衡，更多只是出于战略防守的目的，并且其他移动端产品也不可能再做小程序了，自身的流量不够。 微信小程序独特禀赋在于：用户基数、打开高频度、用户粘性第一，拥有真实的个人账户和社交关系链，微信支付用的人越来越多，而最为难得是微信试图培育出的“去中心化”的小程序生态，而非是中心化流量入口进行系统分配。微信会让用户自主选择小程序，微信首页下拉呈现是用户常用的小程序，便于让用户养成使用习惯。 阿星认为，微信小程序也是为腾讯的商业模式服务的，但创业者大可以放心，正如微信营建公众号庞大生态，它本身并不需要从某个公众号中抽佣或者收费，腾讯本身靠游戏、投资拥有丰裕的利润，腾讯无意与小程序运营者争利。它反而更需要所有用户、企业、产品等在腾讯自己的生态玩下去，这样才有源源不断的“流量”为其商业模式提供肥沃的土壤。 很多创业者和企业已经敏锐觉察到，微信小程序正复制公众号成功的逻辑，很快小程序也会成为企业的标配，正如2000多万个公众号中真正能够生存下来极少数，而小程序运营者痛点也与微信定位的“去中心化产品生态”息息有关：- 目前头部小程序很多是腾讯自己开发或投资项目，很多创业者会担心的我的用户留存在微信，数据在微信上跑，哪天封号怎么办。- 如何结合自身的业务逻辑设计出体验度不比App差的工具，依然需要行业解决方案，市面上的小程序开发商大多良莠不齐。- 小程序不能像公众号那样向用户推送消息，如何唤醒留存用户，提升转化率成为运营难题。而去中心化产品生态的好处在于这些小程序的痛点会微信第三方服务商加以解决，他们本身既是与微信有着深度合作的开发者，熟悉小程序游戏规则，又是其他微信小程序创业者的服务平台，因而在小程序风口成为资本市场投资的重点。 笔者发现此前做公众号服务商的平台已经转型做小程序平台，他们与传统中小企业打交道的多，更了解他们的痛点和需求，并且小程序的开发与此前的公众号微商城成熟经验可以很好的结合，4月份微盟完成10.09亿元D1轮融资，可见资本市场对于小程序企业服务（to B业务）的看好。 移动互联网从流量上更像“微信互联网”，小程序是微信目前主推的用户交易、交互产品，微盟创始人孙涛勇“小程序+”概念或许更容易理解张小龙小程序“连接万物”的野心，小程序可以加官网、加公众号、加电商、加门店、加广告，这么多的玩法没有开发和运营经验的企业单独去玩，可能没法充分释放其“全渠道”价值，另外如何遵守微信相对复杂、变动的产品规则也得有小程序服务商引导，而小程序服务平台崛起满足了这种市场刚需。 而微信小程序服务平台，最重要的不是技术，微信底层技术已经比较简易化了，真正的壁垒是具备不同垂直行业的运营经验积累，只做少数小程序案例的服务商很难应付，小程序的红利就是眼前，但是真正会玩的、能抓到仍然是少数，这种两年左右的红利窗口期试错成本高昂，使得小程序服务平台容易出现“头部化”的马太效益。 提供小程序应用服务是一门技术活，比如做微电商、智慧餐厅、智慧外卖、智慧美业等不同行业的小程序产品逻辑肯定不一样，在不同场景做交易、官网、门店或者会务小程序的交互也不一样。此前帮助不同行业创业者和企业做微网站、微分销的团队对业务理解优势凸显了，笔者认为，这是资本市场看好微盟成为中长尾企业主做小程序开发和运营的赋能者的重要原因。 尽管小程序要超过50个流量入口，要解决小程序推广难的问题，还得依靠“公众号+小程序”组合拳的办法，公众号粉丝留存度高、但入口比较深、打开率低，小程序入口多、使用可以高频，长尾中小企业用户如果能发挥出公众号存量和小程序增量优势，可以节约很多推广成本、并丰富小程序的推广玩法，比如公众号插入小程序，二维码设计粉丝的分配机制，拼多多式的社交+拼团模式，铂涛酒店式的微信卡券营销、礼物说式的送礼等方式可以借鉴和模仿，“专业人做专业事”，阿星相信，目前小程序服务商已经掌握了足够多运营工具和解决方案。 张小龙说小程序不是为电商准备的，意思是小程序在内容、社交、门店、工具等多个应用场景都可以广泛应用，或许内容电商、社交电商、粉丝营销以及本地生活化服务可以通过小程序真正引爆。 当腾讯成为中小企业连接线上线下的“赋能者”的时候，腾讯才会最终与阿里拉开市值差距。 结语小程序会成为巨头争夺的新战场，阿里和百度之所以没有办法与微信小程序分庭抗礼，主要与其商业模式、在连接用户多元化需求以及中心化流量入口产品思维有关，据了解，微信小程序在2018年商业化进程会加快，这是移动互联网创业者流量红利，也是线下门店和企业拥抱微信互联网机会，如何在微信复杂流量宇宙里生存下来，必须借鉴专业微信生态服务商，而第三方服务平台能否把小程序电商及营销能量输出给长尾中小创业者，是微信小程序生态能否繁荣重要角色。（本文首发于钛媒体） 【钛媒体作者：靠谱的阿星（李星），公众号：靠谱的阿星，靠谱汇创始人、科技媒体专栏作家，CMO训练营认证导师，获2017年钛媒体年度作者「最具人气奖」，个人微信即QQ号：1598145405】 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 转载来源：小程序：BAT的下一个新战场]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>电子商务</tag>
        <tag>移动互联网</tag>
        <tag>支付宝</tag>
        <tag>移动支付</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Yann LeCun：距离“真正的” AI，我们还缺什么？]]></title>
    <url>%2F2018%2Fa693f421%2F</url>
    <content type="text"><![CDATA[他讲述了关于深度学习的最新研究成果，同时也描述了深度学习的未来，以及机器智能所要面临的的挑战。训练监督学习模型需要向它展示各种例子，并告诉它正确答案。 【AI科技大本营导读】今天是 GMIC Beijing 2018 大会第一天，首个演讲者是 Facebook 首席 AI 科学家 Yann LeCun。他讲述了关于深度学习的最新研究成果，同时也描述了深度学习的未来，以及机器智能所要面临的的挑战。 # ▌监督学习无可替代 如今的 AI 系统都是使用的监督学习，所有的 AI 应用，不管是图像识别、声音识别还是人脸识别，或者机器翻译等等，这些都是监督学习的应用。训练监督学习模型需要向它展示各种例子，并告诉它正确答案，如果你想让机器学会将汽车和飞机区分开来，比如你给它展示一辆车的图像，它说这不是一辆车，然后你可以对参数进行调整，下次再向机器展示同一张图像的话，你就会得到接近正确的答案。 我们可以对机器进行端到端的训练，来完成特定的任务，feeding 原始的 inputs，就会自动给出 outputs。机器学习这个任务的过程是端到端的学习过程。通过这种方式机器，计算机能更好地了解这个世界。 比如卷积网络，实际上这个想法是可以回溯到上个世纪八十年代。它可识别图像，同时也有很多其他的应用，比如说可以用于语言处理、语言识别和其他很多的应用。我们知道对于神经网络是非常大的，只有在非常强大的计算机上才可以运用，需要有 GPU 加以辅助。 在深度学习变得比较普遍之前，我们首先要确保这样的一些系统可以用于这些情况，比如一个例子是我们在 2009 年、2010 年在纽约大学合作的一个实验，可以看到它可以识别马路上的建筑、天空以及路上的车和人等等，这个在当时并没有被称为最好的系统。再过几年之后，越来越多人相信深度学习是可以奏效的，可以发挥作用的。 在这里大家可以看到在网络当中使用的几个层，比如说有 100 层或者 180 层的一些人工神经网络，在 Facebook 当中我们就会广泛使用。这上面大家可以看到错误率是在不断下降的，有的时候表现的甚至要比人还要好。它的性能非常好，已经成为了一种标杆。 这是 Facebook 人工智能部门所做的研究，叫做 Mask R-CNN，可以看到它的结果，它可以标记这样的图像，就像我刚才给大家展示的例子，展示出非常好的性能。它不仅仅可以识别出每个人，同时它会为每个人加一个标记，所以可以很容易区分出是一个人还是一只狗。 在这里大家可以看到这个系统可以识别电脑、酒杯、人、桌子，也可以数出来到底有多少，而且也可以识别出道路、汽车。如果五年之前问系统这些问题的话，我们当时可能认为需要 10-20 年时间才能达到今天呈现的效果。 这也是 Facebook 所做的一些研究，叫做 Detectron。大家可以下载上面的代码，它可以探测 200 多种不同的类别，这也是 Facebook 在 AI 方面的一些研究，我们不仅仅发布了一些论文，同时连代码也都发布出来了，这样的话世界各地都可以更好的熟知这种技术。 当然还包括其他很多项目，在 Facebook 我们利用 DensePose 这样的技术，预测人类的行为。我们现在有一个系统能够实时的运行，在一个单一的 GPU 上运行。它可以跟踪很多人的行为，生成视频，非常的准确，可以实时地生成一些相应的数据和信息，并且相应的代码也是可以用的，这些都是一些最新的应用。 当然利用的这样的技术不仅仅可以进行识别图像，面部识别，也可以识别人的行动，也可以用来翻译，这是 Facebook 在加州所做的研究（FairSeq）。我们可以用这个系统进来行翻译的工作。 我觉得对于行业说进行这样的开发研究将是会是一个非常有用的过程，同时我们也希望自己所开发的技术能够引导整个社区，解决我们所感兴趣的问题。我们认为 AI 不仅仅会帮助我们解决问题，同时还会帮助我们解决很多人类自己无法解决的挑战，所以我们会与科学团队一起朝这方面努力。 这里是在过去的几年里，FAIR 所发布的一些开源项目，包括像深度学习网络，还有深度学习框架等等。 我刚才讲到每天都会有一些新的应用发布，而深度学习的广泛应用也进一步推动科学方面的研究。在接下来几年里深度学习会发生更大的革命。 接下来为大家举一个例子，这段视频表现出来的是一种加速过程，它可以训练车去进行驾驶，而且可以调整车轮的方向。这样可以让车自己去进行驾驶，而不需要有人去进行校正。 # ▌可微分编程 接下来我们再来看一下可微分编程，这个编程可以用人工神经网络解释。 编者注：程序员不写代码，或者仅写出少量 high-level 的代码，但是提供大量输入数据 X 与对应运算结果 Y 的例子。神经网络根据提供的数据集，自动学出从输入数据X到最终运算结果 Y 的映射（既整个程序）；或者结合程序员提供的 high-level 的代码，用神经网络作为中间函数，补全得到整个程序。来源：知乎&#64;殷鹏程（https&#58;//www.zhihu.com/question/265173352/answer/291994649） 我们通过研究可以实现这样的一种编程，可以利用这样的系统或者培训系统，来完成某一个具体的任务。 这是几年前所开展的工作，是由 Facebook 和纽约大学一起合作做的项目。这个项目是训练模型，让它能够回答相关的问题。在自然语言处理过程中，也可以看到人工神经网络是动态的，在不断变化的。 这是另外一个例子，如果你要建立一个能够回答复杂问题的系统，比如说关于图像的复杂问题等。为了回答这个图片是不是有更多的立体形状，之后我们就会让系统来进行计算。比如说这里有多少是方形体，或者有多少颜色，最后告诉你具体的答案是什么。通过这么做我们可以建立起一个端到端的解答的途径，而且也允许你提出更多新的问题。根据你输入的数据不同，它会有所变化。 大家看到这里是我们最近开发所得到的一些深度学习最新的成就，之后我们来看一下关于 AI 有没有我们触及到的。 ▌机器学习需要常识 对于新技术，我觉得可以进入到更多的领域，比如进行更多的影像分析。在一定程度上，我们觉得机器可能确实拥有一定的人工智能，但具体细节上，我们还需要进行更多探讨。 比如在机器学习方面，我们怎么做呢？在这儿可以看到有一些具体的图像，我们有些新的方法。在实际的生活当中其实这种方式不太成功，因为关于深度学习方面我们要进行深入的挖掘，因为对于机器本身它会有不同的解决方案，比如在实际生活中是不能够去实施的。 有时候让机器学习很长时间才能玩游戏。所以在核心功能方面，现在确实还没有触及到。但这些机器是能做到的，只是我们还没有挖掘出来。我们也可以对机器本身进行更深入的训练，比如我们要让系统进行成千上万次的训练之后，它们才能够进行学习。 有些学习它是与力学相关的，但是在实际的生活当中不可能实时进行，所以我们只能够进行模拟，但它也需要我们进行很多的尝试才能够让机器学到。 婴儿们是怎么学习的呢？比如就像右下角这幅图向他们所展示的，六个月以下的婴儿可能不太了解物理运动，可当他们满了八个月之后，他们已经知道自由落体这个动作了。 所以像右下角的这个小女孩非常了不起，我的一位朋友她给我们展示了婴儿怎么学会一些概念，而且他们也能够了解一些最基本的物理原理，这是他们在生活中最初学到的一些概念，这是凭借人们常识获得的，婴儿们所学会的是就是一些常识。 另外我们向动物展示这样的情景，比如大家看一下这个大猩猩，它们在幼年的时候由培训员给它们进行展示一些东西，所以大猩猩面对这样的魔术会笑出来，而人们会把这当做世界最初的原型。 但我们希望机器能够建立一些样本，使得系统运行，最终机器就能进行一些预测，像人一样有效运行。我们有这样的监督或者学习就能够使得机器得到训练和规划，这是我们所需要建立的一个系统。 不管下次的变革出现在哪里，我觉得它们应该是自我监督或者无监督学习，而且在这样的变革当中也会出现一些常识性的学习。 我总结一下，这是我们最近做的一些非常有意义的事情，这是一些预测性的模型，来由机器进行规划，根据它们的尝试进行预测。 我们进行了对抗性训练，比如说我们可以训练机器来了解哪个分项是更可能的，或者在实际生活中会产生什么样的结果。对于发生的可能性它也会来做出预测，可能有的时候有的结果是虚假的，不是真实的。通过这么做我们就能够得到不同机器产生的结果，之后得到了很多的影像和图片。 我们的系统在进行训练之后，生成了一系列的人脸，大家看看这些名人的面孔，里面有一些是假的图像，是由机器生成的，但看起来是真实的。 我们将在下周会议上向大家展示最新的结果，得到的成果非常好。总之，我们希望把这个工具之后能够融入到我们的机器学习当中。 最后，我想做一下总结，我觉得监督学习是不能够被替代的，不管是无监督学习还是其他的学习方式都不能够替代它，这点已经引起了很多人的兴趣，我们也要进行更多尝试。还有一点我需要强调的是，我们要让机器能够推理，来看深深度学习能带给我们什么样的推理能力，同时也要了解在AI时代，机器的推理能力有多高，逻辑性有多强。 接下来我们也要来朝着可微分编程的智能学习的方向持续发展，这就需要进行做更多对抗性训练的研究。当然，还会出现更多的有关深度学习的变革，比如一些多渠道发展或者是复杂的架构，在这个领域也会出现更多的理论。 关于技术监督的趋势很显然是不断的弱化，甚至监督会消失，这就会导致出现一些新理论的产生，比如新语言，或者是一些新的并行文本，我相信之后应该有多维度的可能性。可能会出现一些新框架，包括了一些动态影像。我们会和微软，和亚马逊会进行更多合作，我们也会不断进行开源。 当然，现在我们的工作量很大，但是关于我们的移动工具和其他工具越来越流行了，Facebook 的用户他们每天能够推出大概 20 亿张不同的影像，所以我们希望能充分发挥这方面的能力，它可能是一种很强的驱动力。另外，我们也要不断强化硬件，以使用户需求能够得到专业化的处理。 转载来源：Yann LeCun：距离“真正的” AI，我们还缺什么？]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>GPU</tag>
        <tag>Facebook</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[俄罗斯的新战略：三分欧亚大陆]]></title>
    <url>%2F2018%2F5185426b%2F</url>
    <content type="text"><![CDATA[俄罗斯在融入西方全球政治秩序失败后，似乎迅速找到了新的定位：欧亚大陆的能源中心。莫斯科为此提出了“三分欧亚大陆”的战略：北极和俄罗斯、里海和中东地区，构成中部能源生产区。 转载来源：俄罗斯的新战略：三分欧亚大陆]]></content>
  </entry>
  <entry>
    <title><![CDATA[百行征信与中国征信的未来]]></title>
    <url>%2F2018%2F90135fb4%2F</url>
    <content type="text"><![CDATA[就金融领域而言，征信系统可以说是金融信息的高速公路，各种金融信贷平台，可以理解成各种交通工具，风控就是驾驶技术。 【财新网】（专栏作家 刘新海）作为市场经济的产物，征信系统对于经济的健康发展和金融市场的稳定的重要性不言而喻，就金融领域而言，征信系统可以说是金融信息的高速公路，各种金融信贷平台，可以理解成各种交通工具，风控就是驾驶技术。但是如果没有一个好的征信系统做基础，再好的驾驶技术也是没有意义。 2017年4月21日，央行征信管理局举行个人信息保护的国际学术研讨会，宣布全国八家个人征信机构没有一家合格，给征信业带来很大的冲击，震撼至今。时隔一年，中国征信领域发生一些变化，引起社会的关注，本文将围绕一些重要的征信现象简单来讨论一下中国的征信问题，并展望一下中国征信的未来。 央行征信系统：非赢利、非市场化的国家基础数据库 中国征信体系的起步是从2006年设立央行征信中心（维护央行征信系统）开始，从征信机构、征信监管者、数据提供商、征信用户、数据主体这些角度来看，形成基本的中国征信行业格局，如图一所示。 图一 中国征信体系（2006-2017） 央行征信中心是2018年之前国内唯一的一个官方征信机构，央行征信系统的名称是国家金融信用信息基础数据库。虽然定位为国家级的基础数据库，但央行征信中心实质上就是肩负着为市场化信贷机构提供征信服务的征信机构。 央行征信中心具有非常独特的一面，它既具有个人征信系统和企业征信系统功能，还承担央行信贷登记系统（服务于央行监管）的作用。目前它的征信数据覆盖约四亿消费者和两千多万企业的信贷记录，提供的主要征信产品有（个人和企业）的信用报告，个人信用报告数字解读（实际上就是个人信用评分）和企业关联关系查询。 央行征信中心在成立之初，在很短时间内就把全国银行的信贷数据进行采集和整合，在解决处理信贷金融风险问题上发挥了重要作用，大幅度降低银行信贷的不良率，同时促进了国民经济发展，清华大学课题小组研究显示，央行征信系统促进了GDP0.33%的增长。 同时，央行征信中心也存在一些问题，有的与金融市场环境有关，有的是自身体制的问题。因为央行征信中心是一个非赢利，非市场化的国家事业单位，而不是独立的商业机构。 首先是整个金融市场服务不完善，金融信贷服务供给不足，2/3的消费者和大量小微企业无法从信贷机构获得贷款，导致央行征信系统覆盖的人群和企业有限。 其次与金融机构监管范围有关系，央行征信中心服务的对象直接受到监管的金融机构，即仅限于持牌的金融机关，对于没有受到监管的新金融机构，央行征信中心按照监管规定，无法为其提供服务。 再次是自身的体制问题，非赢利、非市场化的定位，导致其无法高效率地运行，提供更多的征信服务。深层次的原因是央行征信系统作为国家金融信用信息基础数据库主要任务是采集征信数据和生成最基本的征信产品-信用报告，期望其能够像美国的三大个人征信机构（盈利性的，市场化运作）一样每年能研发出上百个征信产品也的确是勉为其难。 征信“大跃进”（2015-2017）：互联网金融泡沫的衍生品 从2015年到2017年，可以称为是征信大跃进的三年。征信属于相对比较小众的行业领域，在中国引起前所未有的关注度，无论欧美发达国家还是东南亚等新兴国家，从来没有哪个国家的征信能这么大幅度的引起社会大众关注、促使许多新金融机构、大数据公司、互联网公司积极参与。在这三年里，各种背景的征信机构纷纷成立，大量的人力、物力和资本投入，所以称之为征信大跃进。 这种现象的发生并非偶然，首先和国内的互联网金融与大数据泡沫密切相关，在“征信行业躺着赚钱”的社会舆论刺激下，以及“先开枪，再瞄准”的互联网思维引导下，大量的新兴机构在不了解征信商业本质的情况下涌入征信行业寻找商机。其次是因为互联网金融和消费金融的兴起，这些新金融机构需要征信服务，央行征信中心或者由于覆盖人群不足没法给他们提供直接服务的，或者提供的服务不够。 另外一方面，虽然国内只有1/3的消费者有传统信贷数据，但进入大数据和互联网经济时代，消费者有丰富的其它非信贷信用数据或者其它信用相关数据。将央行征信系统、三大电信运营商、微信、支付宝和京东等消费者的数据进行比较，就会发现三大电信运营商和微信的活跃用户远远超过央行征信系统覆盖的信贷人群，这些替代数据是可以用来辅助信用分析。 在上述因素的推动下，央行监管层面对市场化征信开始有所松动。首先从个人征信来说，央行在2015年1月5日通知八家个人征信机构准备征信工作，掀起征信建设高潮的序幕。其中，大量的互联网，大数据等高科技公司和新兴的金融机构都要开展征信业务，特别是个人征信，这也是非常具有中国特色和时代背景的独特现象。 其次从企业征信来讲，目前国内约有130家企业征信机构备案，但这些机构都是比较弱小的，而且商业模式单一。而整个社会，有约50万家公司的名称中包含征信的字眼，积极涉足征信业。 同时征信公司也获得资本市场的热捧，甚至还出现一些证券分析师推出的“中国征信第一股”的咄咄怪事。 这种全社会的征信大跃进式行业投入存在着明显的弊端。首先大量机构涌入征信领域有着很大的盲目性，浪费了大量的人力和大量的资金。其次导致“征信”概念的混乱，造成了征信概念满天飞。征信与风控混淆不清，很多人理解的征信其实是风控，而且“一切数据皆信用”，只要有点数据都想着开始做征信，征信机构变得没有门槛了。 为什么征信大跃进这个泡沫灭掉了？主要原因是金融监管的加强，特别是互联网金融的整治的不断展开和深化。同时征信行业的专业性和积累性的特点使这些机构的大量投入不能很快地变现 征信大跃进的背后，是我们对征信本质的理解欠缺。征信系统建设需要时间的积累，需要前期大量地投入，需要和先进的信息技术进行整合，而且具有一定的专业门槛，并非适合许多企业参与，并非能够短期见效。 对征信大跃进这种现象值得深入地反思，个人征信产品是有公共属性的商业化产品，那么民营征信机构如何保证公信力？如何做一个有责任的公司？如何保证消费者的权益？保证公平正义，赢得监管层、传统金融机构的信任？ 百行征信启航：未来新金融的基石，任重道远 百行征信（信联），这是一个最近比较热的话题。百行征信作为第一家拿到个人征信牌照的机构，引起国内外的广泛关注，国外的主流媒体像美国华尔街日报，英国的金融时报，和国内的许多权威媒体连续追踪报道，对百行征信进行解读和展望。甚至还有很多大数据公司和金融科技公司也想加入这个百行征信。 百行征信有它的明显的优势，首先是具有一定的社会公信力，因为它有央行背景，这一点对于开展具有公共属性的个人征信服务来说，这种得天独厚的优势，是民营征信机构所无法比拟的。其次互联网金融领域的征信服务目前基本上是空白，百行征信的未来业务开展有很大的空间。同时百行征信的企业定位，也会在市场化的道路上走得远一点。 但百行征信的未来仍存在很多挑战：一是能否制定长效的商业机制，例如不完全利用央行的行政权力把数据搜集上来，用商业的力量让不太成熟的新金融机构积极参与信息共享。二是能否充分利用市场化的激励机制，让征信系统更加有效率，能够及时开发出一些更加满足实际需要的产品。三是结合大数据、人工智能和区块链等先进的信息技术做一些创新，满足未来飞速发展的中国互联网经济的需要。 图二 中国（个人）征信体系（2018） 2018年之后随着百行征信的启航，中国的征信体系发生了真正的变化，如图二所示。可以看出，新成立的百行征信在覆盖信贷人群和新金融机构上将作出重要贡献，但是能不能成为一个有效率的征信体系，还需要时间的验证，还有待观察。建成一个高效的征信系统并非一件容易的事情，不是简单地把数据搜集整合成信用报告，而是需要很长时间的技术和业务积累，需要大量的征信产品研发投入，更重要的是商业游戏规则和激励机制的制定。 对于百行征信的未来，既不能因为其天然的优势期望过高，也不能因为其面临的挑战而过度悲观，作为互联网经济时代的重要基础设施，大家应该群策群力，使其更快更好地服务社会，造福我们每一个消费者。 未来中国征信：继续探索，继续完善，寻找市场和政府的平衡点 纵观现实，目前的征信服务和快速发展的互联网经济是不匹配的，不仅缺乏丰富的征信产品和服务，甚至还没有向全社会提供类似美国FICO评分一样可以用于基本自动化信用决策的信用评分，因此中国征信格局并未成型，还没有走向成熟，还需要继续探索。特别是（个人）征信产品是一个半公共属性的商业产品，需要政府的监管和市场的参与，兼顾公平和效率。美国作为全球的征信最发达的国家，就充分发挥了市场和政府的作用。我国的特点是强势的政府，活跃的市场，如何把这两方面有效地结合起来，双轮驱动中国征信体系建设？由于经济发展阶段等原因，感觉目前还需要继续寻找征信体系建设中政府和市场的最佳平衡点，未来可能会继续博弈。 未来个人信息保护对个人征信冲击也会比较大。相比于欧美发达国家，中国征信或者是风控的机会在于，一是强劲的市场需求，二是相对宽松的个人信息保护政策。但是目前似乎有种趋势，某些（个人信息保护）政策研究人员，没有充分考虑消费者的实际需求，不考虑大数据企业真正运营的情况，计划全盘引进欧盟最新出台的个人数据保护措施（GDPR）。过于苛严和不切实际的个人信息保护，对个人征信，对风控都是很大的挑战。 企业征信继续面临挑战。国内目前注册了将近130多个企业征信公司，相比个人征信来说，企业征信的特点是业务非标性，信息维度比较高，信用评估情况也比较复杂。目前企业征信的基本商业模式还存在很大的挑战，即使央行有很多的企业征信数据，但是企业征信的产品仍很难推出来，因为业务理解和产品开发难度还是相当大。 另一方面，国内的征信也面临一些新机遇。虽然国内消费者缺乏传统的信贷数据，但是有很多丰富的非信贷信用数据，或者信用相关的数据。比如电信数据、支付数据、社交数据、电商数据和心理测量数据等。过去几年，互联网金融公司也开始开发和利用这些非信贷类信用信息进行风控，但是每个公司都要自己投入，数据太分散而且成本很高。其实可以从征信角度来看这个问题，通过一些专业化的机构把数据整合，提供一些通用的基础产品，降低风控成本，提高效率。服务于不同消费场景的专业征信机构也是未来值得探索的方向。 作者曾提出非金融征信平台的政策建议。电信数据不仅能反映消费者的经济活跃性，也有“先用后买”的征信含义在里面。根据国内目前的情况，有必要建立一个基于电信运营商数据的征信平台，不仅可以解决电信运营商内部的信用风险问题，也可以对外输出，作为一个基础的征信平台给信贷机构提供服务，而且，可以还为很多“先用后买”的互联网经济提供征信服务。 图三 基于电信运营商数据的征信平台 未来征信行业和社会信用体系建设会产生一些联系。从2003年开始的社会信用体系是中国特有的，征信体系目前是作为社会信用体系的一部分。政府希望通过信用管理的一些机制用于政府管理和社会治理，范围更广，不限于金融领域，2020年的目标是初步建成中国的社会信用体系建设。未来的社会信用体系建设，和征信继续会有交叉、联系，但两者还是有明显的区别。前面提到的50万个征信公司，2017年4月21日之后，部分公司改名了，把征信改为信用，向社会信用体系建设靠拢。 中国征信业的未来充满了挑战，也面临着机遇。面对现实，中国的征信服务还是比较滞后，中国的征信业还未走向成熟。但是创新、专业精神以及政府与市场的平衡将为中国征信业的未来发展注入活力。■ 作者为某大型金融机构副研究员、《征信与大数据》作者。北京大数据研究院李铭博士对本文亦有贡献 转载来源：百行征信与中国征信的未来]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>经济</tag>
        <tag>金融</tag>
        <tag>大数据</tag>
        <tag>中国人民银行</tag>
        <tag>运营商</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[鸿茅药酒发布企业自查整改报告:已停播全部广告]]></title>
    <url>%2F2018%2F6c31b234%2F</url>
    <content type="text"><![CDATA[今天（4月26日）下午，鸿茅药酒在其官方账号发布企业自查整改报告，其中表示，目前已停播全部广告，并表示认识到鸿茅药酒在近五年的广告投放中存在广告投放量大、下游经销商和零售药店广告违规等问题。对于社会关注的安全性、豹骨来源及生产质量等问题，鸿茅药酒表示&quot;豹骨&quot;的购买及使用符合法律法规，并称&quot;按照药品说明书的用法用量使用鸿茅药酒是安全&quot;。 新京报快讯 今日(26日)下午，鸿茅药酒生产方，内蒙古鸿茅国药股份有限公司发布企业自查报告，面向社会公众致歉。 以下为自查报告全文： 内蒙古鸿茅国药股份有限公司(以下简称“鸿茅国药”)，作为鸿茅药酒市场与安全的责任主体，按照原国家食品药品监督管理总局、国家药品监督管理局和内蒙古自治区食品药品监督管理局的要求，认真查找自身问题，强化质量安全，加强风险控制，规范生产经营，坚决做到对消费者负责。 在近期鸿茅药酒事件的舆情发生后，我公司没有认真研判风险，主动发声，主动处置，主动回应社会关切，导致舆情进一步扩大。由此，给社会各界带来的问题和影响，我公司高度重视并向社会真诚道歉，恳请公众谅解。 本次事件，对于鸿茅国药是一次深刻教训。我公司清醒地认识到，作为一家药品生产企业，必须承担主体责任，对产品全生命周期的安全性和有效性负全部责任;承担不良反应直报和对药品质量持续提升的任务，以更高质量的产品和服务保障消费者的安全和健康。 我公司正在认真组织自查，并积极配合国家相关职能部门的检查，现将截至目前的自查及整改情况向社会各界通报如下： 一、对于社会高度关注的鸿茅药酒安全性、豹骨来源及生产质量等问题的说明 1.鸿茅药酒组方中的“制附子、制半夏、制天南星”都是炮制品,按照药品说明书要求的日服用量，折算成药材剂量，上述药材日用量均在药典规定的安全用量范围之内。因此，按照药品说明书的用法用量使用鸿茅药酒是安全的。 鸿茅药酒组方中制附子和制半夏同用在中成药制剂中具有普遍性。 2.针对鸿茅药酒的安全性，我公司主动开展过毒性试验、主要药效学研究和临床试验，研究和试验结论是安全有效的。根据不良反应中心数据，2004年至2018年2月底，鸿茅药酒共有不良反应报告137例，不良反应主要表现为头晕、瘙痒、皮疹、呕吐、腹痛等。 3.鸿茅药酒中“豹骨”的购买及使用符合法律法规。生产过程中，物料平衡符合要求。并在2007年启动了鸿茅药酒中去豹骨研究工作并完成了药效学对比研究实验。 4.我公司始终严格按照《药品生产质量管理规范》的要求进行全面管理。在生产质量管理过程中，不断完善生产质量管理保证体系，保证产品质量稳定。在历次产品监督抽检中，未出现产品不合格情况。今后，我公司会持续按照GMP标准要求组织生产，承担不良反应直报和产品质量持续提升的主体责任。 今后，我公司将进一步加强药品安全性的风险评估，主动监测药品风险，并对鸿茅药酒持续进行安全性和有效性研究，守好“品质关”和“用药安全关”，更好地对消费者负责。 二、关于社会公众及媒体关注的鸿茅药酒广告问题的情况说明 我公司经过严格自查及深刻反省，认识到鸿茅药酒在近五年的广告投放中存在广告投放量大、下游经销商和零售药店广告违规等问题;企业经营管理过度依赖广告、广告发布管理存在漏洞等问题。我公司对由此引发的媒体争议、社会批评，负有不可推卸的主体责任。 1.近五年来，我公司作为广告投放主体，发布的广告平台为中央电视台、中央人民广播电台、各卫视及地方媒体。经认真自查，广告发布过程均依法合规。但鸿茅药酒的全国各地经销商和零售药店存在违规发布广告的问题。通过查询近五年的《违法药品医疗器械保健食品广告公告》，涉及鸿茅药酒的公告共计17个，其中2015年9月1日新《广告法》颁布之后的公告有4个。 2.关于 “鸿茅药酒祝您：每天两口 健康长寿”广告语的创意，是因为鸿茅药酒产品说明书中的用法用量为：口服一次15毫升，一日2次。因药酒剂型特殊，有酒的特性，容易出现消费者超过规定用量服用的情况，所以广告语表述为“每天两口”，是特意提醒消费者每天服用量不要超过“两口”，以保证用药安全;“祝您健康长寿”，则是一句祝福语。为避免歧义，2017年12月，内蒙古自治区食品药品监督管理局按照原国家食品药品监督管理总局有关部门的要求，及时与我公司约谈，要求企业对凡是含有有可能引起误解、歧义、争议广告用语的广告全部改版、尽快停播。我公司已按要求停播有关广告，并交回了相关广告批文。 2018年改版后播出的广告内容特意增加“鸿茅药酒提示您，购买药品前请阅读说明书”的安全用药公益性宣传，同时也明确了鸿茅药酒是药品的属性。 3.近年来，鸿茅药酒饱受侵权产品、假冒产品的侵害，我公司从未发布过“喝鸿茅百病消”、“鸿茅药酒包治百病”等广告内容，也从来没有宣称过“鸿茅药酒能够治疗高血压、糖尿病”，对此我公司将进一步调查其发布主体及来源，并进行追责。 目前，为了消除不良影响，承担企业主体责任，我公司采取了一系列从严整改措施。现已停播中央电视台、中央人民广播电台、各卫视及地方媒体的全部广告;同时派出检查小组，深入全国31个省市自治区开展自查自纠工作;从速建立了从企业到零售终端的完整、严格、可控的广告宣传管理链条;对假冒鸿茅商标或商号的违法经营行为进行维权;积极宣传药品用药安全;承担社会责任、关爱患者健康、大力参与和推动社会公益活动。 作者：王煜 原标题：鸿茅药酒生产方发布自查报告 向公众致歉 转载来源：鸿茅药酒发布企业自查整改报告:已停播全部广告]]></content>
  </entry>
  <entry>
    <title><![CDATA[深度长文：反思互联网的黑暗世界]]></title>
    <url>%2F2018%2F443dcd60%2F</url>
    <content type="text"><![CDATA[本文作者James Bridle在“Something is wrong on the internet”一文中从YouTube上供孩子们观看的视频入手，剖析了互联网通过自动化、规模化框架所产生的一个黑暗世界。 文/木木子 互联网真的可能毒害下一代。 编者按：反思是必要行为，越及时越好，越清醒越好。本文作者James Bridle在“Something is wrong on the internet”一文中从YouTube上供孩子们观看的视频入手，剖析了互联网通过自动化、规模化框架所产生的一个黑暗世界。而重要的是，我们该如何行动。 我随着互联网成长，确信它是对于今天我之所以为我的最重要影响之一。我从13岁开始上网，当时电脑就在我的卧室里。它让我有机会接触到了许多完全不适合青少年所了解的东西，但是这都还好。互联网一直以我认为的于己有益的方式对我的身份产生至关重要的影响，它塑造了我的人际关系、文化与政治。我一直是互联网及其所带来的一切影响的重要支持者，并明显认为它是有益的且具有解放意义。在一开始说明这一点是因为在下文我将描述互联网所产生的影响以一种意味深长的方式驳斥了我之前的假设和偏见。 我经常问自己的一个假设性问题是，如今我对于自己的孩子用同样方式上网有什么感受。我发现这个问题越来越难回答。我明白这是随着年龄增长而自然发生的演变，而且某种程度上这个问题的假设性因素越来越少。我不想在这个问题上成为伪君子。我希望我的孩子拥有与我一样去探索、成长和表达他们自己的机会。我希望他们拥有这个选择。这种信念放松了人们对互联网在公共生活中扮演角色所持有的态度。 我也意识到，在这些时间里年轻孩子与YouTube之间的共生关系与日俱增。我看到孩子们无论是在婴儿车里，还是在餐馆里，都整天关注着屏幕，同时伴随着一种类似于勒德分子（Luddite，十九世纪初英国手工业工人中参加捣毁机器的人，现泛指强烈反对机械化或自动化的人）的阵痛。但我不会为他人或者是他人父母做出判断。我也看到家人和朋友的孩子投入地看《小猪佩奇》和童谣视频，这使他们变得开心并给每个人带来放松的机会，所以这也还好。 我至今没有孩子，而现在只想一把火把所有东西烧掉。 一些人、一些事抑或是一些人与事的结合体正以自动且大规模的方式通过YouTube系统性的恐吓、伤害和虐待儿童，这迫使我从任何角度质疑自己对于互联网的看法。接下来，我要说的大部分内容已经在其他地方报道过了，虽然在我所看的主流报道中没有一个能真正理解那些似乎正在发生事情的含义。 我将由此开始：专为孩子开辟的YouTube内容清楚且引人注目地充满怪异。我意识到它的古怪已经有一段时间了。去年，有许多文章都提到了令人吃惊的惊喜蛋（Surprise Egg）热潮。惊喜蛋的相关视频通常以一种极其痛苦的长度展示了打开金德和其他玩具蛋的过程。就是这么回事，但是孩子们对此着迷。即使没有数百万，也有成千上万的孩子们在观看成千上万这类视频。 自2010年以来，惊喜蛋的制作者已经累积了370万订阅用户，这个孩子友好频道仅仅致力于打开惊喜蛋和拆箱玩具就达到低于60亿的浏览量。视频标题是一种模糊品牌线和搭卖广告的模式：“Blu Toys Surprise Brinquedos &amp; Juegos”“Cars Screamin’ Banshee Eats Lightning McQueen Disney Pixar”“Disney Baby Pop Up Pals Easter Eggs SURPRISE”。 在我写这篇文章的时候，他一共制作了4426个视频。与贾斯汀·比伯官方频道超100亿的浏览量相比，全职YouTube名人PewDiePie拥有近120亿的浏览量，就好像这个男人用一双温柔地打开惊喜蛋的双手为生。（惊喜蛋视频都配有前贴片广告、中断广告和其他广告形式。） 这让你了解到孩子们的在线视频世界是多么怪异，而这一系列视频标题则暗示了这一情况所涉及的不同寻常的范围和复杂程度。我们马上就会讲到后者。但是，就目前而言它已经显得非常奇怪。 另一种尤其对于最小的孩子而言很受欢迎的巨量内容，是童谣视频。 制作这种视频的Little Baby Bum在YouTube最受欢迎频道排名第7。他们共产出515个视频，拥有1150万订阅用户和130亿浏览量。同样，我很快就会说道这些数据的准确性也存在问题，在这里我想说明这是一个庞大的网络产业和世界。 点播视频对于父母和孩子来说都是“猫薄荷”，对于内容创作者和广告商来说也是如此。小一些的孩子无论是出于熟悉的人物还是歌曲，或者是简单的色彩和舒缓的声音而被这些视频迷住。这些视频的长度（一个常见的处理方法是将许多童谣或卡通片段汇编在一起+编辑）和将视频长度作为吸引点而成为营销手段的一部分，指向了那些孩子们与这些视频一起度过的时间。 因此，YouTube广播公司想出大量策略来吸引家长和孩子们的注意力，并获得伴随这些行为而生的广告收入。第一个策略是复制和剽窃其他内容。以我的尝试为例，在YouTube上搜索“小猪佩奇”会收到“大约10400000个搜索结果”，而首页内容几乎全部来自经过认证的“小猪佩奇官方频道”，同时有一个视频来自于未经认证的频道，叫做Play Go Toys，除非你刻意寻找它否则很难注意到。 据我猜测，Play Go Toys频道里的《小猪佩奇》和其他卡通片、玩具拆箱是盗版的，此外还有一些我认为应该是频道主自己孩子的视频。我并不是要说Play Go Toys有什么不好；我只想简单说明YouTube的框架以怎样的方式导致内容与创作者的分离，而这将如何影响我们对于信源的认识和信任行为。 正如另一位博客作者所指出的，品牌内容所扮演的传统角色之一是其信源可信性。无论是儿童电视上播放的《小猪佩奇》还是迪士尼电影，不管人们对于这种娱乐生产的工业模式有什么感受，这些视频通过精心制作和受到控制而让孩子们能以基本安全的方式观看它们，并且被赋予信任。而这不再适应于品牌和内容被平台分离的情况，已知的可信内容为那些未经认证和潜在有害内容提供了无缝衔接的网关。 （同样，这与Facebook和谷歌上对可信新闻媒体的分离过程完全相同，而这些结果正在对我们的认知和政治体系产生严重破坏。我不打算在这里进一步探讨这种关系，但是它显然也非常重要。） 增加视频点击率的第二种方法是关联关键字或是主题标签，这是一种全然黑暗的艺术。当某种内容，比如惊喜蛋视频，成为趋势而能够抵达绝对多的大众时，内容生产者就会蜂拥而至，制作出成千上万类似的视频。这就是上面所提到的那些奇怪名字产生的缘由：官方内容、童谣标题和“惊喜蛋”都被塞进了同一个单词中以出现在搜索结果、侧边栏、以及“下一个”自动排名的位置中。 一个奇怪的例子是Finger Family视频，我不知道他们从哪里冒出来，也不知道这些童谣旋律的起源。但是目前YouTube上至少有1700万个版本，它们也涵盖了包括上百亿拼接场景在内的所有可能类型。 再说一次，必须认真对待视频的浏览量情况。其中大多数视频本质上是由机器人所制作，被机器人所观看，甚至被机器人所评论。这是一个完全陌生的世界。而不应该掩盖的事实是，实际上还有许多孩子通过iPhone或者是平板电脑一遍又一遍地观看着，这在某种程度上解释了这些视频的浏览量数值。孩子们学着在浏览框中输入基本搜索词，或者是在侧边栏中简单添加另一个视频。 令我觉得有些不安的是，即使是相对正常的儿童视频在网上的扩散也无法解释其自动化的程度，如何剖析人与机器之间的差距呢？有近200万订阅者的Bounce Patrol Kids频道显示了这种影响。其内容有专门的真人演员表演，以每周一个的制作速度发布专业制作视频。 有一群人在无休止地演绎着由算法生成的关键字组合的意义所促使的行为，这很奇怪：“Halloween Finger Family &amp; more Halloween Songs for Children | Kids Halloween Songs Collection”, “Australian Animals Finger Family Song | Finger Family Nursery Rhymes”, “Farm Animals Finger Family and more Animals Songs | Finger Family Collection - Learn Animals Sounds”,还有很多很多。这是算法搜索时代的内容制作模式，即使你是人类，也必须去迎合机器。 其他视频也会与人类演员一起，不断制作出无限可重构的相同视频版本。当然，自动化在其中扮演重要角色。各类库存、音频轨道和这些关键字列表以数千种方式拼接在一起源源不断制作出视频。上图中所展示的频道，Videogyan 3D Rhymes — Nursery Rhymes &amp; Baby Songs通过组合这些日益复杂的关键词，以每周几次的频率发布视频内容。他们有近500万订阅者，是Bounce Patrol订阅者数量的二倍不止，然而我们依然不知道是谁或者是什么累积起了这些数以百万计的浏览量。 我试图不让这篇文章被没完没了的例子所充斥，但是我们需要了解这个体系有多阔大、以及是什么决定了此种行动、过程和观众，这很重要。这也涉及国际事宜：有许多Finger Family和Learn Colours视频的不同版本，如Tamil epics和Malaysian cartoons它们不太可能出现在任何英语使用者的搜索结果中。这种极其不确定性和搜索行为是其存在和产生影响的关键。这种广延性让这种行为捉摸不定，甚至难以真正对其形成思考。 我们已经看到了那些确之凿凿的例子，用以说明完全自动化所带来的令人不安的结果，谢天谢地是其中一些已经经由黑色幽默所发酵，而另有一些还没有。从T恤到咖啡杯，从婴儿睡衣到手机壳，许多都是由图片库和按需制作的算法构建而成。上图中最近在Amazon上售卖的物品就是一个例子，它如何产生的故事既迷人又怪异，但从本质而言可以理解。没有人打算用药物和医疗设备制作手机壳，这可能只是一个非常怪异的数字或概率结果。但是，这个需要一段时间才能被人们注意到的事实敲响了警钟。 同样，“冷静地强奸”（Keep Calm and Rape A Lot）T恤以及“冷静被对她持刀”和“冷静地打她”的结果令人沮丧且痛苦，但是可以理解。没有人打算制造这样的T恤，它们只是由一个未经核查的动词和代词列表与一个在线生成器所配对。这些T恤相当有可能从没有出现过、曾经被买过或是穿过，这样就不会造成任何伤害。但是又一次，制作这个内容的人没有注意到，分销商们也没有注意到。他们根本不知道自己在做什么。 基于这些案例以及那些我将要进一步说明的案例，我想说的是，这个系统的规模和逻辑是产生如此结果的同谋，我们需要好好思考它们的含义。 （再次说明，我不打算深入探讨这些内容除这篇文章之外的更广泛的社会影响，但是很明显，人们可以从这些例子中找到一条解决大数据和机器智能驱动系统中存在的种族和性别偏见等当代问题的明显界限，这些问题需要迫切的关注但是我们却没有任何简单的或者是更好的解决方法。） 我们可以在这些成堆视频中选择看一段，然后试着分析它来自哪里。需要重点强调，我并没有打算去找某个特定视频：在一个匿名浏览器窗口（例如，不应该受之前搜索行为的影响）中搜索“finger family”，它的排名很高。这种自动化把我们带到了非常非常奇观的情况中，“兔子洞”如此之深以至于我们不知道这样的东西如何得以形成。 这个视频标题为“Wrong Heads Disney Wrong Ears Wrong Legs Kids Learn Colors Finger Family 2017 Nursery Rhymes”。标题本身就证实了它来自于自动化合成。我不知道为什么有“Wrong Heads”这样的表达，但是可以猜想，就像“Finger Family Song”一样，它通过与Learn Colors,、Finger Family和Nursery Rhymes这些词汇拼接渐渐提高自己的算法排名，这最终形成了我们所看到的这个标题。 这段视频由一个普通的Finger Family歌曲组成，画面中呈现出一个由迪士尼《阿拉丁》动画中的角色头部和身体拼接而成人物。这的确很怪异，但是坦白讲，并不比惊喜蛋视频或其他童谣视频奇怪到哪去。但是我发现这种想法太天真了。一个非《阿拉丁》动画的角色艾格尼斯出现了，她是《卑鄙的我》中的人物。 这段视频的制作者BABYFUN TV已经制作了许多类似的视频。《头脑特工队》的角色Hope与蓝精灵和食人妖交换头部。BABYFUN TV只有170位订阅者和非常低的浏览量，但是平台上有成千上万个这样的频道。长尾数字在抽象情况下并不能显示出重要性，重要的是它们所实际产生的累积效果。 所以问题变成：这些是怎么来的？在BABYFUN TV的频道中也出现“Bad Baby”的修辞。虽然我觉得令人不安，但是我能理解它是如何通过提供一些旋律、节奏或与他们自己经历相关的东西而使得真正的小婴儿被这些内容所吸引，虽然它经由算法的反复与重组而以一种没有人会想要让其发生的情况所扭曲和拉扯。 Toy Freaks频道截图 Toy Freaks是一个非常受欢迎的频道（平台排名第68位），主角是一位父亲和两个女儿。除了学习儿歌和辨认颜色之外，Toy Freaks擅长于制作一些令人恶心的内容，以及令许多观众都觉得自己受到虐待和剥削的行为，其中还不算特别严重的情节包括儿童呕吐和疼痛的视频。Toy Freaks是一个经YouTube认证的频道，无论这意味着什么。 就像Bounce Patrol Kids一样，无论你对这些视频内容有什么感觉，我们不可能知道自动化涉入的起点与抽身的终点，不可能知道谁来提出这些想法以及谁在扮演这些角色。相反，在如Toy Freaks这类受欢迎的、由人类主导的频道中，其所产生的影响使得它们通过越来越古怪且扭曲的重新组合方式在网络中不断出现。 而有些视频比Toy Freaks和与其类似的内容更令人不安。下面是一个相对温和，但依旧令人不安的例子： 比之前所提到的盗版《小猪佩奇》更甚，还存在一种山寨品。这些内容也充斥着暴力。在官方版本中，佩奇得到了和蔼牙医的适当安慰。而从上图的对比版本中看出，她受到了折磨。搜索“peppa pig dentist”会在首页上发现这些视频，而这些让事情变得更糟。（此处引用视频已经被YouTube删除，但是平台上仍有许多类似视频。） 《小猪佩奇》这些令人不安的视频内容，包括佩奇吃自己的父亲和喝漂白粉在内，隐含着极端暴力和恐惧因素却被广为传播。它们是整个YouTube亚文化的一部分。 这段视频以对于佩奇的拙劣模仿开始，后来进入到我们已经见过的那种情节的不断重复中。也许这就是钓鱼行为（Troll，最初作为网络用语用来描述在公共论坛等讨论区故意用激烈言辞引起别人进行没有意义的争论的行为，后来释义延伸为几乎所有做出令人厌恶举止的行为，不论主动还是被动的）。我希望它是。但是我不这样认为。“钓鱼”并不能解释这些人类参与者的交集之处和更多自动化的例子。它在其中显现，却不是故事的全部。 我想，不去深思熟虑这个问题是幼稚的行为，但是有如此多像牙医情节一样未认证的发布，许多孩子们正在观看它。我知道大多数内容并不是想把孩子弄得一团糟，但是它们确实会带来如此效果。 我尝试去理解原因是什么，这并不单单是对于“不会有人想到孩子”的束手无策。显而易见，这些内容不合适。显而易见，有一些不好的演员。显而易见，有些视频应该被删除。显而易见，这引出了关于合理使用、挪用、言论自由等问题。但是那些仅仅通过镜头内容了解问题的报告并没有完全理解正在发生的机制，因此也就无法从整体上考虑其影响，并作出相应回应。 《纽约时报》所写的关于这些问题的文章“On YouTube Kids, Startling Videos Slip Past Filters”强调了那些令人不安的视频中的假冒人物和童谣现象，并将其放置在适度性和立法的问题上面。官方应用YouTube Kids声称其内容对于儿童来说是安全的，但显然不是如此，这即是问题所在，因为它误用了用户的信任。英国小报《太阳报》的一篇文章“Kids left traumatised after sick YouTube clips showing Peppa Pig characters with knives and guns appear on app for children”也采用同样思路，又增加了右翼技术恐惧和自以为是的分析。但是这两篇文章都是从表面上评价了YouTube声称这些结果非常罕见且很快被删除的行为。 Good Baby Toys频道 这是亚洲地区制作的Toy Freaks的基本情况。还有俄罗斯的。我不想再用“人主导”这个词来形容这些视频，尽管这些内容包含了相同的修辞和实际的人类角色。我想不明白到底发生了什么，我认为这就是问题的关键。这就是我为什么开始深思熟虑所发生的一切的部分原因。我们需要作出许多努力。谁在写这些脚本，谁在编辑这些视频？再一次，我想强调：这与许多东西相比仍然是相对温和，甚至是有趣的东西。 有些事情令我不安： 第一件事情是恐怖和暴力被展示的程度。互联网提供一种放大且促进我们潜在欲望的方式；事实上，这是它看起来最擅长的。我花了很长时间来论证这种倾向，关于人类的性自由、个人身份和其他问题。而在这里，绝大多数人有时会觉得，这种倾向本身就有一种暴力和破坏性的倾向。 第二件事情是被剥削的程度。不是因为他们是孩子而成为孩子，而是因为他们的无权利性而成为孩子。像YouTube算法这样的自动奖励系统必定以资本主义的剥削方式进行剥削。如果你对于对等式的后半部分感到恼火，也许这就是让你信服真相的原因。剥削被编码到我们正在建构的系统中，使其更难被发现、更难于对其进行思考和解释、更难于对抗和防御。这不是工厂由机器人构成以及人工智能统治一切的未来，而是此刻、现在，在你的屏幕上，在你的起居室里，在你的口袋里。 其中部分例子都试图证明没有人真的在看这些视频，都是机器人在背后操作。即使人类只出现在这个系统的生产方面，我也对他们表示担心。 这段视频“BURIED ALIVE Outdoor Playground Finger Family Song Nursery Rhymes Animation Education Learning Video”里包含了我们上面所提到的所有元素，并产生比之前更严重的影响。熟悉的人物角色、童谣、关键词、完全自动化、暴力、以及孩子们最糟糕的梦想。当然，这种视频大量存在着。一个频道接着一个频道，以每周数百个新视频的更新速度进行播放。以工业化的水平生产噩梦。 最后：也有比这些更暴力和含有更多性内容的东西。我并不打算给出链接。我不相信它会给别人带来精神上的创伤，但是有必须要继续强调，不要忽视这些黑暗的、怪异的对成人没有多少干扰的东西对于孩子的影响。 一位从事于数字视频的朋友向我描述了制作这些内容需要些什么：一个小型工作室（可能由6人，或者更多人组成）通过大量制造低质量内容而满足这个系统的某些要求（长度似乎是其中一个因素）来获得广告收入。根据这位朋友的说法，供儿童观看的内容是3D动画为数不多的赚钱方法之一，因其审美标准较低并可以通过大规模的独立生产而获利。它使用现有的且易于获得的内容（如人物模型和动作捕捉库），通过不断重复和修改而完成制作。它可以不具有任何意义，因为算法不会对此歧视，孩子们也不会。 这些视频，无论是在哪里制作，无论是如何制作，无论是否有明确目（例如，积累广告收入）都在以有意识向孩子们展示视频的方式获取利润。而不自觉的涌现出来的后果到处都是。 让孩子暴露在这种内容之中是虐待。我们讨论的不是电影或是视频游戏暴力对青少年存在争议却毋庸置疑的影响，也不是色情或极端形象对于青少年的影响，这属于那种我在开篇所描述的青少年时期使用互联网影响。这是重要且值得辩论的内容，但是却不是我在此想要讨论的东西。我们所谈论的是非常年幼的孩子，从出生开始，成为会对他们造成伤害和干扰的目标之物，而互联网则提供了这种进行虐待的极其容易的方式。这不仅关于“钓鱼”问题，而是内在暴力与数字系统和资本主义激励的结合。 我的观点是：这个系统是虐待行为的同谋。 此时、此地，YouTube和谷歌在这个系统中沆瀣一气。他们为了从在线视频中获取最大利益而建立起的框架正在被虐待儿童的不确定分子所入侵，也许这不是故意行为，但是却以大规模的方式存在着。我认为他们需要担负起解决这个问题的绝对责任，正如他们有责任去处理那些意图政治说服的极端视频对年轻人的激进化问题所产生的影响。到目前为止，他们完全没有表现出这种倾向，而这本身就是卑鄙行为。然而，我对于这个议题想做出的最大回应是，我不知道他们如何在不关闭服务本身以及其他类似系统的情况下做出解释。我们建立了一个规模化运作的世界，在那里，人类的监督无法触及到每个角落，也没有任何非人形式的监督能够发现我在本文中所提到的大部分例子。 这是一个非常黑暗的时代，我们为服务于自我而建立起的框架正在以系统且自动化的方式转而对付我们，我们所有人。当网络制造出恐怖的时候，我们很难对网络保有信心。尽管人们很容易将这些更为疯狂的例子视为“钓鱼”行为，肯定有相当数量的人是这样认为，但是这并不能解释那些特别怪诞的内容的绝对数量。就像越来越多人关注俄罗斯对社交媒体的干涉一样，它所带来的纷繁复杂的危险被用作加强控制、增加审核等行为的理由。这并不是我们想要的结果。 而我想说的是： 尽管对于孩子所遭受的暴力问题让我十分担忧，但是我所担忧的不仅仅是这些。我所担忧的是对于这种在任何时间对于我们所有人产生影响的基础设施暴力，我们依然在努力寻找谈论它、描述它的机制、它的行为和它的影响的方式。正如我在开篇所说：这是由人、由事、由人与事的结合所导致。对于这种结果所需要承担的责任无法合理被分配，但是伤害是如此、如此的真实。 原文链接：https&#58;//medium.com/&#64;jamesbridle/something-is-wrong-on-the-internet-c39c471271d2编译组出品。编辑：郝鹏程 转载来源：深度长文：反思互联网的黑暗世界]]></content>
      <categories>
        <category>育儿</category>
      </categories>
      <tags>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>英国</tag>
        <tag>玩具</tag>
        <tag>YouTube</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三年半后，快播王欣拾起来的仍是当年的“区块链”]]></title>
    <url>%2F2018%2F28e4f56a%2F</url>
    <content type="text"><![CDATA[2014年4月22日晚，王欣被警察带走，称被举报涉嫌传播淫秽色情信息，再之后就是法庭上那些曾经刷爆朋友圈的桥段。 提到快播，众多宅男都会心一笑，想起无数个夜晚通过网络种子看过的那些不可描述。 而这个视频软件的缔造者王欣，也被称为中国“最有种的男人”。 2014年4月22日晚，王欣被警察带走，称被举报涉嫌传播淫秽色情信息，再之后就是法庭上那些曾经刷爆朋友圈的桥段。 狱中三年半，外面的世界已经被区块链的浪潮包围。 不过，P2P、流量矿石、互动币，以及王欣狱中的一系列动作都表明，他带头的“快播系”并未错过区块链。 惊艳出场的P2P 王欣出狱后，据传与小鹏汽车创始人何小鹏、 58 同城CEO姚劲波等人畅谈AI、视频、区块链等技术的发展，何小鹏更是表示“他思维完全和大家在一起”。 其实这也在意料之中，尽管在狱中三年多，但区块链对于王欣来说恐怕不是什么新鲜事物，因为他以前玩过的P2P对等网络技术就是区块链系统的重要基石。 2003年，王欣23岁，当时他是“盛大盒子”研发团队的一员。这个花费了陈天桥许多心血的项目，最终没有在市场上获得成功，而王欣也决定另谋出路，和其他技术牛人一样，走上了创业之路。这也导致了之后快播的诞生。 快播巅峰时期拥有5.3亿用户，是国内市占率第一的播放器。而其最吸引用户的点是让电影和游戏的下载变得更容易：用户在线观看电影的同时，该文件同时也被静悄悄地下载下来了，这个功能受到众多用户的追捧。 不知道快播的用户在享受“边看边下”带来的快捷时，是否有思考其背后的技术？其实这种快捷的下载方式就是使用的P2P技术。 P2P又被叫做对等互联网技术，这种技术最大的特点是：它并没有与各计算机相连的中央服务器，只有一套允许数据共享的端对端协议。它依靠的是网络中各个节点的计算能力和带宽，而不是依赖较少的几台服务器。 更形象的来说，一般情况下，如果我们要在网络上下载一部资源，通常用我们的电脑从提供资源的中央服务器上获取，是有一个中心化的组织存在。但在P2P模式下，只要这个网络中的任何节点里有这个资源，我们都可以下载下来，反过来我们下载的资源也可能成为其他网友获取的对象。 区块链网络系统和P2P理念拥有高度默契感，区块链的出发点之一是去中心化，所有的交易都是点对点进行，每个节点都是公平的；而P2P网络的天然属性，就是全网节点平等，无特殊节点。 可以看出，王欣在创办快播并引用P2P技术的时候，他的思维理念已经和区块链不谋而合。 “骗局”流量矿石 早在2013年，快播原科技产品总监黄胜就接触过比特币，在对区块链进行研究后，他和王欣共同发起了流量矿石项目。 快播出事半年后，流量矿石原团队新成立公司云帆科技，流量矿石背后真正的团队正是云帆加速科技有限公司。 对于王欣，黄胜也曾表示团队将邀请他以“原项目发起人、投资人”的角色回归，希望能够在他的支持下，把项目做好。 其实流量矿石平台本质是一种利用共享经济模式玩转CDN（内容分发网络）的云计算方案，让闲置的资源重新恢复它应有的价值。 具体怎么玩？其实它主要汇集个人手持设备、家庭带宽、企业节点等众多闲散的带宽和CPU资源，通过云计算的方式将实时的部署利用达到最优化，这样可以帮助各大视频网站解决带宽不足的问题。 流量矿石团队声称：“我们的使命是通过区块链与网络加速技术，打造一个世界级的去中心化共享CDN网络生态。” 但这种说法本身似乎是自相矛盾：既然流量矿石致力于“汇集个人手持设备、家庭带宽、企业节点、IDC机房等众多闲散的带宽和CPU资源”，那怎么会是一个去中心化的网络生态呢？ 这里要提一下快播的老对手迅雷。 去年，迅雷发布了一款产品“玩客云“，它的玩法和流量矿石类似，核心都是往CDN模式发展，收集用户闲散的宽带资源。玩法也都是卖硬件给用户挖矿，然后通过代币给奖励。 然而，玩客币可以回购，但流量矿石却不支持回购。挖到的矿石，其团队自己不收购，要通过会员充值进来的钱来购买，并且最终还是只能消费在平台上。这也是被许多用户诟病为流量矿石是一场骗局的原因所在。 根据最新的信通院行业研究报告，全球2010-2015年间的CDN市场复合年增长率为27.7%，2016年达到60.5亿美元，预计2020年将达到157.3亿美元，这无疑是一块很大的蛋糕。但流量矿石这一步棋没有走好。 反人性互动币 1月8日，流量矿石宝盒—一款前快播团队，同时也是流量矿石的兄弟团队开发的产品在苏宁开启预约，在1小时内出现了火爆的一幕：这款售价599元的产品被25万人疯抢。而一款名为互动链的项目随后也被推出，其宣称致力于用区块链技术撬动应用流量分发市场。 其官网宣称，互动链应用开发者的目标不再是创造用户价值，而是鼓励用户从应用开发者提供的服务中创造自身需要的价值，从而带动产品价值的提升。 事实上，所谓的互动链有点像游戏里面的“做任务”：开发者可在基于区块链的任务中心上设定好流量任务，在任务发布时根据人群属性的不同进行投放。投放完毕后，用户可以领取系统匹配好的任务，完成任务后智能合约就会触发给予奖励互动币HDT。 也就是说，站在开发者的角度，在互动链上他们掌握了更多的互动性：不用去捉摸如何为用户带来价值，而是让用户在自己提供的任务里面创造自己需要的价值。 但这本身是一种反人性的理念：用户本身是抵触学习，抵触创造的，如何让用户自己由被动变为主动不是一件简单的事情。 【结束语】 王欣，这个宣称“技术无罪”的男人曾赢得了无数技术同行的支持喝彩，当他出狱后，众多曾经的粉丝高喊“我们欠你一个快播币”。然而，如今的互联网格局毕竟已经不能和三年前相比，区块链能否为王欣打一场翻身仗仍有待时间考验。 转载来源：三年半后，快播王欣拾起来的仍是当年的“区块链”]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>云计算</tag>
        <tag>区块链</tag>
        <tag>快播</tag>
        <tag>迅雷</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[徐明星的OKEX涉嫌“非法交易”与“诈骗”全调查 | 钛媒体深度]]></title>
    <url>%2F2018%2F092b1e23%2F</url>
    <content type="text"><![CDATA[声讨这家公司和其背后的控制人：徐明星，国内比特币交易所OKCoin创始人，以及OK系主要公司OKEX实际控制人。 图片来源&#64;视觉中国 钛媒体注：本文来自钛媒体集团旗下区块链资讯与数据平台“链得得”。 赴京维权、上门理论、服毒威胁、集体报案、众人上访，过去的两个月间，络绎不绝的数字货币投资人聚集在OKCoin位于北京海淀区上地的总部办公地，声讨这家公司和其背后的控制人：徐明星，国内比特币交易所OKCoin创始人，以及OK系主要公司OKEX实际控制人，如今外出时常有保镖陪护。 前赴后继的维权行动，看似在一场场徐明星的反击声明和“投资者应该愿赌服输”的争辩中变成了口水战，投资者到底有没有责任？OKEX到底是什么性质的平台？中国的法律边界到底在哪里？为何徐明星会突然来那一场“献给国家”的言论，到底孰是孰非，围绕徐明星的迷雾始终没有散开，链得得研究团队在过去的一个多月也围绕平台交易的各个环节在全国展开了调查，逐渐有了完整而清晰的事实真相。 3月9日，国内比特币交易平台OKEX及OK集团创始人徐明星在员工群里发表言论称,“未来随时准备捐给国家。”这一突然的在很多人看来有些莫名其妙的言论引起轩然大波。 但是鲜为人知的是，据链得得App调查查证，就在此前的2018年2月24日，东莞市公安局以“诈骗案”，正式对OKEX平台可能涉嫌“非法期货交易”或者更严重的“诈骗罪”，展开刑事立案侦查。 另据链得得了解，中国其他地方也有陆续立案。 东莞公安局出示的立案告知书 在链得得APP行情追踪结果中，4月9日，OKEX以约为47.98亿人民币的每日交易额位居世界数字货币交易所第三名。在近65天的日交易额排名中，OKEX也以超过80%的频率稳居前三。巨大的交易额、平台流量和品牌影响力，令OKEX成为了广大普通中国数字货币投资者最主要的交易渠道。 众多投资人上门维权，让OKEX这家长期占据世界数字货币交易所排位前三甲的公司，持续牵动着舆论最紧绷的神经。来自百余位维权投资者所有的指控都来源于一个爆发点，OKEX平台提供的“合约交易”产品。 被爆仓或者利益严重受损的投资者的维权理由，都是基于一点，OKEX提供了非法的期货交易，这在中国违法；而徐明星和OKEX的声明皆认为，平台提供的“合约交易”并非期货产品。不过，根据链得得研究团队多方取证和调查、分析，OKEX的“合约交易”可以说具有比较清晰完备的期货交易属性。 横向对比目前为止世界前五大交易所，完全出海的币安、主体在中国国内的火币均未开设期货，或所谓“合约交易”的产品。但2014年8月至今（截止链得得发稿），OKCoin旗下OKEX交易所平台中，那明显的“合约交易”入口始终没有停息。 OKEX“合约交易”究竟是不是期货交易？区块链及数字货币问世至今所标榜的“去中心化”，在数字货币交易所层面却实现了诸多资本金融权力的集中。数字货币交易所集银行、银联、证券交易所、券商、发行审核部门、甚至监管者的角色而存在。在资产规模日益壮大的数据货币交易市场中，占据资金流动和融通规则的把控核心。 2014年8月18日，OKCoin发布消息，称旗下的比特币、数字货币“合约交易”平台OKEX上线，在“合约交易”币种上，包含比特币、莱特币、以太币。 OKCoin在自己站内发布的推文显示：旗下交易平台OKEX隆重上线，比特币、莱特币、以太币合约交易请到OKEX上来。 当时，OKCoin在“合约交易”业务的对外说明中写到：此次推出比特币合约，可实现比特币的套期保值，利用比特币合约对冲在支付过程中比特币价格波动导致的风险，进而解决比特币在支付领域的最大问题；此外由于比特币市场每日成交额有限，导致当前比特币支付能够承载的业务量十分微小，通过比特币合约放大杠杆，可以变相增加比特币每日成交额。 这也是投资者维权时指摘OKEX违法期货交易的重要源头，虽然这并不被OKEX官方承认。今年3月22日，OKEX官方在对媒体的回复声明中表示：OKEX法律团队认为平台的比特币虚拟合约业务不属于传统期货，交易过程没有法币，属于币币兑换，不符合传统期货定义，用户和OKEX公司之间也没有资金往来。 不过，打开现在OKEX的“合约交易”页面，链得得App也发现，OKEX的“合约交易”业务从交易逻辑到操作规程，均满足期货的显著特征：高杠杆、保证金、强制平仓、周月季度交割期、标准化合约、平台集中交易、套期保值功能宣传等。在OKEX的英文版页面介绍中，始终使用futures一词来指代“合约交易”的业务，而futures在金融交易的使用语境中，对应的中文翻译就是期货。 2011年，国务院出台《国务院关于清理整顿各类交易场所切实防范金融风险的决定》。其中明确提到，“除依法经国务院或国务院期货监管机构批准设立从事期货交易的交易场所外，任何单位一律不得以集中竞价、电子撮合、匿名交易、做市商等集中交易方式进行标准化合约交易。” 链得得研究团队搜集和整理近年来中国整治非法期货交易场所的所有案例，总结其特征可以发现：这些平台通常以当下热门概念投资产品或金属、大宗农产品现货交易为诱饵，面向社会公众开展业务，主要有以下几种类型： 一是单纯提供交易平台，以投资小、收益大等噱头或以配资为名提供更高杠杆率，吸引投资者参与，为买卖双方提供撮合交易，收取佣金。部分场所还为境外交易机构（俗称“外盘”）充当代理，或者以外盘代理为名，行内盘交易之实。 二是不仅提供交易平台充当中介，而且参与交易，成为买方或卖方（俗称“对赌”），剩余头寸进入合法交易场所保值。有的在对赌时，提供虚假行情或者不同步的交易行情，有的在交易系统恶意设置障碍。 三、交易过程中存在的机器人虚假交易、数据造假、欺诈、限制平仓等行为的证据。 反观近期深陷维权风波的OKEX，链得得APP在走访了近二十位维权投资人和业内从业者，了解到OKEX与此三点特征高度的吻合性。 以下，链得得App研究团队的深度调查，从期货特征交易的几大重点环节，来还原OKEX平台“合约交易”的真实面貌。 危险的“合约杠杆”在全球范围内，加密货币期货交易规范化进程中，芝加哥期权交易所（Cboe）开启了最受瞩目的运营尝试。2017年12月11日，美国芝加哥期权交易所正式上线比特币期货交易，当天便引发比特币现货价格突破1.6万美元。作为正规化尝试且最被效仿的芝加哥期货交易所，目前提供的比特币期货合约最高的杠杆倍数为5倍。 而在其他游离各国监管和合法边缘之外的期货交易所中，投机和对赌的色彩就更为显著。这一点在杠杆叠加的倍数上窥见一斑。 在目前全球超过250家规模以上数字货币交易所中，开设期货合约业务并有规模人群参与的交易所不超过10家。其中，具有代表性的平台： 成立于2014年的BitMex，属于纯期货领域交易量最大的交易所。光比特币调期合约24小时就有3亿美元以上的交易量。具备一定交易盘深度，也成为诸多资深期货玩家主要交易的战场。其期货合约杠杆为1至100倍任意选择。 Bitfinex被誉为最具比特币流动性的交易所之一，杠杆倍数最高为3.33倍。 Bitstar现货合约与期货类似，是一种保证金交易的差价合约，用户可以通过判断涨跌来赚取差价。最高提供5倍杠杆。 极端案例中，俄罗斯的一个数字货币期货交易平台更是存在惊人的最高1000倍杠杆，但该平台的交易量和品牌知名度非常有限。 OKEX的“合约交易”杠杆有两个选择，10倍与20倍。 来自湖北的姚彬自进入OKEX的交易合约至今，先后被爆过三次仓，这里面包括自己的钱和亲戚朋友的钱约合人民币80余万。如今的他已然身无分文，靠朋友接济度日。用他的话说，“OKEX的合约杠杆既是瞬间想象暴富的可能，也是让你瞬间倾家荡产的存在。” 今年两会上，前央行行长周小川在讲话中提到了未来监管方向将是动态监管，他说不喜欢创造纯投机产品，让大家有一种一夜暴富的幻想。 基于OKEX全球前三大数字货币交易所的影响力认知，这个倍数无论在合规体系中还是非监管体系下，都属于杠杆居高，且用户倾家荡产风险极大的交易平台。20倍杠杆意味着只需缴纳5%的保证金即可建仓交易，在用户下期货单的数字货币上，该数字货币市场波动只要超过5%，便面临爆仓的风险。期货单有周、月度和季度的平仓时间期限，这些期限分别对应着用户期货单必须平仓的最终时间点，但凡是在对应时间期限之内，只有不被爆仓都可以随时平仓以获取盈亏。 数字货币市场是一个365天、24小时不间断的交易市场，且没有涨停、跌停的限制，亦没有熔断的保护机制。关注过数字货币行情的人都能发现，相比于传统证券市场，数币市场币价的波动可谓“天方夜谭”。 以链得得APP汇总的2018年4月15日每日数字货币涨跌排行榜为例，该日涨幅前三十的币种全部超过20%的涨幅，前四名的涨幅超过133%；跌幅前三十的币种全部超过13%，前四名跌幅均超30%。即便作为期货合约主要标的的比特币、ETH、莱特币等，24小时内的涨跌波动都能够接近或超过5%，更不用说在期货合约标定的周、月度和季度的更长时间周期内，有多少次可以随意穿越5%，这个纸糊的爆仓线了。 因此，在数字货币市场，任何超过200%的杠杆都存在极大的设计风险。 毫无实物交割，一场以空搏空对赌“这就是一个自定规矩的赌场，只是它把人的赌性放得更大”，一位资深从事数字货币期货交易的操盘手对链得得App说，“我上周刚刚被在一个平台上被爆了200个比特币，也愿赌服输，反正再过几笔交易我只要赢一把，前面输的钱都回来了。大部分参与数字货币期货的人都有同样的想法。” 关于为什么不在OKEX上做期货交易的疑问，上述人士回答，“在我们重度参与者眼中，OKEX期货交易深度太浅，真实交易和成交活跃度不高，而且规则与产品设计也存在许多漏洞，这种情况下很容易形成一个庄家市场，风险系数和投资回报不成比例。OKEX主要还是一些初出茅庐又赌性十足的韭菜在里面玩期货。” 期货市场之所以能够被各主要主权经济体视为资本市场不可缺少的一部分，并加以规范建设和监管，是由于期货市场对于实体经济对冲风险、大宗商品价格预判、货币波动方向预测、优化流动性配置、维护市场稳定等方面有调节推动的作用。以期货合约交易标的性质来区分，大致分为商品期货与金融期货。 与传统合规的农业、金属、工业等大宗商品、原油期货等市场不同，OKEX的“合约交易”不存在实物交割的能力和选项。 理论角度看，套期保值和价格发现是期货市场的两大功能。以商品期货为例，在约定平仓时间点以转移合约标的实物的所有权来完成交割。这种情况下对于实体企业在生产资料环节的中远期价格对冲将产生实际套期保值好处，稳定了成本价格，从而保障利润可持续，进而推动实体经济发展。 即便像股指期货这样可以进行现金交割的金融期货，往往也会提供实物交割的选项。这里的实物，指的是一份实实在在通过非杠杆实价购买的ETF指数基金标的产品。 回看OKEX的合约交易，没有提供任何实物交割的选项，在合约交易过程中你也购买不到，看不到任何类似于证券市场ETF股指基金的产品份额。 至少得有现货支持实物交割的产品，而不是空手对空手的虚交易。很大程度上，OKEX的合约成交价格是由买卖双方在固定时间、封闭池子里的成交价决定，无法反映和影响真实数币市场价格。只要有足够的资金和筹码，平台就能够在临近交割日期时，向交割价格进行收敛。这个过程就会时不时引发合约市场较大的波动。 平台所提供的比特币、莱特币、以太坊等交易标的也没有铆钉任何被广泛认知的实物资产，平台通过算法和交易程序撮合，匹配一对多空两向的对手盘交易，以10倍或20倍的杠杆配上一定数额的保证金，便开始了一场既无实物标定又无价格真实传导的对赌冒险。 “合约交易”指数不透明，有鲜明庄家痕迹，价格操纵空间大为何说“又无价格真实传导”？价格发现作为期货主要功能之一，承载了价格对冲稳定和价格预判的功能。股指期货价格的形成有一套完整、公开、明确且备受规程监管的体系。集合了股票现货市场价格、成交量、影响现货市场的各种因素，以及交易者对影响现货市场价格因素的预期和投资者心理和行为等重要信息，连同期货市场的价格走势、持仓量、成交量等因素综合而形成。不可能出现与股指现货价格完全脱节的情况。 OKEX仅凭一套自行定义的“指数价格”对合约进行交割。 在OKEX网站上公示的最新合约交易指数介绍中，只表示从2018年9月30日后，采用以Bitstamp、Coinbase、Bitfinex、Kraken四家平台价格数据标本的新合约“价格指数”。并没有明晰“指数价格”的产生机制；是取四家平台指数的平均值？还是加权求值？加权的各平台权重如何？还是说有自己的一套参考算法？所有的具体环节都没有答案。对指数价格形成过程的第三方监管和审查更是无从谈起。 若期货合约的交割价格计算方式不透明，直接将造成交易价格数据调整和操纵的空间，进一步导致在合约交割时间（比如强制平仓时间节点）上人为介入的机会。 2018年3月30日凌晨5时许，OKex上出现近1个半小时的极端交易行为，BTC季度合约一度比现货指数低出20多个百分点，最低点逼近4000美元。根据OKEX爆仓记录统计，短短一小时瞬间爆破多头46万个比特币的期货合约。跌到最低点后瞬间又拉涨10几个点，部分空头也被爆仓。而在整个异常波动中，现货最低价格也没有跌破6000美元。期货现货差价最高逼近30%。 OKEX不支持实物交割，即使作为金融衍生品也缺乏定价功能。平台合约交易均直接平仓对冲了结，实际交易不以实物交割为目的。无法对数字货币市场价格环境进行有效调节和预测，空转的资本流通更不能对实体经济产生哪怕些许的利好。 由于合约交割价格形成机制的不透明和人为介入的可能性，很难实现OKEX平台声称的“套期保值”功能，不能做稳定有效的对冲操作。最后均以数字货币交割的方式完成，监管、运营、规则设定都集于平台一身，为暗箱操作和非法洗钱创造了巨大的想象空间。 至此，一个可能带有鲜明庄家痕迹的赌性合约市场将繁荣滋长。 2017年3月28日，清理交易场所部际联席会议办公室印发《关于做好清理整顿各类交易场所“回头看”前期阶段有关工作的通知》指出，商品类交易场所的分散式柜台交易“一般为杠杆交易，合约具有标准化特征。交易场所既不组织商品流通、又不发现商品价格，实为投机炒作平台，对实体经济没有积极作用。” 中国经济脱虚向实的政策大背景下，若大量民间资金借由数字货币的渠道流入类似的“合约交易”对赌中，对本就脆弱的实体经济环境将是进一步的打击。 诡异的爆仓K线图显示，当天交易价最低点为68206.52元。 投资人被爆仓的截图。可以看到被平仓的价格为67263元，下面一列是该投资人约30秒前追着行情卖，却没能卖出的价格68843元价格。 有投资人公开质疑，OKEX爆仓价格不透明、不规范。在这位投资人提供的自己爆仓当天，OKEX合约交易的全屏界面。图形数字显示，当天交易价最低点为68206.52元。而当天成交记录显示该用户当天的爆仓价为67263元，也就是说，哪怕当天全天最低的价格都没有触发该用户的爆仓价67263元。没到爆仓线却爆了个精光，究竟这个爆仓价是怎么计算得出的？系统又是怎样自动执行操作的？ 请输入图说 投资人用户与客服沟通的聊天记录显示，该用户质疑OKEX合约交易平台爆仓价格的设定机制，并要求对爆仓价定价方式进行公开。用户表示自己在全过程都盯着合约交易价格看，不存在疏漏，但还是眼睁睁地看着自己的合约在没达到约定爆仓线时，就被系统强行爆仓。 关于爆仓价格是如何计算得出的质问，OKEX客服的答复是：委托数量换成张数进行计算。可委托数量和合约张数是成交量，而爆仓价是价格计算。一个是价格，一个是量，两者完全不属于同一维度。客服这样的答复令人一头雾水。 该投资人表示，虽然方向看错是自己的问题，但之后的反弹也不会让我全部亏完，且如果价格到爆仓附近自己也有补仓的想法。本人之前合约有亏有赚，也被爆仓过。如果是其自己的问题可以接受，但平台这样无故爆仓，无法接受。 原海证券交易所CTO、中科院软件室主任、软件方向首席科学家白硕，在近日针对交易所监管的文章中指出：中心化的数字货币交易所仍然是主流，虽然也有去中心化的交易所，但性能跟不上，要想效率高，只好中心化。一旦中心化，安全就没有保证，交易的真实性也存疑。这时如果没有监管，光靠自律肯定不行，监管必须要介入。倘若传统交易所出事故，不仅内不要通报批评，对外还有有所交代。但现在的虚拟货币交易所一出事就各种推诿搪塞，这种讨论很像游戏网站。这种机制怎么可能颠覆金融？ 在文章的最后，白硕同样呼唤：监管必须介入。 美国当地时间2018年4月17日周二，纽约州总检察长办公室公布，致信13家数字货币交易平台或相关实体，最迟今年5月1日答复相关问卷调查，披露交易规则、使用交易机器人、内部管控、断电等交易被迫中止情形、对客户资产保障措施、利益冲突等重要业务信息，以便普通投资人更好地了解风险和获得的保障。 纽约州已然注意到了数字货币交易所日益积累的诸多顽疾。数币交易所这类轻重有别，普遍存在的问题需要监管进一步找到对应措施。 “独树一帜”的穿仓平摊制度不仅会遭遇爆仓，还有一个奇特的穿仓平摊制度。这张流传甚广的截图相信很多人都见到过： “穿仓分摊制”是OKEX平台在“穿仓”情况下，自己设定的损失分摊机制。正如图片对话中投资者抵触的一样，大部分投资人在莫名被平摊了与自己无关的穿仓费之后，才第一次发觉OKEX的这套机制。整个扣费过程毫无通知、毫无协商的余地。“穿仓分摊制”指的是将所有合约的爆仓单产生的穿仓亏损合并统计，并按照合约所有盈利用户的所有收益，作为分摊基数进行的操作模式。 在加10倍或20倍杠杆的情况下，若方向看反，标的价格大幅波动就容易触及到准备金的爆仓警戒线，系统便会强行按市场价格将该合约卖出。如果当前强行卖出的市场价格低于保证金底线，就发生穿仓。系统显示爆仓数为负，也就是OKEX平台实际上将承担穿仓导致的账面亏损。 此时，为了转嫁穿仓带来的平台亏损。OKEX就强行让平台上的盈利用户来对这部分平台亏损进行分摊。因此，这种躺着中枪的“薅羊毛”行为经常遭到盈利用户的强烈反弹。交易规则和系统设计都是平台构建运营维护的，在传统期货交易中，规范化的期货平台会设置“两条线”。第一条是强行平仓线，这条强行平仓线会比用户保证金高一些，当系统强行平仓时就不会发生穿仓的事件。在OKEX这里，自身产品设计的缺陷却用一套用户分摊机制去弥补自己的草率。 消失的交易记录同样草率的还有用户个人账户里的“合约交易”记录。李铭来自北京，他根据自己在OKEX上合约盈亏记录的统计，发现在一个月内，他“合约操作”应得的币余额比实际少了10个比特币。李铭在对历史交易数据查询时发现， OKEX的交易清单无法下载完全。比如每天下载只有1000条，无法用Excel完整统计，加剧了账务的混乱。OKEX的合约分页功能始终无法显示第二页以后的内容。以上质疑OKEX客服长期无人回复。 前文中，被三次爆仓的姚彬同样寄希望于搜索交易记录，来找到其怀疑平台“定点爆仓”的证据。可在OKEX“合约交易”中，手机客户端的交易数据仅保留一个月的，PC客户端的合约交易数仅显示三个月内。 横向对比，李铭在2013年11月份进入火币交易，当时至今的交易记录，一笔不差都都能查到。李铭说，“大多数期货参与者没有固定证据的意识，一旦他们意识到交易数据证据的重要性时，要么被OKEX恶意删除交易历史，要么被OKEX以超短的3个月数据保留期限自动删除交易历史。” 被清退的OKCoin战地转移OKEX：用户转移和品牌背书2017年中国境内的“9·4监管”之后，包括OKCoin在内的国内几大数字货币交易所被清退，暂停数字货币与人民币兑换业务。OKCoin就此在交易所业务上进军海外市场，以OKEX的品牌身份继续承担数字货币交易所的功能。 OKCoin上线于2013年10月，是中国最早且最大的比特币交易所之一，品牌隶属于北京乐酷达网络科技有限公司。在清退实施后，其用户资源、页面流量、品牌权益通过各种渠道导入了OKEX，这个注册地在美国伯利兹，办公地在香港的公司。使得OKEX迅速在交易量、用户规模上冲进了全球数币交易所三强。OKEX最受关注的业务之一，“合约交易”也借此良机乘帆起航。 林旬来自广东，2016年底注册OKCoin并进行比特币交易。在“清退出海”事件后，林先生通过OKCoin页面上的链接，使用原有账号便直接登录了OKEX，并于2017年11月首次尝试了“合约交易”。谈及对OKEX产生最初信任的原因，林旬解释到，首先OKEX是OKCoin旗下公司，同时两家公司人员有重叠，尤其是创始人和实际控制人均为徐明星。 其次OKCoin首页至今包含了OKEX的链接，OKCoin的用户账号及数字资产可无缝且免手续费地迁移至OKEX，于此同时，两者在招聘启示的公告相同，人事关系的电子邮箱地址后缀一致，在形式上看起来就是两家利益共同体的公司。 再次，OKEX网站上标注了许多境内知名投资人和机构的信息，包括史玉柱的巨人网络、王亚伟的千合资本、蔡文胜的隆领资本等。这些罗列的投资人与OKCoin页面列举的投资人信息有高度相似性。 最后，OKEX在国内网络媒体、社交媒体、自媒体上的推广力度很大，很多身边的投资人是通过网页、微信群和H5推文获悉的OKEX。 请输入图说 违规开放中国国内用户的投资入口OKEX在注册设计上，会根据用户在KYC（know your custmer）上传的信息确定是否支持相关用户的平台交易行为。 在不支持交易的国家和地区用户列表中，办公地位于香港的OKEX没有排除中国内地用户的交易，反而不支持所在地香港的用户交易。因此，中国大陆用户可以畅通无阻地在OKEX平台进行法币交易，币币交易，以及合约（期货）交易。为承接OKCoin原有大量国内用户创造了迁移的有利条件。 目前，在OKCoin交易平台上的数字货币只能够提币至OKCoin中国站账户、OKCoin国际站账户和OKEX站当中。彼此账户系统之间的数字货币转账仍然不需手续费。 与OKCoin不同，OKEX的公司主体注册在美国，办公场地在香港。OKCoin官方常以此来切割与OKEX的关系，并为OKEX撇清非法设立期货业务的责任，表示OKEX经营不在中国境内，因此不受国内政策和法规的约束。但这不能否认OKEX大量“合约交易”的投资人用户在中国境内，OKEX在国内网络、社交、内容平台上大量宣传推广业务的事实。 有趣的是，OKEX官网上服务条款细则中，第十四条仲裁一栏；中文版写的原文是，与OKEX相关的任何仲裁将在香港发生。如将版本切换到同网页同位置的英文版；内容赫然写着，任何相关仲裁将在北京发生。同一公司、同一主体、同一业务，发生仲裁的地址就这样混淆视听，各不相同。 法律上，同一公司主体约定仲裁的地址不可能有两个，各类语言的对应地点必须统一。香港和北京的仲裁方式甚至都不同：在北京，仲裁双方需自己指定仲裁员，国内大多仲裁员不是专职。在香港，当事人双方直接去仲裁机构立案，香港仲裁员一般为专职，由仲裁机构指定。由于效率高、过程专业，因此，国外经济贸易纠纷喜欢仲裁而不喜欢打官司。OKEX的仲裁地点中文写香港、英文写北京，这种明显的混淆方式，也给两边的投资人同时制造了意识困境。 据一位不愿透露姓名的国内知名刑事与经济案件律师观察，OKEX“合约交易”被东莞市公安局以“非法期货”和诈骗罪立案，在法理上是没有任何问题的。 该律师表示，无论其实际工作人员是在境内或境外，所隶属公司是境内公司法人或境外公司法人，是境内服务器或境外服务器，以及国家是否对其境内IP封闭，均不对国内执法部门的管辖权构成影响。责任认定的标准在于用户上网转账的地点是否处于境内。即“属地原则”：案件受害对象在哪儿，作案行为发生在哪儿，就可以在哪儿立案或上诉司法裁决。只要OKEX“合约交易”存在国内用户，就符合《刑法》的管辖适用范围。 该律师介绍，期货交易是受国家严格监管和实际控制的业务，即便平台在国外获得了运营资格，但凡在国内的业务开展没有得到中国官方授权和批准，就存在欺诈的行为。 这种情况下，交易平台不可能向国内的协议投资人，提供其国外交易的所有真实状况；公平性、真实性、和承诺没有任何保障。 “为什么国内没有传统金融机构参与其交易，却几乎都是散户在其中买卖？”律师反问到。“只因大型金融机构均设立风控部，风控部里都是有经验的律师，深知其中巨大的法律和交易风险，是绝不允许有这种投资决策出来的。” OKEX也缺乏牌照授权和经营资质综上，OKEX的这种典型的期货交易属性很难用它自己所说不是期货交易来做解释，那它又到底是否具备期货交易的资质呢？ 链得得在工商查询中获知，OKEX作为境外法人不具备任何国内金融牌照、期货交易资质、办公场所、工作人员、合法经营资质。与此同时，其主要客户群体在境内，其创始人、实际控制人徐明星也在境内。 2018年1月15日，运营主体为北京烽火创杰有限公司的OKEX官微和APP因“通过登记经营场所无法联系”为由而被北京工商局列入经营异常名录。 不仅如此，注册地在国内的OKEX母公司平台OKCoin，及OKCoin所隶属和资本关联的北京乐酷达网络科技有限公司、北京欧凯联创网络科技有限公司，同样没有相关执业资格。 在部分维权投资人向中国证监会关于“北京乐酷达网络科技有限公司，北京欧凯联创网络科技有限公司是否具备期货合约业务资格”的信息公开申请中，证监会回复称，根据《期货交易管理条例》，目前国内合法期货交易场所分别为上海期货交易所、大连商品交易所、郑州商品交易所和中国金融期货交易所。我会未批准其它交易场所组织开展期货交易。 而在证监会深圳监管局的回复中，更直称“中国证监会未批准任何交易场所开展比特币等虚拟货币期货交易，北京乐酷达网络科技有限公司和北京欧凯联创网络科技有限公司不具有中国证监会核准的期货业务相关资格。” 依照《刑法》第二百二十五非法经营罪，第三款：“未经国家有关主管部门批准，非法经营证券、期货或者保险业务的。”其中，“非法经营证券、期货业务”，主要是指以下几种行为：非法设立证券交易所、期货交易所进行证券、期货交易；非法证券、期货经纪行为，如未经工商行政管理部门核准登记，擅自开展证券或者期货经纪业务；证券交易所、期货交易所、证券公司、期货经纪公司超越经营权限非法从事证券、期货交易；从事证券、期货咨询性业务的证券、期货咨询公司、投资服务公司擅自超越经营范围从事证券、期货业务。” 数字货币市场酝酿着巨大的利益交易和价值前景。中心化的交易所在其中扮演着撮合、流动和杠杆的角色。在如此巨大的利益诱惑前，设计、运营、交易、存储、流通、审核、监控、发放、裁定甚至最终权责解释权的全过程，都只依靠交易所自身的自律性来独木支撑。连基本的行业共识规范都没能达成的当下，政府或第三方机构的监管缺位，会加速数字货币市场的失控，从而影响金融和经济秩序的稳定。 另外，投资人自身也应肩负起对投机和赌性行为负责的责任。在OKEX“合约交易”事件中，许多投资人在抗风险能力弱、专业判断能力缺失、极端操作、风险评估不足、交易经验浅薄，甚至在连基本游戏规则都没能吃透的情况下贸然入市，并轻易地动用高杠杆交易，造成了个人巨大损失。 悲剧永远不是孤立产生的，一定是群体性的放纵欲望和无序贪婪造成的共同恶果。平台的责任在于引诱了欲望、放大了欲望、创造了新欲望。可如果投资人自身能理性控制欲望的泛滥，平台也害不了你。 当前，包括中国在内的大部分数字加密货币交易市场主要国家，都没有在法律和监管层面明确定义数字货币的性质和功能定位；同时，明确的监管参考案例又极少，无法有效对应既有法规和判例执行定性追惩。在监管执行层内部也尚未统一对数字货币交易形态的认识和判断，系统化的官方调查追责程序暂时都按兵不动。 正是由于这样的野蛮生长窗口期，一些数字货币交易平台在民间炒币市场繁荣，且监管政策和落实未至的不对称空间内，利用包括高杠杆、高风险、高覆盖面却丧失有效监管的灰色手段攫取利益，并能站在法规与市场的模糊地带继续牟利。 包括比特币、以太坊、莱特币、EOS等大交易额主流数字货币都对应着法币和实物资产，在现实生活中有各种便捷稳定的法币兑换渠道；随着普通人对数字货币可交易、可牟利性认知的迅速普及，在越来越多的市场参与和信任支撑下，主流数字货币对映美元、人民币等法币的交换性将进一步紧密。因此，在大众参与的数币交易市场里，流通的不是积分或服务交换等虚拟产品，而是真金白银。 此时，如果那些涉及高资金杠杆、高赌性风险、无有效监管、无明确规范、影响面巨大且游走于法律之外的数字货币交易平台不断增多，对于普通投资人权益、民间投资环境、货币流通环境、数字货币交易市场健康发展、乃至社会稳定将是一场灾难。这种情绪、收割策略和流动性波动将直接传导致一级和二级资本交易市场，进而干扰更大范围内金融秩序的稳定。 近日，链得得APP联系到一位OKCoin内部人士： 问：“为什么压力这么大的情况下，你们还不关停OKEX的合约交易业务？” 答：“因为这块业务实在太赚钱了，大部分数字货币交易所都盯着想吃这块大蛋糕。” 问：“能有多赚钱？” 答：“具体我也不知道。”（文/ 链得得内容合伙人李非凡，本文独家首发链得得App） （后注：出于保护投资者和线索提供者的原因，故将真实姓名隐去，文中涉及的用户人物皆为化名。） 更多精彩内容，关注钛媒体微信号（ID：taimeiti），或者下载钛媒体App 转载来源：徐明星的OKEX涉嫌“非法交易”与“诈骗”全调查 | 钛媒体深度]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
        <tag>比特币</tag>
        <tag>期货</tag>
        <tag>OKCoin</tag>
        <tag>风投</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[医药界再现“蛇吞象”并购 武田制药豪掷640亿美元收购英国药厂夏尔]]></title>
    <url>%2F2018%2F66d43553%2F</url>
    <content type="text"><![CDATA[日本药业龙头、也是亚洲数一数二的制药公司武田制药再次修改要约出价之后，罕见病药物制造商夏尔董事会今日宣布愿意接受目前估值高达640亿美元的收购要约，并将推荐提交股东大会审议。 转载来源：医药界再现“蛇吞象”并购 武田制药豪掷640亿美元收购英国药厂夏尔]]></content>
  </entry>
  <entry>
    <title><![CDATA[“头条”激战三四线：谁占领下沉人群，谁占领明天 | 深氪]]></title>
    <url>%2F2018%2F2d47a6a6%2F</url>
    <content type="text"><![CDATA[文|方婷编辑|杨轩漩涡中心谈判桌的另一端，摆着最少9份投资意向书，还坐着BAT三家。10亿美金，12亿美金，14亿美金，到最后的16亿，这家叫趣头条的公司，谈判中估值一直在往上涨。 文 | 方婷 编辑 | 杨轩 （感谢36氪作者闫浩、王雷柏对本文的贡献） 漩涡中心谈判桌的另一端，摆着最少9份投资意向书，还坐着BAT三家。 10亿美金，12亿美金，14亿美金，到最后的16亿，这家叫趣头条的公司，谈判中估值一直在往上涨。 趣头条最想拿腾讯的投资。2018年春节前后，趣头条与BAT的融资谈判已经进入开价阶段，为了等腾讯，它拒绝了百度、阿里，腾出一段不算短的时间，专门等待腾讯的回音。 这款同样定位为信息流资讯的产品，只花一年多时间，DAU（日活跃用户数）就过了千万。今日头条不能不心生警惕。去年12月，张一鸣把一张趣头条凶猛增长的图发到高管群里。有传言称，今日头条也曾试图投资趣头条，但趣头条一方没有回应。 最终腾讯还是拿下了这笔交易，以16亿美元的估值领投，交易金额近2亿美元，跟投的还有顺为资本、尚珹资本等。 当流量越来越贵、越来越难出现爆发性增长的产品时，不管情不情愿，趣头条已经来到漩涡中心。 “投资趣头条未必是腾讯对今日头条的防御，只是在现在的态势之下，任何大的流量入口都不能被放过。”光源资本CEO郑烜乐对36氪说。光源是趣头条本轮融资的FA，同时也担任过快手、哈罗单车的融资顾问，通过此前的案例早早意识到了三四线下沉市场的价值。 在一二线城市，大家默认“头条”＝“今日头条”。但在下沉市场里，还有一整个庞大的“头条系”矩阵，它们指的不是抖音、懂车帝、西瓜视频、火山小视频等北京字节跳动公司旗下的产品，而是趣头条、惠头条、淘新闻、东方头条等以返利补贴为主要运营手段的信息流产品。趣头条是其中做得最早，起量最快的一家。 根据趣头条创始人谭思亮的说法，这个行业里的第一名在三线城市及以下市场的渗透率一直不超过20%，“并没有大家想的那么夸张”。剩下的80%，是留给趣头条们攻城略地的空白，它们所接触到的大多数用户，手机里很可能还没有安装过任何新闻资讯应用。 “趣头条们其实是给今日头条盖天花板。现在它们扩张得有多大，未来今日头条在下沉市场的天花板就有多低。”一位要求匿名的投资人说。 但对创业者和投资人们，这真是个好消息。 今年4月初，在一家著名VC的闭门会议里，下沉市场的流量成为诸多圆桌环节里最受欢迎的话题，拼多多、趣头条是被拿来反复剖析的案例。 回顾最近进入极速增长的公司，无论是拼多多还是趣头条，他们共通的特点，就是流量来自“下沉市场”——那些当看似无处不在的淘宝、今日头条还没有触达的人群。 这是个多达五六亿人口的市场，长久以来处于互联网世界的边缘，被认为很难发掘和“不够有价值”。他们是三四线城市里面四十岁以上的主流用户，也包括一线城市里面那些年纪更大的用户。 而如今，有人找到了一套搞定他们的办法。 师徒关系和时间性价比趣头条之所以要等腾讯，一方面是因为腾讯较为宽容的投后管理风格，另一方面，是因为依托于微信、QQ的人际传播才是搞定“下沉”的关键，而非互联网世界过去十多年通行的、买流量的方法。 “我不是从这些大平台采购的，而是从一个一个人手里来组成流量，个人是不会跟我们溢价的。”谭思亮告诉36氪，这是他当时觉得趣头条这件事情可做的原因。在创办趣头条前，谭思亮曾在盛大集团负责过在线广告平台业务，他太清楚线上流量价格如何一路走高。 趣头条尝试过从巨头掌握的渠道里买量，平均获客成本在10元以上。对左手用户右手广告的生意而言，这么高的成本不足以支撑起一个快速成长的公司。令谭思亮更为忧虑的是，如果依赖巨头掌握的分发渠道来获客，渠道只会不断抬价，将属于创业公司的利润不断压缩。 要在下沉市场抢份额，关键点从掌握渠道变成了理解“人”。 86岁的王老太太又开始整夜抱着手机，手指不时在屏幕上滑动，从晚上九点多一直划拉到凌晨两点，在儿子的制止下，才不情不愿地放下手机。下载趣头条之前，她的作息是晚上十一点多入睡，但现在，凌晨一两点睡对她来说也很常见。她得意于自己有个月通过看新闻赚了30多块话费，喜滋滋地将这个消息告诉给别人，家人才知道她口中整天念叨的“头条”，不是今日头条，而是趣头条。 王老太太退休前在兰州当麻醉师，发展她用趣头条的，是她以前炒股时的“师傅”，也是她现实中的熟人。收徒首得3000金币，此后徒弟的阅读收益也能进贡给师傅。王老太太的师傅已经收了数十个“徒弟”。 “金币”刺激带来了大量在微信群和朋友圈的分享行为： 有缘人加我.B7PYYXXX，立得1元。CRB8YFXXX，需要邀请码请复制，输入你得一元。新闻类收徒，3元以上一个徒——大概是嫌邀请码一条条发得太慢，有人干脆直接甩出一张截图，里面包含数个主打阅读得金币的App。 如果认真翻看这些群里每半个小时就新增出的99+条信息，就不太可能错过任何一个市面上新推出的赚钱平台。它们的名目千奇百怪，从看新闻赚零花，收徒就赚888，到每天抢红包，互相帮忙做任务。负责运营维护的群主对这些信息似乎也已经是见怪不怪，很少有踢人的情况出现。 大多数返利平台对机器羊毛党都深恶痛绝，趣头条更是在创业初期就清理了20多万个机器人帐号，对一个DAU刚到百万的平台来说，这在当时是个艰难的决定。但对这些想要薅羊毛的真实用户，平台却显得宽容得多。谭思亮对此想得很明白，“如果说他本来就想贪点小便宜，这些用户其实也很容易被我们的积分机制吸引，后面我们通过阅读，通过算法，去培养他的使用习惯。” 王老太太也想收徒，不过被她的家人强力阻止了。但家人并不反对她看新闻，可以不停往下刷的图文和视频替代了电视和报纸的位置。当她跟随儿孙从兰州到北京生活时，刷新闻更是帮她打发了大量无聊的时间。 用户量的裂变就是这么开始发生的。 在趣头条的排行榜上，排名第一的用户收了四万多名徒弟，获得了八万多元的推广奖励。以这种直接给予金钱刺激的方式，趣头条完成了第一个百万DAU，也冲过了千万DAU的大关。 裂变的基础设施，是王老太太们都已经用上了微信，会相互转发信息，还会发红包和用微信支付。无论是拼多多还是趣头条，它们的商业模式都离不开这一系列基础功能。此前，这群多达五六亿的“互联网边缘人”，虽然有智能手机，但除了微信和手机预装软件之外，很少会主动去下载一个新App。 趣头条的一众跟随者，无论是惠头条、淘新闻、东方头条，都沿用了师徒体系的叫法。这个叫法在各种网赚平台里早已有之，趣头条不过是沿用，创始团队认为对于三线及以下用户而言，师徒体系更容易理解。但这个名称不免让人想到传销，所以趣头条需要反复跟外界解释，传销是向用户收钱，而趣头条是付钱给用户，这里面有本质的不同。 师徒体系相当于平台的拉新成本。根据平台规则的不同，“师傅”每邀请一位“徒弟”下载注册，一般可以获得2块到8块不等。高于2块的额度通常需要分三次返还，激发条件是“徒弟”在平台上的阅读行为。换句话说，师傅除了发邀请码邀请徒弟注册之外，还需要鼓励徒弟阅读信息流。尽管也有开宝箱（签到）、晒收入（分享链接）、阅读资讯、优质评论等令人眼花缭乱的任务体系，但如果想真的依靠这些App来挣钱，拉来新用户才是最有效的手段。 只要在摊子前面摆出一张邀请二维码，扫描下载送西瓜，水果摊主就是他们的王牌地推；卖保险的代理也会发展出十几个徒弟，每天按时按点在微信群里督促徒弟们阅读新闻。他们在现实生活中颇为活跃，都是一张张真实社交关系网上的节点人物。他们的“徒弟”，又会通过朋友圈分享、群发邀请码等方式来扩展自己的队伍。 依靠这种传播方法，趣头条将平均获客成本降低到3－4元。 刚退休不久的老上海人于虹，也是被她的“师傅”一起带着用起了趣头条的。她开始在她朋友圈一天五六条的美食、植物、度假村、碧海蓝天的澳洲旅游照中间，夹着“看新闻，赚零花，填我邀请码：24784XXX”的链接；她把每天花一个小时来刷新闻当成一种游戏，当手机屏幕上跳出那个堆着金币的图标，她和她的“师傅”都能有进账，虽然折算下来，平均一天也就几毛钱的收益。 下载趣头条10个月，于虹的收益总共是60块，尚有28元在帐户里没有提现，她就已经将兴趣转移到补贴更高的惠头条上，当然，是跟着她的“师傅”一起转移的。 “我也不知道我们的第一个100万DAU怎么达到的。”惠头条创始人Mingu Kang想了半天，也没找到这个问题的答案。这位在中国创业有年头的外国人，普通话说得异常娴熟，只是语气里经常有一种亢奋感，在描述惠头条的成绩时就更是如此。 这家公司的上一款产品是惠锁屏，一款解锁手机屏幕就会跳转弹出广告的返利产品，于2013年上线。在很长一段时间，惠锁屏经营惨淡，还引发过提现和信用崩塌的问题。惠头条的模式本质上跟惠锁屏一样，都是以返利索取用户注意力，换取广告主投放。有惠锁屏的案例在前，整个花动传媒对惠头条都没有报太大的希望。 因此，Mingu Kang 2017年年底做新年KPI计划的时候，给惠头条制定的目标是DAU达到300万，当时惠头条上线刚两个月。谁也没有想到，刚进入2018年2月，300万DAU就达成了。 算账惠锁屏当年之所以失败，是因为每天的用户时长只有几分钟，无法吸引足够多的广告。广告投放太少，给用户的返利不够多，这个游戏就无法滚动运转下去。 但信息流产品不同，凭借看似永远也刷不到底部的内容，趣头条们可以将用户黏在手机上，再加上金币刺激，这几款产品的平均用户时长几乎都在60分钟以上。 “这些人对相对价格没那么看重，对绝对价格很敏感。”糖豆CEO张远说。糖豆目前的DAU在300万左右，是广场舞领域里的第一，它所切的人群也是下沉市场，只不过更为细分，以40岁以上的人群为主，张远称之为“小镇中年”。这群用户通过刷手机看新闻，哪怕一个月能挣上20块钱，也是额外的收获。 换句话说，他们更在乎净挣多少钱，而不是时间和收入之间的性价比。这就贡献了长达60分钟以上的使用时长，以及源源不绝的信息流广告位。 说到底，最终要落到能不能算得过来账上。 “虽然他们财富的绝对值比不上一线城市（的人），但是他们的可支配时间和可支配财富其实是比较大的。”糖豆CEO张远说。 更重要的是，他们都没被“洗”过。 此前，赚到这部分人钱的，是插播大量专题广告的电视台，是电视购物，是小镇商场里巧舌如簧推荐不知名品牌的推销员。 “这两年因为变现的手段越来越多，变现的深度越来越深，这个人群的机会还是很大的。”顺为资本合伙人程天对36氪说。流量变现的手段始终没变，主要是直播、广告、游戏、电商，深度是指从单个用户身上可获得的日收入或月收入。 这原本是由今日头条和百度瓜分的生意。2017年，今日头条的广告收入大约为150亿元，2018年的KPI据传翻了3倍，定为500亿（包含抖音等所有今日头条系产品在内）。信息流也是百度过去两年的业务重点，就连百度云盘里都内嵌信息流模块。信息流业务分发量的增长，也是整个2017年度百度财报会上李彦宏和陆奇强调的重点。 今日头条和百度切掉的只是大蛋糕的一块，在下沉市场里狂奔的趣头条和惠头条，单月营收高点均已破亿元。 在不曾被反复“洗过“的下沉市场里，效果广告比品牌广告更有发挥的空间，尽管比起后者，效果广告往往以其粗糙的形式，诱导性的界面被视为急功近利。但就结果而言，以转化率为考核标准的效果广告显然更有效率。 “对这些用户来说，广告甚至也是信息的一部分。”一位资讯类公司高层向36氪指出。相较于一二线典型的城市白领，下沉市场的消费者并不拥有充足的品牌知识和消费选择。他们在做出购买决策时相对盲目，这使得整个市场呈现出广告营销驱动的特征。 网传趣头条融资BP截图 与其等待着消费者上门，不如将品牌和产品推到他们面前，所以信息流广告比搜索广告有着更多驱动购买的机会。这正是趣头条们能够迅速崛起的先决条件。 根据 Mingu Kang 的说法，惠头条的DAU从0到500万的过程中，没有动用过公司任何存量资金，几乎是上线第一天就开始挣钱，趣头条传达出的也是类似的信息。起码现阶段，做下沉市场的信息流广告还是一门看上去稳赚不赔的好生意。获客成本可以控制在5元以下，也不需要今日头条、百度那样的万人销售团队，对于现阶段的它们来说，接入代理投放的广告联盟是消化流量的最佳方案。 下沉市场的“头条系”上，当然不止有退休人员，40岁以下的女性才是这些App的主流用户。瞄准她们的广告主既有爱奇艺、新氧、58同城、大众汽车，也有“双眼皮抽脂价格”、“牙齿种植会痛吗”——各式各样层次不同的广告混杂在一起，等待着用户在领完每日签到金币和阅读完各种本地新闻和娱乐短视频之后，再打开它们。 头条们的竞争在Mingu Kang 如今的计划里，惠头条的2018年度目标变成了DAU 2000万。 这同样也是谭思亮为趣头条定下的未来3到6个月的目标。他心里的DAU生死线是5000万，在他看来，只有过了这道槛，趣头条才算到安全区域。 试图挤入这个新市场的人正陡然变多。之前，很多人对趣头条的态度，是从看不懂到看不上，但当这家公司顺利拿下腾讯投资时，风向变成了跟着做。 今日头条已经不可复制，趣头条看起来还有追击的机会。 据趣头条官方数据，它的注册用户为7000万，这跟创新工场管理合伙人汪华提及的多达五六亿人口的第三波人口红利相比，只占十分之一左右。还有一大片商业价值待开发的下沉人群，尚未被触达到。 在金币体系的刺激下，这些“头条系”产品都呈现出高留存的特征。邀请好友送金币，一元提现——在惠头条的用户群里，能不时看到一个叫微鲤头条的广告。产品上线刚一个多月，微鲤头条已经是盈利状态。 就连今日头条也在“复制”趣头条。先看和今日头条极速版是今日头条推出的两款阅读返利产品，只有安卓市场才搜索得到。它们有着跟趣头条一模一样的师徒体系和金币玩法，在算法和内容上延续今日头条的已有基础，起量迅速。 今日头条极速版的安装包很小，只有2M，适合低配置手机，在头条内部定位本来就是一个下沉市场的策略型产品。在趣头条爆火之后，今日头条极速版也全面拥抱趣头条所仰仗的师徒模式。根据QuestMobile的数据，2017年年底时，今日头条极速版已经有2000万日活。 这也是趣头条把“5000万日活”定为安全线的原因之一。 略带反讽的是，大家都在学习金币体系，内容反而不是做一款资讯类产品最难的一步——今日头条起家时，张一鸣为版权问题遭受非议，乃至于频繁打官司。6年过去，在这个信息冗余的年代，平台甚至不需要花费前期成本，只要愿意开放流量，广告分成，就可以轻松达到10万条以上的采购量。 趣头条每日更新的内容量是30万条，惠头条的单日内容量是15万条，就连刚上线1个月的微鲤头条，日更新量也能达到10万条。它们的内容多数是从腾讯、百度等内容聚合平台上采购，经过双重审核，话题以本地新闻、健康养生、娱乐资讯为主，不够有“营养”，但足够安全。这个数量足以满足用户覆盖80%热点的需求，相比之下，谁都没有太大优势。 看似简单可复制的金币体系，才是现阶段决定差距的关键。只有做过的人才知道，其中隐藏着多少运营的窍门。 30元提现－15元提现－1元提现－无门槛提现；转发链接送30枚金币－阅读送10枚金币－点击视频30枚金币……这些App的奖励规则往往以周为单位变化，有的规则写在明面上，有的则是只有后台的产品和运营才懂得的窍门。比如金币兑换成现金的比例并不是固定的，平台通称为“汇率”。 两个返利“头条”产品的任务对比 “每天赚多少钱进来，给多少出去，需要算得很清楚，这里面涉及到数值的设定，甚至是金融体系的知识。”微鲤头条创始人孙建说。这家人数在100人左右的公司同时运营着数个产品，中华万年历是其中最拳头的一个，7年来累计3亿注册用户，因为主打农历功能，在两广地区和小县城里都不乏忠实用户。 如果没有中华万年历这款下沉产品打底，孙建肯定不会进入返利信息流的混战中。在不确定的运营规则下，唯一确定的一点是，做这件事的门槛正在不断抬高。腾讯旗下的天天快报直接将拉新奖励提高到6到8元，这是趣头条拉新成本的双倍，也超过了今日头条极速版开出的奖赏。 好在下沉这个市场，由于体量过于庞大，发令枪刚打响，暂时还不是赢家通吃的局面。否则这不过又是一个谁的弹药更多，谁就能获胜的乏味故事。 “流量的获取、内容的运营，玩法设计上的竞争，这是个综合性的结果。内容是其中一个方面。”顺为合伙人程天说。顺为同时投资了今日头条、趣头条和一点资讯，所占份额都不大。从不同角度出发，这三个App分别切下了蛋糕中的一块，暂时还没到短兵相接的那一步，但总有一天，它们伸向流量的手会碰到一起。 “现在流量聚拢的趋势太明显了，所以大家都拿不到资源，创新一出来就被扼杀掉。那这个时候，只有拼命地在这个时间段，把你的一席之地给拿下来，不然可能再没有机会了。”微鲤头条的孙建说。返利阅读算是运营手段上的微创新，但它的窗口期也只有半年到一年。错过这个时间段，哪怕是趣头条，也不会有太多优势。 下沉市场还有另外一个典型特点，用户一旦使用了某一款产品，忠诚度往往比一二线城市用户更高——对还处于互联网小白阶段的用户来说，从一款App迁移到另一款上是个麻烦的行为。这多少给了趣头条们喘口气的时间。 获得腾讯投资后，趣头条暂时还算弹药充足，谭思亮表示构建内容体系将是趣头条接下来一段时间的重点工作。据趣头条投资方之一，红点创投管理合伙人袁文达介绍，趣头条还从硅谷重金挖了技术团队改进算法。 但比起这点，业界显然更关注另外一则小道消息：趣头条挖了一个拼好货高管，就连拼多多创始团队也在四处打听这个人的名字。已经长成“下沉三巨头”之一的趣头条，已经无法像一年前那样低调行事。他们想要挖的这个人到底是谁，想做什么，尚无一个准确的说法。但可以看到的是，在利用下沉市场的已有经验复制出一个拼多多之前，趣头条已经在使用拼团的方法来拉新了。 趣头条拼团收徒玩法 趣头条在复制拼多多，也在复制自己。诸多筑起护城河的方法里，模式的复制依然是最简单易操作的一种。趣头条正在做的一件事情是鼓励用户下载趣多拍和麻花语音。前者是短视频产品，后者的产品说明是“情感倾诉互助社区”，一模一样的金币玩法被套用这两款产品上。惠头条也推出了类似的惠动漫，主旨都是填充下沉市场用户的娱乐时间。它们的目标出奇一致，都是为了建立一个丰富的娱乐生态，尽量以低成本占据用户尽可能长的时间。 新一批被瞄准的用户和新一批入局的公司，都在进入“被洗”的过程中。 转载来源：“头条”激战三四线：谁占领下沉人群，谁占领明天 | 深氪]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>创业</tag>
        <tag>移动互联网</tag>
        <tag>今日头条</tag>
        <tag>张一鸣</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汤晓鸥说全球顶尖AI哪有BAT身影，商汤发新产品正面刚苹果谷歌]]></title>
    <url>%2F2018%2F0809c21e%2F</url>
    <content type="text"><![CDATA[商汤不仅专门为这次大会买了竞价排名，还在现场醒目提示：员工不要占用现场座位。今天，商汤推出了一些新玩法，包括能在视频中瘦脸瘦腿美颜美形——归结起来就是，以后不止有P过的照骗，还会有看不出真身的视频。 李根 发自 凹非寺 量子位 报道 | 公众号 QbitAI 商汤，今天召开了一场“人工智能峰会”。 这家刚刚创下AI领域融资新纪录的公司，对这场活动有多重视？看看百度搜索广告和现场标语就知道了。 商汤不仅专门为这次大会买了竞价排名，还在现场醒目提示：员工不要占用现场座位。 为啥如此重视？看完整场大会就知道了。 因为这不光是一场大型技术产品发布会，也是一场大型招商会。 而且也是在这场会上，商汤创始人汤晓鸥也首次提出了商汤的愿景和目标——一个国产手机厂商发布会上司空见惯的目标。 一起围观下详情。 商汤新产品SenseAR开放平台 最先登场的是SenseAR，这是商汤之前AI商业化应用的核心平台。 今天，商汤推出了一些新玩法，包括能在视频中瘦脸瘦腿美颜美形——归结起来就是，以后不止有P过的照骗，还会有看不出真身的视频。 但是，这算是开胃小菜而已。 商汤在AR方面更大的野心是正式推出SenseAR开放平台，基于商汤技术引擎，与OEM手机厂商合作，开放API等工具，打造基于AR的App应用和体验。 对于这个SenseAR开放平台，商汤目光高远，直接对标苹果的ARKit、Google的ARCore，并且放出对比图正面刚，结果上完胜——至少发布会上是这样。 △ 商汤AR正面刚苹果、谷歌 当然，特殊的时间点，民族主义的节奏牌也能带来特殊意义。 商汤方面强调说：这是属于中国原创的AR平台，在当前这个特殊的时间点可能也有不一样的意义。 内容审核系统SenseMedia 其次登台的是SenseMedia，一个内容审核系统，可以鉴黄、集锦剪辑。 基于深度学习，SenseMedia可以实时读懂文字、图片和视频，抓取并过滤其中色情、暴力和敏感内容等有害信息。 之前，这样的工作有专门的“鉴黄师”和审核编辑，但商汤坚信利用AI，可以大幅度提升效率、降低成本。 另外，SenseMedia还具备视频摘要功能，能在无需人工参与的情况下，制作智能视频内容集锦。 趁着2018俄罗斯世界杯将至，商汤宣布推出足球集锦系统，尝试用机器解救熬夜剪片的体育编辑。 安防开放平台 接下来还是开放平台，但这次是商汤营收大头的安防领域。 商汤科技联合创始人杨帆会上发布了拥有城市监控和轨迹还原等功能的SenseFace 3.0，并透露已经在深圳等城市投入使用，最近还在3小时内帮助找到了走失老人。 此外，杨帆还宣布推出名为“SenseFoundry”的方舟城市级视觉开放平台，商汤会把之前应用在城市安防的相关技术引擎对外开放，打造城市安防为核心的开放生态圈。 卡车应用的SenseDrive系统 最后一个新发布的产品是商汤SenseDrive系统，也是商汤在智能驾驶汽车领域的首款产品，运用深度学习技术和嵌入式芯片优化技术结合，实现对驾驶员疲劳驾驶、驾驶分心、危险动作等驾驶员状态的实时智能检测与提醒。 实际上，去年11月，百度在世界大会上也推出了一样的产品，同样也是卡车货运场景，同样针对卡车司机目前存在的多个痛点。 所以也意味着商汤将在该业务上与百度直接竞争，商汤怕不怕？ 答案是：不仅不怕…… AI领域BAT何在？不仅不惧与百度直接竞争，商汤还强调技术上的领先。 在商汤创始人汤晓鸥的压轴演讲中，汤教授再次祭出AI顶会论文数量图，并表示“BAT都说是AI公司，但在国际上，存在的只有商汤。” 汤教授还说，虽然这两年BAT都在紧锣密鼓布局AI，天价挖人才发论文，但今年为止，发力最猛的腾讯AI有20多篇论文中标CVPR，但商汤有44篇。 商汤的自信，也能从投资人那里找到。 前来现场助阵的IDG资本合伙人牛奎光说，汤教授曾以钻石为喻，认为“钻石”商汤身处石头中间——不过汤晓鸥其后解释称说法有误，他当时只是表示大家都是钻石，只不过商汤更优秀一些。 这也能解释商汤的自我定位。 汤教授更倾向于把商汤看做中国原创的AI公司在国际顶尖竞技中的代表，还是在发布会上，商汤宣布与MIT达成合作，成立人工智能联盟。 “我们要做最好的公司，合作伙伴也找最好的，这样次啊能最大限度发挥我们人才的作用。” 牛奎光则透露，商汤之所以囤积了150多名顶尖AI博士，是因为把最初融资的钱都用来挖人了。 但汤晓鸥也强调，即便截至目前为止已累计融资10多亿美元，拥有70多个投资人，但商汤并不是一家烧钱的公司，甚至商汤已经实现了自负盈亏，迈入盈利状态。 最后，作为商汤科技创始人，汤晓鸥也对商汤的文化和愿景做出了明确。 他认为商汤不是一家狼性文化公司，而会是一家强调爱和同理心的“羊”文化公司，并且更希望以“黑羊”（Black Sheep）自居，强调中国原创。 汤教授说这个英文的意思虽然不尽正面，但也有“捣蛋鬼”的意思。他想强调的是一种特立独行、没有羊群跟随效应的意味。 如何证明这种“原创”？ 汤老师举例，2017年底以来，AR大热，但最早推出AR平台的……其实是商汤。 商汤的对手是谁？在段子、玩笑和举例最后，这位商汤科技创始人明确： 要做一家吃“苹果”的公司。 — 完 — 诚挚招聘 量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。 量子位 QbitAI · 头条号签约作者 վ’ᴗ’ ի 追踪AI技术和产品新动态 转载来源：汤晓鸥说全球顶尖AI哪有BAT身影，商汤发新产品正面刚苹果谷歌]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>商汤</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>苹果公司</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯视频开卖搜索广告，又一种付费也躲不开的广告]]></title>
    <url>%2F2018%2Fa75be634%2F</url>
    <content type="text"><![CDATA[当用户总量增长见顶，视频网站们正在想别的办法赚钱。过去一年她正在筹备更多平台上的新增广告资源，包括本月推出的APP内搜索广告产品“搜易达”。 转载来源：腾讯视频开卖搜索广告，又一种付费也躲不开的广告]]></content>
  </entry>
  <entry>
    <title><![CDATA[在Github惨遭404后，那位不能提名字的大学生又选择了区块链]]></title>
    <url>%2F2018%2F8b3a85eb%2F</url>
    <content type="text"><![CDATA[昨天，公共区块链平台以太坊上发生了一笔可能永载史册的交易。通过这笔交易，敢言者的声音被宣扬，正义在某种程度上得到伸张。 昨天，公共区块链平台以太坊 (Ethereum) 上发生了一笔可能永载史册的交易。 通过这笔交易，敢言者的声音被宣扬，正义在某种程度上得到伸张。 区块 5490403，一位用户用自己的钱包给自己转账了 0 以太币。 以太坊每笔交易都需要一笔手续费，也即所谓的“燃料”。为了这笔交易，该用户支付了 0.0007787 个以太币，这笔手续费在交易发生之时大约价值 53 美分，或者三块三毛人民币。 花了手续费，最后却没有完成任何价值的转移，听起来这位用户脑子抽了。 实际上并非如此。这笔交易的关键在于，其正当性和信息的准确性，已经得到遍布全球超过 1.6 万个以太坊节点的认证。没人可以删除，没人可以篡改。这正是以太坊以及大部分公链的特性。 通过这笔交易，一段文字永久地存在了遍布全球的超过 1.6 万个以太坊节点中。而这一切仅耗费了一套煎饼的钱。 为众人抱薪者，必将铭刻于区块链上。 区块链新应用：写文章人们都听说过区块链，但大部分人都不知道这玩意到底能干嘛用。而通过这笔交易，区块链终于证明了自己：它有能力，让一段信息“恒久远，永流传”。 当你在支付宝上转账，可以附上一句话。在支付宝上，这句话只有你和转账对象（或者加上支付宝）知道。 和支付宝一样，在以太坊上转账同样可以留下一句话。然而不同之处在于，这段话并非双方之间的“悄悄话”，而将成为区块链上，甚至整个互联网上一段的“永不消失的电波”。 在炒泡沫、割韭菜和云养猫之外，区块链技术终于发挥了应有的作用。 事实上，在区块链上放置永久的信息，并不是什么新鲜技术，反而是以太坊这类公链平台的基础能力操作起来都简单的不可思议。 今天，我们就来教你怎样在区块链上写文章。 准备你至少需要四样东西： 钱包——相当于银行卡号，唯一，生成起来很方便。 以太币 (Ether)——在以太坊上交易使用的 token，也即所谓“数字货币”，兑换起来也很方便 内容——你需要发布的内容。 编码转换器——后面告诉你为什么需要，以及怎样使用。英文内容可以直接转成 16 进制码，中文内容则需要先转 Unicode 码然后再转 16 进制码。 首先我们需要一个以太坊钱包。你可以用 MetaMask 这样的浏览器插件，或者 MyEtherWallet 网站来生成并管理自己的钱包。今天的教程就围绕 MetaMask 进行。 （如果你是硅星人/PingWest品玩的忠实读者，你可能会记得 MetaMask 就是上次那个在区块链上养猫所用的工具。） 交易本质上，在区块链上做大部分事情，包括发文章，都是交易。 很简单，点击 MetaMask，按照流程完成注册，然后点击 Send 按钮发起一个交易。 什么，没有以太币？你也可以点击 Buy 按钮，购买以太币。因为我们在美国，此处就用美国兑换方式 Coinbase 演示。 输入你想花多少钱，输入你的电子邮件地址，买完之后会邮件告知，以太币会打入你的钱包。 你的银行可能会阻止你以太币这样的数字货币，请你通过和银行联系解决问题，或者找会玩数字货币的朋友给你转一点以太币。 接下来，你有以太币了，可以给自己转账了。 你需要在下面的 Transaction Data (Optional) 里面填写你想发布的内容。 内容需要转换为 16 进制码，还要在代码之前加上固定头部“0x”以表示 16 进制。这里建议你把文字翻译成英文，因为英文 (UTF-8) 转换到 16 进制是最方便的。区块 5490403 就是这样做的。 其实这个功能本来是用来做备注用的，因为区块链交易没有什么名目，最后要靠备注来标记这笔钱用来投资还是买酒了。 接下来，MetaMask 会提醒你设置这笔交易的手续费 (Gas)。 “手续费”是个值得说的东西。理论上，在以太坊或者任何公链上交易，是可以不支付手续费的，但实际不给手续费不可能交易成功。因为每笔交易的背后都是所谓的矿工在执行，当交易量过大的时候（其实一直很多）就会出现交易阻塞，这时矿工先执行谁就要看手续费的多少了。 设置好手续费，点接受，就好了！ 永不消逝的电波前面提到，以太坊是一个公链，交易完成后就登录在一个账本上，而这个账本也是公开的。 全球有 16646 个以太坊节点，也就是 16646 本完全同步的账本。一旦写入，除非这 16646 个节点都下线并被摧毁，你的文章总有一份保存在世界的某个地方，就像永不消逝的电波一样…… 查看这段信息，以及整个交易，也有很多方式。比如 Etherscan 网站，你可以理解为区块链是一个硬盘，而像 Etherscan 这样的网站或者软件，就是文件浏览器。 不必多说，给自己设个小目标吧：在这星期内完成一次交易，把你喜欢的文章保存到以太坊或者任何其他的公链上。 只需要一套煎饼的钱，你也可以让那些站在阴影里的人明白：正义永不缺席，正义的声音也不会消失。 本文转自硅星人（ID：guixingren123），作者邢逸帆、宋图样，文章为作者独立观点，不代表芥末堆立场。 转载来源：在Github惨遭404后，那位不能提名字的大学生又选择了区块链]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>GitHub</tag>
        <tag>数字货币</tag>
        <tag>区块链</tag>
        <tag>支付宝</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缺只眼睛也能补回来！英伟达这个自动修补图像的AI完虐PS]]></title>
    <url>%2F2018%2F9b89c63c%2F</url>
    <content type="text"><![CDATA[然而，Photoshop不一定是最好的选择~这次英伟达，就搞出了一个新AI，拥有技惊四座的P图本领。 问耕 发自 凹非寺量子位 出品 | 公众号 QbitAI 在修图这件事上，Photoshop有着崇高的地位。 前一阵子，流传过这样一个段子：“甲方不要PS！让我们用Photoshop做！”足以说明开头的结论。 然而，Photoshop不一定是最好的选择~ 这次英伟达，就搞出了一个新AI，拥有技惊四座的P图本领。 比方，给你这样一张图。 嗯，对，就是这样，画面严重缺失。请用AI把这张图修复一下，P得要看起来像原图一样真实。 难不难？这画面上是啥都不一定能看清。 普通的AI也就能自动修补成下面这样或那样。 英伟达的AI呢？可以P成这样： 对比下原图。 再来一个，还是同样画面确缺失严重。 普通的AI也就能自动修补成下面这样或那样。 英伟达的AI，可以P成这样： 再对比下原图。 英伟达的AI是不是更赞？ 但，这个技术有什么用？ 其实与大段大段的补全缺失画面相比，快速且优秀的进行局部P图，才是这个技术真正发挥实力的地方。 静态展示不过瘾，动态展示才更令人惊叹。 比如下面这个动图，把左图中的人、线、红旗、石头、棍子都P掉，应该怎么做？很简单，就是直接涂抹掉，然后AI就自动修复了。 还比如这样。 其实这个AI的本事，就是能在一片空白之中，更好的填补上缺失的内容。 极端情况，比方处理人脸时候，眼睛被遮蔽了。 英伟达的AI就能重新补上一双眼睛，当然不可能是原来那个人的眼睛，但是至少能弥补的也算相对完美吧~ 以及，对于也能让头发更浓密。 也能让发际线更高~ 英伟达的新AI是真么做到的？ 答案就在这家公司新发布的论文里。这篇论文标题：Image Inpainting for Irregular Holes Using Partial Convolutions 。 英伟达的研究团队提出了一种新的模型，使用部分卷积的方法，其中卷积被掩蔽，并且仅基于有效像素进行重新归一化等处理。 论文中，还与现有其他方法进行了对比，有很多公式。 比如这种。 还有这种。 详细的方法和原理，可以前往阅读论文，地址： https&#58;//arxiv.org/abs/1804.07723 总而言之就是一句话：我不是针对谁，在座的都是…… 最后顺便提一下，这篇论文的一作Guilin Liu，在加入英伟达之前，还曾在Adobe Research实习过。 Adobe，就是搞出Photoshop（和一堆其他软件）的那家公司~ — 完 — 诚挚招聘 量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。 量子位 QbitAI · 头条号签约作者 վ’ᴗ’ ի 追踪AI技术和产品新动态 转载来源：缺只眼睛也能补回来！英伟达这个自动修补图像的AI完虐PS]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>人工智能</tag>
        <tag>Adobe</tag>
        <tag>英伟达</tag>
        <tag>Photoshop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简述表征句子的3种无监督深度学习方法]]></title>
    <url>%2F2018%2F9a9ba65a%2F</url>
    <content type="text"><![CDATA[本文介绍了三种用于表征句子的无监督深度学习方法：自编码器、语言模型和 Skip-Thought 向量模型，并与基线模型 Average Word2Vec 进行了对比。 本文介绍了三种用于表征句子的无监督深度学习方法：自编码器、语言模型和 Skip-Thought 向量模型，并与基线模型 Average Word2Vec 进行了对比。 近年来，由于用连续向量表示词语（而不是用稀疏的 one-hot 编码向量（Word2Vec））技术的发展，自然语言处理领域的性能获得了重大提升。 Word2Vec 示例 尽管 Word2Vec 性能不错，并且创建了很不错的语义，例如 King - Man + Woman = Queen，但是我们有时候并不在意单词的表征，而是句子的表征。 本文将介绍几个用于句子表征的无监督深度学习方法，并分享相关代码。我们将展示这些方法在特定文本分类任务中作为预处理步骤的效果。 分类任务 用来展示不同句子表征方法的数据基于从万维网抓取的 10000 篇新闻类文章。分类任务是将每篇文章归类为 10 个可能的主题之一（数据具备主题标签，所以这是一个有监督的任务）。为了便于演示，我会使用一个 logistic 回归模型，每次使用不同的预处理表征方法处理文章标题。 基线模型——Average Word2Vec 我们从一个简单的基线模型开始。我们会通过对标题单词的 Word2Vec 表征求平均来表征文章标题。正如之前提及的，Word2Vec 是一种将单词表征为向量的机器学习方法。Word2Vec 模型是通过使用浅层神经网络来预测与目标词接近的单词来训练的。你可以阅读更多内容来了解这个算法是如何运行的：http&#58;//mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/。 我们可以使用 Gensim 训练我们自己的 Word2Vec 模型，但是在这个例子中我们会使用一个 Google 预训练 Word2Vec 模型，它基于 Google 的新闻数据而建立。在将每一个单词表征为向量后，我们会将一个句子（文章标题）表征为其单词（向量）的均值，然后运行 logistic 回归对文章进行分类。 我们的基线 average Word2Vec 模型达到了 68% 的准确率。这很不错了，那么让我们来看一看能不能做得更好。 average Word2Vec 方法有两个弱点：它是词袋模型（bag-of-words model），与单词顺序无关，所有单词都具备相同的权重。为了进行句子表征，我们将在下面的方法中使用 RNN 架构解决这些问题。 自编码器 自编码器是一种无监督深度学习模型，它试图将自己的输入复制到输出。自编码器的技巧在于中间隐藏层的维度要低于输入数据的维度。所以这种神经网络必须以一种聪明、紧凑的方式来表征输入，以完成成功的重建。在很多情况下，使用自编码器进行特征提取被证明是非常有效的。 我们的自编码器是一个简单的序列到序列结构，由一个输入层、一个嵌入层、一个 LSTM 层，以及一个 softmax 层组成。整个结构的输入和输出都是标题，我们将使用 LSTM 的输出来表征标题。在得到自编码器的表征之后，我们将使用 logistics 回归来预测类别。为了得到更多的数据，我们会使用文章中所有句子来训练自编码器，而不是仅仅使用文章标题。 我们实现了 60% 的准确率，比基线模型要差一些。我们可能通过优化超参数、增加训练 epoch 数量或者在更多的数据上训练模型，来改进该分数。 语言模型 我们的第二个方法是训练语言模型来表征句子。语言模型描述的是某种语言中一段文本存在的概率。例如，「我喜欢吃香蕉」（I like eating bananas）这个句子会比「我喜欢吃卷积」（I like eating convolutions）这个句子具备更高的存在概率。我们通过分割 n 个单词组成的窗口以及预测文本中的下一个单词来训练语言模型。你可以在这里了解到更多基于 RNN 的语言模型的内容：http&#58;//karpathy.github.io/2015/05/21/rnn-effectiveness/。通过构建语言模型，我们理解了「新闻英语」（journalistic English）是如何建立的，并且模型应该聚焦于重要的单词及其表征。 我们的架构和自编码器的架构是类似的，但是我们只预测一个单词，而不是一个单词序列。输入将包含由新闻文章中的 20 个单词组成的窗口，标签是第 21 个单词。在训练完语言模型之后，我们将从 LSTM 的输出隐藏状态中得到标题表征，然后运行 logistics 回归模型来预测类别。 这一次我们得到了 72% 的准确率，要比基线模型好一些，那我们能否让它变得更好呢？ Skip-Thought 向量模型 在 2015 年关于 skip-thought 的论文《Skip-Thought Vectors》中，作者从语言模型中获得了同样的直觉知识。然而，在 skip-thought 中，我们并没有预测下一个单词，而是预测之前和之后的句子。这给模型关于句子的更多语境，所以，我们可以构建更好的句子表征。您可以阅读这篇博客（https&#58;//medium.com/&#64;sanyamagarwal/my-thoughts-on-skip-thoughts-a3e773605efa），了解关于这个模型的更多信息。 skip-thought 论文中的例子（https&#58;//arxiv.org/abs/1506.06726） 我们将构造一个类似于自编码器的序列到序列结构，但是它与自编码器有两个主要的区别。第一，我们有两个 LSTM 输出层：一个用于之前的句子，一个用于下一个句子；第二，我们会在输出 LSTM 中使用教师强迫（teacher forcing）。这意味着我们不仅仅给输出 LSTM 提供了之前的隐藏状态，还提供了实际的前一个单词（可在上图和输出最后一行中查看输入）。 这一次我们达到了 74% 的准确率。这是目前得到的最佳准确率。 总结 本文中，我们介绍了三个使用 RNN 创建句子向量表征的无监督方法，并且在解决一个监督任务的过程中展现了它们的效率。自编码器的结果比我们的基线模型要差一些（这可能是因为所用的数据集相对较小的缘故）。skip-thought 向量模型语言模型都利用语境来预测句子表征，并得到了最佳结果。 能够提升我们所展示的方法性能的可用方法有：调节超参数、训练更多 epoch 次数、使用预训练嵌入矩阵、改变神经网络架构等等。理论上，这些高级的调节工作或许能够在一定程度上改变结果。但是，我认为每一个预处理方法的基本直觉知识都能使用上述分享示例实现。 转载来源：简述表征句子的3种无监督深度学习方法]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Word</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>镜音双子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[textgenrnn：只需几行代码即可训练文本生成网络]]></title>
    <url>%2F2018%2F0ee30940%2F</url>
    <content type="text"><![CDATA[本文是一个GitHub项目，介绍了textgenrnn，一个基于Keras/TensorFlow的Python3模块。 本文是一个 GitHub 项目，介绍了 textgenrnn，一个基于 Keras/TensorFlow 的 Python 3 模块。只需几行代码即可训练文本生成网络。 项目地址：https&#58;//github.com/minimaxir/textgenrnn?reddit=1 通过简简单单的几行代码，使用预训练神经网络生成文本，或者在任意文本数据集上训练你自己的任意规模和复杂度的文本生成神经网络。 textgenrnn 是一个基于 Keras/TensorFlow 的 Python 3 模块，用于创建 char-rnn，具有许多很酷炫的特性： 它是一个使用注意力权重（attention-weighting）和跳跃嵌入（skip-embedding）等先进技术的现代神经网络架构，用于加速训练并提升模型质量。- 能够在字符层级和词层级上进行训练和预测。- 能够设置 RNN 的大小、层数，以及是否使用双向 RNN。- 能够对任何通用的输入文本文件进行训练。- 能够在 GPU 上训练模型，然后在 CPU 上使用这些模型。- 在 GPU 上训练时能够使用强大的 CuDNN 实现 RNN，这比标准的 LSTM 实现大大加速了训练时间。- 能够使用语境标签训练模型，能够更快地学习并在某些情况下产生更好的结果。能够在字符层级和词层级上进行训练和预测。 能够对任何通用的输入文本文件进行训练。 在 GPU 上训练时能够使用强大的 CuDNN 实现 RNN，这比标准的 LSTM 实现大大加速了训练时间。 你可以使用 textgenrnn，并且在该 Colaboratory Notebook（https&#58;//drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view?usp=sharing）中免费使用 GPU 训练任意文本文件。 示例 &#91;Spoiler&#93; Anyone else find this post and their person that was a little more than I really like the Star Wars in the fire or health and posting a personal house of the 2016 Letter for the game in a report of my backyard. 该模型可以很容易地在新的文本上进行训练，甚至可以在仅仅输入一次数据之后生成合适的文本。 Project State Project Firefox 这个模型的权重比较小（占磁盘上 2 MB 的空间），它们可以很容易地被保存并加载到新的 textgenrnn 实例中。因此，你可以使用经过数百次数据输入训练的模型。（实际上，textgenrnn 的学习能力过于强大了，以至于你必须大大提高温度（Temperature）来得到有创造性的输出。） Why we got money “regular alter”Urburg to Firefox acquires Nelf Multi ShamnKubernetes by Google’s Bern 您还可以训练一个支持词级别嵌入和双向 RNN 层的新模型。 使用方法 textgenrnn 可以通过 pip 从 pypi（https&#58;//pypi.python.org/pypi/textgenrnn）中安装： 你可以在该 Jupyter Notebook（https&#58;//github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb）中查看常见的功能和配置选项的演示案例。- /datasets 包含用于训练 textgenrnn 的 Hacker News 和 Reddit data 示例数据集。- /weights 包含在上述的数据集上进一步预训练的模型，它可以被加载到 textgenrnn 中。- /output 包含从上述预训练模型中生成文本的示例。/datasets 包含用于训练 textgenrnn 的 Hacker News 和 Reddit data 示例数据集。 /output 包含从上述预训练模型中生成文本的示例。 神经网络架构及实现 textgenrnn 基于 Andrej Karpathy 的 char-rnn 项目（https&#58;//github.com/karpathy/char-rnn），并且融入了一些最新的优化，如处理非常小的文本序列的能力。 本文涉及到的预训练模型遵循 DeepMoji 的神经网络架构（https&#58;//github.com/bfelbo/DeepMoji/blob/master/deepmoji/model_def.py）的启发。对于默认的模型，textgenrnn 接受最多 40 个字符的输入，它将每个字符转换为 100 维的字符嵌入向量，并将这些向量输入到一个包含 128 个神经元的长短期记忆（LSTM）循环层中。接着，这些输出被传输至另一个包含 128 个神经元的 LSTM 中。以上所有三层都被输入到一个注意力层中，用来给最重要的时序特征赋权，并且将它们取平均（由于嵌入层和第一个 LSTM 层是通过跳跃连接与注意力层相连的，因此模型的更新可以更容易地向后传播并且防止梯度消失）。该输出被映射到最多 394 个不同字符的概率分布上，这些字符是序列中的下一个字符，包括大写字母、小写字母、标点符号和表情。（如果在新的数据集上训练一个新模型，可以配置所有上面提到的数值参数。） 或者，如果可以获得每个文本文档的语境标签，则可以在语境模式下训练模型。在这种模式下，模型会学习给定语境的文本，这样循环层就会学习到非语境化的语言。前面提到的只包含文本的路径可以借助非语境化层提升性能；总之，这比单纯使用文本训练的模型训练速度更快，且具备更好的定量和定性的模型性能。 软件包包含的模型权重是基于（通过 BigQuery）在 Reddit 上提交的成千上万的文本文档训练的，它们来自各种各样的 subreddit 板块。此外，该网络还采用了上文提到的非语境方法，从而提高训练的性能，同时减少作者的偏见。 当使用 textgenrnn 在新的文本数据集上对模型进行微调时，所有的层都会被重新训练。然而，由于原始的预训练网络最初具备鲁棒性强得多的「知识」，新的 textgenrnn 最终能够训练地更快、更准确，并且可以学习原始数据集中未出现的新关系。（例如：预训练的字符嵌入包含所有可能的现代互联网语法类型中的字符语境。） 此外，重新训练是通过基于动量的优化器和线性衰减的学习率实现的，这两种方法都可以防止梯度爆炸，并且大大降低模型在长时间训练后发散的可能性。 注意事项 即使使用经过严格训练的神经网络，你也不能每次都能得到高质量的文本。这就是使用神经网络文本生成的博文（http&#58;//aiweirdness.com/post/170685749687/candy-heart-messages-written-by-a-neural-network）或推文（https&#58;//twitter.com/botnikstudios/status/955870327652970496）通常生成大量文本，然后挑选出最好的那些再进行编辑的主要原因。 不同的数据集得到的结果差异很大。因为预训练的神经网络相对来说较小，因此它不能像上述博客展示的 RNN 那样存储大量的数据。为了获得最佳结果，请使用至少包含 2000-5000 个文档的数据集。如果数据集较小，你需要在调用训练方法和／或从头开始训练一个新模型时，通过调高 num_epochs 参数来对模型进行更长时间的训练。即便如此，目前也没有一个判断模型」好坏」的启发式方法。 你并不一定需要用 GPU 重新训练 textgenrnn，但是在 CPU 上训练花费的时间较长。如果你使用 GPU 训练，我建议你增加 batch_size 参数，获得更好的硬件利用率。 未来计划 更多正式文档；- 一个使用 tensorflow.js 的基于 web 的实现（由于网络规模小，效果特别好）；- 一种将注意力层输出可视化的方法，以查看神经网络是如何「学习」的；- 有监督的文本生成模式：允许模型显示 top n 选项，并且由用户选择生成的下一个字符/单词（https&#58;//fivethirtyeight.com/features/some-like-it-bot/）；- 一个允许将模型架构用于聊天机器人对话的模式（也许可以作为单独的项目发布）；- 对语境进行更深入的探索（语境位置 + 允许多个语境标签）；- 一个更大的预训练网络，它能容纳更长的字符序列和对语言的更深入理解，生成更好的语句；- 层次化的作用于词级别模型的 softmax 激活函数（Keras 对此有很好的支持）；- 在 Volta／TPU 上进行超高速训练的 FP16 浮点运算（Keras 对此有很好的支持）。一个使用 tensorflow.js 的基于 web 的实现（由于网络规模小，效果特别好）； 有监督的文本生成模式：允许模型显示 top n 选项，并且由用户选择生成的下一个字符/单词（https&#58;//fivethirtyeight.com/features/some-like-it-bot/）； 对语境进行更深入的探索（语境位置 + 允许多个语境标签）； 层次化的作用于词级别模型的 softmax 激活函数（Keras 对此有很好的支持）； 使用 textgenrnn 的项目 Tweet Generator：训练一个为任意数量的 Twitter 用户生成推文而优化的神经网络。 转载来源：textgenrnn：只需几行代码即可训练文本生成网络]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>GitHub</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tree-CNN：一招解决深度学习中的「灾难性遗忘」]]></title>
    <url>%2F2018%2F27e6ea79%2F</url>
    <content type="text"><![CDATA[如何解决深度学习中的「灾难性遗忘」问题？ 转载来源：Tree-CNN：一招解决深度学习中的「灾难性遗忘」]]></content>
      <tags>
        <tag>PaperWeekly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让机器理解汉字一笔一画的奥秘？]]></title>
    <url>%2F2018%2F7ac50893%2F</url>
    <content type="text"><![CDATA[阿里工程师设计了一种全新的中文词向量算法。 转载来源：如何让机器理解汉字一笔一画的奥秘？]]></content>
      <tags>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[专访｜基于LSTM与TensorFlow Lite，kika输入法是如何造就的]]></title>
    <url>%2F2018%2F08688a4a%2F</url>
    <content type="text"><![CDATA[近日，机器之心采访了 kika 的高级技术总监黄康，他向我们讲述了 kika 开发输入法 AI 引擎（项目代号：Alps）所采用的深度学习模型以及在移动端轻量化部署遇到的各种挑战。本文从输入法与语言模型开始介绍了 kika Alps 项目的理论支持与实践挑战，并重点讨论了轻量化部署方法。 深度学习模型由于强大的表征能力在很多任务上都有非常优秀的表现，但也因为模型大小和计算量很难轻量化部署到移动端。这也是目前很多研发团队都在思考如何解决的难题。 一般在我们借助 TensorFlow、MXNet、和 Caffe2 等框架构建深度学习模型后，它在服务器训练与推断往往会有非常好的效果。但如果我们将模型部署到移动端，即使只执行推断过程，也会因为硬件条件和系统环境而遇到各种各样的问题。此外，目前关注于移动端的解决方案如 TensorFlow Mobile、TensorFlow Lite 等在一定程度上并不完善（TF Mobile 的内存管理与 TF Lite 的 Operators 的缺失），在实践中可能需要更多的修正与完善。 关注于输入法的 kika 成功地将基于循环神经网络的深度学习模型应用到安卓版的手机输入法引擎中，在克服工程化问题的情况下大大提升了输入体验：不仅使基于上下文的词预测更加准确，同时还使得词纠错功能更加强大。 在构建这样的输入法引擎过程中，kika 不仅需要考虑使用 LSTM 还是 GRU 来实现高效的语言模型，同时还需要探索如何使整个方案更轻量化以及如何快速的进行部署。本文首先介绍了输入法及 kika 所采用的语言模型，并在随后展示了 Android 移动端轻量化部署所遇到的工程化挑战。最后，本文介绍了 kika 压缩模型所采用的稀疏词表征方法与 K-means 参数量化方法，它们是轻量化部署深度学习模型的重要前提。 输入法与语言模型 输入法最重要的部分就是输入法引擎，kika 很多算法和项目都围绕它展开。一般而言，输入法引擎的输入包含两部分，即已经键入的词组和当前正在输入的词汇，前者可以视为上下文，而未完成的后者可称为键码。输入法引擎的输出是给定所有上下文和当前输入键码所『预测』的词，它也包含两部分，即当前输入词汇的补全和纠错。实现这样的功能也就是输入法最为核心的模块，kika 最开始是使用谷歌半开源的 LatinIME 来实现这样的功能，但这种基于 n-gram 的方法并不能实现顶尖的用户体验，因此经过研究与开发才有了现在基于循环神经网络（RNN）的解决方案。 输入法引擎这种给定上下文和当前键码以预测下一个词的方法其实可以看成语言建模，一般来说，语言模型旨在定义自然语言中「标记」的概率分布，这种标记可以是单词、字符甚至是字节。根据 kika 介绍，LatinIME 构建语言模型的方法是 n-gram，这种模型定义了一个条件概率分布，即给定前 n-1 个单词后第 n 个词的条件概率。因为假定当前词出现的概率只与前面 n-1 个词相关，那么 n-gram 可以使用这种条件概率的乘积来定义较长序列的概率分布： 虽然 n-gram 一直以来都是统计语言模型的核心模块，但它还是有很多局限性。对于输入法而言，较小的 n（二元语法与三元语法）不足以捕捉整个上下文信息来执行预测，而增大 n 又会使计算量成指数级增加。此外，kika 还希望引擎实现其它一些智能功能，例如根据上下文自动纠错或排序等。因此，kika 选择了更强大的循环神经网络构建语言模型。 为了构建强大的语言模型，kika 选择了长短期记忆单元（LSTM）作为网络的基础。LSTM 作为标准循环神经网络的变体在语言模型上有非常好的性能，它引入自循环的巧妙构想来更新「记忆」，若通过门控控制这样的自循环，那么累积的历史记忆或时间尺度就可以动态地改变。直观来说，LSTM 会通过门控选择需要保留的上下文信息或记忆，并用于预测当前输入的词。每当输入一个词，输入门会控制当前输入对最终预测有用的信息，而遗忘门会控制前面输入词对最终预测有用的信息，最后的输出门则会直接控制前两部分最终有效的信息。 kika 表明最开始 LSTM 只是用来实现标准的语言模型，它不会将正在输入的键码作为模型输入。这一套早期方案使用 LSTM 语言模型根据上下文预测当前词，而键码部分仍然使用传统基于 n-gram 和字典等的解决方案。后来 kika 使用一种新的策略将两部分结合在一起，因此模型不仅能接受上下文的输入，同时还能接受键码的输入。这种通用解决方案的架构如下图所示，它和一般的单词级语言模型和字符级语言模型都不一样，可以说是结合了两种架构。 如上图所示，首先 LSTM 会对前面输入的词进行建模，并输出对应的隐藏状态和记忆而作为后面字符级语言模型的先验输入。后面从 Start Flag 开始对键码实现字符级的建模而最终得出预测。 根据 kika 的解释，最后这种方案统一了两种输入。它的基本思想首先考虑到前面的 LSTM 语言模型除了要根据隐藏状态预测当前时间步的输出，同时还会向后传递这个隐藏状态。且 kika 表示若网络有良好的训练，那么这个隐藏状态是可以包含足够的语意信息，因此我们可以将它作为后面字符级 LSTM 网络的初始状态。这相当给循环神经网络一个初始量，然后再接受键码的输入而作出最终的词预测和词纠错等。 其实这里还有一个非常有意思的问题，即为什么 kika 会采用 LSTM 而不是 GRU。因为我们知道若需要将深度学习模型部署到移动端，那么我们要严格控制模型与计算量的大小，kika 所采用的稀疏词表征与参数量化等方法能有效控制模型大小，这一点将在后文展开。但 LSTM 的结构比 GRU 要复杂，门控也需要得更多，因此 LSTM 的参数会比 GRU 多，那么 kika 为什么不采用 GRU 控制参数数量？ kika 就这一点对机器之心做了详细的解答。黄康说：「在层数和单元数均一致的情况下，GRU 要比 LSTM 少一些参数和矩阵运算，因此，模型体积和训练速度方面都会有一定的优势。为了严谨的进行效果对比，我们做了两组实验。其中第一组是将 LSTM 和 GRU 的超参数设置一致，结果是： GRU 的效果明显差于 LSTM，同时，由于整体模型体积的主要贡献来源于前后两个巨大的词嵌入矩阵，模型体积方面的优势也不明显。」 但在同样超参数的情况下，GRU 的实际参数数量明显少于 LSTM。因此，kika 继续做了第二组实验，在保证基本一致的参数数量而放开网络架构约束的情况下，最后得到的结论是：LSTM 与 GRU 的模型大小基本一致，效果也基本一致，实际上，在 kika 的应用场景下，LSTM 的效果略好，但也仅仅是略好一点点。此外，由于 GRU 在当时也是比较新的结构，因此在体积和效果没有优势的情况下 kika 还是倾向于选择更温和的 LSTM，从而把主要精力用于模型结构的调整与参数调优方面。其实最近 kika 也在做一些网络架构和基本单元方面的调研，因为最近在 GRU 之后又出现了非常多训练简单且高效的单元。在 kika 当前的开发过程中也出现了一些场景更为复杂的 NLP/NLU 应用，因此也在考虑采用一些训练时间上更为友好的网络结果。对于如何选择网络结构，黄康表示：「我们内部有共识，考虑新结构有一个基本原则：我们会采用类似机器翻译的复杂任务去验证此种网络是否真实有效，才会考虑在工程上采用。」 总体而言，kika 花了很大一部分时间完成参数调优，因而能基于一体化的 LSTM 实现效果非常好的输入法引擎。当然只是构建模型还远远不够，将这种深度学习模型部署到移动端还面临着非常多的挑战，例如深度学习框架的选择和模型压缩的方法等等。 轻量化部署的工程挑战 在 kika，轻量化部署包括以下四个方面：模型压缩、快速的响应时间、较低的内存占用以及 较小的 so 库（shared object，共享库）大小等。除了优化模型的设计之外，压缩模型大小的方法主要是稀疏词表征与量化，这一部分我们将在后一部分展开讨论。 响应时间与内存是去年 kika 的工作重点，它主要是需要对 TensorFlow Mobile 和 Lite 做大量的修补。最后是动态链接库文件（.so），它定义了所有需要的运算和操作。因为整个输入法的核心代码是 C++ 完成的，而它在安卓设备中是以一个库（.so 文件）的形式存在的，它的大小直接影响了安装包的大小（由于 Android 加载 so 的机制，也会影响到内存的开销）。 针对响应时间与内存，kika 最开始是基于 TensorFlow Mobile 做一些修补和改进。黄康说：「TensorFlow Mobile 有一个非常好的优势，即它在底层使用了一套很成熟很稳定的矩阵运算库。因此，我们的主要精力放在 TensorFlow Mobile 在底层矩阵运算库之上的部分。它在矩阵运算库之间采用了很多封装与调用，但是没有考虑到很多实际工业化中遇到的问题，尤其是在内存保护这一块做得相当一般。」 TF Mobile 的内存管理与内存保护设计得并不完善，存在两个主要的问题：1. 内存保护机制不完善，在实际内存不足的情况（尤其对于一部分低端机型），容易引发内存非法操作。2. 内存大小控制机制存在明显的问题，例如模型本身在计算时只有 20MB，但加载到内存之后的运行时峰值可能会达到 40 到 70MB。据 kika 的数据，基于 TF Mobile 的解决方案大概有 1% 的场景（如游戏中调起输入法）由于内存大小限制的原因会加载不了深度学习模型，只能回退到非深度的解决方案。 2017 年 11 月，谷歌正式发布了 TensorFlow Lite，这对于移动端深度学习模型来说是非常重要的框架。在 TF Lite 开源后，kika 马上就进行了测试，并重点关注内存管理模块。黄康表示：「TF Lite 的内存管理上确实有非常大的改进，加载不了深度学习模型的场景会成百倍地减少。但它最大的问题就是 Operator 的不全，它基本上只定义了最基础的运算和操作。所以 kika 为了在内存上减少 20 多 MB 的开销，我们自行编写了大量的 Operator。但目前这个还是有一定的风险，因为如果我们修改了模型结构，那还是需要手写新的运算。」 工程化挑战最后一个问题就是动态链接库的大小，这一部分还会涉及到参数量化方法的实现，我们会在参数量化方法那边讨论。其实 TF Mobile 还有一个缺点，即它会将很多冗余的操作与运算都会打包到 .so 文件中，因此也就导致了动态链接库过大。kika 为了让 .so 文件尽可能小，开发了一套全新的工具，用于自动的判断到底哪些操作与运算的定义是模型实际需要的。 稀疏词表征 深度学习模型在输入法客户端部署的一个重要问题就是模型大小，我们需要将参数数量与计算量限制绝大部分移动设备可接受的范围内。kika 发现模型体积的主要矛盾体现在词嵌入矩阵中。因此，如果能够压缩词嵌入矩阵的大小，那么就能有效地控制模型大小。kika 采用了稀疏词表征的方法以压缩词嵌入矩阵的大小，从而大幅度减少 LSTM 语言模型的参数与计算量。 其实对于语言模型，甚至是自然语言处理而言，词嵌入是非常重要的成分，我们可以使用 300 到 500 维的向量表示词表中数以万计的词汇。这种方法不会像 one-hot 编码那样使用超高维的向量表示一个词，可以说词嵌入将词的表征由|V|维减少到几百维，其中|V|表示词汇数量。但是当我们使用词嵌入作为语言模型的输入时，我们会发现尽管每个词的维度只有 n，但需要|V|个向量，而 |V| 通常要比 n 高好几个量级。因此，稀疏词表征就尝试使用少量词向量（少于|V|）而表征 |V| 个词。 这种方法的直观概念即我们的词表可以分为常见词与非常见词，而一般单个词可以由多个词定义，因此非常见词可以使用多个常见词表示。根据这样的观点，我们可以使用一组常见词的词嵌入向量作为基础，再通过组合而表示所有词的词嵌入向量。因此，我们能使用少量词嵌入向量表示大量词汇。又因为每一个词的表征都只使用少量的常见词来定义，所以这种表示方法是非常稀疏的，这也就是稀疏词表征的直观概念。 若我们将词表 V 分割为两个子集 B 和 C，第一个子集 B 为基向量集，它包含了固定数量的常见词。而 C 包含了所有不常见的词，因此现在需要使用 B 的词嵌入向量以线性组合的方式编码 C 中的词。这一过程可通过最小化由基向量集学习重构的词表征和完整表征之间的距离而学习，一般来说整个过程可表示为： 使用全部词汇训练一个词嵌入矩阵。 按词频选取最常见的 |B| 个词嵌入向量，并组成过完备基矩阵。 非常见词的预测可表示为 B 中所有词嵌入向量的稀疏组合，即 其中 w hat 为预测的非常见词词向量、U 为常见词词向量，而 x 为稀疏矩阵。 最小化预测词向量和实际词向量间的距离来学习稀疏表征，即 其中第一项表示通过稀疏表示 x 预测的词向量与完整词向量（w）间的 L2 距离。后一项为 L1 正则化，它会将矩阵 x 中的元素推向 0，从而实现稀疏表示。 在 kika 的论文 Sparse Word Representation for RNN Language Models on Cellphones 中，他们使用了以下伪代码展示了稀疏表示的学习算法： 这个算法很大的特点是实现了一个二元搜索来确定α，因为我们不能直接控制稀疏矩阵 x 的稀疏程度，所以我们根据稀疏矩阵的非零元素数来控制α的变化。整个稀疏词表征算法需要输入过完备基矩阵 U（常见词）、完整词嵌入矩阵 w、稀疏程度 s 和作为终止条件的容忍度 tol。 其中 s 是非常重要的一个参数，它控制了一个词最多需要多少个过完备基向量表征。kika 表示：「s 是一种权衡，如果参数较大，那么压缩比就会很小，模型达不到预期效果。如果参数较小，那么重构的词表征就不能有效地表示所有词。」正因为需要进行精调来确定 s 及其它超参数，kika 表明总体模型调优时间是训练时间的 4 到 5 倍，所以整个稀疏词表征的训练过程还是比较挺长的。 如上算法所示，首先我们会确定α的搜索范围，然后取α的中间值并最小化损失函数而求得稀疏表示 x，并统计 x 中每一个列向量的非零元素数，它们代表了一个词需要多少个常见词表示。如果 k 大于 s，那么非零的元素就过多，我们需要加大 α 以增强 L1 正则化的效果。这样的二元搜索直到α的上下界距离小于参数 tol 才会终止，且一般迭代几次就能快速收敛到合适的 α 来控制 x 的稀疏性。在完成 x 的学习后，我们将每一列稀疏向量抽取为对应的索引与权重，索引代表使用哪些基向量或常见词，而权重代表它们定义某个词的重要性。 又因为前面的二元搜索将 k 限制为不大于 s，所以有可能 k 是小于 s 的，因此我们需要使用零将这些向量补全。经过上面的步骤，最终我们会产生包含 s 个元素的等长向量 indices 和 weights。储存这两种向量而不直接储存稀疏矩阵 x* 能节省很多空间，这对于减小安装包大小有非常重要的作用。 论文中给出的词嵌入恢复算法以一种串行密集运算的方式进行展示，这可以令读者清晰地理解重构过程： 若给定 U、indices 和 weights，一个词的词嵌入重构可直接利用索引取对应的基向量，并与对应的权重求加权和。这种线性组合非常简单且高效，也是线性代数中非常直观的表示方法。因为任何秩为 n 的矩阵都可以由 n 个线性不相关的向量或基表示出来，完整的词嵌入矩阵也就能由过完备基的线性组合表示。算法 1.2 最后返回的 v 就是我们线性组合多个常见词词嵌入而重构出来的完整词嵌入向量。 以上是 kika 采用的稀疏词表征方法，它可以有效减少模型参数和计算量，但我们还能进一步使用参数量化来压缩模型的存储大小。 量化 一般而言，应用的安装包大小对于用户体验非常重要，这一点对于移动端尤为突出。因此，我们可以使用参数量化的方法来减小安装包大小。kika 也曾尝试使用 TensorFlow 封装的压缩方法，但仍发现一些难以解决的问题，因此他们最终使用 k-means 方法重新构建参数量化而解决包体增大的问题。 kika 最开始尝试使用官方的 tf.quantize 执行参数量化，并用 tf.dequantize 恢复参数。这个方法非常迅速，基本上几十兆的模型只需要分钟级的时间就能完成压缩。但 kika 发现这种方法有一个非常大的问题，即如果当我们希望读取量化后的模型时，TensorFlow 会引入大量的 Operator，这势必会造成动态链接库（.so）的体积增大，因而会加大安装包的大小。因为动态链接库包含了所有 TF 定义的加法、减法、卷积和归一化等模型需要使用的运算，因此调用 TF 的量化方法同样会将相关的运算添加到动态链接库中。 根据 kika 的实验，使用 TF 官方的量化方法大概会使动态链接库增加 1 到 2 MB 的体积，对应的安装包大小也会增加这么多。由于这样的原因，kika 最后选择基于 k-means 的方法实现参数量化。简单而言，这个方法会先使用 k-means 将相似的向量聚类在一起，然后储存聚类中心，原参数矩阵就只需要存储聚类中心的索引就行了。kika 表明这种方法的有点在于不会额外增加动态链接库和安装包的大小。因此下面将简要介绍这种基于 k-means 的参数量化方法。 量化即从权重中归纳一些特征，这些特征会储存在码表（codebook）并以具体数值表示某一类权重，而原来的权重矩阵只需要存储索引来表示它们属于哪一类特征就行了，这种方法能很大程度上降低存储成本。 kika 使用的标量量化算法基本思路是，对于每一个 m×n 维的权重矩阵 W，首先将其转化为包含 m×n 个元素的向量 w。然后再对该权重向量的元素聚类为 k 个集群，这可借助经典的 k 均值聚类算法快速完成： 现在，我们只需储存 k 个聚类中心 c_j，而原权重矩阵只需要记录各自聚类中心的索引就行。在韩松 ICLR 2016 的最佳论文中，他用如下一张图非常形象地展示了量化的概念与过程。 如上所示权重矩阵的所有参数可以聚类为 4 个类别，不同的类别使用不同的颜色表示。上半部分的权重矩阵可以取聚类中心，并储存在 centroids 向量中，随后原来的权重矩阵只需要很少的空间储存对应的索引。下半部是韩松等研究者利用反向传播的梯度对当前 centroids 向量进行修正的过程。 稀疏词表征与参数量化是 kika 控制参数大小的主要方法，黄康表示：「实际上模型的大小可以分为两阶段，首先如果原模型是 40MB 的话，稀疏词表征可以将模型减少到 20MB 左右，这个大小是实际在内存中的大小。而进一步采用参数量化可以将大小压缩到 4MB 左右，它解决的问题是 APK 安装包大小，APK 大小也是非常重要的，毕竟作为输入法这样的应用，APK 的大小是非常重要的。不论使不使用参数量化，模型最终在计算上需要的内存就是稀疏词向量表征后的大小。」 最后两部分基本上就是 kika 解决模型大小的方案，它们令深度学习模型在实践中有了应用的可能。当然，要将深度学习模型嵌入输入法和移动端会有很多的挑战，仅仅控制模型大小是不够的，因此也就有了上文 kika 在内存大小、响应时间和动态链接库等方面的努力。 整个模型效果和工程化实践都是 kika 在过去 2 年来对输入法引擎的探索，未来还有很多优化与提升的方向，例如使用新型循环单元或新型强化学习来根据用户习惯调整输入法等。这些新功能与新方向将赋予输入法引擎更多的特性，也能适应性地为不同的用户提供最好的体验。 转载来源：专访｜基于LSTM与TensorFlow Lite，kika输入法是如何造就的]]></content>
      <categories>
        <category>军事</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Word</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相比芯片，我们更该在意深度学习框架的中国化]]></title>
    <url>%2F2018%2F5850525e%2F</url>
    <content type="text"><![CDATA[摘要： 存在感，是一个个脚印踏出来的。 这两天美国宣布对中兴进行封锁，可谓在科技圈掀起了从上到下的一股龙卷风。 4月16日美国商务部发布命令，禁止美国企业向中兴通讯销售元器件，时间长达7年。假如这一纸禁令真正生效，意味着中兴通讯旗下全产业链所依靠的芯片等核心元件失去获取渠道，基本意味着庞大的中兴通讯将面临无法继续经营的最坏可能。 中兴通讯股价随之快速下跌，已相当于两个跌停板，… 摘要： 存在感，是一个个脚印踏出来的。 这两天美国宣布对中兴进行封锁，可谓在科技圈掀起了从上到下的一股龙卷风。 4月16日美国商务部发布命令，禁止美国企业向中兴通讯销售元器件，时间长达7年。假如这一纸禁令真正生效，意味着中兴通讯旗下全产业链所依靠的芯片等核心元件失去获取渠道，基本意味着庞大的中兴通讯将面临无法继续经营的最坏可能。 中兴通讯股价随之快速下跌，已相当于两个跌停板，其美国供应商的股价在“禁令”发布后也遭遇不同程度的下跌。 19日，中国商务部新闻发言人高峰在新闻发布会上表示，美方行径引起了市场对于美国贸易和投资环境的普遍担忧。 随着中美贸易战延伸到科技领域，似乎一夜间我们又回忆起了缺失核心研发能力的恐惧。“缺芯之痛”转瞬弥漫在舆论氛围里，甚至关于“中国科技到底行不行”的讨论又一次尘嚣直上。 当然了，出问题就无限夸大其实并没有太大意义。客观来说，美国的芯片禁令无法持久，毕竟这背后涉及的美国本土产业链、利益群落与工作岗位非常庞大。一旦接连失去中国大客户，美国引以为傲的科技产业本身就会撑不住。 另外我们需要认清的是，半导体行业今天的国际格局并不是几个月，甚至几年内造成的。而是整个半导体工业时代发展和遗留下来的产物。中国以及全世界更多市场的计算机、工业、通用电子系统上本土芯片占有率都是零。 事实上，中兴这样的中国企业，在技术上的锐意进取是有目共睹的。但芯片研发制造能力的国际垄断，是几十年积累下来的产业现实，是大量的科技因素与市场封锁、贸易规则制定综合得出的结论。是一两家公司，甚至是集合整个科技集群都难以改变的。 换句话说，中国科技公司面临可能出现的困境，除了加强研发投入也没有什么别的办法。过去我们无法改写，但今天我们能改变的东西，叫做未来。 就像几十年前的半导体技术是核心中的核心。今天提起能改变未来世界的技术，AI绝对是当仁不让。尤其值得注意的是，这个刚刚兴起、充满变化的技术领域里，中美之间的价值突围和技术博弈其实更加激烈。 AI的国家战略重要性是母庸质疑的，而针对产业链上游核心技术的争夺正在逐步呈现白热化。假如我们希望若干年后整个产业界，甚至整个国家不会再因为一纸封锁领而恐慌，那么AI这个战场的基础设施，才是真的不容有失。 或许对于大部分人来说，AI的底层之争在今天还有些陌生，但它确实很可能像曾经的半导体一样，产生新时代的世界科技格局垄断效应。比如说每个AI开发者都会用到，所有AI应用产生的基础——深度学习开发框架。 在这个普通人很陌生的领域，中国科技公司和万千开发者，正在一点点刷新着中国科技的存在感。 被忽略的深度学习框架 芯片为什么重要？原因在于它是一切运算的基础，是最后端的的东西，没有它一切硬件都玩不转。所以当垄断形成，就能对其他经济体的科技发展形成底层制约。 同样的道理，在AI时代也体现在开发框架这件事上。我们知道，AI开发者不能每开发一个模型就从最底层重新来过，所以想要进行算法训练、模型开发、应用部署，都必须在一定的开发平台上来完成。AI发展到今天，这个平台的角色主要依靠大学和企业提供的深度学习框架来扮演。 在中国，深度学习框架相对来说是一个科研和开发领域的事情，但在美国，产业界围绕开发框架的争夺战早已经火星四溢。 比如说，很多美国媒体都认为，谷歌今天在云计算、硬件、语音助手、AI教学等业务中，全都展现出“TensorFlow First”的特点，用尽各种办法将开发者引导至自己的开发平台上，并且坚决不兼容其他开发框架。 而Facebook、微软则对TensorFlow的封闭深恶痛绝，形成了以caffe、Python结盟形式的“反谷歌联盟”，希望以兼容性和社群开放等优势，打破谷歌一骑绝尘的战略格局。 对开发框架的重视，隐藏着科技企业和背后国家经济体对AI未来的押注。试想无数应用都在自己的平台上进行开发，那么所有数据、算法创新和模型训练过程就都留在了平台当中。企业和平台收获的，是作为地基的产业地位。而国家经济收获的，是可以从源头上控制其他经济体AI应用的“上游效应”。 幸运的是，已经吃够了“下游之苦”的中国，在深度学习框架这件事上并没有落后。 为了解决当时主流开发框架仅支持但GPU应用，无法进行大规模数据处理的问题。百度从2013年就开始研发自己的深度学习框架PaddlePaddle，经过长期内部应用后，在2016年正式将其进行开源。 这也让百度成为继谷歌、Facebook、IBM之后，全球第四家、中国第一家开源深度学习开发框架的科技公司，之后BAT相继推出深度学习开发框架，在这场基础设施争夺中，中国产业壁垒的高度已和过去不再相同。 可能出现的中美AI对决中，开发框架或是轴心武器 就目前中国AI的整体行业氛围而言，似乎普遍更关注AI“用”的一面，容易忽略在应用之前的开发与创新，以及为创新提供的基础设施，是整个AI商业想象力的原点。 事实上，假如我们将中美两国看做处于竞比关系的两个AI技术群落，那么深度学习框架的质量和接受度，很可能会影响到整个产业竞赛的进程甚至结果。 或许可以从三个角度，来看为什么中国一定要有自己的深度学习框架，以及中国开发者为何更应该支持“国货”。 1、中国AI无法离开中文：我们知道，AI的一个重要领域是语言与对话的交互。那么未来在中国市场应用的，必然是基于中文的AI开发。但在NLP与语音交互、神经网络翻译等技术上，国外主流开发框架很少有中文数据集，也缺乏在中文领域的技术探索。如今来看，开发者想要开展这方面的工作，几乎必须依赖PaddlePaddle这样的国产框架所提供的开发基础和数据集、文档。 2、产业链的安全风险：去年，谷歌的TensorFlow曾经被爆出重大安全漏洞。虽然没有造成实质影响，但当时专家评估，类似的漏洞完全可以影响甚至摧毁所有基于该平台开发出的AI模型。要知道AI大量涉及安防、识别、城市交通、公共服务等国家事务核心领域应用，这些应用如果在国外框架中开发运行，那么安全风险不言而喻。 3、产业应用需求不同：相比于美国，中国对AI开发这件事的需求其实有很大不同。比如说传统企业多、开发者的应用需求大、商业期待迫切、开发人才处在发展阶段。那么相比于前沿探索类的开发，中国开发者更需要在开发框架提供高效、灵活的开发方案，以及快速部署、弹性学习的能力。这些因素当然是远在天边的欧美开发平台不会考虑的。只有深谙中国开发者需求和中国AI市场生态环境的企业，才可能进行针对性价值提供。 不难看出，基于应用性、安全性和中文开发的必然性，中国的深度学习开发框架之争都是注定要发生的。 别是一风景 在科技领域，“理性支持国货”显得尤为重要。毕竟不能为一些大局层面的考虑，牺牲货真价实的成本与效率。 好在“国框”其实在很多层面上已经足可与欧美一较高下，比如Caffe 创始人贾杨清在评价百度的PaddlePaddle时，也认同其在简洁、灵活、快速等领域功力不俗，并且解决了Caffe早期的不少遗留问题。 今天的“国框”已经不能说是为了爱国而爱国的强硬选择。在很多层面上，AI开发的自主、自有、自生态，已经可以在中国这个世界第二大AI技术实体与市场独立完成。 或许对于中美贸易战，以及可能的科技禁运等情况，我们还是有些过于敏感了。 诚然，硬件和底层技术有差距，是必须要承认的事实；但在新的领域，在争夺未来的原点上，中国科技工作者、开发者以及无数企业，一直都没有停止奔跑。中美之间的差距，今天也在以肉眼可见的速度缩小。 对待中美科技之争，更合理的方式或许是承认差距的同时，认清很多关键领域的国家自信。 更多核心领域达成技术突破；开发者、资本和平台有效组织产业聚合；营造更好的创新土壤，那么中国终有一天不会再被人牵着鼻子走。 星河流转之后，或许别是一风景。 转载来源：相比芯片，我们更该在意深度学习框架的中国化]]></content>
  </entry>
  <entry>
    <title><![CDATA[特朗普考虑启动紧急法案 扩大限制中方敏感领域投资权力]]></title>
    <url>%2F2018%2F9409b59a%2F</url>
    <content type="text"><![CDATA[紧急法案赋予总统广泛限制交易的权力 ，例如可以限制中国资金投资某些特定产业。 因此，美国政府可能双管其下，最后可能同时使用紧急的行政法限制和CFIUS新法来规范中资对美投资。 （特朗普 资料图） 《财经》记者 蔡婷贻/文 郝洲/编辑 4月22日，中国商务部公开就美国财政部长姆努钦考虑来华磋商表示欢迎，为两国近几个月来因为贸易问题引发的各种交锋带来些微缓和的希望… &gt; 紧急法案赋予总统广泛限制交易的权力 ，例如可以限制中国资金投资某些特定产业。 因此，美国政府可能双管其下，最后可能同时使用紧急的行政法限制和CFIUS新法来规范中资对美投资。 （特朗普 资料图） 《财经》记者 蔡婷贻/文 郝洲/编辑**** 4月22日，中国商务部公开就美国财政部长姆努钦考虑来华磋商表示欢迎，为两国近几个月来因为贸易问题引发的各种交锋带来些微缓和的希望。 美国对与中国展开的谈判以及可能达成的协议表示“谨慎乐观”，姆努钦指出。 不过，缓和极可能是表面迹象。就在数日前，美国商务部4月16日宣布美国企业至2025年为止，不可对中兴出口软件、技术和货品。接着，美国财政部助理部长塔博特（Heath Tarbert）于19日确认，该部门正研究是否为限制中国对美国特定高科技产业的投资和并购启动1977年通过的《国际紧急经济权力法案》(International Emergency Economic Powers Act，下称紧急法案) 。 美国限制外国投资的机构为跨部门的美国外国投资委员会（Committee on Foreign Investment in the United States，简称CFIUS）。塔博特称，根据特朗普的命令，在CFIUS之外，财政部还下设一个专门的办公室处理限制中国投资的事务。 美国国会也正推动修改法律，寻求从严规范外国资金对美国敏感企业的投资。但由于修改法律旷日费时，财政部考虑使用行政法直接阻止中资在美国的并购或投资。 紧急法案主要在美国面临“异乎寻常的严重威胁”时，对政权、个人和特定组织实施制裁。根据前例，美国使用该法案对其他国家**进行经济制裁时多出于政治考量，如伊朗和苏丹，而且制裁对象扩大到包括考虑与这些国家进行**商业往来的美国企业 。 特朗普上台后，曾于2017年8月25日对委内瑞拉动用紧急法案实施金融制裁，禁止美国金融机构参与委内瑞拉政府和国有的委内瑞拉石油公司新的债务和股权交易，禁止美方机构参与委内瑞拉公共部门现已发行的部分债券交易等。 企业并购行业的资深律师戴维斯（Christian Davis）对《财经》指出， CFIUS立法需要在参众两院通过后，特朗普才能签署成为法案；但即便如此，到时候CFIUS可能都不包括特朗普政府希望对中国投资使用的限制。而紧急法赋予总统广泛限制交易的权力 ，例如可以限制中国资金投资某些特定产业。 因此，美国政府可能双管其下，最后可能同时使用紧急的行政法限制和CFIUS新法来规范中资对美投资。 推动CFIUS修法和研究启动紧急是因应301知识产权调查结果的两个独立机制。紧急法案一旦启用，将赋予特朗普全面限制中国在半导体、机器人等敏感领域投资的权力。 美国国会研究（国会的智库）亚洲贸易和金融专家莫里森（Wayne Morrison） 对《财经》指出，特朗普政府目前采取的是“大棒”策略。主要目标包括防止中国企业通过并购美国公司在特定产业取得领先地位，实现“中国制造2025”的目标；同时也希望迫使中国对美国企业做出互惠对待，同等程度地开放市场 。 特朗普政府自3月22日在白宫宣布将对部分中国产品征收关税后，贸易争端引发的紧张就不断上升，各方对争端升级为贸易战的担忧也持续加深。 代表美国主要企业利益的美国贸易全国委员会就对《财经》指出，他们了解特朗普政府正考虑把相应投资限制当作一个选项，但是“我们看不出来这个政府的策略是什么…这怎么解决问题？这个政府要中方采取什么行动来改善知识产权保护和终止强迫技术转让？我们希望（美国）政府能说清楚。最终，美国企业寻求的是在中国和国内同业者在各方面享有平等的机会。” 由于这一法案从未在贸易纠纷时使用，部分贸易法专家质疑特朗普政府是否扩大解释了该法案中的“紧急状态”。 不过，彼得森国际经济研究所高级研究员赫夫鲍尔指出，法院从未质疑过总统宣称的“国家紧急状态”，因此引用此法案在法理上应不会受到挑战。 由于特朗普在竞选时做出各种强硬的贸易承诺，赫夫鲍尔于2016年就罗列出美国法律赋予总统在贸易政策上的行政特权；除了紧急法案外，《对敌贸易法》 （Tading with the Enemy Act）也赋予总统广泛权力，此法案允许总统监控所有国际贸易和金融活动，甚至冻结或没收外国资产，对象不限于敌对国家。1962年通过的《贸易拓展法》（Trade Expansion Act）赋予总统为巩固国家安全而提高关税的权力；另外，1974年的《贸易法》下，总统有权以处理国际逆差为由，将关税提高15%，为期150天。 戴维斯指出，在财政部公布紧急的具体实施方案前，对哪些投资的具体限制不得而知，但任何方面的限制都会使中国企业投资美国更加困难，特别是和“中国制造2025”相关的投资将可能是该法案限制的主要对象。 美国财政部将在5月底向特朗普提交新的投资限制计划。莫里森担忧的指出，“这个政府采取的策略是正确的吗？当两个对手实力悬殊时，边缘政策能奏效，但是中美对峙并不符合这种情况。中国也可以像美国一样，对商业往来采取各种限制。” 转载来源：特朗普考虑启动紧急法案 扩大限制中方敏感领域投资权力]]></content>
  </entry>
  <entry>
    <title><![CDATA[施一公：科研水平低下，所有精英都想干金融，是中国潜伏的最大危机]]></title>
    <url>%2F2018%2F379c86b3%2F</url>
    <content type="text"><![CDATA[作者：施一公，1967年5月5日出生于河南郑州，1989年毕业于清华大学，1995年在美国约翰霍普金斯大学获博士学位。中国科学院院士、结构生物学家、清华大学教授 。曾获第二届“未来科学大奖”之“生命科学奖”。 现任中国科学技术协会第九届全国委员会副主席 ，西湖大学校长 。 中兴事件注定将成为中国崛起路上的一个标志性事件。虽然自家的头牌“高科技公司”一打就趴下，但它能带给我们疼痛和清醒。西… 作者：施一公，1967年5月5日出生于河南郑州，1989年毕业于清华大学，1995年在美国约翰霍普金斯大学获博士学位。中国科学院院士、结构生物学家、清华大学教授 。曾获第二届“未来科学大奖”之“生命科学奖”。 现任中国科学技术协会第九届全国委员会副主席 ，西湖大学校长 。 中兴事件注定将成为中国崛起路上的一个标志性事件。虽然自家的头牌“高科技公司”一打就趴下，但它能带给我们疼痛和清醒。西湖大学校长施一公曾发表演讲：当所有精英都想干金融，这个国家一定出了大问题！以下为施一公演讲摘录： 如今我们的GDP已经全球第二， 但是看技术革新和基础研究的创新能力， 作为一个国家我们排在20名开外。 我不知道在座的哪一位可以心安理得地面对这个数字。 我们有14亿人口， 我们号称重视教育、重视科技、重视人才。 我们的科技实力、创新能力、科技质量在世界上排在20名开外。 有的人或许会怀疑， 会说我们都上天揽月、下海捉鳖了， 怎么可能创新不够， 我们都高铁遍布祖国大地了， 怎么可能科技实力排在20名开外。 我想说的是，你看到的指标和现象， 这是经济实力决定的， 不是科技实力决定的。 我们占的是什么优势， 我们占的是经济体量的优势。 请大家别忘了1900年我们签订《辛丑条约》赔款九亿八千万白银的时候， 中国的GDP也是世界第一， 但大不代表强， 这是我们面临的一个沉重的现实。 我在海外的时候， 只要有人说我的祖国的坏话， 我会拼命去争论， 因为我觉得我很爱国。 四月份， 我在瑞典皇家科学院年会上领奖， 晚宴时，与一位瑞典的知名教授聊天， 谈到中国的科技发展， 他很不屑一顾， 我觉得很委屈、很愤懑， 但是我轻描淡写地说了一句：不管怎么说，我们国家登月已经实现了，你们在哪儿？ 但他回敬了一句，让我说不出话。 他说：施教授，如果我们有你们中国的经济体量，我们能把五百个人送到月球上并安全回来。 我们对国家的科技实力和现状应该有一个清醒的认识， 中国的大学很有意思， 比如我曾经所在的清华大学， 学生从入学开始， 就要接受“就业引导教育”。 堂堂清华大学， 都要引导学生去就业， 都让学生脑子里时时刻刻有一根弦叫就业， 我觉得非常不可思议。 研究型大学从来不以就业为导向， 从来不该在大学里谈就业。 就业只是一个出口， 大学办好了自然会就业， 怎么能以就业为目的来办大学。 就业是一个经济问题， 中国经济达到一定程度就会提供多少就业， 跟大学没有直接关系。 让学生进去后就想就业， 会造成什么结果？ 就是大家拼命往挣钱多的领域去钻。 清华70%至80%的高考状元去哪儿了？ 去了经济管理学院。 连我最好的学生， 我最想培养的学生都告诉我说， 老板我想去金融公司。 当这个国家所有的精英都想往金融上转的时候， 我认为这个国家出了大问题。 管理学在清华、在北大、在整个中国都很热， 这是违背教育规律的一件事情。 每个学校都用就业这个指标考核领导， 这对大学有严重干扰。 我们的大学现在基础研究能力太差， 转化不出来，不是缺乏转化， 是没有可以转化的东西。 你们认为我们的文化鼓励创新吗？ 我觉得不鼓励， 我们的文化鼓励枪打出头鸟， 当有人在出头的时候， 我觉得很多人在看笑话。 当一个人想创新的时候， 同样有这个问题。 什么是创新，创新就是做少数， 就是有争议。 科学与民主是两个概念， 科学从来不看少数服从多数， 在科学上的创新是需要勇气的。 我们有1400万中小学教师， 我们虽然口口声声希望孩子培养创新、独立思考的思维，但我们的老师真的希望孩子们多提一些比较尖锐的问题吗？ 这和我们的部分文化， 师道尊严又是矛盾的， 所以我们在创新的路上的确还背负了沉重的文化枷锁。 转载来源：施一公：科研水平低下，所有精英都想干金融，是中国潜伏的最大危机]]></content>
  </entry>
  <entry>
    <title><![CDATA[专家：建议中国搞x86与Intel竞争的，都是在忽悠国家的钱]]></title>
    <url>%2F2018%2Fc7d8c52d%2F</url>
    <content type="text"><![CDATA[新智元专栏 作者：筋斗云 【新智元导读】为美国制裁中兴事件，对国内集成电路产业影响多大？芯片的基本生态是谁先做出一个超出同行的东西，大家都会自动地转入这个生态。即便ARM这样成功的公司背后，是无数产业链公司艰辛的活着。本文作者有多年芯片从业经验，他认为：所有建议中国搞x86的，与Intel竞争的，在行业内看来，都是忽悠国家/VC 钱的。 中兴事件对集成电路有多大的影响… 新智元专栏 作者：筋斗云 【新智元导读】为美国制裁中兴事件，对国内集成电路产业影响多大？芯片的基本生态是谁先做出一个超出同行的东西，大家都会自动地转入这个生态。即便ARM这样成功的公司背后，是无数产业链公司艰辛的活着。本文作者有多年芯片从业经验，他认为：所有建议中国搞x86的，与Intel竞争的，在行业内看来，都是忽悠国家/VC 钱的。 中兴事件对集成电路有多大的影响？ 作为行业内的人来说，基本没有影响。 这个行业产业链和生态最重要，因为硅片的NRE成本高，单价成本低。所以这个生态基本是谁先做出一个超出同行的东西，大家都会自动地转入这个生态。 这个类似于从A城市修了一条道到B城市。修道路成本极高，过路费的价格不高，而且过路费还在不断下降中。 现在你自己要重新修一条路，你的道路比别人窄，收费更贵，人家又修了B到C。你自己跑自己的路还比对手的路又慢又贵，你怎么进行竞争？ Intel和思科在当年占了硅谷一半以上的利润，无数的VC想再做个Intel出来，没有一个成功的。ARM现在成功背后，是无数类似的竞争公司的艰辛活着。欧洲、日本搞了多年，没搞出一个新的Intel。美国搞了多年，没搞出一个新的ARM。（最近RISC-V又在搞） 所有建议中国搞x86，与Intel竞争的，在行业内看来，都是忽悠国家/VC 钱的。 那么正确的道路是什么呢？弯道超车，大家一起竞争造新路。 路是无限的，而钱是有限的。如果我们把钱拿去重新造CPU，让美帝在新路上独家制造，收未来的过路费，我觉得这才是美帝最得意的阴谋了。（估计川普没这么聪明） 所以，我们不应该花大钱去造x86 CPU这样行为，不要去重新造一条同样的路。而是要往前一起造新路，因为这个时候你能拉到客户收过路费。 最近的新路有： 1、5G芯片。国家应该大力支持这方面的资金投入，特别是对企业的研究经费，如果能够对失败/成功项目的科研经费进行100%补贴。企业会大大增加新品研发的。 2、AI芯片。这个Google很奇特地没有加入战场，我们还有一定时间的余地。Google修了一条高速，开发了TPU，但是它只是自己用，不销售，也不收“过路费”。（其实这是AI公司头顶的一把剑，等到做出来了，谷歌可能又开源或者开卖芯片。） 3、数字货币。目前数字货币芯片已经占到台积电的10%，我预估未来还会上升。这是一个新品，而中国在此领先的。可惜去年9月的政策等在削弱这个领先。三星等在大幅度追赶。 4、低功耗GPU芯片。这个GPU不是为了显卡，而是为了类似VR/AR的新应用。 5、ARM服务器、RISC-V等，建议国家让企业多看着先预研，如果起来了，中国就自然地用新品替换了x86服务器等了。 数字货币最好的办法是监管和准入证，监管类似期货，普通投资者自然排除在外。目前这种扑灭的模式，如果遇到数字货币类似PC/通讯/手机这样大产业，我们会又一次上演拱手让人的悲剧。（我们数字货币软件已经如此了，数字货币金融创新基本全在美日了。就算矿机这个领域，三星也进入，三星有fab，极大优势。） 到底什么是新路，旧路还有多少油水，值不值得投入。这个每年看看fab的流片大致就知道了，其实并不是那么难理解的。 超越，说起来很简单，但是要考虑一个行业的特点，就不是那么容易了。很好的事是，集成电路是一个飞速发展的行业，旧路的大小基本定了，最发展的大多是新路。华为等在手机芯片上的切入，就是这种新路上的突破。比特大陆的崛起，也是因为它一直走的是条新路。趁着美日韩等还没注意时，就先修好了一条高速路。 中国在新路上多投入，别制造障碍，随着新路的繁荣，旧路过路费慢慢占比就少了。 那种别人有我一定要有的思维模式，会导致我们在旧路上投入过高，反而是歧路。 那些认为投入就能产出的，我建议先不计一切代价，先搞个国足世界杯冠军，因为显然这个要更容易些。 转载来源：专家：建议中国搞x86与Intel竞争的，都是在忽悠国家的钱]]></content>
  </entry>
  <entry>
    <title><![CDATA[巨头正在将互联网变成一个“伪市场”]]></title>
    <url>%2F2018%2F2f318e45%2F</url>
    <content type="text"><![CDATA[Fog Creek Software CEO Anil Dash提出，互联网用了一代的时间已经从免费开放的新市场变成了创建一系列利用社会的伪市场，而大多数媒体或政客甚至都没有注意到这一点。 编者按：互联网一开始是承载着我们开放自由的梦想而崛起的。但当巨头垄断了少数的平台时，他们慢慢开始作弊让天平向自己倾斜。Fog Creek Software CEO Anil Dash提出，互联网用了一代的时间已经从免费开放的新市场变成了创建一系列利用社会的伪市场，而大多数媒体或政客甚至都没有注意到这一点。我们作为消费者如何才能避免长期利益受损呢？答案是最简单也是最困难的。 1、开放的互联网市场 美国文化热衷用理想的竞争性自由市场作为包治百病的解决方案。尽管其自诩的自由市场对关心患癌症的婴儿并没有动机，一个完善的市场当然可以是看看哪一家提供商提供了一卷手纸或者一斤苹果最便宜的价格的很好手段。 鉴于这种文化嗜好，在web早期建立新市场是大家一开始比较喜欢做的事情之一。也许eBay就是典型例子；任何人（好吧，几乎任何人）都可以把自己的陶瓷雕像放到eBay上面去卖并且参与到一个相对公平的市场里面。在市场的一头，一群雕像的狂热粉丝正在踊跃地寻找最好的交易，在另一头，一群雕像供应商则要在价格、质量和服务上展开竞争。在中间，一个中立的市场通过即时更新的信息帮助将买家和卖家连接起来。每个人都很满意！ 后来，卖家可以为自己的产品购买在eBay搜索结果上的首选广告位置，而一些产品目录开始被批发供应商统治，但这仍然是一个相对开放的系统。每个人基本上都是满意的！ 在eBay推出后不久，Google也作为一种内容市场的形式面世了，其PageRank显然决定了哪些页面会出现在我们的搜索结果里面，其依据是导入链接的数量。一头是读者，另一头是出版商，中间是Google利用神秘但在一定程度上仍然可以理解的算法来建立一个几乎每个人都觉得自己能参与进来的市场。 可是不久之前，那些排名机制开始被spammer污染，因为在搜索结果中排名更高突然有了货币化价值，而制作垃圾链接的费用要比支付给Google的广告产品便宜。这时候开放市场应该怎么做呢？ 2、作弊市场的崛起 早期开放数字化市场不可避免的自动化对赌无意间催生了下一个时代：作弊市场。Google对恶意的搜索引擎优化技巧感到担忧，总是不断调整自己的算法，意味着只有那些能够不断调整自身技术跟上这场新的军备竞赛的web出版商才能发展下去。仅仅几年之后，这变成了一种富者恒富的经济，刺激了每一家较小规模的出版商采用少数标准化的出版工具来跟上Google的要求。只有最大的内容提供商才能付得起开发自己的工具同时还能遵循Google永远在变的算法要求。 问题不可避免变成了在最有价值市场成为最显著的那个。最终，在类似旅游这样有利可图的垂直市场，Google开始优先展示自己的订票工具而不是第三方订票网站的结果，其想法是他们的体验要好于第三方令人困惑且不一致的结果。没错，但对于Google来说赚钱也太方便了，现在他们已经开始从那些链接上赚到更多的钱了。 这就是web上一个微妙但极其重要的模式的开端：用户体验的短期改进帮助一家统治性的技术公司在远期占领一个传统的市场。 Amazon经历了类似的过程，他们后来开始试图影响结果，比如在产品搜索中优先展示自己的产品，哪怕他们的东西并不是最便宜的。我们目睹了一种迅速转变，那些经营着之前还是开放的市场的公司开始赋予自身不公平的优势，而市场的其他卖家根本没法抵消这种优势。 动图由Rob Weychert/ProPublica绘制 https&#58;//www.propublica.org/article/amazon-says-it-puts-customers-first-but-its-pricing-algorithm-doesnt 那些经营着之前还是开放的市场的公司开始赋予自身不公平的优势，而市场的其他卖家根本没法抵消这种优势。 这种像作弊市场的转变在应用商店中又得到了更淋漓尽致的体现，像苹果和Google这样的主流玩家可以选择那些app成为精选或者予以推销，同时防止任何会取代或威胁其市场统治力的app的建立。即便一个app取得了成功，应用商店也会推销广告支持的模式，让app创建者依赖于该公司的平台进行分发，而不是让app直接从用户获得收入。 但即便是在今天的作弊市场新玩家仍然有一些竞争的手段。你可以帆布一款新的照片共享app，并且理论上可以跟Instagram或者Snapchat在苹果的应用商店上同台竞技。一位普通的买家可以在Amazon的网站上面搜索“床单”，然后预期得到一系列可以购买的床单列表，其中既有来自独立制造商的，也有来自Amazon自己的Pinzon品牌。即便这些市场是扭曲的，它们仍然还是市场，是市场就会有机会。 当然这不是说这些系统就是公平的：大公司可以选择哪些玩家进入市场参与竞争，而网络不平等的问题意味着有足够特权成为早期采用者的人或者公司会获得不公平优势。但即便存在这些不公平待遇，我们仍然可以应付过去，新产品或者竞争对手有时候仍然能崭露头角。 这就是过去10年大部分时间的现状。但下一波技术创新者的崛起将令“市场”的定义甚至更加扭曲，扭曲到其实已经不算市场的程度。 3、现在：伪市场 Uber的承诺很简单：你用他们的app打车，独立司机池里面的一位司机同意载你，然后每个人都很满意。在他们的设想中，自己是一个中立的市场，把客户和服务提供商连接到一起——有点像eBay！ 不过跟eBay上的竞争性卖家不一样的是，Uber司机没法自己定价。实际上，Uber可以单方面（而且经常）改变价格。而在挑选司机这件事情上乘客无法做出知情选择：匹配乘客与司机的算法是不透明的——无论是对乘客还是对司机来说都是如此。实际上，正如Data &amp; Society的研究所表明那样，Uber有时候会在自己的app里面故意显示“幽灵”车给用户看，有意制造一个虚假的市场。 这个“市场”似乎有一些十分恶心和怪异的特质。 消费者无法信任被提供的信息来做出购买决定。1. 单个不透明的算法定义了哪一位买家与哪一位卖家匹配。1. 卖家对自己身的定价或者利润空间没有控制权。1. 监管者看到了真正的短期消费者利益，但并没有意识到会带来的长期伤害。单个不透明的算法定义了哪一位买家与哪一位卖家匹配。 监管者看到了真正的短期消费者利益，但并没有意识到会带来的长期伤害。 按照任何合理的定义来看，这些根本就不是市场。也许有人会把Uber称为是“伪市场”。尽管如此，通过很有心机地把系统内的司机称为是“创业者”并且采用真正市场的说法，Uber已经受到了社区和政策制定者的欢迎，就好像他们建立了一个新市场一样。这对于政策、监管甚至人权都具有重大影响。比方说，我们可以由衷地赞美Uber让非洲裔美国乘客更可靠更容易地打到车，但如果其对司机冥顽不化的偏见模式在Uber时代再度抬头的话，监管这些滥用行为就会变得更加困难，因为Uber通常并不遵循与监管有拍照的司机相同的政策。 这些伪市场模式还掩盖了补贴的模式，比如Uber目前的运营其实是投资者提供了补贴，每年高达20亿美元。这种成本很快就会转嫁到消费者头上，只要Uber成功取代了传统的士的话。 《金融时报》非常明确地指出了这种经济布局的潜在意图： 所有这一切都等同于一种从劳动阶级向都市精英的经济转移，受益的只有一家特定企业而不是别人。这实在是太疯狂了。 这些新的伪市场只有在对监管者和媒体使用障眼法的时候才会看起来像是真正的市场，因为后者对高科技解决方案的热枕是没有边际的，而他们对互联网上的市场的理解仍然停留在20年前的早期eBay时代。 伪市场不仅产生在传统产品和服务上——也来自于内容和出版的世界。出版商日益被激励去使用像Facebook的Instant Articles这样的平台以及Google的AMP这样的格式。就像Uber临时补贴更便宜的价格以及对打车服务更广泛的访问一样，这些新的出版格式也的确为消费者提供了一些短期的好处，其形式是更快的加载时间以及更干净的阅读体验。 但Facebook和Google提供更快速阅读体验的技术机制正好顺带取代了大多数的第三方广告平台——那些不是由Facebook和Google本身提供的平台。使用这些新的分发渠道的Facebook出版商被激励去使用Facebook的广告平台，其支付率和利润空间最终将随时可变。就像Uber在取代受监管的士期间补贴费用一样，Facebook也在他们取代第三方广告网络期间补贴出版商广告费。 除了让出版商在收入上对这两家技术巨头更加依赖以外，还有用于发现内容的算法问题。几乎使用Facebook的每个人都已经意识到其用于展示内容的算法是不透明的，无论是对出版商还是读者来说都是如此。因此，出版商可用来确保读者看到自己内容的可理解的技巧越来越少——而用Instant Articles格式发布是少数已知有效的办法之一。这正好又要求出版商把稀缺资源投入到支持Facebook格式上面，其结果是该出版商变得愈发依赖于Facebook进行分发。 那么：也就是说读者和出版商都不知道为什么Facebook会把一篇特别的故事展示到新闻流里面。而媒体监管者和政策制定者有没有办法对加载更快的故事的短期好处。 内容的伪市场看起来是这样的： 读者无法信任被提供的信息来做出决定。 单个的不透明的算法定义了哪一位读者跟哪一家出版商匹配。 出版商对自己的广告费或者利润空间没有控制权。 监管者看到的是对读者真正的短期利益，但并未意识到这会带来的长期伤害。 4、市场之后：自驱动新闻 不过请等一下，情况会变得更加糟糕。接下来我们会取代市场上的卖家。 现在共享乘车或者内容出版的局面是朝着一个由一或两家私有企业玩家控制的锁定系统快速迈进。但即便在这些伪市场里面，目前也还有多家提供商在生态体系内提供自己的服务。这些提供商是那些Uber司机或者Facebook出版商，这些提供商是值得赞美的，正是这些独立的创业者令平台欣欣向荣。 但Uber已经明确宣布了自己的路线图：自动驾驶汽车。备受称颂的独立司机创业者将会被全自动服务提供商尽快取代，而且那些新的自动驾驶汽车不仅没有要付费的司机，而且它们还是Uber所有的。当这一转变在未来10年变成现实时，整个独立承包商的市场将会被取代，这正好是社会保障体系被拆解的时点。与此同时，不同的政客一直都在把这些“零工经济”说成是未来的工作形态。 不过无人车是很难做成的。制造一个可以在城市里穿梭将乘客安全可靠送达目的地的机器人是一个极其困难的问题，需要很长时间才能做好。 相比之下，自驱动新闻的障碍又是什么呢？我们已经看到很多新闻消费者对安全可靠地将精确新闻送到自己手上并不感兴趣。这种情况下成功会容易得多：机器人出版商只需要提供情感上足够吸引人的内容来赢得读者的阅读即可。如果内容出版商或者分发商不关心故事正确与否的话这件事甚至还要容易。 还有要记住的是，Facebook往往会对那些利用自身新平台功能的出版商，但一旦那些出版商对他们形成依赖之后补贴就停止了。出版商已经在努力挣扎于媒体业总体的经济状况；Facebook的出价他们感觉是无法拒绝的。 那么我们该怎么办？ 在这些公司开发这些功能的大多数人目的并不是要破坏市场。在Uber和Facebook这样的公司的编码者和设计师意图通常都是好的，是真心为用户着想的。从目前看来，他们甚至都没有错；能够轻易打到车或者迅速读到文章是真正有好处的。但大多数技术员工，包括最大型技术公司里面的那些技术员工，他们对自己公司所有者和投资者激进的政治和社会议程都一无所知。 更糟的是，我们已经丧失了辨别能力，看不到给某些用户带来短期好处的补贴背后是难以维系投资模式，会给社会带来恐怖的长期后果。我们已经被风投注入到市场的资本所带来的暂时激励给迷住了，尽管我们知道这样的市场将会被技术变革和自动化所重塑。唯一能指望或者防止这些颠覆的社会力量是政策制订者，但是这帮人往往对高科技的工作机制又不甚了了，同时又极力想要自己身上蒙上一股“高科技”的光环，因为后者就是美国的世俗宗教。 我们加大对这些问题的发声力度是必不可少的，也许最有效的行动就是教育当选官员正在发生的改变。这个东西很复杂，而教育所有的议员为什么这些新的高科技app带来的改变从长期来看未必就是对我们的社区最好的是需要时间的。 但我们仍有时间让事情重回正轨。我们不可避免要被迫将我们开放的市场交给新的由1或2个技术巨头公司统治的伪市场。也许我们能够做的唯一一件最大的事情既是最难又是最容易的一件：我们可以改变自己的行为。马上看看你手机上的app吧。当每个人的手机上跑的都是跟你一样的app时，你确定会对即将发生的事情感到舒服吗？ 原文链接：https&#58;//medium.com/humane-tech/tech-and-the-fake-market-tactic-8bd386e3d382 编译组出品。编辑：郝鹏程。 转载来源：巨头正在将互联网变成一个“伪市场”]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>Google</tag>
        <tag>苹果公司</tag>
        <tag>亚马逊公司</tag>
        <tag>eBay</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[碎片信息太多怎么办？这几款收集神器来帮你]]></title>
    <url>%2F2018%2F6c693166%2F</url>
    <content type="text"><![CDATA[而在手机端上就是各种复制，「方片收集」中的“历史剪切板”上就会出现复制过的信息，只需把有用的信息左滑即可，超简单的。 碎片化的信息的充斥，当遇到一些好的文章、有价值的网页、优美的句子，总会把它收藏起来。其他还好，但是收藏零散的句子却挺麻烦的，一般先复制下来，打开便签，将复制的句子粘贴到便签上。这么多步，就算是有耐心的人都很烦这种操作。而且每次的不经意收藏，日后总会面对各种凌乱，那怎么办呢？ 方片收集：不一样的摘抄方式，方方片片都收集「方片收集」是一款碎片化信息的收集与内容整理神器，简单并没有繁多的步骤。 在电脑端加入了「方片收集」的插件后，将需要的资料（图片/文字/网址/视频）向左拖拽就可以了，它还会帮你表明来源呢。 而在手机端上就是各种复制，「方片收集」中的“历史剪切板”上就会出现复制过的信息，只需把有用的信息左滑即可，超简单的。不过，收集前记得把软件打开。 除了各种碎片化信息的收藏、摘抄，方片收集还有个“便签”功能，供用户自己进行输入，输入时不仅可以文输入字，还可以插入图片，超链接，视频等。 而且它还击中了一个痛点：可以实时保存。再也不怕手机突然发生故障，好不容易写的信息因没有保存而丧失。在「方片收集」中，每当输入一个字，就会自动保存一次，再也不会发生信息丧失了。想让你的生活更加简约流畅但又高信息化，那就试试这款软件吧。 收趣：收藏有趣的内容，你也会变得有趣 「收趣」一款偏向于稍后阅读的软件，收藏各种信息后会以卡片的形式呈现出来，而且用户可以自由整理标签，排序、搜索，超级方便阅读。在阅读的过程还可以对收藏信息进行修改、记笔记等。 除了自己收藏的内容外，「收趣」的“发现”还藏有不少好的文章供阅读。 当不想看的时候，可以“听”。收趣支持原文朗读，在文章中有个耳机的图标，点一下就可以让眼睛休息一下了，提前用WiFi下载好语音包，就不用担心流量了。零碎时间读读文章、做做笔记或者“听”一篇好文，不觉得挺好的吗？ 有道云笔记：这款笔记的收集功能，也是挺不错的 对于网址或链接，复制后打开「有道云笔记」，就可以收集所复制网址信息。而对于互联网的一些 APP 则有其特有的收藏方式，如打开微博，在下方评论&#64;有道云笔记就可以，挺新颖的。 生活中，很多时候在看到报纸、报刊、各种读物时，有一些比较好的文章想记下来，一般都是用手机一个字一个字的打，或者是用手抄，而「有道云笔记」可以帮助用户将想要的部分拍下来，通过图片识别文字功能来识别文字。 而且语音记录功能，也特别不错，如：开会时开启该功能，做会议记录的时候就不怕遗漏了。 「有道云笔记」在登录后会免费送 3G 的云空间，可以储存很多文章文档。而且，只要每天签到都能得到一定的云空间，只要每天签到，云空间就越来越庞大。 幕布：整理信息也许需要一款思维导图 很多时候，一味的收集各种信息，到头来会发现：凌乱。这时可以试试用「幕布」来做收集工具，它具有很强的整理能力。 收集起来的内容，可以根据各种需求进行编辑，简单的操作就能让凌乱的内容更具条理性、清晰了然。而且如果不想面对索然无味的文字，还可以转化为有趣的思维导图。 会整理信息也是一种技能，学会使用之几款神器，就相当于学会了一种新的技能。面对这些具有简约设计界面、粗暴强大功能的应用，相信很多朋友已经按捺不住了，那就一起去发掘它们吧！ 转载来源：碎片信息太多怎么办？这几款收集神器来帮你]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>网易有道</tag>
        <tag>有道云笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【深度】微视重启与腾讯错失的一年]]></title>
    <url>%2F2018%2Fce3f8661%2F</url>
    <content type="text"><![CDATA[”对方听到也有些无奈，她告诉严然：“你目前看到的所谓微视补贴都不是微视给的钱。全是那些经纪公司和工会打着官方的幌子在外面招人，我们的补贴3月才会出来，他们现在只是为了抢占市场”。 今年二月份春节期间，看着朋友圈转发着各式各样的微视补贴政策，严然忍不住问了微视对接人一个问题，“官方补贴到底什么时候开始？为什么现在会流出这么多版本？” 对方听到也有些无奈，她告诉严然：“你目前看到的所谓微视补贴都不是微视给的钱，全是那些经纪公司和工会打着官方的幌子在外面招人，我们的补贴3月才会出来，他们现在只是为了抢占市场。” 情况和严然想象的差不多。但得到了对方会在三月开始发力的消息，她还是有些紧张，毕竟，按这个时间来算，她只剩下不到一个月的时间做准备。 作为一名资深达人经纪，严然手底下运营着几百号网红，做到这个阶段，她在意的已经不是补贴，而是腾讯到底有没有把短视频放在一个很重要的位置。“如果答案是肯定的，那微视至少会迎来几个月的红利期。而这样的平台和机会，对新人来说绝对是可遇不可求的。” 三月，官方补贴如期而至。令所有人意外的是，这一次，微视竟然给出了高达30亿的巨额补贴。不仅如此，4月10日下午，腾讯内容开放平台也发布回应称，未来将持续为微视提供优质的原创短视频内容。 一位接近腾讯的人士告诉界面新闻记者，微视拿出的这30亿其实正来源于企鹅号2018年的补贴计划。在去年底的腾讯全球合作伙伴大会上，腾讯集团首席运营官任宇昕曾介绍，腾讯将打造全新的企鹅号，计划2018年投入100亿元人民币，服务图文资讯和短视频的创作者，而微视就是这计划中的一环。 事实上，作为中国最早开发短视频产品的企业之一，腾讯的短视频之路一直充满坎坷。早在2013年，腾讯就已经以“微视”这一品牌推出了一款短视频产品，然而，到了2015年，这款产品就被腾讯战略边缘化，直至2017年4月10日被正式关闭。 某种意义上说，现在重新回归公众视野的微视已经是一款全新的产品，不仅账号数据未和老微视打通，产品设计也和以前大不相同。 回溯过去的几年，短视频似乎是一直是腾讯想做却做不好的内容，为什么会出现这种情况？如果说新微视的目标是追击抖音，那钱烧完了之后呢？当战争真正发展到产品和运营之争的时候，新微视又有几分胜算？ 为了解答这些问题，界面新闻记者采访到几位2013年就加入微视的老员工，包括部分接近微视的网红和代理商，试图还原一个真实的腾讯短视频发展史。 高光时刻事实上，腾讯内部最早提出要做一款短视频产品的是现任小米生态链副总裁、腾讯微博早期负责人高自光。然而，在更多人的认知里，与微视紧密相连的却是另一个名字——邢宏宇。 这位腾讯OMG的高管曾历任搜索产品部副总经理、网络媒体产品技术部总经理、微博事业部总经理等职务，直至2013年接手微视。 按微视早期员工Amy的话说，邢宏宇接手微视纯属临危受命。“Grandy（高自光）提出这个项目不久就去小米了，hy（邢宏宇）只能硬着头皮接。” 在Amy看来，微视就是一个烫手山芋，原因在于产品从立项就没有一个清晰的定位，”Grandy在内部总说我们要再造一个Vine，但当你问他更具体的思路时，他的回答就变成了，国外有，我们也必须有。” 换句话说，微视是高自光提出的项目，但高并没有想清楚这款产品的定位，直到后面邢宏宇接手，这个问题也依旧存在。而且，从后面的产品设计来看，刑对于这种针对年轻人的短视频社交产品也并不擅长。 据一位腾讯微博的老员工回忆，邢宏宇会接手微视纯粹是因为当时已经没有更好的选择。 2013下半年，由邢主导的腾讯微博已经开始疲软。微信出现以后，腾讯微博作为防御性产品的战略重要性下降，到了后期，核心成员更是大量流失。“对hy来说，接手微视也算是最后一搏。他甚至和Pony承诺，这次如果还做不好就立马走人。” 另一方面，短视频在当时确实是一个热门的创业方向。2013下半年，4G网络正在逐步推行，很多大公司都认可短视频是一个值得布局的新赛道。在阿里投资了趣拍，新浪微博投资了秒拍的情况下，无论是基于提前布局或是战略防御的考虑，腾讯都需要有自己的短视频产品，而微视就是在这样的背景下诞生。 2013年09月28日，微视上线App Store，主打8秒短视频，用户可以通过微信、QQ和QQ邮箱账号登陆，同时支持分享短视频到微信对话、微信朋友圈以及腾讯微博。 据Amy回忆，一开始，腾讯还是非常重视微视的，从邢宏宇往下，产品和运营的总监都可以和马化腾在一个群里直接汇报。“为了推广微视，Pony（马化腾）还在平台开了号，传了4条短视频。” 2014年春节，腾讯大手笔的邀请了李敏镐和范冰冰等明星为微视拍了一则电视广告，据当时的宣传通稿显示，春节期间，微视的日活跃用户一度高达4500万人，除夕至初一共有数百万人通过微视发布、观看拜年短视频，总播放量达上亿次。 在Amy心中，那几乎就是微视这四年来唯一的高光时刻。 问题爆发如果以现在的眼光审视上线之初的微视，你一定可以挑出一大堆毛病，例如页面不好看，画面不清晰，没有办法把女孩子拍美等等。 对于这些毛病即使是微视的前员工们也都是认可的。一位微视早期的运营人员林冉告诉界面记者，一开始，微视甚至都没有滤镜功能。“是黄一琳（昕薇模特，微视早期达人）提了很多次需求我们才上的。” 林冉把这种迟钝归结于团队的审美老旧，“我们团队大多数人都在70-80之间，要做一款90后甚至00后爱用的产品理解起来太难了。” Amy则有另一种看法，在她看来，很多问题其实会上都讨论过，但最后就是无法推进，归根结底还是体制问题。“腾讯太大了，很多需求就算提出来了落实到产品和技术上也会变得无比冗长。”而这种拖延对于团队的士气又是一种很大的消耗。 但无论如何，微视在那时还是少有对手，平台一开始采取的明星策略也吸引了一大批用户紧随而来，巅峰时期，范冰冰在微视的粉丝甚至多达600多万。但换一个角度来看，中心化太过严重也会导致普通人很难在这里找到存在感。 林冉彼时运营着一个上百人的微视达人群，通过她的观察，能进到这个群的，几乎都是本身就有硬实力和专业背景的人。“微视的门槛其实很高，它并不能把女孩子拍美，一条时长又只有8秒，要想在这么短的时间展示自己，需要非常强的硬实力。” 2014年4月，林冉明显感觉到，经历了春节的爆发增长，红人们已经开始有些疲惫。此时无论是上传视频还是用户活跃都呈现了下降趋势。 为了挽回颓势，在接下来的一段时间，微视一直在不停地调整运营策略，但在林冉看来，部分调整反倒是导致平台走错方向的导火索。“我承认运营方面责任很大，我们太主观了，对于想要一个什么样的社区没有明确的认知，导致很多真心创作的人得不到推荐，反而那些低俗的熊孩子系列，或者是那些所谓高逼格的国外系列得到了推荐，到后来平台上就充斥着诸如此类的样板内容，用户看着不舒服，我们也难受。” 更重要的是，在微视进入瓶颈期的同时，美拍上线了。虽然效果同样不够清晰，但美拍提供的滤镜和MV工具，很快就让其和同类产品拉开了距离。 Amy用了“噩梦”这样的词汇去形容美拍对微视的影响。“美拍上线之后我们才意识到，做一款年轻人的产品，把用户拍美真的是刚需。” 虽然微视后来也仿效美拍上线了小mv功能，但最后的呈现效果还是与美拍相差甚远。这件事儿对林冉打击很大，“抄美拍我觉得都没什么，但问题是最后出来的效果特别土，我就想不通，腾讯不应该比美拍技术更强吗?” 这之后不久，林冉就离开了微视，Amy虽然还在，但7月发生的一系列事情，开始让她对微视的发展前景产生怀疑。 2014年7月，微博事业部降级被整合到了腾讯新闻，在外界眼里，这几乎就是被腾讯战略放弃的意思。此前，微视一直都是挂靠在腾讯微博下运营，微博并入新闻后，微视也进行了组织架构调整，不仅成立了单独的产品部，还组建了版权合作、平台运营、产品技术以及客厅业务等四个部门。 在外界看来，这都是腾讯重视微视的表现，但在Amy看来，微博被放弃以后，微视就失去了赖以传播的土壤。再加上，微信当时也在筹备小视频功能，7月以后，微视在组织内的位置就变得非常尴尬。 “当时能明显感觉到腾讯内部对我们都是不看好的。从5月开始，团队里核心成员就在逐步流失，好像又重走了一回微博的老路。”在Amy的记忆里，2014年下半年对整个团队来说异常难熬。美拍和秒拍都在急速成长，腾讯又取消了微信对微视的资源支持，尽管后来微视将拍摄时间从8秒延长至5分钟，但体现在数据上还是没有任何火花。 “在腾讯这种赛马机制下，如果给过你资源效果还是不明显，最终就是产品线被裁撤的命。”9月，Amy也离开了微视。 邢宏宇在腾讯的最后一搏失败了，2015年3月，微视产品部被降级并入腾讯视频，随后邢宏宇离职加入58同城，微视的运营总监何钐则转岗加入腾讯内部一个新产品团队。 至此，微视基本已经被战略边缘化，腾讯的第一次短视频尝试也以失败告终。 微视复活此后长达两年，微视都只有几个技术在做简单的维护，体现在大众眼里，这款软件相当于就是消失了。 真正的死亡宣告书是在2017年3月下达的。彼时，腾讯发表声明，称将在4月10日正式关闭微视。不久，腾讯投资快手的消息传来。 罗休休是微视平台上发布视频最多的达人，即使在后来腾讯放弃运营微视，她也依然有坚持在微视上同步视频。听到微视即将下线的消息，罗休休把自己关在房里大哭了一场。 和其他人略微不同的是，罗休休就像是一个被微视一手带大的网红，大一的时候，她曾在腾讯微博实习2个月，后来，微视内测，运营人员一下子就想到她，而她也成为了微视最早的一批用户。 对罗休休这样在微视上上传过几十甚至上百条视频的达人来说，下线App，几乎就等同于抹掉了他们最珍贵的回忆。但腾讯已经做出决定。 然而，就在大家都觉得微视已经退出历史舞台之后，2017年5月，App Store里又出现了一个全新版本的微视。助理告诉罗休休，这个版本的微视和抖音很像，主打的是音乐短视频与对口型录制。 与其说这是老微视复活之后的产物，不如说，它已经是一款全新的产品。 据一位腾讯内部人士介绍，一开始，腾讯也没有想明白要怎么重新杀入短视频，直到2017年抖音的异军突起，才让腾讯内部真正的感到紧张，随后，微视便被复盘到了深圳SNG事业群去做，由QQ空间团队正式负责，此后，微视的迭代速度就明显加快。 2018年，微视相继推出了高能舞室、视频跟拍、歌词字幕、AI美颜美型滤镜等四个功能，并打通了QQ音乐的千万曲库。不仅如此，腾讯还宣布，不止音乐，腾讯生态里的所有游戏、动漫、影视、综艺将为微视提供内容支持。 在目前的环境下，短视频在腾讯内部的战略重要性无疑将再次提升，但单靠输血能不能达到很好的效果却仍需打一个问号。 界面新闻记者于近期采访了多位接近微视的网红经纪和工会组织，听到最多的一句话就是“微视现在太乱了”。 这种“乱”主要是因为微视选择了和供应商合作去招揽红人，但供应商群体庞大，包括工会、经纪公司、代理公司、MCN等等。这本身就是个鱼龙混杂的圈子，选择了走这条捷径，也就要承担“乱”的后果。 据界面新闻了解，现在和微视合作的代理公司至少也有100余家，每一家的抽佣标准都不同，这样就导致外部流传的微视补贴政策五花八门，甚至有人给出了上万的金额。严然说，这种看起来很高的补贴大多都是假的，“他们的目的就是招人，招到了以后给不给结算就不一定了。” 除此以外，也有一些实力较大的组织选择了暂时观望。越度传媒就是其中之一，该公司的网红中心总监杨涛告诉界面新闻，像他们这样规模比较大的网红公司，目前很难花费太多的精力去运营微视，“你只能说是以布局的心态去做，因为新平台前期基本是赚不到钱的，我们现在手头抖音的单子又多，很可能在微视辛苦拍一月视频赚的补贴在抖音一个单子就赚回来了。” 根据杨涛的介绍，目前抖音达人接一单活的市场均价大概是三万，而微视最高的S级补贴是一条1500元，换句话说，一个各方面素质不错的达人，在最勤奋的情况下，一个月也只能拿到2-3万的补贴。而微视对内容又有独家的要求，也就是说，如果选择拿微视的补贴，那基本就需要放弃全平台运营，这里面的机会成本，对于已经在其他平台成为头部的玩家来说几乎不可承受。 但无论如何，对那些在抖音和美拍暂时拿不到广告资源的中腰部网红来说，微视的补贴力度对他们来说还是有一定吸引力。 但就算能用钱买到内容，在抖音快手已经占据了大部分目标用户心智后，微视又能拿什么来抢夺这些用户的消费时间呢？ 一位曾和微视市场负责人沟通过的代理商表示，目前微视官方对于操盘方向也是一头雾水。“聊下来的感觉就是，他们真的很焦虑。毕竟，短视频创业也是有时间窗口的，时间窗口过了，不是有钱就能弥补。” 下图是微视官方给各大代理商提供的内容范畴，可以看到，目前微视还是较为侧重生活和搞笑类的内容，而这也是抖音现在的运营重点。 换句话说，现在微视初期的打法基本就是以抖音为对标。但问题在于，腾讯微博的例子已经能够证明，尽管腾讯可以为微视输送流量，提供资源，但是，本质上如果还是在用竞争对手的那一套逻辑去做产品，最后大概率也就是拖一拖对方后腿，一款防御型的产品不可能做到对竞品取而代之。 拼多多敢于正面对抗淘宝京东，本质在于他抓住了二者此前忽视的下沉群体，QQ有7.83亿用户，微信则有9.88亿，就算略过抖音快手现在2亿左右的重度用户不看，腾讯也还有很大的空间去寻找新的增量，没必要抓着竞品不放。 此外，现在对于微视来说其实是一个发展的黄金时期。毕竟，目前针对短视频应用的监管力度正在不断加大，抖音和快手都相对进入了增速放缓阶段，在这个时刻花钱买时间无可厚非，但钱烧光了之后呢？市场不需要更多的同类型产品，微视必须尽快想明白这一点。 （应采访者要求，Amy、林冉为化名） 转载来源：【深度】微视重启与腾讯错失的一年]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>移动互联网</tag>
        <tag>微视</tag>
        <tag>马化腾</tag>
        <tag>Vine</tag>
        <tag>任宇昕</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结合产品从0到1，阐述各阶段的产品方法论]]></title>
    <url>%2F2018%2F5f9dc947%2F</url>
    <content type="text"><![CDATA[文章围绕产品从0-1的每个阶段，并结合作者自身实践总结了其中的方法论，希望能够给大家带来一些帮助。下文将围绕产品从0-1的每个阶段列举阐述其方法论，并加以具体的栗子说明，算是自己一年多的产品学习及实践总结，不足之处还望各位大佬们指正。 文章围绕产品从0-1的每个阶段，并结合作者自身实践总结了其中的方法论，希望能够给大家带来一些帮助。 产品分析的“五要素法”是什么？需求采集的“Z字采集法”又是什么？如何用“KANO模型”对需求进行分类及优先排序？如何确定MVP？“Hooked模型”是如何让用户对产品上瘾的？ 如果你有上述一个或多个疑问，我猜你产品经验不足2年或者没有系统的提炼产品体系，那么请继续阅读下去，下文将围绕产品从0-1的每个阶段列举阐述其方法论，并加以具体的栗子说明，算是自己一年多的产品学习及实践总结，不足之处还望各位大佬们指正。 产品从0到1的阶段一个产品从无到有再到用户手上基本都可分为3个大阶段。 第一阶段：一定要想清楚产品做什么。给B端用户还是C端用户，做工具型的还是内容型的，做交易还是做平台。主要用户是谁，要解决Ta们什么痛点，这些痛点又是在什么样的场景下产生，用什么样的解决方案可行，跟现有的解决方案相比有何竞争力。 Eg：之前有过一个诗词项目，一款拍照配诗工具，主要用户为有诗词情怀的人，帮他们在一些特定的想要分享表达的场景中筛选出应景的诗词，制作出有意蕴的图片。比起图片社交的“黄油相机”，保留图片文字处理、元素添加等功能，提供更丰富的诗词数据内容，比起诗词收录“西窗烛”，我们提供更细化的标签维度与筛选机制，将诗词与图片完美结合。 第二阶段：用最高效的方法、最舒服的协作将产品做出来。这期间包括原型评审、立项启动、敏捷开发等，解决方案务必得到整个项目组的一致认可，小版本迭代更新，所谓“天下武功，唯快不破”。 第三阶段：将产品推出去。这个无用多说，产品做到一定程度后都是为了盈利，只有上线后才能获取流量，才有机会将流量转化成有价值的用户，才能从用户身上获取收入实现盈利。 下面是我近期一个社交游戏项目的文件，基本是按照规范流程执行的，仅做参考。当然并不是每个产品都必须经历每个阶段，不同的公司不同，不同的产品也不同，适合自己的才是最好的。 每个阶段及涉及的方法论1、概念提取与筛选产品的概念包括核心用户，刚性需求，典型场景及竞争优势。 产品概念来源：**1、自身或他人的需求随着越来越多的85后开始考虑小孩上幼儿园问题，如何筛选出最合适的学校。教育择校平台产品——有钱兔APP2、现有产品的启发**如现在的社交游戏应用。（以H5小游戏切入）同桌游戏、快手小游戏、开心斗 体验竞品及分析的方法即可用到“五要素法”和“5W1H法” 1.1 五要素法_竞品体验及分析 产品体验五要素包括：表现层、框架层、结构层、范围层、战略层，正向可用来分析产品，逆向则可以用来创造产品。 以“拼图酱”体验分析为例，拿到应用时，主色调以浅灰和橙、粉为主，给人一种活泼、浪漫、女性、健康的“氧气质感”，整体调性偏小清新文艺，当体验完它的页面操作时即可知它的主业务流程：选择模式→选择图片→根据选择的图片数量分别列出不同的版式→滤镜添加文字等图片编辑→保存，主要功能为多种布局选择、加多种滤镜多种外框等进行拼图，其它功能为拼接长图、海报模型、主题推荐。回头再理解这个产品时，她就是一款多张图片美化、设计、拼接、制作及分享的APP工具，帮助那些热爱生活喜欢分享的年轻人文艺的记录那段回忆。 1.2 5W1H分析法_竞品体验及分析 以“网易严选为例” - what_零售行业的电商产品，ODM模式（原始设计制造商）包含供应链。- why_通过ODM模式与大牌制造商直连，剔除品牌溢价和中间环节，提升性价比。- who_注重品质、看重性价比、了解ODM模式的用户。- where_看中品牌但又不能接收品牌货价格的时候。- when_注重商品性价比，多方比较包括产品的品质/颜值/描述/价格等再做出购买决策。- how_线上性价比高版的“无印良品”，从信任我的“甄选”，到信任我的“品牌”。 当有一定的产品概念时，就需要结合内外实际情况对其进行筛选，看是否有价值做下去 1.3 产品概念筛选要素 如当时我们提出了一个做“幼儿园择校平台应用”的概念，可先满足家长对武汉市所有幼儿园信息的分类筛选与对比，但具体到幼儿园数据来源的时候，幼儿园简介、师生配套信息、费用、招生计划等信息需要幼儿园相关的很多人脉资源，最后这个概念也pass了。 外部筛选可考虑政策支持、市场空间等，用到PEST分析法、波特五力模型、SWOT分析法 1.4 PEST分析法_宏观环境分析 对于大环境要顺势而为，如蚂蚁森林就是逐步开放的“碳汇交易”的一个载体，而“河长制”也将为水利信息化带来更多的业务方向。 1.5 波特五力模型_行业环境分析 以“社交游戏”为例 - 同行业内现有竞争者的能力，即现有市场成熟度和竞争激烈程度——强。现有“同桌游戏”和“快手小游戏”等，均以H5小游戏切入陌生人社交，做国内的市场稍艰难，可考虑海外市场。- 潜在竞争者进入的能力——强。微信小游戏“跳一跳”一出就有现象级霸屏，故小游戏未来很有可能进一步优化其在对话列表的能力，即直接可以在对话界面玩互动游戏。- 替代品的替代能力——弱。增加更多玩法的视频社交暂时不会取代。- 供应商的议价能力——中等。上游游戏内容提供商不太集中，但也有可能跨界到社交应用领域。- 购买者的议价能力——弱。下游客户并非一个，暂不存在客大欺店问题。综上所述此款“社交游戏”国内市场竞争激烈，可考虑做海外市场，快速出版本验证迭代。 1.6 SWOT分析_了解竞品，制定产品策略 以“武汉吃虾地图”为例（一款专门提供吃虾信息服务的工具，利用抓虾互动游戏将线下活动和线上服务结合） - S：长江垄上作为湖北本土的服务“三农”媒体和产业集团，自身有着精细化的水产信息相关资源及运营基础，吃虾地图本身的数据易收集，上下游的配套服务也支持功能扩展，借助已有的新媒体资源易展开推广运营。- W：休闲互动小游戏玩法单一，用户留存堪忧。- O：虾作为美食届的网红，也是电商届的新宠，吃虾已经成为了越来越多人的一种生活选择方式，以精美的吃虾地图切入生活信息服务细分市场，与抓虾休闲互动小游戏结合，另有完善的上下游服务体系做支撑，定给产品带来无数的可能。- T：口碑网和美团已有稳定的用户群，在内容方面已部分涉及虾板块，如何深度挖掘存量市场是一大挑战。SO战略：收集丰富的数据，制作精美的吃虾地图是基础。ST战略：相较于品类服务丰富的口碑和美团，吃虾地图将虾这一细分市场做细做精，再将模式复制到蟹、水产乃至其它。WO战略：做好休闲互动小游戏的用户体验（包括操作简单流畅、视觉效果佳），更重要的是争取福利更多的赢券等运营活动，通过游戏引导用户参与。WT战略：挖掘更多美团和口碑忽略的内容，如上游供应商的来源等。 2、需求收集与分析转化当筛选完产品概念觉得它能产生用户价值和商业价值时，就该进一步收集更多的相关需求，收集的方法很多，包括产品规划前期确定产品方向是什么的“用户访谈”，项目早期产品功能优先级的“调查问卷”，项目实施过程中验证需求实现方案的“可用性测试”，以及产品上线后迭代优化依据的“数据分析”。此部分先说明用户访谈和调查问卷，可用性测试和数据分析后文再提及。 2.1 用户访谈 _需求采集 做任何一件事情都要清楚为什么要做这件事，如何做，做完之后能输出什么。故访谈前就要规划好访谈对象、访谈时间、访谈素材准备，若为产品规划阶段访谈对象可从周围朋友中选择“潜在用户”，若为了解某个现象背后的原因，可深度了解这些典型用户。条件允许可约几个或者十几个用户到公司聊一聊，一般持续几十分钟到几个小时，通过问答了解用户的目标和观点。 以我们诗词图片社交工具为例，当时第一个内部小版本出来后成片效果不够精美，基于我们的核心优势在于筛选出应景的诗词，所以主流图片应用的滤镜、元素自定义等多种功能我们没有做，这时就找了几个朋友（图片工具的一般/重度用户，也可定义为我们的“潜在用户”）了解下他们的观点。具体我是以下面几个问题切入的： - 平时拍照、有时加些有趣的贴纸文字等一般使用哪些APP比较多，有没有不好用的地方。——（了解竞品， 看到潜在竞争对手的不足，优化自己产品 ）- 用过黄油相机或者IN没，怎么知道它们的，感觉怎么样？（了解对标产品的吸引点）- 如果现在有一款拍照配诗的APP，它有哪些功能你才会去用它？（希望用户提些建设性意见）现在看看这个问题问的最傻，我们不能给用户提太难的问题，而应该引导他们去回忆、描述一些故事来发掘他们的需求，所以这个问题可以优化如下：用黄油相机是如何挑到自己喜欢的模板的？（了解他们的行为习惯，对标搜索、推荐功能）如果有主题查询功能，会偏向于哪种风格的主题？（了解内容偏好）做完访谈后就该对结果进行梳理分析，需求进入需求池。 2.2 调查问卷_需求采集 调查问卷可用于项目早期功能优先级的参考，也可用于项目过程中的验证，在不影响用户体验的情况下可在WEB端或APP端以弹窗或者小功能入口的形式存在，针对人群根据目的设计内容。若内容较多，则开篇要简单，需要思考敏感的问题放中间，跟被访者相关的个人信息放最后。 如天天P图的小调查 2.3 马斯洛需求原理_需求分析 此时我们应该收集了无数个需求，无论是是一手需求还是二手需求，除了一些表面需求（用户的观点和行为），我们还需要对需求深度分析，了解需求背后的目的以及反映的人性。马斯洛需求层次理论就是对人性需求最常见的解读； 以具体的用餐需求来说明这5个层次。首先食物本身满足消除饥饿的生理需求，其次相对健康的选材及独立隔音的小包间满足安全需求，用餐期间借酒助兴满足社交需求，用餐环境的优质与用餐服务的周到满足尊重需求，图片或视频分享来展示生活的仪式感和饮食文化满足自我需求。 2.4 七宗罪_人性解读 七宗罪揭露了人类原始本能欲望，在日常产品中都可找到印证。 2.5 需求转化及Y模型_需求转化 ① → ② → ③ 拿到用户需求时，首先要思考why，即需求背后的真实目标及动机，再思考how，即用什么方法什么功能来解决用户的问题，尝试进一步挖掘到需求的本质即④，列出所有的解决方案，最后再根据优先级和性价比来确定功能组合。需求转化的原则为“用心听，但别照着做”。 经典案例福特用户需求：“我需要一匹更快的马”真实目标：为了更快的到达某地最后转化的更靠谱的解决方案：汽车，而非研发新饲料或者改进训练方法让马跑得更快。 3、功能管理及MVP的确定3.1 KANO模型_功能分类 A、基础功能（不做很不满意，做了觉得理所应当）——必做- B、亮点功能（不做没感觉，做了赞不绝口） ——产品初创期实现个别低成本的- C、期望功能（也称线性需求，实现的越多用户越满意）——先做性价比高的- D、无差别功能（做不做用户对产品的感受无变化）——低成本验证后再做- E、反向功能（做的越多用户越讨厌，比如广告位）——需要权衡各方利益后再决定 探探作为社交产品的后来者，功能迭代并不多，但定位清晰、操作简单，适合简单的分析。若你作为探探的产品经理，如何将下列功能进行分类。 - 同城定位及推荐。用户信息卡片的展示，包括图像、年龄、距离、职业。- 筛选操作，右滑喜欢，左滑无感，相互喜欢即配对成功。- 聊天可发送文字、表情。- 聊天时的表情和文字全屏特效。- 滑动筛选时的反悔操作。- 用户最后活跃时间的显示。- 用户的个性签名、标签、兴趣爱好。- 匿名暗恋表白。- 筛选条件的设置。- 聊天时的辅助模块，真心话和私密话。- 超级喜欢功能。若对一个人操作了超级喜欢，则对方会收到此消息的推送。- 会员充值引导。- GIF表情斗图。- 朋友圈。- 被喜欢的总次数统计及炫耀分享。根据我个人理解：1、2、3、6、9为基础功能，这是探探最核心的功能“刷脸，相互喜欢才能聊天”，至于用户最后活跃时间我把它也列为基础功能，因为探探是同步聊天模式，粗暴的显示“刚刚活跃”或者“几分钟前活跃”可以让用户得知自己的“目标”是否在线，掌握对方信息，增强老用户粘性。4、11、15为亮点功能，这些功能都是为了提升用户体验，没有的话也不影响当前主操作。5、7、13、14为期望功能，可帮助用户多维度的了解与互动。 8、10为无差别功能，使用频次并不多，匿名暗恋表白主要是短信推广的一种方式，而真心话模块也是为了提升产品活跃所做的运营功能。12对于某些非RMB用户来说就是反向功能，而对于平台方来说则是盈利的关键。 对于一个功能需求如何判断属于哪种，则可利用KANO问卷，分别测量用户在面对存在或不存在某项功能时的反应。由正向和反向两个问题组成。数据统计完后占比最高的属性作为该功能的属性类别，参考分类对照表。例如“探探”的聊天系统是否增加“视频功能”。 3.2 波士顿矩阵_功能分类 若探探当前所面对的公司战略目标为“增加公司的盈利”。则“VIP功能”则为明星需求，既能赋予用户VIP特权提高用户体验，也与战略目标吻合。“启屏或其它广告”则为金牛需求，不利于用户体验但可盈利。“视频或互动小游戏”为问题需求，有助于加深用户聊天深度，但需要一定的开发成本。“拉黑或解除匹配”则某种程度上可理解为瘦狗需求，不利于用户体验也不能盈利。 3.3 MVP_功能优先级确定，版本规划 考虑探探核心流程的体验（个人资料设置→匹配→私信），MVP的功能可包含：登录、个人资料完善、用户信息卡片的展示、筛选匹配、基础聊天。从探探的版本记录可知，V1.X版本主要围绕匹配和私信功能展开（同城定位、匹配、个人信息展示、基础聊天系统）， V2.X版本围绕用户互动和联系，新增朋友圈、匿名暗恋表白、GIF表情斗图、VIP（超级喜欢、反悔操作、地理位置切换）等功能。 MVP确定后就是具体的敏捷开发及项目管理了，下篇将继续说明可用性/AB测试、smart原则、Hooked模型，以及数据分析的AARRR模型、二八定律。 本文由 &#64;放慢快乐64 原创发布于人人都是产品经理。未经许可，禁止转载。 题图来自PEXELS，基于CC0协议 转载来源：结合产品从0到1，阐述各阶段的产品方法论]]></content>
      <categories>
        <category>职场</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>社交网络游戏</tag>
        <tag>幼儿园</tag>
        <tag>小游戏</tag>
        <tag>摄影</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[继《魔戒》之后，托尔金又一力作即将出世：《郭冬临之陷落》！]]></title>
    <url>%2F2018%2F68b7830e%2F</url>
    <content type="text"><![CDATA[虽然《指环王》作者J.R.R.托尔金已经在1973年去世，但很快书迷们就能读到这位英国作家的新书了。 最近，“郭冬临之陷落”承包了不少网友的笑点。 ？？？ 小新你在说什么，都快到五一的节头了怎么把春晚名人儿搬出来啦？ 别急，起因是这样：据外媒报道，虽然《指环王》作者J.R.R.托尔金已经在1973年去世，但很快书迷们就能读到这位英国作家的新书了。 原来，HarperCollins将在今年8月出版托尔金的《贡多林的陨落(The Fall of Gondolin)》。 该书由托尔金的儿子克里斯托弗编辑，插画仍由英国艺术家艾伦·李负责，《指环王》的插画同样也是出自他手。 《贡多林的陨落》的故事将围绕贡多林的精灵城展开，它被认为是托尔金《失落的传说集(The Book of Lost Tales)》的组成部分。 本来这是一个令魔戒迷们振奋的好消息，微博博主&#64;和菜头就抑制不住内心的喜悦，为这本书取了一个粗暴且更接地气的译名：《郭冬临之陷落》…… 网友纷纷表示，这个翻译非常“信达雅”。 大家为这个译名笑得前仰后合，这本书也成功引起了郭老师的注意，他发微博皮了一下：“听说国外写我的新书要出版了！中文版啥时候出？” 网友们表示这本书能跟《精灵王冯巩之崛起》、《巨石郭达之稳》并列为“远古时期三大传奇”。 大家纷纷开动脑洞脑筋，深扒郭老师跟西方某种神秘魔幻力量的关系。 有网友惊呼，郭冬临还与另一部欧美史诗有着千丝万缕的联系，那就是《权力的游戏》！ 大热美剧《权力的游戏》的重要城池Winterfell，就正好和他的名字完美对应：郭(Castle，城郭)，冬（Winter），临（Fell）。 这一发现不得了，网上掀起了搜集各种脑洞翻译的大狂欢！ 网友率先捧出了一直统治脑洞翻译界的“山东天后”蕾哈娜。 蕾哈娜的好多歌名都能和山东的风土完美对接，比如： Where Have You Been，“威海油饼”。 We Found Love， “潍坊的爱”。 Fool In Love， “福临莱芜”。 Talk That Talk，“聊城”。 除了蕾哈娜的山东歌名，我们还有无数满分翻译： Wake Me Up When September Ends 《一觉睡到国庆节》 论翻译是怎么毁掉一首好歌的。 Lil Daggers 《刘大哥》 感觉刘大哥的亲切喊声已经穿脑而过。 Follow Your Heart 《怂》 We Are the Champions 《我们是昌平人》 继山东人热闹过后，是昌平人的狂欢。 Dimond Mine 《呆萌的我》 感觉不光呆萌，还比较蠢。。。 Somebody That I Used to Know 《有些人，用过了才知道》 这个歌名的翻译者可能有什么不得了的故事。。 The best of the Yardbirds 《绝味鸭脖》 绝味鸭脖真的绝了啊哈哈哈哈！ 还有什么能阻挡我天朝神翻译的！ Pearl Harbor珍珠港，我们叫：蚌埠！ New York纽约，我们叫：新乡！ Downton Abbey唐顿庄园，我们叫：唐家屯！ Red River Valley红河谷，我们叫：丹江口！ Greenland格陵兰，我们叫：青岛！ 全世界都是中国的，就问服！不！服！ 最后，再奉上小新心目中的今日最佳： An apple a day keeps the doctor away. 每天玩手机，让你博士毕不了业。 微笑。 本文来源：中国日报双语新闻 转载来源：继《魔戒》之后，托尔金又一力作即将出世：《郭冬临之陷落》！]]></content>
      <categories>
        <category>文化</category>
      </categories>
      <tags>
        <tag>郭冬临</tag>
        <tag>指环王</tag>
        <tag>美剧</tag>
        <tag>欧美电影</tag>
        <tag>权力的游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[平安好医生赴港IPO的背后，是互联网医疗的彷徨]]></title>
    <url>%2F2018%2F5ab965c9%2F</url>
    <content type="text"><![CDATA[对行业头部企业都相当关键《财经》记者张利/文王小/编辑4月22日，成立仅三年多的平安健康医疗科技有限公司对外公布香港首次公开募股计划。 流量带来的收益不能抵消成本，大多数互联网医疗企业未能盈利，投资者渐趋谨慎。2018年，能否上市筹资或获得融资，对行业头部企业都相当关键 （2017年4月29日，北京全球移动互联网大会上， 微医展台。图/视觉中国） 《财经》记者 张利/文 王小/编辑**** 4月22日，成立仅三年多的平安健康医疗科技有限公司（下称平安好医生）对外公布香港首次公开募股（IPO）计划，预计5月4日上午9时，正式在香港联合交易所有限公司挂牌上市。公司招股价范围每股50.8港元至54.8港元，拟募资规模超过80亿港元（超过65亿人民币）。 “此时再不上市，就要找下一轮接盘侠喽。”对于2018年互联网医疗公司的“上市潮”，北京深行投资管理有限公司投资总监赵传礼分析。 两年前，他投资了一家做预约挂号的互联网医疗公司，如今“发现挣不着钱，挺彷徨的”。 互联网医疗的融资热潮已三年。2015年，公开互联网医疗融资事件187起，投资总额超18亿美元，比2014年增长近30%。到2016年，平安好医生A轮融资就达到5亿美元。 “（现在）钱都花得差不多了。”春雨医生药企事业部一位前员工对《财经》记者说。对于普遍未能盈利的互联网医疗企业而言，2018年，“上市”成为一个具有操作性的选项。 尤其是，港交所在2月发布《新兴及创新产业公司上市制度咨询文件》，允许“未能通过财物资格测试的生物科技公司，包括未有收益或盈利记录的公司”在港上市。没有盈利的硬性要求，大陆的生物科技公司和互联网医疗平台跃跃欲试。 微医集团首席战略官陈弘哲对《财经》记者说，微医正在寻求上市前融资，微医四大业务平台之一 “微医疗”，预计今年下半年单独赴港上市。 丁香园CEO李天天告诉《财经》记者，丁香园也希望能够赶上资本利好，抓住一些窗口期。 一旦上市成功，对亏损中的企业而言，意味着有了较为稳定的资金流。资金可以加大头部企业的壁垒，也给了它们试错的底气。“你有花不完的钱，市场会把你推到正确的路上。”MediCool医库CEO徐宏钢说。 不能盈利，何以为继 按照赵传礼原来的设想，公司快速扩展用户规模，若能与几百家医院合作，做医疗大数据，想象空间很大，按照这种方式也可以上市。但很快，他发现营收是个大问题，线上业务甚至难以覆盖成本，需要不断找投资方去融资。 如今，赵传礼的公司已融资四五轮，投资方从一家增加为七家，现在又在准备新一轮融资。因为还没能找到投资者，他改变了战略，正与一家上市药企洽谈，希望并入其中，变相上市，能使前期投资顺利退出。 他的公司主营预约挂号。大多互联网医疗企业，做的是“搬运工”生意，试图把线下的流程挂号、问诊、诊断、随访、缴费、健康管理等搬到线上去。当热钱涌入之初，企业掷重金开拓市场、集聚流量并整合资源，打法是先做大用户规模，跑马圈地，希望通过流量变现。 赵传礼的公司靠用户增值服务和与医院合作的项目收费，也有互联网医疗企业靠交易佣金、数据营销等模式创收，但这些模式都难以形成规模化营收。“从医院收钱不成，从用户收钱市场没有培养出来，消费习惯没有形成。”赵传礼说。 平安好医生《招股说明书》显示，排除以股权为基础的付款及外汇盈亏额影响，2015年、2016年及2017年9月30日止九个月，平安好医生经调整净亏损分别为3.22亿元、9.81亿元、7.1亿元、3.3亿元。 此前爆出，微医2016年实现全面盈利。“这是误传。我们正在进行上市前的审计工作。”陈弘哲说。 互联网医疗难以盈利，未能深层次解决用户求医问诊需求是主因。 最早被看好并发掘的在线问诊，遇到的当头一棒是患者不能清晰描述自己的病情，直接影响医生的诊疗。医米调研2016年发布的《中国医生在线问诊行为报告》显示，仅有35.5%的患者可以大概描述自己的病情，仅有18%的医生认为在线问诊对国内病人帮助很大，六成医生选择“有一定作用但有限”。 平安好医生《招股说明书》中，截至2017年9月30日，当年在线医疗咨询服务为主的家庭医生服务收入仅为165.1万元。 盈利困境下，流量为王的互联网思维遭到质疑。“流量重要，但不能靠流量驱动整个商业模式。”李天天说。更何况，近年线上流量成本也趋高。 2016年，新增用户超过1.3亿，平安好医生耗费近6亿元推广费用和广告费用。 徐宏钢分析，在不计算人力和其他成本的情况下，获得普通用户成本约7元，获得留存活跃用户的成本约60元，总平均付费用户的获得成本350元－400元，而每位用户平均带来的毛收入达不到这个数字。 病人都倾向于往大医院跑，由于医疗行业特殊性，补贴拉动的用户留存率低，一旦补贴停掉，用户量、活跃度、卸载率等会高达50%以上，需要企业不断拉新、激活用户，然后将这部分流量变现，用户每一次来，都有成本，但不是每一次来，都能有营收。 “没有‘土豪爸爸’强力补贴和输送业务的情况下，其他的创业公司哪敢如此烧钱。”徐宏钢说。 探索中的企业，资金足是保障，这一两年互联网医疗头部企业找钱的动静会更大，扎堆掀起“上市潮”。“行业关注度增加，有利于资金融入，是很大的利好。”山东天业集团投资总监王博分析。 与医院的“恩怨” 为突破盈利困境，远程问诊、互联网医院，是互联网医疗最先关注的商业模式，现在又有企业尝试做全科诊所等。在纯线上模式折戟后，互联网医疗企业尝试逐步深入线下诊疗环节。 互联网医院本质是医院的延伸。2018年4月16日，国务院新闻办举行政策例行吹风会首度在官方层面承认了互联网医院的合法性，提出允许依托医疗机构发展互联网医院，医疗机构可以使用互联网医院作为第二名称，允许在线开展部分常见病、慢性病复诊等。但互联网医院必须落地在实体的医疗机构，线上线下要一致监管，并且必须得有实体医疗机构作为依托。国家卫生健康委员会副主任曾益新在此次吹风会上说，这对医院来说，等于拓展了业务范围，拓展了服务半径，是政策利好。 然而，患者在家中接受互联网诊断仍被禁止，互联网医疗企业只能做远程会诊、慢病管理等辅助性工作。国家卫生健康委员会医政医管局副局长焦雅辉在此次吹风会上强调，在互联网上初诊是绝对禁止的，这在世界上各国都是这样要求的。 互联网技术适合开展远程诊疗，被认为是实现分级诊疗的重要工具。曾益新表示，支持符合条件的第三方机构，搭建互联网信息平台，开展远程医疗。 迎合医改大势是个机会。2018年，好大夫在线重点转向基层医院，连接上下级医生，开展远程专家门诊业务；春雨医生则为医院提供系统改造，也是为引入远程会诊、远程慢病管理等。 不过，独角兽工作室创始人刘谦分析，分级诊疗尚未完全解决上下级医院之间的利益关系。 对于政府而言，远程问诊可帮助实现医改提倡的分级诊疗，即将三甲医院定位在解决疑难杂症，将50%的常见病分流下去。但一位做远程问诊的业内人士对《财经》记者分析，基层医院买不起检查设备很难诊断，即便能诊断在当地医院也治不了。 线上的远程问诊需要线下医院配合，可三甲医院没有兴趣做，远程诊疗是分流患者的，而患者意味着巨大的收入。因此，即便是互联网医院模式相对成熟的微医，目前更多以“小病”和“慢病”为主，医院间的大病远程会诊很少，基本难以触及。 “会诊本质上是一个医院之间的业务，第三方在其中很难获得发展，只能是一个提供基础设备和软件的角色。”医疗咨询公司Latitud Health发布的《远程医疗：价值、挑战和机会》报告称。 在医疗行业，形成壁垒的不是技术，而是资源。赵传礼分析，“医院活得好好的，为什么要跟你合作？”比如，在线挂号需要与医院的His系统（覆盖医院所有业务和业务全过程的信息管理系统）打通，然而，即使在卫计体系内部都很难打通所有的医院。 投资人王博在考量互联网医疗企业时，政府关系和资金状况是他重点考量的。“这决定着，企业能否拿到大医院的订单。”他对《财经》记者说。 政府提倡的分级诊疗，很重要的一个环节在于全科诊所。自建诊所，为互联网诊疗提供了医疗机构资质，又“占坑”线下就诊入口，因而，挺进诊所将是这两年互联网医疗企业的一个目标。迄今为止，有4家丁香诊所已运行；微医自建了6家线下全科中心和全科学院；3家企鹅诊所落地。 有医生资源做人才支撑，“为什么我要找公立医院合作”？李天天直问。他思考的是如何用好平台上的医生资源。丁香园有医生资源，运营诊所更有优势。 建立诊所，使互联网医疗企业必须直面与医院展开人才竞争。其实，整个医疗的终极在于医生。要激活现有医疗资源，政府乐于鼓励人才流动，互联网医疗企业则要放出更美好的“诱饵”。 对于互联网医疗的种种举动，中国医学科学院北京协和医学院整形外科医院院长祁佐良曾公开表示，“都是在有步骤地使大型公立医院面临这样必然到来的医疗体制改革。” 长远看，对互联网医疗企业而言，“（现阶段）与公立医院的合作是过渡”，中国社科院特约研究员贺滨认为，未来将出现更多可能性。 未来可能性的变量，还取决于政策因素。曾益新在上述吹风会上明确表示，鼓励逐步推进“互联网+保险结算”，拓展在线结付功能，包括异地结算、一站式的结算来方便病人。但目前，远程医疗，尚未被纳入医保报销范围。“真正的会诊业务很少，因为实在找不到人来买单。”山西迈普锡公司总经理程远宇对《财经》记者分析，远程医疗跟人工智能的困境是一样的，泡泡吹得再好，最终还要看医院、政府还是患者，谁来买单。 在李天天看来，与互联网不同，医疗健康产业还不是一个可以用资本快速催熟或清场对手的赛道，融资和IPO只是公司发展的一个基本保障，而不是把事情做成的关键。 那么，互联网医疗现在走到哪一步了？平安好医生的《招股说明书》将其描述为“一个新兴及不断演变的行业的初级阶段”。 深陷于其中者是痛并快乐着。陈弘哲认为“市场机会还很大”；好大夫在线CEO王航认为“互联网医疗的收获期还远着”；李天天给出的词是“曙光乍现”；健康160CEO罗宁政称“还处于极早期”。无论如何，互联网医疗企业总要回答“靠什么挣钱”。 那些迎着互联网医疗浪潮进入这个行业的人，当初憧憬的“大蛋糕”并没有预期而至。“慢得不像互联网。”一位等待其公司上市的员工说。 （本文首刊于2018年4月16日出版的《财经》杂志） 转载来源：平安好医生赴港IPO的背后，是互联网医疗的彷徨]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>IPO</tag>
        <tag>移动互联网</tag>
        <tag>平安保险</tag>
        <tag>丁香园</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识付费类产品竞品分析]]></title>
    <url>%2F2018%2F44411ce4%2F</url>
    <content type="text"><![CDATA[本文主要是对市场上知识付费排行榜中占有率较大的几款产品：知乎、得到、在行、百度知道的横向对比。二、竞品的选择从知识付费排行榜中选择市场占有率较大的三款产品：知乎、得到、在行；并从火爆一时的老牌知识付费产品中选择一款：百度知道。 本文主要是对市场上知识付费排行榜中占有率较大的几款产品：知乎、得到、在行、百度知道的横向对比，分析他们的优势、存在的问题、以及潜在机遇。并结合具体实践，提出产品设计方案。 一、本次竞品分析的目的 通过对市场上有竞争力产品的横向对比，分析他们的优势、存在的问题、以及潜在机遇；1. 将分析得到的收获，与具体学习生活场景相结合，提出我的产品设计方案。 二、竞品的选择 从知识付费排行榜中选择市场占有率较大的三款产品：知乎、得到、在行；1. 并从火爆一时的老牌知识付费产品中选择一款：百度知道。 三、选择原因维度：动机、成本衡量、内容质量 根据十字象限图，四个产品在这三个维度上各有特色，具有分析价值。 四、竞品分析1. 得到（1）公司层面 公司背景：罗辑思维，知识服务商和运营商。包括微信公众订阅号，知识类脱口秀视频节目：《罗辑思维》；知识服务App：得到APP。1. 产品定位：提供最省时间的高效知识服务。提倡碎片化学习方式，让用户短时间内获得有效知识。1. 发展历程：主推音频+文稿的内容形式；注重内容质量，大力度邀请各科领域优质内容生产者入驻。（2）产品层面 1）核心功能（知识+服务） 知识内容方面：建立以订阅专栏和每天听本书模块为核心，其他在线内容为补充的跨领域、多形态精品付费内容生态。其中订阅专栏是得到App的主要盈利来源，而每天听本书的低价模块用于养成用户使用习惯、提高用户粘性。 增值服务方面：基于用户行为及学习规律提供多种辅助功能，完善其学习闭环。 一方面，今日学习、学习记录及知识清单等工具型功能，通过对用户站内收听/浏览行为进行统计，帮助用户梳理学习轨迹，管理学习进程，提升学习效率；- 另一方面，内容推荐、学习小组、学习勋章等兴趣化功能，鼓励用户坚持在线学习，保持知识进阶，逐步建立跨领域知识图谱。2）竞争能力 以波特五力分析模型来看： 行业内竞争者现在的竞争能力：品牌上，得到是罗辑思维出品，信服度高，在占领用户心智上有着先天优势；内容形式上，其他竞品比如知乎有问答，在行有线上加线下的创新教育模式，得到仅仅是采用直接售卖的形式，较为单一，且没有互动。 替代品的替代能力：音频+文字的内容形式，行业内有竞争力的还有喜马拉雅FM，但是喜马拉雅付费模块没有全面展开，内容品质繁杂参差不齐，娱乐性大于专业性，与得到针对的目标用户有一定差异。 购买者的议价能力：订阅专栏199/年、大师课99/专题、听书4.99/本，得到在行业内的价格略高，用户考虑到知识内容大多是自我升值而不是生存必须，在衡量成本和动机时会有所顾虑。 供应商的供应能力：得到走高端路线致力于邀请知名度高权威性强的生产者。成本势必较高，普通消费者在学习课程之后，一般也无法达到App所要求的生产能力，所以无法构成产销合一的闭环。 潜在竞争者的竞争能力：若内容方不走平台直销知识，以其本身的内容资源的专业性与目标用户的重合性，对得到来说无疑是很大的打击。 2. 知乎（1）公司层面 公司背景： 2011年1月正式上线运营，作为知识分享平台，主要为用户提供问答、专栏、电子书等多种形式的信息服务。1. 产品定位：网络问答社区，用户围绕着某一感兴趣的话题分享彼此的知识、经验和见解。1. 发展历程：以问答社区为核心基础，2016年起，探索传统广告以外的商业路径，逐步拓展了多种形态的知识付费业务。通过多元知识变现模式吸引站外内容生产者的入驻，激励站内内容生产者生产优质付费内容，形成健康的内容生态。（2）产品层面 1）核心功能（核心基础**+**上层建筑） 以原本免费问答社区积累的内容与用户资源作为核心基础，探索更多的知识服务场景，形成了多条不同产品形态的知识付费业务线。 知乎live：付费进入课程，以问答形式参与答主短时、单场次的实时互动；- 付费咨询：通过支付标价费用向答主提问或直接观看已有问题；- 知乎书店：囊括了购买、阅读、讨论和传播的完整知识闭环；- 私家课：领域头部优秀回答者提供分模块、结构化、体系化的在线课程服务。2）竞争能力 以波特五力分析模型来看： 行业内竞争者现在的竞争能力：品牌上，知乎在行业内积累多年的声望与资源毋庸置疑，付费是众望所归也有助于内容质量的提升；传授形式上，包括了问答、线上授课、电子书等，媒介形式上包括文字、音频，现在也逐渐加入直播视频，多条业务线几乎包括了行业内的大部分产品形态。 替代品的替代能力：电子书与私家课模块行业内，有多个产品竞争且业务相对成熟。比如：得到、在行等，不具备竞争优势；知乎live模块，话题范围广、互动性强，业内的直接竞品有在行，但从价格和话题范围的广度看，在行的竞争性略低；付费咨询模块，在行在口碑与知名度上优势较弱。 购买者的议价能力：授课与问答价位不同，授课平均20-100，问答平均1-50，用户可以根据自身学习动机选择不同价位的学习形式，在成本衡量面较占优势。 供应商的供应能力：不仅有站外内容生产者的入驻，也有站内生产者生产优质付费内容，且兼顾到腰部与长尾力量，消费者学习达到饱和后也可贡献出一定的内容，形成产销合一的生态闭环。但需要对内容的品质、体系化进行有效整合。 潜在竞争者的竞争能力：以知识问答为核心基础的知识付费产品有潜力的是百度知道，但是从口碑、内容、用户质量上看，百度知道任重道远。 3. 在行一点（原分答）（1）公司层面 公司背景：果壳网，作为一个开放、多元的泛科技兴趣社区，提供负责任、有智趣的科技主题内容。1. 产品定位：是知识技能共享平台「在行」最新推出的付费语音问答服务，基于学者的问题与期望答案的个性化差异，以O2O和C2C模式让问答获得新的出路。1. 发展历程：果壳网在2015年3月13日推出产品 “在行”，可以约见不同领域的行家，与他们进行一对一见面约谈。2016年5月15日上线分答，由在行团队孵化，也是延续了知识传播与分享的分享方式。不仅是科学家，很多名人和各领域的专家也都加入付费问答的模式。2018年2月6日，分答更名在行一点，且对板块做了划分。（2）产品层面 1）核心功能（线上**+**线下） 基于在行起初一对一线下约见的授课形式，为了迎合碎片化学习时代的背景，果壳一步步从线下走入了线上，新一版的在行一点在首页清晰展现了四大功能模块：课、班、讲、问，对应不同的使用场景。 “课”是基于某个专题耕者专家深度学习；- “讲”跟改版前的“小讲”内容完全一致；- “班”则对应旧版本的“社区”；- 而之前的“找专家”和“快问”则汇总成了现在的“问”。行业内竞争者现在的竞争能力：品牌上，和知乎等一线产品相比优势不大；内容形式上，与大多竞品相仿，除了线下约见与在线社群互动略显特色。 替代品的替代能力：问、讲、课的模块，无论从内容资源的丰富度还是内容生产者的权威性，都不如知乎和得到，可替代性极强。但是“班”模块的社区功能中的互动问答，作业跟进反馈，极大提高学习效率，是一大亮点。 购买者的议价能力：标价在行业内偏高，但由于其内容范围专业性与实用性强，针对的目标用户动机纯粹，所以在价格衡量上会适当放宽要求。 供应商的供应能力：授课模块与得到类似，主要是头部内容生产者，问答模块主要是头部与腰部生产者。但是内容相较其他产品而言丰富性有待提高，且专业性太强消费者难以转化成生产者，产销合一的闭环难以实现。 潜在竞争者的竞争能力：与得到类似，且在行融合了直接售卖、知识社群、创新教育三种产品形态，形势虽然多样，但同时失去了产品特色。 4. 百度知道（1）公司层面 公司背景：百度全球最大的中文搜索引擎、最大的中文网站。1. 产品定位：一个基于搜索的互动式知识问答分享平台，用户自己有针对性地提出问题，通过积分奖励机制发动其他用户，来解决该问题。（2）产品层面 1）核心功能 提问（悬赏）+回答（互动）+分享（搜索）（悬赏人是提问者） 2）用户体验-表现层 优势：一对多的提问形式，鼓励用户回答问题，激发长尾内容生产者的力量。知乎与在行的问答是一对一，模块列表以答题人为主，且为答题人标价，产品付费体质明显，但也不利于长尾用户贡献内容生产力；百度知道答题页面以问题为主，可促进产销合一的生态构建 劣势：提问内容的质量，回答内容的专业性与系统性，用户不断流失的主要原因。 五、我的产品设计方案结合学习生活场景：有面试需求的求职者在网上寻找各种面试经验的过程中，发现所出来的内容都太笼统，质量不高，不落地。 目标用户：18-30岁即将毕业或刚毕业，有面试需求的求职者。 核心流程： 提供免费的增值服务：用户可以免费看面经；1. 付费看精品面经；1. 联系撰写者进行一对一辅导；1. 由（2）或（3）受益后的面试成功者获取相应荣耀值；1. 荣耀值高的用户成为生产者产出面经或去辅导别人。特点： 生态闭环，产销合一；1. 用户动机纯粹，就是想通过面试；1. 帮助用户理性筛选：点赞多的面经会被推至首页，面经以行业、公司、岗位、面试形式四个维度进行分类，帮助用户个性化筛选。用户留存方案： 免费的面试经验；1. 以付费用户学习后的面试反馈来调动潜在用户付费；1. 每日签到，积分代币；1. 荣誉感，通过面试多的人会有勋章，上光荣榜；1. 社群，激发用户去互动（以不同公司不同岗位分类）；1. 增值服务一：从拉勾或脉脉，获取一些及时的招聘信息个性推送给用户，一键投递；1. 增值服务二：邀请大厂员工，组织线上模拟面试（单面、群面）。商**业变现模式：** 平台抽成；1. 广告；1. 置换资源，合作共生（比如拉勾提供岗位资源，我们把用户信息以一定的手段曝光给拉钩）。风险与挑战**：** 面经的质量如何把控？平台与用户对于面经的评价标准不同，实用性因人而异；1. 产品初期如何和别人竞争？产品初期需要收集大量高质量的面经以及做一定推广，平衡成本方面需要仔细考量。本文由 &#64;Naom 原创发布于人人都是产品经理。未经许可，禁止转载 题图来自 Pexels，基于 CC0 协议 转载来源：知识付费类产品竞品分析]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>雅虎知识堂</tag>
        <tag>在行</tag>
        <tag>罗辑思维</tag>
        <tag>百度知道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[任志强房地产最新演讲：现在是抄底的机会，但这些地方不能碰]]></title>
    <url>%2F2018%2F005afb12%2F</url>
    <content type="text"><![CDATA[来源丨广州PLUS 昨天（4月22日）下午3点30分， 来源丨广州PLUS 昨天（4月22日）下午3点30分，任志强作为演讲嘉宾出现在“2018诺亚财富房地产金融高峰论坛”上。 这次任志强以北京华远地产股份有限公司原董事长身份发表演讲，时长达60分钟，不乏批判与反思。 以下为任志强杭州演讲实录—— 一季度房价暴涨 我们可以看到1月份的时候，施工面积是负的。今年一季度涨了多少呢？涨了7.9。今年的一季度是全国平均房价历史上涨幅最高的一年。 利用70个大中城市或者100个城市的指数，看来房价是跌了。跌到哪了呢？跌到政府的手上了，因为政府把销售价格给你限制了，所以表面上看是跌了。从有房地产以来，历史上的一个季度计算，今年一季度是房价涨幅最高的一个季度。 现在是“抄底”机会 我们看到，销售增长了百分之十几的销售额，为什么没钱呢？他们公司基本上是没钱的，这个投资增速是2008年以来增速最低的一年，比2008年还惨，开发商基本上兜里就没钱了。 为什么我们谭总请大家来开这个会？就是这个基金有了一个最好的机会，可以便宜收购。因为开发商兜里没钱了，开发商要有很多钱的话要基金干吗？去年开发商从境外的融资，388亿美元，今年一季度193亿美元，国内融资很困难，就跑到国外融资。 所以今年一季度，开发商境外的融资已经达到了去年的50%。前年是多少？2015年境外融资只有140亿美元，也就是说今年一季度以前，比2016年全年在境外融资的钱还多。主要是因为国内没机会，这是一个很重要的问题，开发商兜里的钱不够了。 所以最开始我说，投资会持续下降，就是因为没钱了，如果还保持百分之十几的高位资金增长的话，可能还会持续一段时间，现在看来要想维持一个高速的增长，已经有困难了。 东北、西部地区不能碰 分地区看，我们看看东北地区、西部地区，他们的投资增长百分之2.9、1.3，也就说明了这些地区已经没有了增长能力。东部和中部地区还维持一个增长，其中相当一部分棚改，三四线城市主要的力量在这两个投资领域，所以这个支撑效果还是有的。 但是中部、西部的销售是什么呢？销售是高速增长，西部和东北地区。前面我们看到投资是负的，或者基本上是不增长的，可是从销售看，东部地区，投资增长快速地区是负增长销售，负的7.3，中部地区还维持14，西部12，去年前年的高杠杆，导致相当一部分回收的资金没有进入到开发商的资金盘子里，而是跑到了银行的兜里面。现在差别不大。 70家上市公司拍卖股票 今年一季度我们可以看一些数据，融资下降了1.33万亿，下降了20%，企业贷款下降了15.8，委托贷款下降了50%，信托贷款下降了9%，融资下降了80%，所以到3月份为止，企业存款下降了1.21万亿，和去年年底相比。一个季度少1万个亿，开发商手里的钱很紧。 更严重的是，现在有70家上市公司的股票抵押贷款开始进行司法拍卖了，也就是说这70家公司的现金流已经不行了。上市公司一共2000多家，70家公司开始拍卖股票，还银行债，信用是非常严重的不足。 有人说，4月25日开始降息，银行准备降准，这是个信号，但是这个信号会到什么时候不知道。到目前为止，1.3万亿里头有9000亿是银行间进行内部调整的钱，对社会只有4000亿，但主要用于中小企业贷款，而且命令禁止流向房地产。别人家娶媳妇你看着高兴就行了，那不是你家娶媳妇儿，所以这个差距是很大的。 调控造成劣币驱逐良币 另外一个实际问题，比如产品与价格，我们现在看到市场上的调控政策基本上劣币驱逐良币，就是开发商没盖好房子，你只能盖破房子，越破越好。这个破房子破到什么程度呢？就是上边有一些一期的房子卖的很好，又有空气净化器，又是高级的电梯，又是高级的门窗，二期的价格比一期的还低，于是大家把空调都撤了，把电梯换成最破的电梯，把外墙的瓷砖给弄没了。 总之，以后可能得盖破房子，不能盖好房子，这是一个很麻烦的问题。所以，产品与价格之间的矛盾，尤其是想盖绿色产品，我们想盖环保产品，你不让卖高价，怎么办？ 很多企业在扩大规模，但是扩大规模和利润之间产生矛盾，因为你想扩大规模很容易，有钱就行，但是不让你卖高价，你的利润差越来越减少。我们可以看看领头的这些企业，实际上整体销售价格很低。比如说碧桂园，去年比前年的低，就是只能卖破房子，卖低价，扩大规模，但是利润达不到那么高。所以规模和利润之间的矛盾，这是很多人难以理解的。 只租不售诞生“灰色空间” 另外一个，土地招标的时候，好多加入固定性住房了，你投标还是不投标？要是投标了房子只能租不能卖，坏了。前天开会我问一个人，你的房子租出去没有？他摇摇头，没有。 他是一个月1.5万，一次性交180万，十年的租金，在北京的一个很远的地方，那也就是平均一个月2万块钱的租金，90平米以下的房子。我觉得固定性住房以后给腐败开了一个很好的头儿，过去腐败都是送房子，然后这个房子改名就可以了。名字不是你的，法院没法判你的房屋。 用市场化手段提供住房 房子不管是不是用来住的，都得有人先盖。但是我们看一看北京，看看很多大城市，都建公租房，建共同产权房和其他的房子，把商业房的比例降到很低很低，或者说基本上没有什么商品房用地，北京可能连四分之一都不到，这个市场是要还是不要？挺麻烦。 最重要的是，这个房子是住的，但是不一定是产权人住的。什么意思呢？你要想限制租赁性住房，租赁性住房就是告诉你不是产权人去租，如果都是产权人的话，哪还有什么租赁房？我自己租不就完了？所以租赁房一定不是产权人住。 这里就出了一个麻烦，不是我们要宣传，而我们实际造成的结果就市场最需要你建房，至少你得把房子建出来，你再说是用来租的还是用住的。 我们刚才叫什么总我也不知道，讲的氪空间。这个氪空间什么意思呢？他就说大企业都得租我的办公室，都得有流动，那我们人租房子是不是也得有流动呢？他们这个氪空间解决的是临时办公和流动性办公问题。我就想到一个问题，临时办公和流动性办公的这些人是不是也是流动性住呢？ 比如说媒体人，比如说演员，比如说地产商，他总得来回跑，来回跑的时候他是不是也得有一套房子呢？这套房子不管是他自己买的还是什么的，如果一个项目干六七年，他是在这买一套房子六七年以后再把它卖了好，还是我租个六七年什么也没剩下好？非常简单的事儿。但是他买了六七年以后，卖了，你一定说是炒房了，就和刚才的流动空间是一个道理，你那个流动空间就是炒空间，这个逻辑是一样的。 越出政策的地方房价越涨 我们的媒体在所有的宣传活动中把这个意思都搞错了，政策陷入了一种悖论，这种悖论是非常严重的悖论。大家都说，出台政策以后很多人担心房价是不是会跌了，我个人觉得，越出政策的地儿，越证明房价要涨。不涨他出政策干吗？他傻呀？ 在座的这些人，我开谭总召开的会，每次都问我，到哪买房子？我说你真傻，政府告诉你到哪买房子了，他在那儿使劲压着，就告诉你到那儿买房子，不压着不就涨了吗？涨了才压着，是吧？如果那个葫芦扔在水缸里头，你不按着不就往上走吗？你按着才往下走。现在按着，葫芦下去，水上来了。你想想，葫芦按下去了，水缸里的水是不是往上走？这么简单的道理还用问吗？政府告诉你到哪买房子，你就到哪去。 为什么？因为我们出台的这些政策造成了供给面的扭曲，就像我说的，北京为了这个那个，一大堆，保障房，租赁房，共有产权房，最后把商品房的用地弄没了。弄没了房子怎么会不涨价呢？没供应了，你看的是下来了，过两年怎么办？总得有人想结婚生孩子吧？怎么办呢？所以这是一个很矛盾的问题。 供给面在扭曲 价格是来自于什么？来自于需求。如果没有需求就没有价格。有人说地价涨了房价就得涨，正确的分析应该叫做，地价是房价的地板价，就是最低价格了。我把地价加上一个建安，税费，各种成本加进去以后，这是我卖得不赔钱的价，叫地板价。 天花板价在哪？天花板价在顾客身上，一个人买，可能加点利润就算了，10个人买我就得往上加价，这个价叫天花板价。现在这个天花板价让政府按住了，政府把天花板价打破了，打到地板上去了。如果政府把天花板价打到地板上，这个供给面不就扭曲了吗？ 所以形成的结果是，房价继续上涨的压力加大，越来越大。因此，用这种政策导致的结果，我们有五次大型调控，每次调控之后房价都是上涨的，没有一次是下跌的，原因就是它把供给面扭曲了。当供给面扭曲的时候，跟不上以后，下一次你一旦放开就很麻烦。所以，人家不准让我说涨价，我也没说涨价，我说政府可能要求我们涨价，不是我说的。 所以各种政策加码的时候，就形成了很多地区出现了一二受房价倒挂。倒挂是什么意思？二手房卖6万块钱，政府给你批的一手房卖5万块钱。这说明什么？说明政府告诉你，赶紧炒房。你买了就有1万块钱的差价，那你还不去炒。 政策变相鼓励“炒房” 所以政府的政策说悖论，就是因为他在鼓励大家炒房，这是一个很麻烦的事情。如果是开发商自己定价，那就是说我怎么也得新房子比旧房子贵点吧？不贵太多也得比二手房的价格高点吧？反正这两个里头有一个傻不是政府傻就是开发商傻，你怎么比二手房卖的还低呢？这就是一个问题。 最大的问题在哪呢？最大的问题在于，十九大明明告诉我们市场决定价格，那政府决定价格不是违反十九大规定吗？你们看看十八届三中全会和十九大里头，是不是说市场决定价格、市场决定资源配置？我们得按十九大办。所以你一旦按十九大办的时候，政府这几条可能就有问题了。 比如说为什么要摇号？摇号就是供不应求，100套房子有3个人买用摇号吗？摇不摇都摇到你头上了。上海前两天摇了好几个号，我一看，一个公司买了170套房子，他组织一大堆公司人员在那儿填窟窿，摇号，占名额。这说明什么？说明是政府在帮你。 我们最近最高院、最高检察院、国务院连续发了好几个文章，叫做保护产权，保护私有产权，保护什么，保护企业家，说了一大堆。这个房子是开发商建的还是政府建的？要是开发商建的就是开发商的产权，产权上没写着政府，你为什么要政府摇号？你不是侵犯产权吗？那你这个违反了国务院的规定，也违反了政府最高院、最高检察院的规定。 中央与地方的博弈 这就是出现了很多很多问题，造成了结果很不好。结果不好到哪了呢？我最近去了很多地区，地方官员都问我，怎么想办法和中央政府政策博弈？我说你们怎么都这么想？ 我们看看最早，比较早的大家听的，90、70，这个调控政策针对谁的呢？针对开发商的。所以开发商和政府斗争，把90、70的户型改来改去，然后把户型，厕所、卫生间的空间，阳台都调来调去，就是要躲90、70的政策。还有的是加层高，变成一个小二层，偷面积，这是开发商和政府的政策斗争。第二步就变成老百姓(74.520, -0.06, -0.08%)离婚了，那就是消费者开始跟政策进行斗争。 现在就是地方政府开始跟政府进行斗争。地方政府本来是市场监管者，监管者现在有一个问题了，我问几个房管局局长，那天我去干什么了，房管局局长陪我吃了三顿饭，就是要问一大堆问题，拿着小本子使劲记，一个重要的就是我的第一任务是不能让市长和书记被请去谈话。因为房价涨到一定程度以后，市长书记被约谈官儿就当不成了，所以这是一个很重要的问题。 地方政府就得跟政策做斗争，所以他们就想个办法，把市里的房价和县里的房价结合起来。先是远郊区，远郊区不行就把周边市管县的价格全合进来。所以我们看这个房价，涨不和涨，那个数字已经不是一个真实数字了。全国平均房价涨了，那和70个大中城市的数据完全不是一个概念，一个小破干州惨的不行。 为什么？它被列在70个城市范围之内了，周围400公里没有第二个城市，其实它很穷，但是没办法。这就造成了一个什么呢？开发商、消费者和地方政府三方联合起来和中央博弈。要是不博弈，地方政府地卖不出去，你要硬压着开发商，地卖不出去了，所以，这就是一个很严重的问题。 楼市如何走取决于特朗普 这些政策出台，我们认为变成悖论就是现在是一个难题，很多人问我，什么时候这些政策能够取消？什么时候这个政策能够解封？前两天开会有一个老总告诉我，最好就得看看我们特朗普先生给我们帮多大的忙。特朗普先生要让中国的外贸掉下去了，要让中国的经济掉下去了，可能政府就得把这个后门开开，让开发商日子好过点，要不然经济就掉下去了。 我个人认为，开发商在和地方政府比财政支出，如果地方政府的财政支出能够挺得住的话，可能他就不会轻易把这个事儿掉了。但是中国有句古话，兵马未动，粮草先行。如果地方政府财政支出遇到了问题的时候，它对土地财政的依赖性就加大，去年土地财政是5万亿，土地出让金是5万亿，房地产相关的税收18000多亿，然后和建筑业相关的，就是除了房地产本身的税收以外，相关的费用由6000多亿。 地方财政一共8万亿，如果没有这5万多亿的支撑的话，地方财政很难支撑债务转化问题。今年就得看看了，我们的土地出让到底能怎么样。一些好的城市仍然在高价出场土地，但是很多城市已经出现了一些控制，就是土地我刚才说涨价那么多，所以我们一季度财政增长了17.8%，GDP才6.8。一季度财政收入还是不错的，但是地方的财政收入，很多已经开始出了困难，这就是问题。 改善需求十分强劲 他们忘了一个事情，就是我们首先得确定不管房子是用住的还是用炒的，我们当前的主要矛盾是什么？城市化的主要矛盾，从眼前看，相当一部分原因是来自于我们的城镇化问题。到目前为止，我们的城镇化速度发展还是很慢的，还没有真正解决农村进城的问题。 大家都知道，中央提出一个，叫建立中国的长效机制，住房的综合住房制。现在我们没有综合住房制，现在我们的住房制度叫做城市住房制，只解决城市居民的铢分问题，不解决农村的居民住房问题。 所以地方政府的财政里头，只包括了有户籍人口的住房困难，不包括农村人口，所以很多城市，比如上海、北京，把农村人口都轰走了，否则他得解决住房问题，这是个麻烦。我们的主要结果，就是农民进城问题。 对于老龄化来说，我们现在是改善性需求占主导地位，年轻人结婚生孩子是刚性需求，老年人是有房子，但是他给改善。其中有两个主要矛盾，一个是没有电梯，老人爬不动，北京70%，上海大概也得有70%的房子是没有电梯的，6层也爬不上去。 老龄化越来越严重，英国怎么解决的？政府出钱，把3层楼都加上电梯。但是中国出不了这个钱。虽然我们有一些补贴，北京已经开始了，大概改了几十栋楼，但是差得很远，没有电梯的楼太多了，所以改不过来。 还有一个问题就是，80%以上的房子没有卫生间，你们觉得上海的房子好吗？上海房子都是刷马桶，早上起来刷马桶，没有卫生间。没有卫生间，它连厕所都没有，所以上海政府改了一栋房子，加了个厕所，厕所和卫生间是两个概念，卫生间是可以洗澡的地方，厕所只能叫半个卫生间，你只能解决一半的卫生问题，另外一半的卫生问题解决不了。 所以很多楼没有热水，我们大概全国90%以上的楼没有热水，70%以上的没有卫生间。所以很多家庭买热水器，淋浴器，搁到厕所里头，底下还得躲着那个洞，上头淋浴。刷牙呢？早上起来得到厨房刷牙，这种情况在大多数楼里头仍然保持了这个现象。这是一个很严重的问题，所以改善性需求所占的比例是越来越大的。 还有一个就是独居需求，独居需求可能很多人不太了解，到现在为止大概有750万独居，我们估计五年以后，每年增长30%到40%，其中一部分是孤寡老人的独居，另外一部分是年轻人，90后，00后不愿意跟父母在一起住。他们宁愿远离父母，自己单独租一个小房子，也不愿意跟你在一块住，你那个房子太大，他不跟你住。 北欧40%这种，整个欧洲大概平均有25%这种情况，现在中国是5.8%。未来的发展是什么？如果要发展到25%，我们得有两亿五千万户独居户，越来越多的90后和00后开始独居了。 城镇化红利期还很长 史上来看，重要的GDP是在于1800年以后产生的，十八世纪以前我们用了3万年时间，大概只产生了全世界5%的GDP，而后来的95%的GDP，这是累积计算的，都是因为十八世纪以后产生的。 原因是什么？原因是城市化，大规模的城市化集中在十八世纪后，因为十七世纪末才有了私有产权制度的保护。在十二世纪的时候英国就有一个大宪章，但是皇帝老毁约，到十七世纪末的时候，皇帝终于不能毁约了，所以全世界都开始确立私有产权保护制，城市就发展起来了。 尤其是十八世纪以后的工业化，导致城市化加剧，第一产业农业越来越不行了，这个发展过程是加速。所以从1800年到2010年，全世界人口增加了6倍，可是城市人口增加了60倍。 我们可以看到城市化需求在全球的发展过程。2007年的时候，城市人口已经超过了农村，到2016年的时候城市已经40.27亿人，农村34.15亿人，农村人口越来越少。中国到现在14亿人里头，8亿人在城市生活，但只有5亿多是城市户籍，40%是城市户籍，剩余的人都是农村户籍。 所以虽然有一部分农民住在城市里头，但是他孩子不能上学，不能领退休金，不能买房子等等。所以中国的城市化，还早得很。对于美国来说，根本不缺土地，农村面积很大，但是他们的城市化发展速度一点不低于中国，发展的速度远远超过中国。所以中国到目前，农村的人口比例是大于城市人口比例的。 从全球看，不管是发达地区还是非发达地区，城市化的速度都在加速，为什么？因为第一产业的产值太低了，中国有27%，接近30%的劳动力，农村劳动力，只生产7%的GDP，而70%多左右的劳动力生产93%的GDP。所以人均GDP上，城里人比农村人高了很多很多，钱多，收入高，所以人都往城里跑。 去年我们中国的服务业已经超过了GDP的50%，换句话说，如果服务业越来越多的时候，一定要靠城市才能解决问题，靠农村是解决不了服务业的问题的，靠农村就是老婆和孩子给你倒水洗脚，能有人给你捏脚吗？ 所以城里城外，不管是发达地区和不发达地区，我们都可以看到，未来发展的趋势，第一产业的人口一定是越来越少，必须到城市才能富起来。中国要想达到基本现代化和现代化小康，你得满足70%的城市化率，我们还早着呢。 重点城市人口流入加快 在城市发展的过程中，重点城市的城市化率，增长速度是非常快的。人口增长，在2016年以前不是说一线城市都是最高增长，其中一部分二线城市、三线城市，人口增长的比例速度也是非常非常快的，厦门达到了7.5年均，年均7.5，这不得了。 去年发生一个变化，为了吸引优秀人才，西安将近60万人，武汉37万人，长沙20多万人，合肥也是十几万人。就是有些地区，郑州好像也是30多万，我具体记不清了，总之利用吸引人才造成的人口大量向这些二线城市集中的速度非常快，一年你要增加30万人，你给他多少补贴，他也得有房子，没房子总不行吧？所以这个城市人口变化的规律是不可打破的。 如果全球都这样，中国要想跟上世界的步伐，你还想成为强国，你还要美好生活，不让农民进城就美好生活了？我看谭总刚才那个标题，叫做追求美好生活，那你得让农民进城，这不是你没解决吗？ 还要用20年完成70%城镇化 我们的现有城市里头，现在大概有22亿到240亿平方米的住宅，这包括破房子，包括非成套住宅。那如果按70%的城镇化率计算的话，我们最少得有400多亿。大现有情况下，好像增长1倍的住房增长量。我们每年住宅多少呢？去年大概7.8亿平方米，今年大概也就10亿平方米。 即使是这样算的话，我们还得用20多年的时间才能满足70%的城市化率的人口需求。我们满足不了。如果你天天用按着的方法，这个速度可能就很难达到。 我们仇保兴原来的住建部副部长在博鳌论坛上曾经说，我们现在的户均已经达到了1.1套房，他觉得我们基本上满足了。他就没想想那个房子有多破，我们说的折旧。如果每年有5%的折旧，400亿房子的话最少一年有20亿，我们现在一年就10亿。 换句话说，就是房地产长远的发展你是改变不了的，美国200多年呢，纽约现在房地产市场仍然是大头。你不是说房地产市场，我可以把房子是住的不是炒的，把它弄没了，弄没了中国经济就没了，这个是无法改变的一种情况。 但是仇保兴忘了一条，我们孩子的户口在父母的户口上，但是那个孩子已经单独住了一套房子，我儿子前两天偷偷结婚了，既没告诉男方的家里，也没告诉女方的家里，然后两个人偷偷在外头租了一套房子住。这种事儿我说是只有我们家出现吗？不是，突然发现他们公司十几个人都是这样。 年轻人不愿意告诉你，他自己愿意过小日子，干吗非得告诉你？我又不需要你的婚礼，人家过的挺好的。我觉得你们在座的可能也会遇到这种情况。独居家庭的速度，我们现在750万户，今后估计得有2500户，这个发展速度可能是非常快的，可能用五六年时间就得这样。 因为虽然我们的80后，90后比80后少了三分之一，00后和90后少了三分之一。所以很多人说，我可以从父母那儿继承一套房子，从老婆家里还可以继承一套房子，我一个人可以分三到四套房子。 胡扯，因为老人不死。我们的平均年龄估计从60多岁，70多岁，现在涨到80多岁了，过两年就是90多岁。你想想，30岁生孩子，你要想继承老人90岁的房子，你得活到60岁才能继承，那你30岁结婚的时候，到60岁之间这30年你老住别人的房子？那不是胡扯吗？ 所以很多专家都在那儿瞎说，就忘了老人不死。为什么我们退休养老金老不够用？我们原来计算的时候，是按照你70岁以前就死了计算的，结果人不死了，这个钱不够花的。这很是个问题。他们没想到，我们的美好生活让老人不死了，老人不死就变成一个结果呢？ 原来一套房子能解决问题，现在得两套、三套房子才能解决问题。你要熬到老人90岁死，下次他活到120的时候你怎么办？更麻烦了。我们的最新科技告诉大家，2038年新科技就可以保证这些人，未来就告诉你人可以活到120岁，高科技，没法弄了。 并非每个城市都需要租赁住房 我也不知道这些官员怎么想的，所以他们都出了很多政策，房租不炒，集体土地上建租赁应租房，共有产权等等。我个人觉得，这些问题都解决不了当期矛盾。第一个是租赁房，就是集体土地上建租赁房，我可以很自豪的告诉你们，这是我2011年的政协提案，要解决唐家岭等几个村，房子要塌了，要着火，怎么解决租赁应租房的问题。 国土资源部找我谈了很多次，批判了我六年时间，突然有一天我发现变成他的国家政策了。我很头疼，怎么搞的？我敢把政协的号都告诉你，我告诉你，这是真的，不是编的。 但是现在有人认为集体土地上大量供应的租赁应住房能不能破坏市场？我觉得不行。为什么不行？没有一个地方政府会把管子和路修到他不能卖的土地上去，他如果能拍卖这个土地就拼命的修市政基础设施，不能卖的地他就不修了。 只有什么样呢？就是顺路沾了光的这些集体土地才能建租赁性住房。有多少？没多少。所以每一个城市里都有极少的集体土地才能建租赁性住房。就是因为我顺路，有管子，有煤气，有燃气，有供暖什么的东西，你要是离得远的话，我才不给你修管子呢，你自己修管子修不起，所以并不是所有的集体土地都能用，这个矛盾要解决好。 我们在做租赁性住房，大家都说租赁性住房好，我刚才说了，万科的租赁性住房有多少人能租得起？不知道。美国，前十大城市，租赁的房子占的比例是非常高的，从人数，从比例数都可以看到。蓝色的是占的总的住房比例，就是租赁人口也可以看，都非常高。 所以大城市和特大城市，我们觉得要有50%左右的租赁性住房才能满足需求，因为流动人口和临时居住的创业人员等等，大概需要这样。而一般的城市，或者三四线城市，可能5%、2%就可以了，中等城市大概也有10%左右就够了，并不是所有的城市都需要大量的租赁性住房。 “租赁住房”必须市场化 反过来说，租赁性住房来自于哪？从美国来看，它不是政府掏钱盖的，不要以为多方建设靠政府出钱盖能行，解决不了问题。 我们再看看香港，香港的租赁性住房，私有持有的只有50%，另外40%和其他部分都是靠政府提供的，政府提供多少？免租的只有2%，廉租的这部分也很少，户主提供的也有2%，单位提供的也占到一定比例。但是这个房源从哪来的呢？房源从私有拥有的房源里来的。 也就是说发达国家的资本市场这么好，都是靠私有产权拥有，单位在国外就叫私有，拥有了租赁性住房，中国试图走到计划经济分配那种方式，几乎是不可能的。租赁性住房，为什么要靠私人？重要政府可以用税收和住房补贴来解决租赁导向的问题。 日本，我们看看，日本的租赁市场巨大，70%来自于私人。不要以为靠国家可以解决问题，解决不了问题，再有钱也解决不了问题，一定要靠私人租赁市场来解决问题。北京，北京大概700多万套私人的住房，20%用于租赁，大概140万到150万套左右。 有多少人用呢？有百分之三四的人用，平均一套房子要住五到七个人。所以我们看到，北京就是打隔断，N+1，客厅变成住房，一改改两间，所以它就打隔断。去年11月份一场大火以后北京开始取隔断，把所有隔断都取消了以后，人没地儿住了，涨房租。 所以去年到今年，普遍房租增长了百分之十几，个别地区房租增长40%，重点地区，比如通州，普遍涨了20%以上，因为政府让往这边搬。租赁性住房的价格根本无法解决问题。 我们需要多少房子，我们现在的情况来看，北京按道理说应该是40%到50%的房子是用于租赁的，否则外地人口都没法办了，各媒体都在北京有一个点儿，要不然最新的新闻拿不到。 外国领导来了，你要到现场拍一个照，两会来了你要拍一个照，你不得在北京派记者？怎么办？都买房子？两年就换人了，所以你还是得租。因此干部、高官，比如各个公司的高管们都在北京买房，但是他的低级管理人员待不了那么长时间，一年两年就完了，所以就得租房子，所以租赁性住房的欲求很大。 可是我们总在试图用官方的办法解决租赁性住房，我觉得解决不了。这个意见我已经跟国务院提出来了，政策研究室专门跟我讨论用什么办法解决租赁性住房，但是他们好像似乎还没有入门，问题还很严重。 共有权房，政府赚双倍 还有人说北京建了共有产权房，共有产权房我觉得更是政府贪财的一个取向，本身那个土地卖3万块钱，然后房价卖4万块钱，然后他占50%的股权，这个房价就变成了8万块钱。周边的二手房房价多少？6万。你要卖给业主，说4万块钱卖给你一套房子，你是不是觉得很高兴？比坊间的6万二手房便宜多了。 可是你别忘了，政府还拿了50%，政府这50%出钱了吗？没出钱，他得了双份的地价，3万的低价变成了6万，还得了一套房子。所以共有产权房从目前看高于当地二手房房价的项目已经很多个了，我只能说，本来拍卖土地的商品房，政府拿走了70%，到了共有产权房的时候，政府就从房价里拿走了90%或者更多。 我不觉得它是一个好政策。说我4万块钱拿到一套房子已经很不错了，反正我能住，先解决眼前问题吧。对，可能解决眼前的问题了，但是从法理上和税收理论上来说，这是一个不合理的。所以我也觉得，它并不能解决市场的问题。 房地产税，路还很远 还有一个关心的问题，就是房产税。今年我们两会期间有一个财政部的副部长回答了记者的提问，记者说我们能不能像国外的私有土地那样收取房产税，这个副部长告诉他，中国从来没有收过这样的房产税。我觉得这个副部长是不太懂，没看过中国的税法，他不知道1951年的时候，1949年的时候我们是房产税是房产税，地税是地税，1951年的时候把房产税和地产税合并了，叫做房地产税，那个时候土地和国际一样是私有产权的。 如果我们的财政部长在回答人民代表提问的时候都不知道自己国家发生的历史，我想他一定是搞错了，这个副部长，如果我是总理一定把他撤了。1951年以后为什么不收了？因为公私合营以后没有私人房屋了，全都是公家的了。因此，房产税没人收了，没法收了，收谁的？收不了了，所以他就取消了。 取消以后变成了什么？就变成了工商税，变成了城市维护事业税，附加税，土地使用金，土地出让使用税，耕地占用税等等。现在我们列出来七八个税种，都是属于房产这个范围之内。 因为凡是收了房产税的，都不能收其这类的税，房产税你都收了，不就是改善环境吗？维护城市的，你还能收绿化税吗？类似的情况很多。现在的情况下，2011年的时候楼继伟当财政部副部长提出建立物业税的时候，或者是我们房产税初期的时候就提出，要减去相应的税费。 但是现在后头这句话都被人抹了，他们总想在不减现有税的情况下加税，这是不可能的，老百姓一定会造反。 但是如果减了一些税，再征，能不能解决现在的土地财政问题？解决不了。不懂行的人以为，房产税还能替代土地出让金、财政问题解决不了，土地出让金70年的一次性支付相当于永久性的土地费，它是复利计算的。可是你要把它分成70年收，政府兜里一下子就没钱了，所以替代不了地方税。 回答记者问的时候，他提出通过房产税来调紧税负公平问题，如果要现在收房产税，税负是极不公平的。 第一，现有的房产税已经很重了，所以你要先取消再收才合理，否则就是税上加税。 第二，原有房屋的价格构成是不一样的，有的交了土地出让金，有的没交土地出让金，我们的商品房占总房量的多少呢？30%多。也就是说70%多的房子，60%多的房子，接近70%的房子是没有交土地出让金的房子，你能一并收税吗？你要一并收税的话，可能就会出现很多麻烦。 我们还可以看到有的交了大市政费，基础设施费，什么什么一大堆，有的没交。有的房改房是交了土地出让金的房子，商品房改成了房改房，有的不是，是原来分配的住房改房。 这里头的构成矛盾很多。最重要的是，我们的房改文件1997年23号文件，朱镕基当时出台的房改文件里头有一句话，叫老人老办法，新人新办法。那今天你要统一收税，人家说了，文件上写着，我老板得老办法，你怎么能按新人新办法解决呢？所以统一实行这种房产税，几乎是不可能的。 有人老问，房产税出台，房产税出台了，也就是他们吹吹吧。 另外一个是取得房屋产权的方式不一样，有人是花钱取得，有人是分配取得，有人拆迁取得的，有的是经济适用住房转换成商品房的，但是他没交土地房产税。有的是各种各样的房子，还有自建房，原来的私有产权房等等一大堆，你怎么把它统一分配呢？ 我们最低收入者人群里头，拥有的私有产权，拥有第二套产权房的也有7%。他们的房子大半在老城区，房子很破，但是学区房卖的很贵。你要按他的卖价收他的房产税的话，老百姓交不起，所以几乎是不可能的。 房地产税与租售并举矛盾 同时，税收一定是大大提高了租赁标准，和你这个租售并举是违背的，这两个是相悖的。靠税收去提高租金，老百姓更租不起房子，这是一个很麻烦的事情。我也不认为房产税能解决房价问题，能解决供应性问题，能解决任何问题。 为什么？因为我们历史的发展阶段不一样。国外为什么行呢？因为他一直是市场经济，土地私有制，所以不管他取得的房价是多少，他的规矩是一样的。我们的规则不一样，因为我们有住房分配制的，有住房房改制的，有大量的市政基础设施拆迁阶段的，有住房改革阶段，有商品化的阶段，有非商品化的阶段。 最初的商品化是划拨土地而形成的，后来的商品房土地办理土地出让制度形成的，然后就变成土地招牌挂制度形成的，所以各种取得方式是完全不同的。 你现在要统一市场评估的方式解决，一定会出乱子的，大家就会拿原来的房产证，原来的土地取得条件，或者房屋取得条件跟你打官司，为什么他的和我的是一样？我的成本比他高多了，或者我的成本比他低多了等等，法院以后就变成集市了。所以我估计，要这样说的话，税务比现在的军队要扩大3倍到4倍才能忙得过来。 空置税可解决租赁住房问题 因此在不改变现有双轨制的一些条件下，我个人觉得用市场化的办法解决问题是最好的，不是限制个人买房子，而是鼓励大家买房子。你买第三套、第四套、第五套、第六套都行，买的越多越好。 但是我要加你一个空置税，香港、德国，很多国家都是用这种方法。只要你的房子是为了住的，不是为了炒的，那你就让里头有人住，你不要空置半年以上我就要收你的税。 所以他的房子里有人住，有人住你不就达到了房子是用来住的目的了吗？但是人们为什么要把它用于出租呢？就是因为你减税，德国就是这样的，他用减税的方式控制房价，同时用减税的方式，用政府补贴让穷人有房子租。 意大利也同样，你要拿着住房券放的时候，政府给你减免个人所得税。所以那个住房券租房子的时候，你比市场的房价要低得多，租房价要低得多，可是减免你的个人所得税，它能交换。所以用市场化的办法，完全不需要政府大量的盖房子，可以解决我们租赁市场的问题。 很多，比如说美国，美国有一个网站叫空中食宿，它就是专门用于租赁住房的一个软件。上了这个网以后，你说我今天从北京到杭州开会，我家里的房子就可以用来租，租两天，我开两天会，那个房子租两天。它就收到很高，比酒店便宜，但是比一般的旅馆费用要高得多，因为所有的条件都很方便。 在欧洲这种以家庭方式进行短租，住一天两天、一个礼拜、两个礼拜的，这种房子多得一塌糊涂。所以空中食宿，就用这种方式成为了现在在美国非常受欢迎的一个网站，但是它也有很多官司，但是它有利的解决了这些问题。 比如说旧金山、硅谷，它的租赁住房是不够的，空中食宿就把原来的整体租赁房，整栋整栋的给你租了，然后变成时租，因为来往的人员太多了。所以中国完全可以扩大租赁市场，用市场化的办法去解决我们现在存在的一些矛盾。 长效机制很难建立 倒过来说，如果要用长效机制彻底解决中国的问题，那么就要解决的是土地制度问题，户籍制度问题。那么矛盾就在于，我们的短期政策不利于长期机制的建立，你没法解决土地制度问题，也没法解决户籍制度问题。 他们的矛盾在哪？我们今年出台了一号文件，农民的土地承包再增加30年，很多人就欢呼，真好，农民又可以多用土地30年了。但是很多农民在发愁，因为你只给我30年，我是不能修长期的基础设施的，因为我修这些基础设施，可能要用40年、50年，你只给我30年，我怎么敢修呢？ 中国严格说起来是没有私有产权制的，因为我们没有土地的私有化。你们现在都是有钱人，但是你们都叫浮财，你们自己想想，你们能生根落地吗？过两年把你的房子收了，都是浮财。 只有土地变成私有制的时候，我们才能谈得上中国的长期的住房制度和农民与城市人口利益相一致的制度，这样才能最终解决问题。否则，如果户籍制度和土地制度问题不从根本上解决，我们很难建立一套长效机制，你仍然是城里人只解决城里的住房，然后农村人进住房的时候，你就左卡右卡，反正不让他进来，然后他的孩子也不能上学，也不能享受医疗保障等等。 我们的十九大提出，要人类命运共同体，中国人首先得形成共同体，如果中国人连共同体都没有，你怎么能实现世界人的共同体？所以十九大已经提出了很多很多重要的，非常好的报告，但是问题在于哪呢？问题在于，我们的地方政策没有跟上十九大报告，造成了房地产出现了很多的问题。历史上凡是单一政策试图解决单一问题的时候，大部分都适得其反。 “单一政策”往往事与愿违 我们可以讲两个笑话，一个是布莱尔当英国首相的时候出台了一个政策，叫医生必须在48个小时给预约的病人看病，他们都能电话预约私人医生。布莱尔出来的这个政策，非常明确的要保护病人。 最后的结果是什么样的你们能想象到吗？所有的医生都取消了电话预约。为什么？医生的良心过不去，因为医生如果把所有的病人填满他的就医时间，临时出现了撞车、生病的这些病人，生命就会出现危险，不然他就违法了，因为布莱尔出的是法。 他到时候说，我要给临时得病的病人看病的时候，那个约的病人不干了，告你。所以他干脆为了保证临时可能出现的这些治病需要，我就所有的预约全取消了，我宁愿没有预约病人。医生的道德真好，所以他就把布莱尔这个临时性的单向措施彻底打败了。 第二，去年年底说台湾的行政院出台了一项政策，为了保护劳工的利益，劳工的加班费要从一个小时2倍的工资变成一个小时4倍的工资，蔡英文很科学的告诉你，我要保护劳动人民的利益。 从此以后，没有一个人雇原来的员工加班了，所有的工厂主都说我雇临时工，我不雇这个员工，这个员工来了叫做加班，所以过去我给2倍工资还行，现在你让我给4倍工资我不用他了，我宁愿到市场上找一个临时工来给我干一天，干两天，因为这个临时工不是按加班算的，因为他就干这两天。 所以单一政策通常在市场当中是悖论，所有的好心都会变成坏事，员工也很苦，也很生气，你这个政策真烂，原来我还能拿2倍工资，现在我连1倍工资也拿不着了。最后台湾行政院做了修改，修改法律。 所以当一个政府试图用单一政策，出于好心解决某一单一问题的时候，通常是悖论。我们如果用市场中的方法解决这种房价，你使劲按着，不用市场化的办法解决问题我觉得是适得其反，也不可能建立长效机制，我就讲这么多，谢谢。我再说一遍，你们千万别给我传出去，我都被问过了。 谢谢大家，我的演讲完了，这些仅代表我个人观点。 转载来源：任志强房地产最新演讲：现在是抄底的机会，但这些地方不能碰]]></content>
  </entry>
  <entry>
    <title><![CDATA[创记录！九价宫颈癌疫苗两日完成技术审评]]></title>
    <url>%2F2018%2Fda1b76c6%2F</url>
    <content type="text"><![CDATA[九价宫颈癌疫苗上市加速度，潜在市场空间望超千亿。 转载来源：创记录！九价宫颈癌疫苗两日完成技术审评]]></content>
      <tags>
        <tag>中钟看药</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[任志强房地产最新演讲：现在是抄底的机会，但这些地方不能碰]]></title>
    <url>%2F2018%2F26b3457d%2F</url>
    <content type="text"><![CDATA[来源丨广州PLUS 昨天（4月22日）下午3点30分， 来源丨广州PLUS 昨天（4月22日）下午3点30分，任志强作为演讲嘉宾出现在“2018诺亚财富房地产金融高峰论坛”上。 这次任志强以北京华远地产股份有限公司原董事长身份发表演讲，时长达60分钟，不乏批判与反思。 以下为任志强杭州演讲实录—— 一季度房价暴涨 我们可以看到1月份的时候，施工面积是负的。今年一季度涨了多少呢？涨了7.9。今年的一季度是全国平均房价历史上涨幅最高的一年。 利用70个大中城市或者100个城市的指数，看来房价是跌了。跌到哪了呢？跌到政府的手上了，因为政府把销售价格给你限制了，所以表面上看是跌了。从有房地产以来，历史上的一个季度计算，今年一季度是房价涨幅最高的一个季度。 现在是“抄底”机会 我们看到，销售增长了百分之十几的销售额，为什么没钱呢？他们公司基本上是没钱的，这个投资增速是2008年以来增速最低的一年，比2008年还惨，开发商基本上兜里就没钱了。 为什么我们谭总请大家来开这个会？就是这个基金有了一个最好的机会，可以便宜收购。因为开发商兜里没钱了，开发商要有很多钱的话要基金干吗？去年开发商从境外的融资，388亿美元，今年一季度193亿美元，国内融资很困难，就跑到国外融资。 所以今年一季度，开发商境外的融资已经达到了去年的50%。前年是多少？2015年境外融资只有140亿美元，也就是说今年一季度以前，比2016年全年在境外融资的钱还多。主要是因为国内没机会，这是一个很重要的问题，开发商兜里的钱不够了。 所以最开始我说，投资会持续下降，就是因为没钱了，如果还保持百分之十几的高位资金增长的话，可能还会持续一段时间，现在看来要想维持一个高速的增长，已经有困难了。 东北、西部地区不能碰 分地区看，我们看看东北地区、西部地区，他们的投资增长百分之2.9、1.3，也就说明了这些地区已经没有了增长能力。东部和中部地区还维持一个增长，其中相当一部分棚改，三四线城市主要的力量在这两个投资领域，所以这个支撑效果还是有的。 但是中部、西部的销售是什么呢？销售是高速增长，西部和东北地区。前面我们看到投资是负的，或者基本上是不增长的，可是从销售看，东部地区，投资增长快速地区是负增长销售，负的7.3，中部地区还维持14，西部12，去年前年的高杠杆，导致相当一部分回收的资金没有进入到开发商的资金盘子里，而是跑到了银行的兜里面。现在差别不大。 70家上市公司拍卖股票 今年一季度我们可以看一些数据，融资下降了1.33万亿，下降了20%，企业贷款下降了15.8，委托贷款下降了50%，信托贷款下降了9%，融资下降了80%，所以到3月份为止，企业存款下降了1.21万亿，和去年年底相比。一个季度少1万个亿，开发商手里的钱很紧。 更严重的是，现在有70家上市公司的股票抵押贷款开始进行司法拍卖了，也就是说这70家公司的现金流已经不行了。上市公司一共2000多家，70家公司开始拍卖股票，还银行债，信用是非常严重的不足。 有人说，4月25日开始降息，银行准备降准，这是个信号，但是这个信号会到什么时候不知道。到目前为止，1.3万亿里头有9000亿是银行间进行内部调整的钱，对社会只有4000亿，但主要用于中小企业贷款，而且命令禁止流向房地产。别人家娶媳妇你看着高兴就行了，那不是你家娶媳妇儿，所以这个差距是很大的。 调控造成劣币驱逐良币 另外一个实际问题，比如产品与价格，我们现在看到市场上的调控政策基本上劣币驱逐良币，就是开发商没盖好房子，你只能盖破房子，越破越好。这个破房子破到什么程度呢？就是上边有一些一期的房子卖的很好，又有空气净化器，又是高级的电梯，又是高级的门窗，二期的价格比一期的还低，于是大家把空调都撤了，把电梯换成最破的电梯，把外墙的瓷砖给弄没了。 总之，以后可能得盖破房子，不能盖好房子，这是一个很麻烦的问题。所以，产品与价格之间的矛盾，尤其是想盖绿色产品，我们想盖环保产品，你不让卖高价，怎么办？ 很多企业在扩大规模，但是扩大规模和利润之间产生矛盾，因为你想扩大规模很容易，有钱就行，但是不让你卖高价，你的利润差越来越减少。我们可以看看领头的这些企业，实际上整体销售价格很低。比如说碧桂园，去年比前年的低，就是只能卖破房子，卖低价，扩大规模，但是利润达不到那么高。所以规模和利润之间的矛盾，这是很多人难以理解的。 只租不售诞生“灰色空间” 另外一个，土地招标的时候，好多加入固定性住房了，你投标还是不投标？要是投标了房子只能租不能卖，坏了。前天开会我问一个人，你的房子租出去没有？他摇摇头，没有。 他是一个月1.5万，一次性交180万，十年的租金，在北京的一个很远的地方，那也就是平均一个月2万块钱的租金，90平米以下的房子。我觉得固定性住房以后给腐败开了一个很好的头儿，过去腐败都是送房子，然后这个房子改名就可以了。名字不是你的，法院没法判你的房屋。 用市场化手段提供住房 房子不管是不是用来住的，都得有人先盖。但是我们看一看北京，看看很多大城市，都建公租房，建共同产权房和其他的房子，把商业房的比例降到很低很低，或者说基本上没有什么商品房用地，北京可能连四分之一都不到，这个市场是要还是不要？挺麻烦。 最重要的是，这个房子是住的，但是不一定是产权人住的。什么意思呢？你要想限制租赁性住房，租赁性住房就是告诉你不是产权人去租，如果都是产权人的话，哪还有什么租赁房？我自己租不就完了？所以租赁房一定不是产权人住。 这里就出了一个麻烦，不是我们要宣传，而我们实际造成的结果就市场最需要你建房，至少你得把房子建出来，你再说是用来租的还是用住的。 我们刚才叫什么总我也不知道，讲的氪空间。这个氪空间什么意思呢？他就说大企业都得租我的办公室，都得有流动，那我们人租房子是不是也得有流动呢？他们这个氪空间解决的是临时办公和流动性办公问题。我就想到一个问题，临时办公和流动性办公的这些人是不是也是流动性住呢？ 比如说媒体人，比如说演员，比如说地产商，他总得来回跑，来回跑的时候他是不是也得有一套房子呢？这套房子不管是他自己买的还是什么的，如果一个项目干六七年，他是在这买一套房子六七年以后再把它卖了好，还是我租个六七年什么也没剩下好？非常简单的事儿。但是他买了六七年以后，卖了，你一定说是炒房了，就和刚才的流动空间是一个道理，你那个流动空间就是炒空间，这个逻辑是一样的。 越出政策的地方房价越涨 我们的媒体在所有的宣传活动中把这个意思都搞错了，政策陷入了一种悖论，这种悖论是非常严重的悖论。大家都说，出台政策以后很多人担心房价是不是会跌了，我个人觉得，越出政策的地儿，越证明房价要涨。不涨他出政策干吗？他傻呀？ 在座的这些人，我开谭总召开的会，每次都问我，到哪买房子？我说你真傻，政府告诉你到哪买房子了，他在那儿使劲压着，就告诉你到那儿买房子，不压着不就涨了吗？涨了才压着，是吧？如果那个葫芦扔在水缸里头，你不按着不就往上走吗？你按着才往下走。现在按着，葫芦下去，水上来了。你想想，葫芦按下去了，水缸里的水是不是往上走？这么简单的道理还用问吗？政府告诉你到哪买房子，你就到哪去。 为什么？因为我们出台的这些政策造成了供给面的扭曲，就像我说的，北京为了这个那个，一大堆，保障房，租赁房，共有产权房，最后把商品房的用地弄没了。弄没了房子怎么会不涨价呢？没供应了，你看的是下来了，过两年怎么办？总得有人想结婚生孩子吧？怎么办呢？所以这是一个很矛盾的问题。 供给面在扭曲 价格是来自于什么？来自于需求。如果没有需求就没有价格。有人说地价涨了房价就得涨，正确的分析应该叫做，地价是房价的地板价，就是最低价格了。我把地价加上一个建安，税费，各种成本加进去以后，这是我卖得不赔钱的价，叫地板价。 天花板价在哪？天花板价在顾客身上，一个人买，可能加点利润就算了，10个人买我就得往上加价，这个价叫天花板价。现在这个天花板价让政府按住了，政府把天花板价打破了，打到地板上去了。如果政府把天花板价打到地板上，这个供给面不就扭曲了吗？ 所以形成的结果是，房价继续上涨的压力加大，越来越大。因此，用这种政策导致的结果，我们有五次大型调控，每次调控之后房价都是上涨的，没有一次是下跌的，原因就是它把供给面扭曲了。当供给面扭曲的时候，跟不上以后，下一次你一旦放开就很麻烦。所以，人家不准让我说涨价，我也没说涨价，我说政府可能要求我们涨价，不是我说的。 所以各种政策加码的时候，就形成了很多地区出现了一二受房价倒挂。倒挂是什么意思？二手房卖6万块钱，政府给你批的一手房卖5万块钱。这说明什么？说明政府告诉你，赶紧炒房。你买了就有1万块钱的差价，那你还不去炒。 政策变相鼓励“炒房” 所以政府的政策说悖论，就是因为他在鼓励大家炒房，这是一个很麻烦的事情。如果是开发商自己定价，那就是说我怎么也得新房子比旧房子贵点吧？不贵太多也得比二手房的价格高点吧？反正这两个里头有一个傻不是政府傻就是开发商傻，你怎么比二手房卖的还低呢？这就是一个问题。 最大的问题在哪呢？最大的问题在于，十九大明明告诉我们市场决定价格，那政府决定价格不是违反十九大规定吗？你们看看十八届三中全会和十九大里头，是不是说市场决定价格、市场决定资源配置？我们得按十九大办。所以你一旦按十九大办的时候，政府这几条可能就有问题了。 比如说为什么要摇号？摇号就是供不应求，100套房子有3个人买用摇号吗？摇不摇都摇到你头上了。上海前两天摇了好几个号，我一看，一个公司买了170套房子，他组织一大堆公司人员在那儿填窟窿，摇号，占名额。这说明什么？说明是政府在帮你。 我们最近最高院、最高检察院、国务院连续发了好几个文章，叫做保护产权，保护私有产权，保护什么，保护企业家，说了一大堆。这个房子是开发商建的还是政府建的？要是开发商建的就是开发商的产权，产权上没写着政府，你为什么要政府摇号？你不是侵犯产权吗？那你这个违反了国务院的规定，也违反了政府最高院、最高检察院的规定。 中央与地方的博弈 这就是出现了很多很多问题，造成了结果很不好。结果不好到哪了呢？我最近去了很多地区，地方官员都问我，怎么想办法和中央政府政策博弈？我说你们怎么都这么想？ 我们看看最早，比较早的大家听的，90、70，这个调控政策针对谁的呢？针对开发商的。所以开发商和政府斗争，把90、70的户型改来改去，然后把户型，厕所、卫生间的空间，阳台都调来调去，就是要躲90、70的政策。还有的是加层高，变成一个小二层，偷面积，这是开发商和政府的政策斗争。第二步就变成老百姓(74.520, -0.06, -0.08%)离婚了，那就是消费者开始跟政策进行斗争。 现在就是地方政府开始跟政府进行斗争。地方政府本来是市场监管者，监管者现在有一个问题了，我问几个房管局局长，那天我去干什么了，房管局局长陪我吃了三顿饭，就是要问一大堆问题，拿着小本子使劲记，一个重要的就是我的第一任务是不能让市长和书记被请去谈话。因为房价涨到一定程度以后，市长书记被约谈官儿就当不成了，所以这是一个很重要的问题。 地方政府就得跟政策做斗争，所以他们就想个办法，把市里的房价和县里的房价结合起来。先是远郊区，远郊区不行就把周边市管县的价格全合进来。所以我们看这个房价，涨不和涨，那个数字已经不是一个真实数字了。全国平均房价涨了，那和70个大中城市的数据完全不是一个概念，一个小破干州惨的不行。 为什么？它被列在70个城市范围之内了，周围400公里没有第二个城市，其实它很穷，但是没办法。这就造成了一个什么呢？开发商、消费者和地方政府三方联合起来和中央博弈。要是不博弈，地方政府地卖不出去，你要硬压着开发商，地卖不出去了，所以，这就是一个很严重的问题。 楼市如何走取决于特朗普 这些政策出台，我们认为变成悖论就是现在是一个难题，很多人问我，什么时候这些政策能够取消？什么时候这个政策能够解封？前两天开会有一个老总告诉我，最好就得看看我们特朗普先生给我们帮多大的忙。特朗普先生要让中国的外贸掉下去了，要让中国的经济掉下去了，可能政府就得把这个后门开开，让开发商日子好过点，要不然经济就掉下去了。 我个人认为，开发商在和地方政府比财政支出，如果地方政府的财政支出能够挺得住的话，可能他就不会轻易把这个事儿掉了。但是中国有句古话，兵马未动，粮草先行。如果地方政府财政支出遇到了问题的时候，它对土地财政的依赖性就加大，去年土地财政是5万亿，土地出让金是5万亿，房地产相关的税收18000多亿，然后和建筑业相关的，就是除了房地产本身的税收以外，相关的费用由6000多亿。 地方财政一共8万亿，如果没有这5万多亿的支撑的话，地方财政很难支撑债务转化问题。今年就得看看了，我们的土地出让到底能怎么样。一些好的城市仍然在高价出场土地，但是很多城市已经出现了一些控制，就是土地我刚才说涨价那么多，所以我们一季度财政增长了17.8%，GDP才6.8。一季度财政收入还是不错的，但是地方的财政收入，很多已经开始出了困难，这就是问题。 改善需求十分强劲 他们忘了一个事情，就是我们首先得确定不管房子是用住的还是用炒的，我们当前的主要矛盾是什么？城市化的主要矛盾，从眼前看，相当一部分原因是来自于我们的城镇化问题。到目前为止，我们的城镇化速度发展还是很慢的，还没有真正解决农村进城的问题。 大家都知道，中央提出一个，叫建立中国的长效机制，住房的综合住房制。现在我们没有综合住房制，现在我们的住房制度叫做城市住房制，只解决城市居民的铢分问题，不解决农村的居民住房问题。 所以地方政府的财政里头，只包括了有户籍人口的住房困难，不包括农村人口，所以很多城市，比如上海、北京，把农村人口都轰走了，否则他得解决住房问题，这是个麻烦。我们的主要结果，就是农民进城问题。 对于老龄化来说，我们现在是改善性需求占主导地位，年轻人结婚生孩子是刚性需求，老年人是有房子，但是他给改善。其中有两个主要矛盾，一个是没有电梯，老人爬不动，北京70%，上海大概也得有70%的房子是没有电梯的，6层也爬不上去。 老龄化越来越严重，英国怎么解决的？政府出钱，把3层楼都加上电梯。但是中国出不了这个钱。虽然我们有一些补贴，北京已经开始了，大概改了几十栋楼，但是差得很远，没有电梯的楼太多了，所以改不过来。 还有一个问题就是，80%以上的房子没有卫生间，你们觉得上海的房子好吗？上海房子都是刷马桶，早上起来刷马桶，没有卫生间。没有卫生间，它连厕所都没有，所以上海政府改了一栋房子，加了个厕所，厕所和卫生间是两个概念，卫生间是可以洗澡的地方，厕所只能叫半个卫生间，你只能解决一半的卫生问题，另外一半的卫生问题解决不了。 所以很多楼没有热水，我们大概全国90%以上的楼没有热水，70%以上的没有卫生间。所以很多家庭买热水器，淋浴器，搁到厕所里头，底下还得躲着那个洞，上头淋浴。刷牙呢？早上起来得到厨房刷牙，这种情况在大多数楼里头仍然保持了这个现象。这是一个很严重的问题，所以改善性需求所占的比例是越来越大的。 还有一个就是独居需求，独居需求可能很多人不太了解，到现在为止大概有750万独居，我们估计五年以后，每年增长30%到40%，其中一部分是孤寡老人的独居，另外一部分是年轻人，90后，00后不愿意跟父母在一起住。他们宁愿远离父母，自己单独租一个小房子，也不愿意跟你在一块住，你那个房子太大，他不跟你住。 北欧40%这种，整个欧洲大概平均有25%这种情况，现在中国是5.8%。未来的发展是什么？如果要发展到25%，我们得有两亿五千万户独居户，越来越多的90后和00后开始独居了。 城镇化红利期还很长 史上来看，重要的GDP是在于1800年以后产生的，十八世纪以前我们用了3万年时间，大概只产生了全世界5%的GDP，而后来的95%的GDP，这是累积计算的，都是因为十八世纪以后产生的。 原因是什么？原因是城市化，大规模的城市化集中在十八世纪后，因为十七世纪末才有了私有产权制度的保护。在十二世纪的时候英国就有一个大宪章，但是皇帝老毁约，到十七世纪末的时候，皇帝终于不能毁约了，所以全世界都开始确立私有产权保护制，城市就发展起来了。 尤其是十八世纪以后的工业化，导致城市化加剧，第一产业农业越来越不行了，这个发展过程是加速。所以从1800年到2010年，全世界人口增加了6倍，可是城市人口增加了60倍。 我们可以看到城市化需求在全球的发展过程。2007年的时候，城市人口已经超过了农村，到2016年的时候城市已经40.27亿人，农村34.15亿人，农村人口越来越少。中国到现在14亿人里头，8亿人在城市生活，但只有5亿多是城市户籍，40%是城市户籍，剩余的人都是农村户籍。 所以虽然有一部分农民住在城市里头，但是他孩子不能上学，不能领退休金，不能买房子等等。所以中国的城市化，还早得很。对于美国来说，根本不缺土地，农村面积很大，但是他们的城市化发展速度一点不低于中国，发展的速度远远超过中国。所以中国到目前，农村的人口比例是大于城市人口比例的。 从全球看，不管是发达地区还是非发达地区，城市化的速度都在加速，为什么？因为第一产业的产值太低了，中国有27%，接近30%的劳动力，农村劳动力，只生产7%的GDP，而70%多左右的劳动力生产93%的GDP。所以人均GDP上，城里人比农村人高了很多很多，钱多，收入高，所以人都往城里跑。 去年我们中国的服务业已经超过了GDP的50%，换句话说，如果服务业越来越多的时候，一定要靠城市才能解决问题，靠农村是解决不了服务业的问题的，靠农村就是老婆和孩子给你倒水洗脚，能有人给你捏脚吗？ 所以城里城外，不管是发达地区和不发达地区，我们都可以看到，未来发展的趋势，第一产业的人口一定是越来越少，必须到城市才能富起来。中国要想达到基本现代化和现代化小康，你得满足70%的城市化率，我们还早着呢。 重点城市人口流入加快 在城市发展的过程中，重点城市的城市化率，增长速度是非常快的。人口增长，在2016年以前不是说一线城市都是最高增长，其中一部分二线城市、三线城市，人口增长的比例速度也是非常非常快的，厦门达到了7.5年均，年均7.5，这不得了。 去年发生一个变化，为了吸引优秀人才，西安将近60万人，武汉37万人，长沙20多万人，合肥也是十几万人。就是有些地区，郑州好像也是30多万，我具体记不清了，总之利用吸引人才造成的人口大量向这些二线城市集中的速度非常快，一年你要增加30万人，你给他多少补贴，他也得有房子，没房子总不行吧？所以这个城市人口变化的规律是不可打破的。 如果全球都这样，中国要想跟上世界的步伐，你还想成为强国，你还要美好生活，不让农民进城就美好生活了？我看谭总刚才那个标题，叫做追求美好生活，那你得让农民进城，这不是你没解决吗？ 还要用20年完成70%城镇化 我们的现有城市里头，现在大概有22亿到240亿平方米的住宅，这包括破房子，包括非成套住宅。那如果按70%的城镇化率计算的话，我们最少得有400多亿。大现有情况下，好像增长1倍的住房增长量。我们每年住宅多少呢？去年大概7.8亿平方米，今年大概也就10亿平方米。 即使是这样算的话，我们还得用20多年的时间才能满足70%的城市化率的人口需求。我们满足不了。如果你天天用按着的方法，这个速度可能就很难达到。 我们仇保兴原来的住建部副部长在博鳌论坛上曾经说，我们现在的户均已经达到了1.1套房，他觉得我们基本上满足了。他就没想想那个房子有多破，我们说的折旧。如果每年有5%的折旧，400亿房子的话最少一年有20亿，我们现在一年就10亿。 换句话说，就是房地产长远的发展你是改变不了的，美国200多年呢，纽约现在房地产市场仍然是大头。你不是说房地产市场，我可以把房子是住的不是炒的，把它弄没了，弄没了中国经济就没了，这个是无法改变的一种情况。 但是仇保兴忘了一条，我们孩子的户口在父母的户口上，但是那个孩子已经单独住了一套房子，我儿子前两天偷偷结婚了，既没告诉男方的家里，也没告诉女方的家里，然后两个人偷偷在外头租了一套房子住。这种事儿我说是只有我们家出现吗？不是，突然发现他们公司十几个人都是这样。 年轻人不愿意告诉你，他自己愿意过小日子，干吗非得告诉你？我又不需要你的婚礼，人家过的挺好的。我觉得你们在座的可能也会遇到这种情况。独居家庭的速度，我们现在750万户，今后估计得有2500户，这个发展速度可能是非常快的，可能用五六年时间就得这样。 因为虽然我们的80后，90后比80后少了三分之一，00后和90后少了三分之一。所以很多人说，我可以从父母那儿继承一套房子，从老婆家里还可以继承一套房子，我一个人可以分三到四套房子。 胡扯，因为老人不死。我们的平均年龄估计从60多岁，70多岁，现在涨到80多岁了，过两年就是90多岁。你想想，30岁生孩子，你要想继承老人90岁的房子，你得活到60岁才能继承，那你30岁结婚的时候，到60岁之间这30年你老住别人的房子？那不是胡扯吗？ 所以很多专家都在那儿瞎说，就忘了老人不死。为什么我们退休养老金老不够用？我们原来计算的时候，是按照你70岁以前就死了计算的，结果人不死了，这个钱不够花的。这很是个问题。他们没想到，我们的美好生活让老人不死了，老人不死就变成一个结果呢？ 原来一套房子能解决问题，现在得两套、三套房子才能解决问题。你要熬到老人90岁死，下次他活到120的时候你怎么办？更麻烦了。我们的最新科技告诉大家，2038年新科技就可以保证这些人，未来就告诉你人可以活到120岁，高科技，没法弄了。 并非每个城市都需要租赁住房 我也不知道这些官员怎么想的，所以他们都出了很多政策，房租不炒，集体土地上建租赁应租房，共有产权等等。我个人觉得，这些问题都解决不了当期矛盾。第一个是租赁房，就是集体土地上建租赁房，我可以很自豪的告诉你们，这是我2011年的政协提案，要解决唐家岭等几个村，房子要塌了，要着火，怎么解决租赁应租房的问题。 国土资源部找我谈了很多次，批判了我六年时间，突然有一天我发现变成他的国家政策了。我很头疼，怎么搞的？我敢把政协的号都告诉你，我告诉你，这是真的，不是编的。 但是现在有人认为集体土地上大量供应的租赁应住房能不能破坏市场？我觉得不行。为什么不行？没有一个地方政府会把管子和路修到他不能卖的土地上去，他如果能拍卖这个土地就拼命的修市政基础设施，不能卖的地他就不修了。 只有什么样呢？就是顺路沾了光的这些集体土地才能建租赁性住房。有多少？没多少。所以每一个城市里都有极少的集体土地才能建租赁性住房。就是因为我顺路，有管子，有煤气，有燃气，有供暖什么的东西，你要是离得远的话，我才不给你修管子呢，你自己修管子修不起，所以并不是所有的集体土地都能用，这个矛盾要解决好。 我们在做租赁性住房，大家都说租赁性住房好，我刚才说了，万科的租赁性住房有多少人能租得起？不知道。美国，前十大城市，租赁的房子占的比例是非常高的，从人数，从比例数都可以看到。蓝色的是占的总的住房比例，就是租赁人口也可以看，都非常高。 所以大城市和特大城市，我们觉得要有50%左右的租赁性住房才能满足需求，因为流动人口和临时居住的创业人员等等，大概需要这样。而一般的城市，或者三四线城市，可能5%、2%就可以了，中等城市大概也有10%左右就够了，并不是所有的城市都需要大量的租赁性住房。 “租赁住房”必须市场化 反过来说，租赁性住房来自于哪？从美国来看，它不是政府掏钱盖的，不要以为多方建设靠政府出钱盖能行，解决不了问题。 我们再看看香港，香港的租赁性住房，私有持有的只有50%，另外40%和其他部分都是靠政府提供的，政府提供多少？免租的只有2%，廉租的这部分也很少，户主提供的也有2%，单位提供的也占到一定比例。但是这个房源从哪来的呢？房源从私有拥有的房源里来的。 也就是说发达国家的资本市场这么好，都是靠私有产权拥有，单位在国外就叫私有，拥有了租赁性住房，中国试图走到计划经济分配那种方式，几乎是不可能的。租赁性住房，为什么要靠私人？重要政府可以用税收和住房补贴来解决租赁导向的问题。 日本，我们看看，日本的租赁市场巨大，70%来自于私人。不要以为靠国家可以解决问题，解决不了问题，再有钱也解决不了问题，一定要靠私人租赁市场来解决问题。北京，北京大概700多万套私人的住房，20%用于租赁，大概140万到150万套左右。 有多少人用呢？有百分之三四的人用，平均一套房子要住五到七个人。所以我们看到，北京就是打隔断，N+1，客厅变成住房，一改改两间，所以它就打隔断。去年11月份一场大火以后北京开始取隔断，把所有隔断都取消了以后，人没地儿住了，涨房租。 所以去年到今年，普遍房租增长了百分之十几，个别地区房租增长40%，重点地区，比如通州，普遍涨了20%以上，因为政府让往这边搬。租赁性住房的价格根本无法解决问题。 我们需要多少房子，我们现在的情况来看，北京按道理说应该是40%到50%的房子是用于租赁的，否则外地人口都没法办了，各媒体都在北京有一个点儿，要不然最新的新闻拿不到。 外国领导来了，你要到现场拍一个照，两会来了你要拍一个照，你不得在北京派记者？怎么办？都买房子？两年就换人了，所以你还是得租。因此干部、高官，比如各个公司的高管们都在北京买房，但是他的低级管理人员待不了那么长时间，一年两年就完了，所以就得租房子，所以租赁性住房的欲求很大。 可是我们总在试图用官方的办法解决租赁性住房，我觉得解决不了。这个意见我已经跟国务院提出来了，政策研究室专门跟我讨论用什么办法解决租赁性住房，但是他们好像似乎还没有入门，问题还很严重。 共有权房，政府赚双倍 还有人说北京建了共有产权房，共有产权房我觉得更是政府贪财的一个取向，本身那个土地卖3万块钱，然后房价卖4万块钱，然后他占50%的股权，这个房价就变成了8万块钱。周边的二手房房价多少？6万。你要卖给业主，说4万块钱卖给你一套房子，你是不是觉得很高兴？比坊间的6万二手房便宜多了。 可是你别忘了，政府还拿了50%，政府这50%出钱了吗？没出钱，他得了双份的地价，3万的低价变成了6万，还得了一套房子。所以共有产权房从目前看高于当地二手房房价的项目已经很多个了，我只能说，本来拍卖土地的商品房，政府拿走了70%，到了共有产权房的时候，政府就从房价里拿走了90%或者更多。 我不觉得它是一个好政策。说我4万块钱拿到一套房子已经很不错了，反正我能住，先解决眼前问题吧。对，可能解决眼前的问题了，但是从法理上和税收理论上来说，这是一个不合理的。所以我也觉得，它并不能解决市场的问题。 房地产税，路还很远 还有一个关心的问题，就是房产税。今年我们两会期间有一个财政部的副部长回答了记者的提问，记者说我们能不能像国外的私有土地那样收取房产税，这个副部长告诉他，中国从来没有收过这样的房产税。我觉得这个副部长是不太懂，没看过中国的税法，他不知道1951年的时候，1949年的时候我们是房产税是房产税，地税是地税，1951年的时候把房产税和地产税合并了，叫做房地产税，那个时候土地和国际一样是私有产权的。 如果我们的财政部长在回答人民代表提问的时候都不知道自己国家发生的历史，我想他一定是搞错了，这个副部长，如果我是总理一定把他撤了。1951年以后为什么不收了？因为公私合营以后没有私人房屋了，全都是公家的了。因此，房产税没人收了，没法收了，收谁的？收不了了，所以他就取消了。 取消以后变成了什么？就变成了工商税，变成了城市维护事业税，附加税，土地使用金，土地出让使用税，耕地占用税等等。现在我们列出来七八个税种，都是属于房产这个范围之内。 因为凡是收了房产税的，都不能收其这类的税，房产税你都收了，不就是改善环境吗？维护城市的，你还能收绿化税吗？类似的情况很多。现在的情况下，2011年的时候楼继伟当财政部副部长提出建立物业税的时候，或者是我们房产税初期的时候就提出，要减去相应的税费。 但是现在后头这句话都被人抹了，他们总想在不减现有税的情况下加税，这是不可能的，老百姓一定会造反。 但是如果减了一些税，再征，能不能解决现在的土地财政问题？解决不了。不懂行的人以为，房产税还能替代土地出让金、财政问题解决不了，土地出让金70年的一次性支付相当于永久性的土地费，它是复利计算的。可是你要把它分成70年收，政府兜里一下子就没钱了，所以替代不了地方税。 回答记者问的时候，他提出通过房产税来调紧税负公平问题，如果要现在收房产税，税负是极不公平的。 第一，现有的房产税已经很重了，所以你要先取消再收才合理，否则就是税上加税。 第二，原有房屋的价格构成是不一样的，有的交了土地出让金，有的没交土地出让金，我们的商品房占总房量的多少呢？30%多。也就是说70%多的房子，60%多的房子，接近70%的房子是没有交土地出让金的房子，你能一并收税吗？你要一并收税的话，可能就会出现很多麻烦。 我们还可以看到有的交了大市政费，基础设施费，什么什么一大堆，有的没交。有的房改房是交了土地出让金的房子，商品房改成了房改房，有的不是，是原来分配的住房改房。 这里头的构成矛盾很多。最重要的是，我们的房改文件1997年23号文件，朱镕基当时出台的房改文件里头有一句话，叫老人老办法，新人新办法。那今天你要统一收税，人家说了，文件上写着，我老板得老办法，你怎么能按新人新办法解决呢？所以统一实行这种房产税，几乎是不可能的。 有人老问，房产税出台，房产税出台了，也就是他们吹吹吧。 另外一个是取得房屋产权的方式不一样，有人是花钱取得，有人是分配取得，有人拆迁取得的，有的是经济适用住房转换成商品房的，但是他没交土地房产税。有的是各种各样的房子，还有自建房，原来的私有产权房等等一大堆，你怎么把它统一分配呢？ 我们最低收入者人群里头，拥有的私有产权，拥有第二套产权房的也有7%。他们的房子大半在老城区，房子很破，但是学区房卖的很贵。你要按他的卖价收他的房产税的话，老百姓交不起，所以几乎是不可能的。 房地产税与租售并举矛盾 同时，税收一定是大大提高了租赁标准，和你这个租售并举是违背的，这两个是相悖的。靠税收去提高租金，老百姓更租不起房子，这是一个很麻烦的事情。我也不认为房产税能解决房价问题，能解决供应性问题，能解决任何问题。 为什么？因为我们历史的发展阶段不一样。国外为什么行呢？因为他一直是市场经济，土地私有制，所以不管他取得的房价是多少，他的规矩是一样的。我们的规则不一样，因为我们有住房分配制的，有住房房改制的，有大量的市政基础设施拆迁阶段的，有住房改革阶段，有商品化的阶段，有非商品化的阶段。 最初的商品化是划拨土地而形成的，后来的商品房土地办理土地出让制度形成的，然后就变成土地招牌挂制度形成的，所以各种取得方式是完全不同的。 你现在要统一市场评估的方式解决，一定会出乱子的，大家就会拿原来的房产证，原来的土地取得条件，或者房屋取得条件跟你打官司，为什么他的和我的是一样？我的成本比他高多了，或者我的成本比他低多了等等，法院以后就变成集市了。所以我估计，要这样说的话，税务比现在的军队要扩大3倍到4倍才能忙得过来。 空置税可解决租赁住房问题 因此在不改变现有双轨制的一些条件下，我个人觉得用市场化的办法解决问题是最好的，不是限制个人买房子，而是鼓励大家买房子。你买第三套、第四套、第五套、第六套都行，买的越多越好。 但是我要加你一个空置税，香港、德国，很多国家都是用这种方法。只要你的房子是为了住的，不是为了炒的，那你就让里头有人住，你不要空置半年以上我就要收你的税。 所以他的房子里有人住，有人住你不就达到了房子是用来住的目的了吗？但是人们为什么要把它用于出租呢？就是因为你减税，德国就是这样的，他用减税的方式控制房价，同时用减税的方式，用政府补贴让穷人有房子租。 意大利也同样，你要拿着住房券放的时候，政府给你减免个人所得税。所以那个住房券租房子的时候，你比市场的房价要低得多，租房价要低得多，可是减免你的个人所得税，它能交换。所以用市场化的办法，完全不需要政府大量的盖房子，可以解决我们租赁市场的问题。 很多，比如说美国，美国有一个网站叫空中食宿，它就是专门用于租赁住房的一个软件。上了这个网以后，你说我今天从北京到杭州开会，我家里的房子就可以用来租，租两天，我开两天会，那个房子租两天。它就收到很高，比酒店便宜，但是比一般的旅馆费用要高得多，因为所有的条件都很方便。 在欧洲这种以家庭方式进行短租，住一天两天、一个礼拜、两个礼拜的，这种房子多得一塌糊涂。所以空中食宿，就用这种方式成为了现在在美国非常受欢迎的一个网站，但是它也有很多官司，但是它有利的解决了这些问题。 比如说旧金山、硅谷，它的租赁住房是不够的，空中食宿就把原来的整体租赁房，整栋整栋的给你租了，然后变成时租，因为来往的人员太多了。所以中国完全可以扩大租赁市场，用市场化的办法去解决我们现在存在的一些矛盾。 长效机制很难建立 倒过来说，如果要用长效机制彻底解决中国的问题，那么就要解决的是土地制度问题，户籍制度问题。那么矛盾就在于，我们的短期政策不利于长期机制的建立，你没法解决土地制度问题，也没法解决户籍制度问题。 他们的矛盾在哪？我们今年出台了一号文件，农民的土地承包再增加30年，很多人就欢呼，真好，农民又可以多用土地30年了。但是很多农民在发愁，因为你只给我30年，我是不能修长期的基础设施的，因为我修这些基础设施，可能要用40年、50年，你只给我30年，我怎么敢修呢？ 中国严格说起来是没有私有产权制的，因为我们没有土地的私有化。你们现在都是有钱人，但是你们都叫浮财，你们自己想想，你们能生根落地吗？过两年把你的房子收了，都是浮财。 只有土地变成私有制的时候，我们才能谈得上中国的长期的住房制度和农民与城市人口利益相一致的制度，这样才能最终解决问题。否则，如果户籍制度和土地制度问题不从根本上解决，我们很难建立一套长效机制，你仍然是城里人只解决城里的住房，然后农村人进住房的时候，你就左卡右卡，反正不让他进来，然后他的孩子也不能上学，也不能享受医疗保障等等。 我们的十九大提出，要人类命运共同体，中国人首先得形成共同体，如果中国人连共同体都没有，你怎么能实现世界人的共同体？所以十九大已经提出了很多很多重要的，非常好的报告，但是问题在于哪呢？问题在于，我们的地方政策没有跟上十九大报告，造成了房地产出现了很多的问题。历史上凡是单一政策试图解决单一问题的时候，大部分都适得其反。 “单一政策”往往事与愿违 我们可以讲两个笑话，一个是布莱尔当英国首相的时候出台了一个政策，叫医生必须在48个小时给预约的病人看病，他们都能电话预约私人医生。布莱尔出来的这个政策，非常明确的要保护病人。 最后的结果是什么样的你们能想象到吗？所有的医生都取消了电话预约。为什么？医生的良心过不去，因为医生如果把所有的病人填满他的就医时间，临时出现了撞车、生病的这些病人，生命就会出现危险，不然他就违法了，因为布莱尔出的是法。 他到时候说，我要给临时得病的病人看病的时候，那个约的病人不干了，告你。所以他干脆为了保证临时可能出现的这些治病需要，我就所有的预约全取消了，我宁愿没有预约病人。医生的道德真好，所以他就把布莱尔这个临时性的单向措施彻底打败了。 第二，去年年底说台湾的行政院出台了一项政策，为了保护劳工的利益，劳工的加班费要从一个小时2倍的工资变成一个小时4倍的工资，蔡英文很科学的告诉你，我要保护劳动人民的利益。 从此以后，没有一个人雇原来的员工加班了，所有的工厂主都说我雇临时工，我不雇这个员工，这个员工来了叫做加班，所以过去我给2倍工资还行，现在你让我给4倍工资我不用他了，我宁愿到市场上找一个临时工来给我干一天，干两天，因为这个临时工不是按加班算的，因为他就干这两天。 所以单一政策通常在市场当中是悖论，所有的好心都会变成坏事，员工也很苦，也很生气，你这个政策真烂，原来我还能拿2倍工资，现在我连1倍工资也拿不着了。最后台湾行政院做了修改，修改法律。 所以当一个政府试图用单一政策，出于好心解决某一单一问题的时候，通常是悖论。我们如果用市场中的方法解决这种房价，你使劲按着，不用市场化的办法解决问题我觉得是适得其反，也不可能建立长效机制，我就讲这么多，谢谢。我再说一遍，你们千万别给我传出去，我都被问过了。 谢谢大家，我的演讲完了，这些仅代表我个人观点。 转载来源：任志强房地产最新演讲：现在是抄底的机会，但这些地方不能碰]]></content>
  </entry>
  <entry>
    <title><![CDATA[魏则西去世两年了，“医疗竞价”却死灰复燃，怎样才能让百度们长记性？]]></title>
    <url>%2F2018%2F61938f2a%2F</url>
    <content type="text"><![CDATA[是否以用户利益为先，我们不得而知，但可以确定，百度对“竞价排名”，恐怕是真爱。老毛病又犯了2016年，魏则西用生命换来了公众对“医疗竞价排名”的声讨，那一场声势浩大的讨论，想必大家记忆犹新。 转载来源：魏则西去世两年了，“医疗竞价”却死灰复燃，怎样才能让百度们长记性？]]></content>
  </entry>
  <entry>
    <title><![CDATA[个人电脑上训练深度学习模型：Uber开源「深度神经进化」加速版]]></title>
    <url>%2F2018%2Fc974d65d%2F</url>
    <content type="text"><![CDATA[通过使用遗传算法高效演化DNN，可以训练含有超过400万参数的深度卷积网络在像素级别上玩Atari游戏。 Uber 在去年底发表的研究中发现，通过使用遗传算法高效演化 DNN，可以训练含有超过 400 万参数的深度卷积网络在像素级别上玩 Atari 游戏；这种方式在许多游戏中比现代深度强化学习算法或进化策略表现得更好，同时由于更好的并行化能达到更快的速度。不过这种方法虽好但当时对于硬件的要求很高，近日 Uber 新的开源项目解决了这一问题，其代码可以让一台普通计算机在 4 个小时内训练好用于 Atari 游戏的深度学习模型。现在，技术爱好者们也可以接触这一前沿研究领域了。 项目 GitHub 地址：https&#58;//github.com/uber-common/deep-neuroevolution/tree/master/gpu_implementation Uber 去年底曾发表了五篇有关深度神经进化的论文，其中包括遗传算法可以解决深度强化学习问题的发现，以及一些有前景的其他方式，如深度 Q 学习和策略梯度。这些工作是 Salimans 等人 2017 年研究《Evolution Strategies as a Scalable Alternative to Reinforcement Learning》的后续，后者展示了另一种神经进化算法进化策略（ES）的能力。Uber 进一步介绍了如何通过添加探索新奇的智能体来改进 ES（论文《Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents》），以及 ES 与梯度下降的相关性。所有这些研究在此前都是非常耗费计算资源的：需要使用 720-3000 块 CPU，在分布式大型高性能计算机集群上运行，这为大多数研究者、学生、公司和爱好者对深度神经进化的进一步探索带来了阻力。 不过这一问题最近已经得到了解决，Uber 于昨日开源的新代码使得快捷方便地展开此类研究成为可能。有了新的代码，原先需要花费 720 个 CPU、一个小时训练的 Atari 游戏深度神经网络，现在只需要在常见的台式机上单机花费 4 个小时就可以完成训练了。这是一个非常重要的进展，它极大地改变了人们对于此类研究所需资源的看法，使得更多研究者们可以进入这一领域。 神经进化技术是解决具有挑战性的深度强化学习问题颇具竞争力的方案，其可用范围包括 Atari 游戏、类人体仿真运动等等。上图展示了使用简单遗传算法进行深度神经网络训练的一些形式。 什么使其速度加快，并且可在一台计算机上运行？ 现代的高端计算机具备数十个虚拟核，这种计算机本身就像一个计算集群。如果采用适当的方式执行并行评估，那么在 720 个内核上耗时一小时的运行可在一个 48 核的个人计算机上运行，耗时 16 小时，速度较慢，但是也还可以。现代计算机还有 GPU，因此可以较快运行深度神经网络（DNN）。Uber 的代码最大化 CPU 和 GPU 的并行使用。在 GPU 上运行深度神经网络，在 CPU 上运行域（如视频游戏或物理模拟器），并且在同一批次中并行执行多个评估，这使得所有可用的硬件都得到高效利用。如下所述，它还包含自定义 TensorFlow 操作，极大地提高了训练速度。 在 GPU 上训练需要对神经网络操作的计算方式进行若干修改。在 Uber 的设置中，使用单个 CPU 运行单个神经网络的速度比使用单个 GPU 要快，但是当并行执行类似计算时（如神经网络的前向传播），GPU 的效果更好。为了利用 GPU，Uber 将多个神经网络前向传播集成到批次中。这种做法在神经网络研究中很常见，但是通常是同一个神经网络处理一批不同输入。但是 Uber 的做法使用的是多个不同的神经网络，不过即使网络不同，该操作仍然实现了加速（对内存的要求也提高了）。Uber 使用 TensorFlow 基础操作实现了多个神经网络批次处理，并实现了大约 2 倍的加速，将训练时间降低到大约 8 小时。但是，研究人员认为他们可以做得更好。尽管 TensorFlow 提供所有需要的操作，但是这些操作并不是为这种计算量身定做的。因此，Uber 添加了两种自定义 TensorFlow 操作，由此再次获得了 2 倍的加速，将在单个计算机上的训练时间减少到大约 4 小时。 第一个自定义 TensorFlow 操作大大加速了 GPU 的速度。它专为强化学习领域中异质神经网络计算而开发，这些计算中的 episode 长度不同，正如在 Atari 和很多其他仿真机器人学习任务中那样。该操作使 GPU 仅运行必须运行的神经网络，而不是每次迭代中都运行固定数量（大量）的神经网络。 这些改进使得 GPU 在成本方面优于 CPU。实际上，GPU 非常快，Atari 模拟（CPU）都跟不上了，即使使用了多进程库执行计算并行化。为了改进模拟性能，Uber 添加了第二套自定义 TensorFlow 操作，将 Atari 模拟的封装器从 Python 转到了自定义 TensorFlow 命令（重置、step、观测），便于利用 TensorFlow 提供的快速多线程功能，省略了 Python 和 TensorFlow 交互造成的减速。所有这些改变带来了 Atari 模拟器中大约 3 倍的加速。这些创新应该会加速任意具备多个并行运行实例的强化学习研究（如 Atari 或 MuJoCo 物理模拟器），该技术在强化学习领域中将越来越普遍，如分布式深度 Q 学习（DQN）和分布式策略梯度（如 A3C）。 一旦我们可以在 GPU 上快速运行多个不同神经网络，在 CPU 上运行更快速的模拟器，那么挑战就变成了尽可能地保存所有计算机运行的资源。如果我们在每个神经网络中都执行了前向传播，询问每个网络在当前状态下应该采取什么动作，那么尽管每个神经网络都在计算自己的答案，但是运行游戏模拟器的 CPU 什么也没做。类似地，如果我们执行了动作，并询问模拟器「这些动作会导致什么状态？」，那么运行神经网络的 GPU 在该模拟步中就处于空闲状态。这就是多线程 CPU+GPU option（如下图所示）。尽管单线程计算出现改进，但这仍然是无效的。 更好的解决方案是具备两个及以上与模拟器配对的神经网络子集，并使 GPU 和 CPU 在更新网络或根据即将采取的步骤（神经网络或模拟）而执行的来自不同集的模拟时同时运行。该方法如下最右图「pipelined CPU+GPU」所示。使用它以及上述改进，我们可以使具备 ~4M 参数的神经网络的训练时间降低到单个计算机大约 4 小时。 在强化学习中优化异质网络集群的调度。蓝色框是模拟器，如 Atari 游戏模拟器或 MuJoCo 物理引擎，它们的 episode 长度不同。使用 GPU 的普通方式（左）性能较差，原因有二：1）GPU 的批大小无法利用其并行计算能力；2）GPU 等待 CPU 时的空闲时间，反之亦然。多线程方法（中）通过使多个 CPU 并行运行模拟器实现 GPU 的更高效使用，但是这导致 GPU 在 CPU 运行时处于空闲状态，反之亦然。Uber 提出的流水线型实现（右）允许 GPU 和 CPU 都高效运行。该方法还可以同时运行多个 GPU 和 CPU，这已经应用于实践中。 快速、低成本实验的影响 Uber 的代码能够帮助研究社区中的每个参与者，包括学生和自学者快速上手试验性地迭代训练深度神经网络，研究各种具有挑战性的问题，如 Atari 游戏智能体。在此之前，只有财力雄厚的行业和学界实验室可以这样做。 快速的代码可以带来更快的研究进展。例如，Uber 的新代码可以用很少的成本对遗传算法启动广泛的超参数搜索，带来了大多数 Atari 游戏模拟器的性能提升。Uber 表示会在近期更新其在 arXiv 上发表的研究《Deep Neuroevolution&#58; Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning》中的测试结果。更快的代码也加快了研究进度，通过缩短迭代时间来改进深度神经进化，使我们能够在更多的领域尝试每个新想法，并延长算法的运行时间。 Uber 的新软件中包含了深度遗传算法的实现、Salimans 等人的进化策略算法，以及 Uber 自己的随机搜索方法。Uber 欢迎研究社区的贡献者使用这些代码，并对这些代码进行进一步改进。例如，进行分布式 GPU 训练或加入为此类计算定制的其他 TensorFlow 操作——这可能会进一步提高速度。 深度神经进化的方向还有很多可以探索的东西，除了前面提到的 Uber 的研究、OpenAI 的工作以外，近期还有使用 DeepMind、Google Brain 和 Sentient 的进化算法带来的深度学习研究进展。Uber 希望通过通过此次开源进一步降低该领域的进入门槛。 最重要的是，这一工具可以降低研究成本，让各类背景的研究人员都能在其上尝试自己的想法，以改善深度神经进化并利用它实现自己的目标。 转载来源：个人电脑上训练深度学习模型：Uber开源「深度神经进化」加速版]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>Uber</tag>
        <tag>雅达利</tag>
        <tag>CPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[店员经典培训教材：发烧用布洛芬还是对乙酰氨基酚]]></title>
    <url>%2F2018%2Fe6add368%2F</url>
    <content type="text"><![CDATA[一般认为人体当口腔温度高于37.5 ℃，腋窝温度高于37℃，或一日之间体温相差在1℃以上，即为发烧。 作者：海浪 发烧，又称发热。是指致热原直接作用于体温调节中枢、体温中枢功能紊乱或各种原因引起的产热过多、散热减少，导致体温升高超过正常范围的情况。 一般认为人体当口腔温度高于37.5 ℃，腋窝温度高于37℃，或一日之间体温相差在1℃以上，即为发烧。发烧是疾病进展过程中的重要临床症状表现，可由多种感染性疾病和非感染性疾病引起。 发热本身不是疾病，而是一种机体自我保护机制，一种症状表现。发烧时体温升高，有些病源微生物活性和繁殖就会变得不那么活跃。而人体的免疫系统反应性则显著增强，包括白细胞计数增加，吞噬细胞和嗜中性粒细胞的杀菌活性增强等。发烧是人体进化获得的一种对抗病原微生物感染入侵的有益的保护性机制，对人体是有利的。 通常，测量体温未超过38.5℃时，不推荐马上服用退烧药。应尽量用物理降温的方式来减少不适感。但尽管采用物理降温仍需警惕超高温，当体温超过38.5℃时，或肛温大于41.5℃，或口温大于40℃，对人体的危害是很大的，特别是儿童。当出现高烧时，应及时看医生做出病因查找和对症治疗。 在常用退烧药中，布洛芬和对乙酰氨基酚是目前应用最广泛的两个OTC类药品，它们也是目前认为最适合儿童使用的退热药。可是，二者由于分子结构、作用特点、不良反应存在着明显的差别，该如何正确选择充分发挥药效呢？ 一、布洛芬和对乙酰氨基酚是同一类退热药吗？ 1. 布洛芬 布洛芬属于芳基丙酸类解热镇痛药，有明显的抗炎、解热、镇痛作用，强度与阿司匹林相当，对血小板功能有一定的抑制作用，可延长出血时间，但在常规治疗剂量使用时，不良反应发生率低，耐受性与对乙酰氨基酚相似。 布洛芬是世界卫生组织、美国FDA唯一共同推荐的儿童退烧药，是公认的儿童首选抗炎药。常见的以布洛芬为有效成分的药品有芬必得、美林等。 2. 对乙酰氨基酚 对乙酰氨基酚又称扑热息痛、泰诺林、必理通等为苯胺类解热镇痛药，其解热、镇痛作用强度与阿司匹林类似，但对凝血机制无影响，其抗炎作用也远不及布洛芬。 对乙酰氨基酚毒副作用少，较易耐受，是一种比较安全的退热药，很多复方制剂的感冒药里都含有它。 二、布洛芬和对乙酰氨基酚在抗炎、镇痛、解热功能方面的区别|适应症/功能主治|布洛芬|对乙酰氨基酚 布洛芬|头痛、偏头痛、牙痛、肌肉痛、神经痛、咽喉痛、痛经|对痛经更适合|对头痛更适合 对痛经更适合|腹痛|不适合|不适合 不适合|消炎作用|风湿性关节炎和骨关节炎，对与炎症相关的窦性头痛、肌肉痛、耳痛、牙痛效果好|没有消炎作用（弱的环氧酶抑制剂，不能抑制中性粒细胞的激活） 风湿性关节炎和骨关节炎，对与炎症相关的窦性头痛、肌肉痛、耳痛、牙痛效果好|退热时间|最大退热时间：183分钟|最大退热时间：134分钟（在30分钟时的体温下降速度比布洛芬更明显） 最大退热时间：183分钟 三、布洛芬和对乙酰氨基酚在毒副作用方面的区别 1、毒性方面：对乙酰氨基酚用量过大可能导致肝损害，且是不可逆损伤，在超剂量、脱水、营养不良情况下服用，肝损害风险会增加，长期大量用药也可导致肾功能异常。布洛芬长期使用可能造成肾损伤、心脏病发作和卒中，超剂量、脱水情况下，肾损害风险增加。 2、副作用方面：对乙酰氨基酚对胃肠副作用较少，对血小板、出血时间、尿酸排泄无影响。而布洛芬可导致胃溃疡出血、胃烧灼感、轻度消化不良，改变血小板功能、延长出血时间。 四、布洛芬和对乙酰氨基酚在适用年龄范围、剂型和用法用量方面的区别 1、适用年龄范围：对乙酰氨基酚适用于＞3个月的儿童和成人，布洛芬适合＞6个月的儿童和成人。 2、药物剂型：对乙酰氨基酚市售的有对乙酰氨基酚片、对乙酰氨基酚缓释片、对乙酰氨基酚泡腾片、对乙酰氨基酚颗粒、对乙酰氨基酚滴剂、对乙酰氨基酚口服溶液，对乙酰氨基酚栓等。布洛芬市售的有布洛芬片、布洛芬缓释片、布洛芬胶囊、布洛芬缓释胶囊、布洛芬颗粒、布洛芬悬浊液、布洛芬乳膏、布洛芬口服液、布洛芬栓等。医生或药师会根据患者身体状况、疾病特点选择合适的药物剂型。 3、用法用量：若持续疼痛或发热，对乙酰氨基酚可餐前服用，每4-6小时服一次，24小时内不得超过4次，儿童每次最大剂量：15mg/kg，日最大剂量为2g。而布洛芬需随餐或餐后服用，12岁以上儿童及成人一次2片，若持续疼痛或发热，可间隔4～6小时重复用药1次，24小时不超过4次，具体布洛芬用量见下表：|年龄（岁）|体重（公斤）|一次用量（片）|次数 体重（公斤） 次数|1～3|10～15|1/2若持续疼痛或发热，可间隔4～6小时重复用药1次，24小时不超过4次。 10～15 若持续疼痛或发热，可间隔4～6小时重复用药1次，24小时不超过4次。|4～6|16～21|1 16～21|7～9|22～27|1.5 22～27|10～12|28～32|2 28～32 五、使用布洛芬和对乙酰氨基酚的注意事项有哪些？ 1. 布洛芬 有消化性溃疡史、胃肠道出血、心功能不全、肝肾功能不全、高血压、凝血机制或血小板功能障碍（如血友病）的患者应慎用。布洛芬与阿司匹林有交叉过敏，故对阿司匹林过敏的患者禁用。脱水或水分补充不够等低血容量的患者使用布洛芬退热可增加肾功能损害的风险。 罹患水痘的患者使用布洛芬则可增加 A 组链球菌感染的风险。 2. 对乙酰氨基酚 对阿司匹林过敏者对对乙酰氨基酚通常不发生过敏，但＜5%的阿司匹林过敏的患者服用对乙酰氨基酚后可能会发生轻度支气管痉挛性反应。不要服用超过一种含有对乙酰氨基酚的药物，特别是含对乙酰氨基酚的复方制剂感冒药，服用药品前应仔细阅读说明书中成份组成部分，避免因重复用药而使对乙酰氨基酚过量，否则可能引起头痛、呕吐、倦怠低血压及皮疹等。严重肝肾功能不全者禁用；肝病或病毒性肝炎、轻至中度肝肾功能不全者、严重心肺疾病患者应慎用；如果出现黄疸症状需立即进行肝功能测试。如果是混悬液，用前要上下摇晃，使之搅拌均匀，使用产品包装中的量杯或容器来取相应的剂量。 综上，布洛芬和对乙酰氨基酚各有优缺，要严格按照临床医师或药师吩咐合理选择药物，使用二者任何一种时，不能同时服用其他含有解热镇痛药的药品（如某些复方抗感冒药）。 长按上图3秒钟，识别二维码关注 亲，中国药店公众号长期公开征集稿件，如您欲抒发心声、记录生活、分享经验……可以文字或图片形式将作品发送到yaodian2018&#64;163.com（邮箱），稿费=200元+阅读量*0.01元。温馨提示，投稿时请注明联系方式 喜欢的话就点赞吧！↙ 转载来源：店员经典培训教材：发烧用布洛芬还是对乙酰氨基酚]]></content>
      <categories>
        <category>健康</category>
      </categories>
      <tags>
        <tag>药品</tag>
        <tag>高血压</tag>
        <tag>低血压</tag>
        <tag>黄疸</tag>
        <tag>痛经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[九价宫颈癌疫苗冲刺内地上市：默沙东提交的申请已获受理]]></title>
    <url>%2F2018%2Fe6852184%2F</url>
    <content type="text"><![CDATA[美国药企默沙东提交的九价HPV疫苗上市申请已经在4月20日获得了受理，该药品目前的办理状态为“审评审批中”。 九价宫颈癌（HPV）疫苗在中国内地上市的脚步越来越近了。 4月24日，澎湃新闻（www.thepaper.cn）记者在国家食药监局药品审评中心的网站上查询到，美国药企默沙东提交的九价HPV疫苗上市申请已经在4月20日获得了受理，该药品目前的办理状态为“审评审批中”。 宫颈癌是仅次于卵巢癌的女性生殖道恶性肿瘤，全球每年新发病例近60万，死亡约30万。中国每年新增病例约13.5万，其中8万人因此死亡。而99.7%的宫颈癌都是由HPV病毒感染所引起。 公开资料显示，默沙东的佳达修九价HPV疫苗于2014年在美国获批上市，其可接种的年龄为9-26岁，该疫苗可预防90%的宫颈癌病毒。默沙东的佳达修九价，于2017年11月在国内获批临床，至本次上市申请获得受理只用了不到半年的时间。 2006年香港成为中国最早开放接种宫颈癌疫苗的地区，而直到去年宫颈癌疫苗才开始在中国内地正式上市。目前内地上市的产品为英国葛兰素史克生产的希瑞适二价疫苗和默沙东的佳达修四价疫苗，而香港更为普及的则是默沙东的九价产品。 价代表的是病毒覆盖的范围，价越高，覆盖的病毒亚种越多，疫苗的预防性就越好。高危型HPV的持续感染是宫颈癌的主要病因。HPV系乳头瘤病毒科旗下的DNA病毒，以人为唯一宿主，最喜爱安家的部位是皮肤和黏膜。研究表明有15种高危型HPV——尤其是编号为16和18的两种——会导致宫颈癌癌前病变及宫颈癌的发生。HPV二价疫苗就可以预防16、18两种HPV病毒；HPV四价疫苗则可用于预防6、11、16、18四种HPV病毒亚型；HPV9价疫苗，则在原有四价的基础上新增了31、33、45、52和58五种HPV病毒亚型，对病毒的覆盖面也达到了90%。 这导致在很长一段时间内，前往香港接种疫苗的内地游客络绎不绝。 方正证券的研报分析指出，预防宫颈癌市场，至少有百亿市场。之前每年有近200万人到香港注射疫苗。有专家预计，每年新增1600多万人口中800万女性，假设50%接种宫颈癌疫苗，在市场稳定后每年能带来40亿元的市场规模。 不过，佳达修九价要在内地正式上市，还要等待监管部门的最终审评审批。 此前，北京大学人民医院知名妇科专家魏丽惠教授接受澎湃新闻采访时表示，从对宫颈癌的预防效果上来说，二价和四价的疫苗几乎没有区别。对于目标接种人群，应当在有接种条件的情况下尽早接种，不要因为等待错过了最佳接种时间。 转载来源：九价宫颈癌疫苗冲刺内地上市：默沙东提交的申请已获受理]]></content>
      <categories>
        <category>健康</category>
      </categories>
      <tags>
        <tag>癌症</tag>
        <tag>药品</tag>
        <tag>默克药厂</tag>
        <tag>卵巢癌</tag>
        <tag>魏丽惠</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让用户自愿转发推荐你的产品？]]></title>
    <url>%2F2018%2F482ec1d7%2F</url>
    <content type="text"><![CDATA[如果你的产品是C端产品，那么你一定能发现，在所有用户购买的转化渠道中，亲朋好友推荐一定是占比最高的且最为重要的。 怎么样才能用户自愿转发推荐你的产品呢？在转化渠道中，哪一条占比是最高的呢？那一个品牌应该从哪些方面着手，使得推广更加有效呢？ 如果你的产品是C端产品，那么你一定能发现，在所有用户购买的转化渠道中，亲朋好友推荐一定是占比最高的且最为重要的。比起在电视上看到的商品广告，用户更容易相信好友推荐的产品，尽管后者可能是个默默无闻的品牌。 好友推荐以往都是经过街坊邻里的口口相传的方式进行着，但对于品牌方的难处在于——品牌难以介入这种亲友推荐的营销模式中。 但移动互联网的兴起，让好友之间的信息分享变得更加快捷且可监测，品牌信息的转发，让品牌方能够介入亲友推荐这一自古以来都是最为重要的转化渠道中。 因此逻辑就是——要促进产品更有效的销售转化，就需要促进熟人关系之间产品信息的分享转发。 那么，品牌方可以从以下两个方面入手： 一、品牌内容打造，给用户转发素材有时候用户并不是觉得转发品牌信息会影响其朋友圈的个人形象，而是品牌方没有提供足够的内容让用户拥有转发的素材。用户都是十分懒惰的，不会为了转发你的品牌信息而绞尽脑汁地去拍照修图想转发语，恨不得让你直接给他们现成的文案和图片，他们只要无脑复制就行。 也就是说：不是用户不愿意转发分享，而是你没有提供相应素材，你让用户去花脑力自发帮你做传播，出发产品确实很惊艳，否则是非常难的。 那么，品牌方要做的就是在内容打造上着力，让用户能够更容易对品牌信息进行转发分享。可以从以下两个方面着手： 1. 内容多样化，满足不同的转发需求总体来说品牌方的内容分为两个类型： 一类是销售类信息，比如说优惠券、优惠活动等信息，能够给产品带来直接转化的；- 另一类是品牌类信息，比如说感性的、情绪化的主张，能够给品牌带来长期溢价的。而用户在微信端有两个不同的分享渠道： 第一个是熟人间的好友分享，更多是基于强社交关系链的人群之间，比如家人、闺蜜群、寝室群、好友等；- 第二是朋友圈的分享转发，更多可以看做自媒体的信息发布，基于弱社交关系链的信息分享，单向发布生活状态，微博、抖音等平台也是如此。那么在品牌内容打造上，可以分别针对用户分享的不同渠道做不同内容的打造： 1）接地气的好友分享 针对强关系链中的好友分享，更多需要接地气的内容。因为在这种强关系链中，双方十分熟悉，可以去除人设伪装，直接对话分享，所以更需要直接了当尽快进入正题。 那么在这个场景之下，品牌方更多可以做一些娱乐化“魔性”的内容以及优惠类内容。 人们往往会在意自己在大众眼中的形象，所以即使看到有趣的内容，也会较为介意内容过于通俗化对自身人设形象的损害。看到优惠信息时即使有转发冲动，也会担心转朋友圈是否会对自身人格形象的档次拉低。因此，段子类内容和优惠分享更多存在与好友之间、熟人群之间的转发。 2）高大上的朋友圈分享 与强关系链的分享转发不同，弱关系链中人们会更在意自身人格形象的塑造。无论是在微信朋友圈，还是微博、抖音等自媒体属性渠道中，我们都很少能看到优惠类信息的转发。而更多的是美美的照片，高大上的生活方式，这并不是他们不会转发优惠信息和段子内容，而是渠道让他们做出了内容选择。 但正因为朋友圈等自媒体渠道的个人覆盖面会更广，所以品牌方也需要针对朋友圈的转发内容做出相应规划。大到具有品质感的宣传片，小到每日金句类的打卡日签，或者精美漂亮的文案及海报，都能让用户产生转发朋友圈的欲望，以维持朋友圈中的个人形象。 另一类是有趣但不低俗的内容也容易引发朋友圈的转发，比如：用漫画创作的图文、抖音上有趣的视频等。不低俗是基本，而有趣是营造品牌亲和力并制造槽点，给用户转发分享一个明确的分享点。 2. 内容模板化，让用户自发生产素材除了品牌方制作的原生内容外，用户自发生产的内容对于品牌方意义重大。它能够让品牌方在小投入下曝光指数级的增长，但许多品牌都希望能够让用户生产内容，成功案例并不多。 1）内容模块化 想让用户生产内容，一方面需要品牌方的传播内容模块化，并且足够简单。我们都能看到“友谊的小船”漫画的二次创作刷遍了全网，除了社会情绪等外在原因外，其核心在于该漫画非常容易规模化复制，只需要添加两句文案就可以成为一个新的内容。 模块化的内容让用户大大减少了学习成本，正因为创作门槛的降低，让用户有兴趣去尝试，而用户对于自己创作的东西是天然会有转发动力的，在转发的过程中也就增加了你的品牌曝光度。 2）专业化内容引导 每一个传播案例都会面临着初始投放的问题，而相对于内容生产而言，要想引导用户自发生产内容，品牌方需要准备大量的专业化生产内容，也就是通过PGC带动UGC。 通过品牌方专业化生产的内容，可以给用户一个示范效应，当你的初始用户达到一定量级或品牌方生产的内容达到一定数量时，就容易引发用户跟风式的内容创作。 另外，品牌方专业化生产的内容相对于大多数用户生产内容会质量更高，也更具有传播价值。 二、产品超预期，制造体验惊喜产品本身会是用户转发的最强动力，你的产品如果足够优秀，用户都会自发分享转发。归结到底，用户买的是你的产品或服务，产品的好坏本质上决定着用户的需求有没有被满足，给用户惊喜，便能让用户超出期待，事实上类似一种“捡到便宜”的心态，花了一定的成本却得到超过计划的产品，这样会让用户自发与好友分享。 其实产品超预期已经不是什么新鲜事，但也有几个要注意的点容易被忽略： 1. 100分才是及格线在今天产品过剩的时代，用户在每个领域都有大量的产品可以选择，产品达到100分仅仅是个及格线，并没有什么值得分享转发的。 这里所说的100分就是能够很好地完成产品应该有的功能，比如说：你卖的是洗衣服，把衣服洗得很干净并不是什么值得用户转发的事情。产品功能的本身的好坏并已经不是转发动力了，产品要达到该有的效果只是好产品的起跑线而已。 要让用户自发分享产品信息，必须有超出100分的体验，比如说：你的洗衣粉能够比别家更快的洗干净，别的品牌可能需要洗40分钟才能洗干净，你的只需要20分钟就可以达到同样的效果，这才是超出预期的产品。 这里面又涉及到一个锚定点的设定问题，即什么才是100分产品？ 这个解释往往是来自品牌对外宣传口径中，品牌对外向消费者保证的产品功效就是你产品的100分，达到你所保证的仅仅是及格。再比如：上面那个洗衣粉的例子，如果你的宣传物料中写到20分钟洗干净，那么用户在使用时就会以20分钟为锚定点，不会产生新的超预期。 因此，品牌可能需要善用“保留项目”，说出来的one more thing不一定能成为真正的one more thing。在对外宣传中并不主打的惊喜点，这可能会成为产品口碑传播的分享点。 2. 体验上的超预期，而非功能上对于超预期而言，更多会在于产品体验上的预期，而非产品功能。事实上，用户购买你的产品是为了解决他的特定需求，用户并不会因为你的产品功能更多而得到更多的好处，有时候产品功能过多的叠加会让用户在使用产品时更疑惑也更有压力，这就是“少就是多“。 堆叠产品功能会使产品体验的下降，用户也许只是想治个流感你非要给他来个全身体检，这会加重用户的负担。 超预期是产品体验上的超预期，从物流速度，到客服态度，再到产品包装，每一个用户体验环节都能制造超预期。但许多超预期的背后是大量固定资本投入与流程优化的结果，并没有看上去那么简单。 3. 性价比不是万能的消费升级的时代，用户对性价比其实并没有以往那么敏感，当然它依旧是一个关键。一般来说，价格的下调能够让用户对产品的期望值下降，从而更容易地达到超预期的体验。但同时，价格的下调也会让用户对产品抱有怀疑态度，这种心理因素的影响，很可能会导致产品体验的错觉。 名创优品就曾表示自己总是被质疑为什么价格那么便宜？是不是产品质量不过关。同样的情况也被众多心理实验及实操案例所证明，比如：一斤智利进口车厘子卖60元你可能觉得物有所值，如果价格降到40元，用户可能就开始抱怨质量问题了，比如：不够甜、易腐烂之类的问题，而事实上产品质量可能并没有明显差别。 总结一下，通过多元化内容的搭建，满足用户各渠道的推荐转发需求，并通过产品体验的超预期，达到用户的自发推荐，你的产品及品牌才能够在当下传播环境中获得更多曝光。 作者：郑卓然（公众号：传播体操），擅长广告文案、新媒体运营，现任某独角兽高级内容运营经理。 本文由 &#64;郑卓然 原创发布于人人都是产品经理。未经许可，禁止转载 题图来自Unsplash，基于CCO协议 转载来源：如何让用户自愿转发推荐你的产品？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>市场营销</tag>
        <tag>自媒体</tag>
        <tag>移动互联网</tag>
        <tag>朋友圈</tag>
        <tag>漫画</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国硬独角兽TOP100：实业科技公司崛起！]]></title>
    <url>%2F2018%2F5f6bd87b%2F</url>
    <content type="text"><![CDATA[一份不一样的独角兽榜单 转载来源：中国硬独角兽TOP100：实业科技公司崛起！]]></content>
      <tags>
        <tag>i黑马</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于 Go 语言的 API 网关 Goku-API-Gateway | 软件推介]]></title>
    <url>%2F2018%2Fd030d96d%2F</url>
    <content type="text"><![CDATA[国内首个开源 Go 语言 API 网关，帮助企业进行 API 服务治理与 API 性能安全维护，为企业数字化赋能。 转载来源：基于 Go 语言的 API 网关 Goku-API-Gateway | 软件推介]]></content>
      <tags>
        <tag>开源中国</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[36氪专访丨马蜂窝首次回应黄轩广告争议：下一个时代属于00后？]]></title>
    <url>%2F2018%2F89af2990%2F</url>
    <content type="text"><![CDATA[对于上市这件事，马蜂窝选择“佛系随缘”。 36氪_让一部分人先看到未来 转载来源：36氪专访丨马蜂窝首次回应黄轩广告争议：下一个时代属于00后？]]></content>
  </entry>
  <entry>
    <title><![CDATA[巧用百度指数进行市场和竞品分析]]></title>
    <url>%2F2018%2F5685d526%2F</url>
    <content type="text"><![CDATA[百度指数，我们并不陌生，但是在大部分产品经理的日常工作中，使用频次并不多。以共享单车为例：1.1市场趋势研究通过在百度指数中搜索“共享单车”关键词，可以查看到该关键词的搜索趋势如下：从以上趋势图可以看出，共享单车的搜索热度大概从2016年10月开始增长。 百度指数，我们并不陌生，但是在大部分产品经理的日常工作中，使用频次并不多。原因可能是觉得它离我们实际工作太遥远，太宏观，没什么用，也不知道如何使用。在这篇文章中，将跟大家分享如何巧用百度指数这个免费的资源，帮助我们完成市场分析、竞品分析等产品经理必须的工作。 要知道如何利用百度指数，首先要知道百度指数到底是什么？有哪些特性？ 百度官方的定义：百度指数是以百度海量网民行为数据为基础的数据分享平台。在这里，你可以研究关键词搜索趋势、洞察网民需求变化、监测媒体舆情趋势、定位数字消费者特征；还可以从行业的角度，分析市场特点。 剖析官方定义，得知百度指数的如下几个属性： 数据来源：网民搜索行为数据；- 数据基础：搜索关键词；- 数据主要应用场景：探索市场趋势、了解用户需求、监测舆情、用户特征分析。针对几个典型的应用场景，结合具体案例，我们一起探索下究竟如何使用百度指数的趋势研究、需求图谱、舆情洞察、人群画像。 1. 趋势研究趋势研究可应用在研究市场趋势和竞品。以共享单车为例： 1.1 市场趋势研究通过在百度指数中搜索“共享单车”关键词，可以查看到该关键词的搜索趋势如下： 从以上趋势图可以看出，共享单车的搜索热度大概从2016年10月开始增长，在2017年2月左右出现爆发式增长，并从2017年7月开始逐步降低，趋于平缓。从关键词的热度趋势我们能大致估计出该行业的热度走势。 此外，我们可以再看看在相同时段内，该关键词的媒体指数，并挖掘出每个时段内值得关注的信息点。如下图： 通过上图可以看出，在2016年～2017年间，关键词“共享单车”的媒体指数与热度趋势基本趋同，说明媒体的报道与用户关注度是相互促进的。而且通过在同一时段最热的媒体报道可以总结出如下信息： 共享单车行业在2016年11月的时候已经进入恶性竞争阶段；- 行业内最强的竞争对手是摩拜和ofo；- 2016年12月共享单车已经出现野蛮生长态势；- 共享单车的管理、回收、监管等问题亟待解决；- 共享单车押金问题存在安全隐患；- ……如果我们要进入共享单车这个领域，以上问题和环境也将是自己面临的，可以帮助我们判断自己是否有足够的优势进入该领域。 1.2 竞品研究除了通过行业核心关键词研究行业趋势外，我们还可以通过竞品关键词研究竞品的趋势及优劣势。 我们以ofo为例做竞品分析。在百度指数中搜索关键词“ofo”，可得到如下趋势： 从以上趋势图，我们可以看出，ofo的搜索热度从2016年8月左右开始逐渐上升，在2017年1月开始断崖式下滑，然后从2月左右开始出现触底反弹，在2017年3月左右达到进入新一轮峰值。 在看到趋势及拐点之后，我们可以根据时间线索去搜索、寻找出现拐点的原因。通过查看ofo百科中的发展历程，以及每个时间段的媒体报道，我们可以发现： 在2016年8月时，ofo完成A+轮融资；- 2017年1、2月是春节，春节之后ofo马上推出了智能锁（智能锁推出前，车锁一直ofo硬伤）；- 大概在2017年3月时，ofo完成了D轮融资；- ….所以，我们可以通过分析每一个时间拐点上的：产品动作、运营动作、市场动作，去分析竞品的动向及结果。 最后，趋势分析还可以支持同时多个关键词的对比分析。例如，我们如果要同时比较摩拜和ofo的趋势，可以添加两个关键词进行趋势比较（百度指数最多支持5个关键词的比较检索），如下图： 从以上趋势可以简单看出，从2016年10月至2017年8月期间，ofo的搜索指数都是高于摩拜的，但是后续ofo下降明显，趋于平缓之后，只略微高于摩拜。 搜索指数的热度与市场份额应该是正相关。由此我们可以猜测，ofo在全国的市场份额是多于摩拜的。如果要看各地区，还可以通过修改关键词地区指数进行查看，从而了解在每个省份的市场份额情况，如下图： 2. 需求图谱需求图谱又叫需求分布，提供关键词的相关词及相关程度的信息。 其中，相关词距圆心的距离表示相关词相关性强度； 相关词自身大小表示相关词自身搜索指数大小，红色代表搜索指数上升，绿色代表搜索指数下降。相关词可以帮助我们了解，围绕关键词，用户的聚焦点，以及产品和服务的痛点。 如上图，搜索共享单车，通过调整下方的时间轴，可以看到在不同时间段内，共享单车的相关词分布情况。 以2018年4月2日至4月8日期间的相关词分布为例，“共享单车”的热门相关词包含：“摩拜单车”、“摩拜”、“哈罗”、“哈罗单车”、“ofo”、“共享单车盈利模式”等等。 从这些相关词中我们可以了解到： 共享单车领域几大主要市场玩家是摩拜、哈罗、ofo，而且这几大玩家的搜索热度都呈现上升趋势，与共享单车的相关性也很强，尤其是摩拜和哈罗。1. 针对共享单车这个行业，人们很关心的点是盈利模式是什么？单车怎么使用？有什么样的管理规则出台？再比如，我们以“ofo”为关键词进行分析，可以看到在2017年7月31日至2017年8月6日时间段内，相关词的分布如下图所示，发现“ofo”的其中一个相关词是“淘宝”，相关性较高且还呈现搜索热度上升趋势。 为了弄明白它们之间究竟是如何关联上的，于是在百度上搜索一组组合关键词：淘宝为了弄明白它们之间究竟是如何关联上的，于是在百度上搜索一组组合关键词：淘宝＋ofo，搜索结果如下： 从上图可以了解到，ofo曾发生了红包被盗刷的事件。 需求图谱除了可以看到相关词分布外，还可以查到top15的来源相关词和去向相关词（如下图所示）。 来源相关词是指用户在搜索中心词之前搜索过哪些关键词；去向相关词是指用户在搜索中心词之后搜索过哪些关键词。 例如，用户在搜索“共享单车”之前，经常搜索“哈罗”、“摩拜”、“共享单车盈利模式”等关键词，但是在搜索了“共享单车”之后，经常搜索“摩拜”、“共享单车新规”、“共享经济”等关键词。 3. 舆情洞察当我们需要了解某行业或某竞品在某个时间段内的主要动向时，可以使用舆情洞察。 例如，要了解ofo的动向，我们看到ofo的媒体报道热度是从2017年2月左右开始增长的，从热门报道看，这应该得益于4.5亿美元的D轮融资。此外，在2017年3月至2017年8月期间，ofo的主要动向： 完成D轮融资；- 在共享单车行业排名第一，并牵头制定行业标准，奠定行业地位；- 通过一些绿色公益活动、明星代言等形式提升品牌影响力；- 存在商标侵权的公关危机。除此以外，如上文中的案例所示，将舆情洞察与趋势研究中的拐点结合，也是分析趋势走势的一个得力工具。 4. 人群画像人群画像比较简单，就是体现搜索关键词的用户基本属性，这些属性包括：年龄、性别、地域等。 例如，我们可以通过，同时输入“摩拜”和“ofo”两个关键词，将对摩拜和ofo的用户进行对比，如下图所示，可得出如下结论： 摩拜和ofo的用户年龄分布基本一致，30～39岁年龄段最多，占尽50%；- 摩拜和ofo的用户性别分布基本一致，男性占比约70%，远远超过女性；- 从地域分布看，ofo主攻的是北上广，而摩拜主攻北京、广东、浙江、江苏、山东、湖北等地。 5. 检索技巧百度指数除了对单个关键词进行分析之外，还支持多个关键词的分析。 （1）比较检索 在多个关键词当中，用逗号将不同的关键词隔开，可以实现关键词数据的比较查询。 例如，如果要对几个竞品进行对比分析，可以检索“ofo,摩拜,哈罗”。百度指数最多支持5个关键词的比较检索。 （2）累加检索 在多个关键词当中，利用加号将不同的关键词相连接，可以实现不同关键词数据相加。相加后的汇总数据作为一个组合关键词展现出来。 例如，要更全面覆盖摩拜相关关键词的数据，可以检索“摩拜＋摩拜单车”等，百度指数最多支持3个关键词的累加检索。 （3）组合检索 即可以将“比较检索”和“累加检索”组合使用，例如“ofo+ofo共享单车，摩拜＋摩拜单车，哈罗＋哈罗单车” （4）地域检索 每一组关键词，都可以通过地区筛选不同省份的关键词搜索数据，百度指数最多支持5个地区对比检索。 以上即为通过百度指数的免费资源获取一些宏观数据信息的小技巧。希望能给大家的实际工作带来一定帮助。 作者：菜花，前阿里巴巴产品经理，微信公众号：菜花谈产品（ID：caihuatan2016） 本文由 &#64;菜花 原创发布于人人都是产品经理。未经许可，禁止转载。 题图来源于网络 转载来源：巧用百度指数进行市场和竞品分析]]></content>
      <categories>
        <category>职场</category>
      </categories>
      <tags>
        <tag>自行车</tag>
        <tag>产品经理</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dlib 19.9的巨大进步，安装无须Boost.Python]]></title>
    <url>%2F2018%2Fe905ff27%2F</url>
    <content type="text"><![CDATA[Dlib Release 19.9New Features and Improvements&#58;Major Changes in this ReleaseSwitched the Python API from Boost.Python to pybind11. This mean Dlib Release 19.9 New Features and Improvements&#58;Major Changes in this Release- Switched the Python API from Boost.Python to pybind11. This means Python users don’t need to install Boost anymore, making building dlib’s Python API much easier.- ……（其他的更新不关心！） 我看到了什么？！ don’t need to install Boost anymore don’t need to install Boost anymore don’t need to install Boost anymore 重要的话说三遍！ 用过或者曾经试图用Python版Dlib未遂的人一定会对它安装过程中对于Boost.Python印象深刻，一定可以理解我为什么看到上面的更新日志那么激动。 对于那些使用dlib未遂，在安装过程中就放弃的人，我想说，我非常理解你们。也许是我用Python还是不够多，但是就我的浅薄的经验，在我用Python以来，安装个Python库还需要这么麻烦的，只有dlib一例。 我曾经花费大力气编译了Boost然后配置好了环境，后来每次安装的时候就方便多了。Dlib确实是一个非常好用的库，我用它做过一些非常有意思的事情，比如： 40行代码的人脸识别实践- 用Python给头像加上圣诞帽- 还有一些更有意思的还未来的及写出来用Python给头像加上圣诞帽 不少读者想要尝试自己做一些这些有意思的项目的时候通常都会卡死在安装上，不断有人问dlib安装的时候遇到找不到Boost的问题怎么办。为此我写了Dlib的配置教程： python下安装dlib（boost.python的编译）- Dlib在VS2015上的编译和配置（人脸检测人脸识别比OpenCV更好用）Dlib在VS2015上的编译和配置（人脸检测人脸识别比OpenCV更好用） 不少人尝试过，但是我敢肯定不少人放弃过，我在知识星球中不止一次的发布过dlib的更简单的安装方式，但是都避不开Boost。 这一次，Dlib终于摆脱了Boost这个沉重的包袱，轻装上路。Dlib的作者Davisking为此在19.8版本放发布一个多月的时候专门发布了一个新版本19.9。想必他也是被来问问题的人困扰了N久了。 这是一个巨大的进步！（this is a massive improvement!）Github上有人如是说，说出了大家的心声。 安装现在安装Dlib就不会想上面提到的教程那么繁琐了。 之前安装过dlib的需要先卸载以前的版本。 下载dlib19.9.zip，解压后再dlib19.9文件夹下会发现一个名为setup.py的文件。 然后在当前文件夹下打开命令行（Shift+右键）。输入一下命令： 如果cpu支持AVX指令集，还可以让dlib更快一点 如果有可用的GPU而且安装了CUDA，那么dlib还可以更快。 转载来源：Dlib 19.9的巨大进步，安装无须Boost.Python]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>GitHub</tag>
        <tag>Python</tag>
        <tag>GPU</tag>
        <tag>OpenCV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯研究院：独家解读腾讯首款区块链游戏化应用白皮书]]></title>
    <url>%2F2018%2F33401f46%2F</url>
    <content type="text"><![CDATA[新文创生态大会上，腾讯游戏创新工作室与腾讯区块链联合发布了腾讯首款区块链游戏化应用《一起来捉妖》。但是腾小研要在这里提醒你：少年，想要了解一款区块链应用，得先从阅读白皮书开始啊！ 2018年4月23日，UP2018腾讯新文创生态大会上，腾讯游戏创新工作室与腾讯区块链联合发布了腾讯首款区块链游戏化应用《一起来捉妖》。 看完新闻，很多人的第一反应是迫不及待的去游戏官网进行预约。但是腾小研要在这里提醒你： 少年，想要了解一款区块链应用，得先从阅读白皮书开始啊！ 白皮书，其实就是区块链项目的说明书、产品文档、技术说明，起到向公众、使用者、技术研发人员解明项目的愿景、技术实现、主要功能的作用。 之所以在区块链领域会有“白皮书”这个概念，是因为“区块链”这个词其实本就出自于中本聪在2008年发布的《比特币白皮书》。所以，之后的几乎所有区块链项目都会发布一份白皮书。而阅读白皮书，也成为了深入了解一个区块链项目的必备环节。 那么，腾讯首款区块链游戏化应用《一起来捉妖》的白皮书在哪里呢？ 这你就来对地方了，《一起来捉妖》的白皮书由腾讯FiT（支付基础平台与金融应用线）、腾讯研究院、腾讯游戏创新工作室共同撰写。就在刚刚，和《一起来捉妖》游戏一起发布啦！ 不过，白皮书很长，你的心情很急切，我们摘出了白皮书中大家最关切的问题。如果你对白皮书全文感兴趣，可以跳过这一部分哦： 解读一、腾讯为什么要在游戏中融入区块链要素？在区块链发展的初期，产业生态以比特币为代表的数字货币为主。 2014年起，区块链的影响扩散到广义金融领域，在清结算、跨境支付、资产登记等领域应用层出不穷。 区块链与传统金融结合，在提升交易效率、降低交易成本方面大显身手。以太坊的出现提供了图灵完备的区块链底层，帮助开发者便捷地创建包含状态和完备逻辑的智能合约，大大降低了区块链项目的开发成本和技术门槛，使区块链的分布式、去信任的机制等广泛运用到金融之外的知识产权保护、供应链管理、公共管理、公益等各个领域。 区块链本身并不神秘，只有真正的产业场景落地才能彰显其内在价值。游戏为区块链与产业的融合打开了一扇大门。 游戏产业绝大多数环节都是纯数字化的、虚拟化的。游戏世界原本就存在用户社群、虚拟商品交易、代币结算，也与区块链应用的很多要素不谋而合。区块链的运行原理决定其自发性和不可篡改性。区块链的交易信息采用非对称加密，保证了交易信息的准确性和安全性。非对称加密除了保证信息的安全性之外，还可以进行身份验证，确保信息的准确性。 我们希望借助于区块链技术中的“公开、公正、公平”特点，解决传统游戏设计中由于黑盒、暗改、玩家地位不对等问题带来的玩家对运营方的不信任感问题，同时使用游戏化的方式普及区块链概念，玩家将在游戏道具的获取和交易中体会到区块链账本、智能合约相关的功能和机制。 游戏中将诞生1105亿只专属猫，它们可以彼此之间自由繁殖，保存在永不消失的中央游戏中。大家也可以把捉到的极品猫进行保存，这是非常令人激动的尝试和探索，意味着虚拟的价值可能超过一款产品成为更长期的存在。 解读二、先有游戏，后应用区块链《一起来捉妖》是一款腾讯游戏创新工作室制作的增强现实（Augmented Reality）游戏。 游戏的主要体验是玩家通过在游戏中使用AR功能抓捕身边的妖精，获取基础的生存和成长资源；使用这些资源对妖精进行培养，以完成游戏中PVE/PVP对战玩法和展示、收藏、交易等诸多功能。 区块链技术，作为游戏中一些功能落地应用，比如专属猫的搜集、收藏、繁育。同时，游戏中专属猫的交易也基于区块链技术。 因此，和其它的区块链游戏不同，《一起来捉妖》首先是一款好玩的游戏，然后从游戏的可玩性、功能性出发，融入和应用了区块链技术。 解读三、区块链如何提升游戏体验？既然核心玩法和其他区块链游戏并不一样，那么区块链技术在《一起来捉妖》中时如何体现的呢？ 根据白皮书介绍，腾讯利用区块链技术从数据可信任、游戏道具确权、区块链道具在游戏中的实际作用、通过区块链账本实现游戏进程中的传承与永久记载、安全保护、媒体节点引入六个方面实现了游戏体验的提升。 统而言之，与传统网络游戏、手机游戏中游戏道具和游戏资产只是运营公司服务器上的一个数字相比，《一起来捉妖》里的专属猫采用区块链技术确权、保存、交易，就算游戏运营方数据库被入侵，也不会造成用户游戏财产的丢失或盗用。同时，可以让玩家与游戏中的数字藏品建立情感连接，无论何时都可以调取，交互，成为玩家永恒的记忆。 解读四、所以这个游戏究竟怎么玩？在游戏中， 玩家通过游戏的相关AR系统，与游戏中的各种交互点进行不同的交互（抓捕、挑战、摆摊交易等），以获取游戏中的各种资源，完成成长线，收获游戏乐趣体验。 游戏中最核心的AR系统是AR抓捕：玩家通过向镜头中的AR对象，也就是游戏中的妖精，抛掷游戏中的抓捕法宝——梦灵，以完成抓捕。每次抛掷梦灵，都需要消耗一颗封妖魂珠的能量。而AR功能带来的人机交互和场景代入感是本核心玩法中最重要的情感体验。 玩家通过AR玩法进行妖精收集，并且可以通过重复抓捕妖精来获取妖精符印。玩家获得足够的符印后，可使用通过游戏中各种途径产出的游戏货币——云纹来对妖精进行升级、操作。妖精等级提升到一定程度后，就可以消耗一定数量的符印进行觉醒。觉醒后的妖精会拥有更炫酷的形象、更多的技能和更强的数值。 当玩家拥有妖精并达到一定的等级后，就可以参与游戏设计的封妖之路、妖精擂台、孔明灯挂机、须弥岛养成、妖精挂机等玩法。 同时，游戏还提供了聊天、罗盘、组队、圈子等社交玩法。玩家可以通过这些玩法寻找志同道合的玩家一起完成日常任务、攻克PVE关卡、挑战圈子任务等。 解读五、能解释一下其中区块链部分怎么玩吗？专属猫是《一起来捉妖》游戏中首个接入区块链技术的玩法。 专属猫是一种猫形数字宠物，玩家通过商城、猫的繁育、参与活动三种方式获取新的猫。专属猫数量有限，且可以在游戏中通过玩家之间的点券支付进行转让。 在《一起来捉妖》游戏中，我们将投放640000只“0代猫”，0代猫的投放速度由系统按游戏运营的实际需求控制。 游戏中的专属猫储存在区块链网络上由特性进行区分，由区块链技术保证每一只猫都独一无二，绝对不存在特性完全一致的两只猫。 玩家可以通过游戏道具召唤、从市场（其他玩家）购买、繁育、运营活动四个渠道中获得专属猫。 每只专属猫有不同的外观特性，游戏中总计有十数种特性类型，每种类型下都有若干个不同的样式。总计有超过千亿种组合。多数特性最早都会出现在0代猫身上，由系统控制投放。特性基因可通过繁殖有概率继承。 每只猫的出生信息、交易信息、繁育信息将作为“猫的一生”被记录在区块链区块链账本中，实现每只猫的透明、溯源。 解读六、未来打算如何发展？《一起来捉妖》演进路线图 发文时比特币价格 ￥58039.29 原文：腾讯研究院（https&#58;//mp.weixin.qq.com/s/1G-x1-Yd0F2REJ7JeFyTUw） 作者：腾讯研究院 编辑：野比大雄 稿源：http&#58;//www.8btc.com/tencent-blockchain-game-0423 版权声明： 作者保留权利。文章为作者独立观点，不代表巴比特立场。 转载来源：腾讯研究院：独家解读腾讯首款区块链游戏化应用白皮书]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>数字货币</tag>
        <tag>比特币</tag>
        <tag>区块链</tag>
        <tag>网游</tag>
        <tag>金融</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二甲双胍被称为“神药”，为什么很多糖友不愿意吃？]]></title>
    <url>%2F2018%2F4ffaaf22%2F</url>
    <content type="text"><![CDATA[不论是单药使用，还是与胰岛素等其他药物联合使用都能发挥很好的作用，且有辅助减重、降低心血管疾病、癌症等发病率的功效。 二甲双胍，是2型糖尿病患者的一线**首选用药。不论是单药使用，还是与胰岛素等其他药物联合使用都能发挥很好的作用，且有辅助减重、降低心血管疾病、癌症等发病率的功效，甚至被媒体封为“神药**”。 但英国有研究发现，2型糖尿病患者对二甲双胍的接受度很低，30%的患者并未按要求服药，相比于DPP-4抑制、磺脲类、噻唑烷二酮类等药物，依从率最低。 为什么二甲双胍功效那么好，糖友的依从率却很低**，很多糖友宁可换药甚至不吃？** 糖友对二甲双胍的依从率低，主要是其常见副作用及糖友对它的误解引起的。 常见副作用 胃肠道反应 二甲双胍会刺激肠胃，很有糖友会产生常见的胃肠道反应，如：胃胀、腹泻、恶心、腹部不适、食欲差等，导致不想服用二甲双胍。 其实，大多数糖友经过一段时间的治疗，二甲双胍的副作用会逐渐消退。而且为了规避这些不良反应，医生也会调节用药，推荐初始剂量，适应后再逐渐增加。 糖友误解 损伤肝肾功能 网传二甲双胍会损伤肝肾功能，致使很多糖友在服用二甲双胍类药物时都提心吊胆，尤其是出现一些不良反应时，可能被吓的自行停药。其实并非如此。 事实上，二甲双胍吸收到体内后，有90%会以原型从肾脏中排泄出去，没有肝、肾毒性。 糖友服用二甲双胍后，在增加葡萄糖无氧酵解和减少糖异生的过程中，会产生一种酸性代谢物产物——乳酸。 正常情况下，乳酸会被进一步分解代谢，再从肾脏排出体外，并不会损伤肾脏。但如果糖友伴有肾功能受损，乳酸的代谢、排泄就会受阻，使其蓄积在体内，可引起乳酸性酸中毒，从而损伤肝、肾等脏器。 简单而言，对肾功能正常者，口服常规剂量的二甲双胍不会伤害肾脏。但如果肾功能不好，因排泄受阻，会引发药物不良反应。 那么，二甲双胍究竟是通过什么原理来降糖的？ 二甲双胍，不仅可以辅助降糖，还是目前口服降糖药中唯一被推荐可以有效降低糖尿病患者心血管事件的药物，其作用机理可以分为以下四个方面。 1**提高胰岛素敏感性** 二甲双胍可以提高机体对胰岛素的敏感性，增加肌肉、脂肪组织对葡萄糖的摄取、利用率，从而促进葡萄糖的无氧酵解，加大消耗。 2**减少肝糖输出** 肝脏贮存的葡萄糖，可以输送到血液供全身使用。而二甲双胍能抑制肝糖原异生，继而减少血葡萄糖，以降低血糖。 3**抑制食欲** 二甲双胍能抑制肠壁吸收葡萄糖，从而降低食欲，减少食用量。 4**降低心血管病发病率** 二甲双胍不仅可以辅助降低甘油三酯，还能抑制小肠胆固醇的合成与储存，降低血胆固醇，对于伴有肥胖的糖友，又能辅助减肥。 也就是说，二甲双胍能降低心血管疾病的风险因子，从而减少心血管疾病的发病率。 此外，二甲双胍不会增加胰岛素水平，所以一般不会引起低血糖，可以减少血糖的波动幅度。相对来说也更为安全。 但是，市面上的二甲双胍有各种剂型，怎么选择更适合？ 二甲双胍以剂型分类，主要有普通片剂、肠溶片、缓释片。 1、普通片剂 普通片剂，即盐酸二甲双胍片，是最普通的片剂，价格也相对低廉。 二甲双胍普通片剂大部分会在食道、胃中分解吸收，所以胃肠道反应相对较大。因此，建议餐时或餐后服用，一般每天至少服用2次。 2、肠溶片 肠溶片，即盐酸二甲双胍肠溶片（或胶囊**）**，是二甲双胍普通片的改良版。在肠溶材料的包裹下，它能直接到小肠，从而减少胃肠道尤其是上消化道的不良反应。 要注意的是：肠溶制剂不能掰开服用。一旦掰开，就无法达到肠溶的效果，影响药效、刺激胃部。 二甲双胍肠溶片应该放在餐前15-20分钟服用会比较好，服用次数一般也至少2次/天。 3、缓释片（或控释片） 二甲双胍缓释片，即盐酸二甲双胍缓释片（或控释片），是以凝胶包裹的药物，以达到缓慢释放的效果。 不仅能减少胃肠反应，还能减少服用次数，每日仅需服用1次，对长期用药者更为便利。但缓释片的吸收和起效普遍较慢，所以适宜餐前30分钟服用。 二甲双胍虽是首选药物，但也有注意事项，如下： 1、定期检查不能少服用二甲双胍期间，应定期检查空腹血糖、尿糖、尿酮及肝肾功能。2、避免过量饮酒酒精，会减慢二甲双胍的排泄，从而增加乳酸性酸中毒的风险，一定要避免过量饮酒。3、预防缺乏维生素B12长期服用二甲双胍，可能引起维生素B12的缺乏，尤其是摄入不足或吸收不良者，应监测血清维生素B12水平。4、特殊人群/期间忌服二甲双胍类药物禁用于肾功能不全，缺氧或接受大手术等糖尿病患者。如果要进行造影检查，也要暂时停用二甲双胍。 转载来源：二甲双胍被称为“神药”，为什么很多糖友不愿意吃？]]></content>
      <categories>
        <category>健康</category>
      </categories>
      <tags>
        <tag>癌症</tag>
        <tag>药品</tag>
        <tag>糖尿病</tag>
        <tag>心血管</tag>
        <tag>腹泻</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为中国芯万字投书马化腾：从Intel和ARM争霸战，看看做芯片有多难]]></title>
    <url>%2F2018%2F59235777%2F</url>
    <content type="text"><![CDATA[有着十余年芯片行业经验的torvaldsing投书新智元，把x86生态系统和ARM生态系统的艰难发展历程和残酷的市场竞争大起底。 作者：torvaldsing 【新智元导读】为什么中国做了30年芯片都没有出现英特尔、ARM这样的巨头？关键在于国产CPU缺少强大的生态系统。有着十余年芯片行业经验的torvaldsing投书新智元，把x86生态系统和ARM生态系统的艰难发展历程和残酷的市场竞争大起底。最后呼吁马化腾：请借助腾讯的强大生态，把CPU和OS这两个老大难问题给OTT掉！ 这几天中兴事件持续发酵以来，各种议论纷纷扰扰。 上周，新智元推送了《中国芯“逃兵”：缺芯是因为缺钱；中国芯“老炮”：芯片救国靠BAT不是开玩笑》一文，引起了无数从业者热议。 有十余年芯片从业经验的水木网友torvaldsing告诉新智元，这几天对他触动最大的，还是碧树西风写的这句话： 一碗牛肉面，真的要用牛肉，真的要用面，真的要炖很久，这么简单的道理，偌大一个国家，这么多精英，过去这么多年了，咋就不能懂呢？ 做芯片很难，做核心芯片更难，做需要生态系统的CPU芯片，比大家想象得都要难。 因此，torvaldsing投书新智元，尝试谈一谈x86生态系统和ARM生态系统的艰难发展历程和残酷的市场竞争，向大家介绍一下做CPU的各种困难，以及眼下能看到的一线希望。 以下是torvaldsing的雄文： 我尽量写得轻松一些，因为其实这个话题很有趣，仔细探究起来，很多看似爆炸性的新闻，其实草蛇灰线伏脉千里，在很早之前就发端了，这其中的故事，真的像演义小说一样好玩。 本文会罗列很多的往事和参考资料，保证有诚意。一些地方没忍住加上了一些三脚猫的分析，欢迎拍砖打脸。 （本文约1.3万字，建议先收藏后阅读） x86**生态系统**如今Intel在服务器市场占有率近乎100%，在桌面市场也大于80%，再加上Intel一贯重视宣传，在普通大众的心目中，Intel就是芯片的代称，甚至是高科技的代称。但Intel并非生而如此，它的牛X千真万确是熬出来的，是在列强环伺的竞争环境中杀出来的。 称王 七十年代，在搭上IBM PC这趟快车之前，Intel的8位处理器已经很成功，但也有很多竞争者，Zilog是其中翘楚，它研发的Z80系列产品和Intel的8080兼容，性价比高。一直到90年代，中国很多大学的微机实验课，还在用Zilog的板子。当时还有一款处理器风头不逊于8080系列，即MOS公司的6502。后来MOS把6502的ISA（指令集架构）授权给了众多厂商，流传甚广。70年代苹果创立之初的Apple-I和Apple-II，80年代任天堂的红白机，90年代初的小霸王学习机，90年代末的文曲星，都使用了6502系列的CPU。 IBM PC给了Intel和微软大发展的机会。但它俩必须面对竞争。IBM PC是IBM主导下的一个开放标准，各个零部件都是可以替换的。所以才有了“兼容机”的概念，和延续至今的装机市场。当时IBM要求Intel必须把x86指令集授权给其它厂商，避免CPU供应商一家独大。（详细的x86兼容处理器生产厂家列表见https&#58;//en.wikipedia.org/wiki/List_of_x86_manufacturers）IBM自己也有生成x86兼容CPU的权力。同时，为了限制微软的MS-DOS，IBM自己也做DOS操作系统，名为PC-DOS。 在IBM PC阵营内部，Intel面对其它CPU供应商的竞争，在阵营外部，还要和苹果的Macintosh电脑竞争。当时苹果已经换用Motorola 68000系列CPU，性能强劲，图形界面诱人。当时用Mac的人，逼格要高于用IBM PC的人。 Intel顶着阵营内外的竞争压力，苦心孤诣地发展壮大。这时候潜在的威胁在慢慢酝酿。从1981年的RISC-I开始，精简指令集（RISC）逐步流行起来，诞生了一系列RISC风格的CPU：1985年MIPS公司推出第一款商用的RISC芯片，HP公司在1986年推出PA-RISC，SUN公司在1987年推出SPARC，Motorola在1988年推出MC88000。当时大家普遍认为RISC优于以x86为代表的CISC风格CPU，就连Intel和AMD也害怕在RISC潮流中落伍，AMD在1987年推出了AM29000，Intel在1988年推出了i860/i960。 开始时RISC似乎并没有威胁到桌面市场，MIPS、PA-RISC、SPARC全是用来做服务器和工作站的。被苹果流放的乔布斯用MC88000系列CPU做NeXT桌面电脑，铩羽而归。1986年，英国的Acorn公司推出了一款名为ARM的RISC处理器，次年，它还配了个操作系统叫RISC OS，强攻桌面市场，可惜最终只在英国掀起来了一些波澜。 1991年，RISC阵营实实在在地杀入桌面市场。这一年，IBM看到在PC阵营里，Intel和微软这两个小弟坐大，慢慢不受自己的控制，索性拉拢Apple和在RISC市场不得志的Motorola，推出了PowerPC架构，由IBM和Motorola生产芯片，Apple做操作系统和整机，推出全新的Power Macintosh电脑。这三家组成了AIM（Apple-IBM-Motorola）联盟，气势汹汹地向Wintel联盟发起攻击。 结果是Wintel赢了，个中原因众说纷纭。有人说Wintel保持对已有软件的向下兼容，而Apple频繁更换底层的CPU，导致的不兼容气走了用户，然后由此强调软件生态的重要。我则以为，历史的发展有一定的偶然性，如果当时Wintel不是比尔盖茨和格鲁夫在掌舵，而Apple是乔布斯在掌舵，可能结局完全不同。2005年，乔布斯掌舵下的苹果，把Mac里面的CPU由PowerPC换成Intel的芯片，就完成得干脆利落，没怎么受到软件生态的牵绊。 总之，在80年代，大家就已经深深懂得CPU的ISA是软件生态系统的根基，不愿让这个“生态之根”被别人控制。整机和系统的制造商，通过强制CPU厂商给其它厂商授权自己的ISA，来保证有第二家甚至更多的供应商。如果不慎“生态之根”被别人控制了，例如IBM被Wintel篡了权，甚至不惜另起炉灶来竞争。 同样是把自己的指令集授权给其它厂商，Intel把几乎所有的其它供应商都挤死了，只省下AMD苟延残喘；MOS则销声匿迹了，完全靠其它生产商把6502系列延续到了二十一世纪。造成这一差异的原因纵有千万条，我想“打铁还需自身硬”是最根本的。 霸业 在桌面市场上，Windows 95和Windows 98这两款操作系统，让Wintel联盟登上了霸业的顶端。从1995年到2003年，Intel看起来简直是不可战胜的。 与此同时，Intel还把几乎所有的RISC架构的CPU都干趴下了，占领了服务器市场。原因大概有这么几点。 第一，从技术角度讲，RISC是一种设计CPU的理念，而不是具体的某一种ISA。像x86这样的复杂指令集，其实在实现过程中，也能借重RISC的理念。1989年的80486，已经隐隐地可以看到RISC风格的流水线，1995年的Pentium Pro，其核心已经是一个乱序执行的RISC了，只不过多了一个复杂的译码逻辑，把x86指令拆分成RISC风格的微操作。因此从技术角度讲，RISC指令集未必比x86有优势。 第二，RISC成也UNIX，败也UNIX。UNIX和C语言树立了很好的软件开发传统，确保同一套代码可以很方便地在不同CPU之间移植。80年代，一大堆RISC架构的CPU，都可以很快配上自己的UNIX，很快把已有的C语言编写的应用跑在CPU上，然后就可以卖了。SUN公司的SPARC配有Solaris，HP公司的PA-RISC配有HP-UX，IBM公司的PowerPC配有AIX。 这些林林总总的UNIX变体，反过来又进一步促使UNIX生态系统中软件开发人员重视代码的可移植性，大家都很小心地围绕POSIX标准来编程，避免过分依赖于某个操作系统独有的功能。这样，一旦Intel芯片携Linux（一种开源的UNIX变体）来和RISC架构的工作站竞争，软件应用就纷纷以很小的移植难度，离开了昂贵的专有UNIX工作站。 第三，当时PC市场比服务器市场大得多，Intel在PC市场的盈利帮助它研发更好的服务器芯片，巨大的出货量降低了芯片的制造成本。研发优势和成本优势，奠定了Intel最终胜利的基础。 这段时间，Intel还几次面临挑战，每次都成功保卫了自己对于生态系统的掌控权。 第一个挑战，来自Internet浏览器。Netscape Navigator诞生后，对微软和Intel都是挑战。虽然当时的动态网页还非常初级，但是已经有人喊出“Web is the computer”的概念。等到Java Applet出现之后，大家更是觉得可以在网页上实现桌面应用的效果，未来只需一个浏览器，就能取代桌面。Netscape的Marc Andreessen在1995年，就着手把Netscape浏览器打造成一个Internet OS。以那个时代的软硬件水平，毫无疑问地，这些尝试失败了。 用一个高层次的软件API，兜住所有的上层应用，然后让底层的硬件，都来支持这个API——这个主意不单单在技术上看起来很炫，从商业上，这是上层应用厂商消解底层平台厂商生态霸权的终极武器。因此，在那之后的二十年里，商业上的尝试一直在持续，包括： 腾讯开发的WebQQ和Q+，在网页里面提供一个类似Windows桌面的应用场景，后来失败了，回退到功能单一的SmartQQ。个中原因，我个人认为还是那个时代的PC性能不够。 腾讯开发的微信小程序，在微信里面通过HTML5和Javascript实现手机App的功能，可以横跨iOS和Android。 谷歌推出ChromeOS和ChromeBook笔记本，里面跑的应用，全都是基于HTML5和Javascript的。 我个人认为，微信小程序几乎一定会成功，它一旦成功，腾讯必然会重燃在PC平台上做Q+的野心。Intel在桌面的霸权，最大的威胁不是AMD，也不是ARM，而很可能是HTML5+Javascript，熟悉“降维打击”的人，对此不会感到意外吧。 第二个挑战，来自虚拟机（Virtual Machine）和JIT（Just-in-time）编译器。先锋是Java的虚拟机JVM，后来微软也推出了DotNet虚拟机，支持C#等语言。虚拟机有一套虚拟的指令集，源代码先被编译到这个虚拟的指令集上，在程序运行时，JIT编译器再把这套虚拟指令集编译为CPU的原生指令集。面向虚拟机开发的程序，例如Java Applet，可以在不同的CPU和操作系统平台上运行。 如果有某个虚拟机，它的指令集可以无缝支持所有的编程语言，还能保证高效率，那么所有CPU的都将被OTT（over-the-top）了，就像短信被微信OTT一样。可惜还没有一个虚拟机可以实现此目标。现在大家熟知的虚拟机，都是和语言绑定的，例如JVM只支持Java、scala、kotlin等；DotNet虚拟机只支持C#、VB.net等；V8只支持Javascript、typescript等；HHVM只支持PHP。 同一个VM上跑的语言相互调用很容易，跨VM很难互操作。由于虚拟机实在太多了，它们反而成了新的CPU架构的拦路虎：80年代只需要搞定C语言编译器就能卖Unix工作站，如今ARM服务器要想挑战Intel，必须把所有这些基于VM的编程语言都支持得很好，JIT编译器的效率都要做得比较高才行。 第三个挑战，来自Transmeta公司对x86指令集的Emulation（Emulation这个词很难翻译，索性不翻了）。简单地说，Emulation就是把x86指令集看成一个虚拟机的指令集，然后用类似JIT编译器的技术，在非x86的CPU上跑x86的程序。未经许可用别人的ISA做CPU是违法的，但用Emulation的方式实现ISA则不违法（Intel和Transmeta只打过专利的官司没打过ISA的官司，Intel还输了）。 如今最广为人知的Emulator是Qemu，上文提到的x86、MIPS、PowerPC、Sparc、MC68000它都可以支持。一般而言，Emulation会导致性能下降一个甚至若干个数量级，根本不足为虑。 1995年，Transmeta公司成立，经过艰苦的秘密研发，于2000年推出了Crusoe处理器，用Emulation的方式，在一款VLIW（超长指令字）风格的CPU上执行x86的程序，这样就规避了没有x86指令集授权的问题。Transmeta的牛X在于，虽然是Emulation，但实现了接近Intel处理器的性能，同时功耗低很多。2000年年底Transmeta的IPO大获成功，其风光程度，直到后来谷歌IPO的时候才被超过。 Transmeta最后还是失败了，Intel在渠道上打压它是次要原因，性能不足是主要原因。虽然VLIW在90年代中后期被广为推崇，但事实证明，它的性能比起乱序执行的超标量架构，还是差一截。另外Transmeta的芯片是在台积电制造的，那个时候不比现在，台积电的工艺水平比起Intel还差很多。2000年的时候，PC还远没有性能过剩，性能还是比功耗重要。等到2010年，Intel的Atom处理器慢得一塌糊涂，依然靠着低功耗，点燃了上网本的大火。 Transmeta虽然失败了，Emulation技术仍然在发展。NVidia在2008年购买了Transmeta的低功耗技术的授权。2014年，NVidia推出了Tegra K1芯片，其中的Denver处理器，利用Emulation技术，在底层的7路超标量架构上，实现了ARM64指令集。值得注意的是，NVidia拥有ARM64的指令集的授权，它不是用Emulation技术来规避什么，而是用Emulation来提升性能，实现比硬件直接执行还要高的性能。根据评测结果，Denver超过了当时苹果最好的手机CPU。近期推出的Denver2处理器的，性能更是秒杀苹果的A9X和华为的麒麟950。 Emulation技术如果真的发展到了比直接执行还要快，Intel的麻烦才刚刚开始。微软联合高通，推出基于SnapDragon835处理器的笔记本，运行Windows 10操作系统，上面可以安装x86的软件。Intel虽然很不爽，但Emulation并不需要指令集授权，所以他只能警告说，在实现Emulator时，不许侵犯Intel的专利，而这一点，微软和高通肯定早已考虑到了。 挫折 x86生态系统曾经面对过一次最严重的、近乎灭顶之灾的挑战。这次挑战来自于谁？就来自于它的缔造者Intel。 Intel心不甘情不愿地把自己的x86指令级授权给了AMD等一众供应商，眼睁睁看着他们分享自己的利润，很不爽，于是想在x86之外另起炉灶，建设自己独享的生态系统。正巧在90年代初期，升级64位计算成为一个风潮，1991年有MIPS R4000，1992年有DEC Alpha，1995年有SUN SPARC64。1994年开始，Intel联合HP，准备趁32位升级64位的时机，抛弃原有的x86架构，新推出一个EPIC（Explicitly Parallel Instruction Computing）架构，名为IA64（Intel Architecture 64-bit）。 x86架构兼容老旧应用程序的能力是出了名的。8086把8位的8080升级为16位的时候，80386升级到32位的时候，都完全兼容旧有的程序。直到今天，Intel的处理器依然支持虚拟8086模式，在此模式下，可以运行30多年前的8086程序。升级到64bit的时候，Intel居然要放弃所有之前的8位、16位、32位应用了！可想而知当时在业界会引起怎样的轩然大波。Linux的缔造者Linus Torvalds公开对此表示反对。 IA64进展得并不顺利，EPIC本质上就是一种VLIW，如前所述，VLIW的性能比乱序超标量要差。而且EPIC的编译器非常难以开发。原定1997年就会推出产品，但直到1999年才发布IA64指令集，2001年才推出产品。另外Intel也不敢完全放弃之前的32位x86应用，它给出的解决方案是Emulation，但EPIC不像Transmeta为Emulation做了很多专门优化，跑32位x86应用的性能很差。 这个时候，千年老二AMD站了出来，为x86续命。2000年，它推出了AMD64指令集，延续了x86架构兼容老旧应用程序的优良传统，可以原生执行8位、16位、32位的老程序。2003年，AMD推出Opteron服务器CPU和Athlon64桌面CPU。 AMD64从技术上和生态上都压了IA64一头，Opteron在服务器市场上为AMD赢得了前所未有的成功。2004年，Intel推出了代号为Nocona的至强服务器CPU，它支持一种称为EM64T的技术，EM64T就是AMD64的马甲。江湖有传言说，Intel曾想提出另外一套不同于AMD64的x86升级64位的方案，但微软为了避免x86生态的分裂，极力阻止了。2012年，Intel推出了最后一代IA64的CPU，关闭了这个不赚钱的产品线。 回顾这段历史，有几点特别令人感慨。 首先，即使是看似无比强大不可战胜的Intel，不顾生态系统中其它伙伴的利益，一意孤行也是会撞南墙的。 其次，幸好由于历史的原因，x86生态中，AMD和Intel是交叉授权的关系，AMD有权加入3DNow这种多媒体扩展指令，也有权加入64位指令，如果是像如今ARM的架构级授权方式，被授权的企业不能自行加以扩展，那可能还真没有办法阻止Intel了。 最后，Intel的执行力还真是超强，掉头极快，EM64T的CPU只比AMD64的CPU晚出了一年（当然不能排除Intel早就有备份方案）。 虽然在IA64上栽了跟头，但Intel靠着自己的技术实力，持续不断地推出性能和功耗表现更好的产品，AMD在64位战役中所取得的优势，慢慢也被消磨掉了。 岁月如梭。进入移动互联网和云计算时代之后，服务器的需求量上升。这时RISC架构的服务器CPU几乎快被消灭干净了，只剩下IBM Power奄奄一息。于是Intel几乎独享了服务器市场扩大所带来的红利。但它却高兴不起来，因为移动市场形成了ARM一家独大的局面，移动终端CPU这个市场，Intel怎么也挤不进去。 正巧Intel在刚刚火过一把的上网本市场里设计了一种低功耗的x86核心，即Atom。Intel以Atom为武器，杀入了手机芯片市场。2012年，Intel的老伙计联想，推出了第一款Intel芯片的手机K800。紧接着还有Motorola的XT890。2013年，中兴、华硕也有产品问世。但三星、小米、华为、OPPO、VIVO等出货量大的厂商，都没有采用Intel的芯片。这些手机大厂，看看x86生态中做整机的联想如何艰难度日，估计心里也是一万个不乐意让Intel到移动领域来继续称王。 到2014年，Intel芯的手机还是没有打开局面，市场唱衰之声一片。但Intel并不想放弃。手机攻不下，那就攻平板！大厂攻不下，那就攻白牌！嫌我的芯片贵，我就给补贴！又过了两年，平板也没有攻下来。在移动市场赔了上百亿美金的Intel，黯然离场。 Intel失利的原因众说纷纭，我觉得根本原因还是竞争力不足： 首先，这个时候的台积电已经不是Transmeta家Crusoe芯片诞生时的吴下阿蒙，它生产的手机芯片的功耗和性能并不输给Intel； 其次，这次Intel并无生态系统的优势，要靠名为houdini的Emulator来执行ARM指令集的程序，性能打了折扣。试想，Intel芯的手机如果性能和待机时间都是iPhone的两倍，谁能抵挡得住这种诱惑？ 几乎在进攻移动市场的同时，Intel也在推出产品试水物联网市场，只不过没有大举宣传。2013年10月，Intel推出一款叫做伽利略的Arduino开发板，上面的CPU叫做Quark（夸克）。Quark是比Atom（原子）还小的基本粒子，这个名字暗含着轻巧、低功耗的意思。接着，Intel在2014年的CES大会和2016年的IDF大会上，先后推出了升级的爱迪生和焦耳开发板。 Intel的大名和Arduino联系在一起多少有些奇怪。Arduino是一套可以跑在低端MCU上的C语言函数库，是电子创客们的最爱。淘宝上Arduino开发板才几十块钱。焦耳开发板上的处理器是4核心、1.5GHz，跑Arduino太浪费了。和它参数近似的Raspberry PI 3 Model B+开发板，四核64位ARM Cortex A53跑1.2GHz，淘宝价不到200块。焦耳开发板要369美元。谁会当这个冤大头？ 物联网市场极度分散，有无数应用但规模都不大，Intel赚大钱习惯了，在这个微利又需要贴近客户做服务的市场里，百般不适。2017年，Intel悄悄停产了针对物联网市场的开发板。 Intel接下来所可能面对的挫折，是ARM侵入服务器和桌面领域。这个话题下文还会有简单分析。 ARM**生态系统**近几年ARM风光无限，抢新闻头条的能力不逊于Intel。 在很多圈外人看来，这家高科技公司好像是在移动互联网时代新冒出来的，但其实它的历史和几乎和80286一样古老。而且它自诞生以来，就以移动（portable）设备为自己首要的目标市场。它等待一飞冲天的风口，等待了二十年。 发端 前文提到，ARM是Acorn电脑公司创造的。 Acorn电脑公司创立于1978年，在80年代初，它用6502系列CPU制造的BBC Micro电脑在英国大获成功。6502的性能慢慢跟不上时代了，Acorn想基于80286开发新的电脑，但是Intel连样片都不给——要是Intel大方些，ARM或许根本就不会诞生。 Acorn一气之下开发了ARM（Acorn RISC Machine），这是世界上第一款定位中低端（而非服务器）RISC处理器。1985年，ARM1诞生（但从未被商用），后来Acorn在1986年和1990年分别推出了ARM2和ARM3，1987年推出了RISC OS和桌面电脑Archimedes。它在英国的教育市场获得了一定的成功，但1990年之后，很快被Wintel的生态击败了。 1990年前后，研发掌上电脑成为一股风潮。当时有家叫做Active Book的公司，拿ARM2处理器开发一个叫做Personal Communicator的产品。可惜产品上市前，Active Book被AT&amp;T收购了，AT&amp;T把ARM2换成了自家的Hobbit处理器。 幸好东方不亮西方亮，当时的苹果公司看好ARM，把自己研发的Newton平台中的处理器，由AT&amp;T的Hobbit，换成了ARM。这个“彼此互换”的故事听起来让人头大，大家只需要记住，ARM的第一颗商用处理器ARM2，就曾被尝试拿来做手持的电脑。 ARM的东家是Acorn，和苹果在电脑市场上有竞争。苹果公司花了6周时间说服Acorn把ARM独立出来运营。1990年11月27日，合资公司ARM正式成立，苹果、Acorn和VLSI分别出资150万、150万、25万英镑，Acorn把ARM处理器相关的知识产权和12名员工放在了新成立的公司里。此后，ARM的缩写被转而解释为Advanced RISC Machine。 为了节省成本，新公司在剑桥附近租了一间谷仓作为办公室，全力为苹果的Newton研发ARM6处理器（4和5这两个编号被跳过去了）。 Newton（牛顿）是苹果花大力气研发的触屏移动技术平台，Newton OS是不同于Mac OS的操作系统（如同后来的iOS）。如果你听过苹果、牛顿和万有引力的故事，应该能体会苹果公司对Newton平台有多么高的期望。 Newton平台的第一款产品MessagePad于1993年8月上市了，采用32位ARM610处理器，频率为20MHz，屏幕大小为336×240，重量410克，采用4节7号电池供电，售价699美元（相当于今天的1129美元）。可惜的是，它销量很差，上市头四个月的销量不过5万台。 1998年，中国的恒基伟业公司推出了一款叫做 “商务通”的产品，像极了Newton Messagepad。它采用Dragonball处理器，主频仅16MHz，屏幕大小10汉字x10汉字，重量105克，采用2节5号电池供电，售价人民币1988元。靠着“呼机手机商务通，一个也不能少”的广告，商务通在1999年大卖100万台。虽然2001年后商务通及类似产品很快就被越来越强大的手机挤出了市场，但让人好奇的是，背靠营销能力更加强大的苹果，Newton为何没能一炮而红？ 其中一个重要的原因是，Newton重点宣传的手写识别功能表现很糟糕。而商务通对手写汉字的识别率——根据我个人的体验——还真是不错，考虑到它仅仅16MHz的CPU主频，能做到这么好简直是奇迹。当时商务通部分型号的卖点就是“连笔王”，对潦草的汉字识别得相当好。 软件对于一款产品的重要性，真的是生死攸关啊！ 深耕 扯远了，让我们回到ARM的故事上来。 1990年ARM创立之初，给自己定下的使命是“设计有竞争力的、低功耗、高性能、低成本的处理器，并且使它们成为目标市场中广为接受的标准”，目标市场包括：手持设备（Portable），嵌入式（Embedded Control）和汽车电子（Automotive）。跨越近三十年，这个使命和市场定位始终未变，直到今天。 而且，根据我了解到的知识，ARM是处理器的源代码授权这一商业模式的开创者。如今，芯片设计从Verilog等源代码出发，经过一系列自动化或半自动化的优化步骤，最终形成工厂制造芯片所需要的版图文件；整个过程类似软件从源代码被编译为CPU的机器码。但在80年代，芯片的设计自动化非常原始。七八十年代的处理器授权，都是指令集的授权。Synopsys公司于1986年成立，1987年推出把Verilog编译为门级网表的DesignCompiler，之后基于源代码的芯片自动化设计流程才慢慢地被建立起来。于是源代码授权才成为技术上可行的模式。 ARM从未自己生产过商用的芯片。它只是将自己研发的处理器的源代码的知识产权（IP）授权给芯片厂商，由它们推出最终芯片。受益于这一商业模式，尽管在1993年，Apple的Newton失败了，但ARM并未因为设备卖不出去而亏钱，还幸运地拿到了TI的订单，于是成功盈利了。员工数量也由12人增长到了42人。次年ARM又拿到了三星的订单，员工增长到70多人，搬出了谷仓。 除了源代码授权的模式之外，ARM也做指令集授权，1995年，ARM把指令集授权给DEC，DEC很快设计出了性能更好的StrongARM处理器。1997年，StrongARM产品线被卖给Intel，更名为XScale。 1995年，Motorola在香港的研发团队基于MC68000指令集开发出了针对手持设备的DragonBall处理器，在这之后的十年，DragonBall处理器一直都是ARM强大的竞争对手。不但Moto自己的手机用它，Palm、三星、Sony的手机也用它。当然还有前文提到的商务通。ARM相对于Dragonball处理器有什么优势？我认为最大的优势是从客户需求出发的、持续的创新；其次是ARM的开放的商业模式。 RISC指令集一般都采用32位定长指令，代码密度比起x86之类的CISC来要差一些，但手机的存储空间有限，对代码密度的要求高。1994年，ARM为此专门研发了16位的指令集Thumb，以及支持这一指令集的ARM7TDMI。 开放授权的商业模式，使得整机厂在选择芯片时，可以找到支持同一指令集的多种芯片产品，不容易被绑架。Nokia作为和Motolora旗鼓相当的手机制造商，肯定不会选择竞争对手的Dragonball，而ARM的技术实力和商业模式，正好符合Nokia的需求。 1997年，Nokia推出了一代经典6110，它采用TI的芯片，处理器核心是ARM7TDMI。6110是Nokia第一款带红外接口的手机，第一次内置了经典的贪吃蛇游戏，它的界面成为了之后Nokia手机的标准。从此，Nokia和ARM成为了好基友，Nokia的Symbian操作系统，一直都建立在ARM架构的基础上。 1998年，趁着6110大红大紫的东风，ARM在Nasdaq上市了。同一年，SGI公司看到处理器IP授权生意有利可图，把MIPS部门拆分出来，次年MIPS推出了它第一款可授权的处理器设计M4K。此后的十年里，MIPS一直都是ARM有力的竞争对手。 商务通在中国流行的那几年，国际市场上流行性能更高的掌上电脑和智能手机，操作系统包括Palm OS、微软的WinCE、Nokia的Symbian、RIM的Blackberry OS，Motorola的Wisdom OS。在这个领域里，ARM阵营中负责高性能的XScale大放异彩，暴击Dragonball。当Dragonball的频率还停留在33MHz/66MHz时，Xscale已经飙到了200~400MHz。MC68000指令集在手持设备领域败走。Palm OS的1.0~4.0都是基于MC68000指令集的，5.0就换成了ARM。后来Motorola的半导体部门Freescale干脆推出了基于ARM核的iMX系列产品，替代Dragonball产品线。 苹果作为掌上电脑的先行者，却在这次浪潮里无所作为，在Wintel的挤压下，它的桌面业务都已经濒临绝境，无暇顾及其它市场了。1997年，不温不火的Newton从苹果公司独立了出来。当乔布斯回归苹果之后，又火速把Newton收编了回来，并且干净利落地停掉了Newton产品线——乔帮主只想要Newton手里的ARM股份。1998年到2003年，苹果通过出售ARM的股票获利11亿美元。这笔钱，是乔布斯复兴战略的重要燃料，可以说是苹果的救命钱。 绽放 经过多年的深耕，ARM在新世纪开始时，已经是手机领域里的王者，依然在为客户的需求做着持续的创新，Java加速技术就是一个典型的例子。 从2000年开始，功能手机的性能提升到了足够高的水平，人们希望在手机上玩比较复杂的游戏，而不仅仅是贪吃蛇。但是手机的处理器和操作系统实在是太分散了，为了方便游戏跑在不同手机上，J2ME平台应运而生。从原理上讲，J2ME和Applet并无不同，都是基于JVM的。Java在并不分散的桌面领域没有获得成功，但在分散的手机领域获得了成功。 J2ME的游戏越做越复杂，但手机的处理能力毕竟有限，桌面和服务器上的JIT编译器在手机上跑得太吃力了。于是ARM在2001年推出了ARM926EJ-S处理器，它支持Jazelle DBX技术，可以直接解码和执行Java的字节码，省掉了JIT编译器的负担。这一功能大受欢迎，帮助ARM9系列成为了迄今最受欢迎的ARM处理器，总共有250多个授权厂家，其中100多个授权的是ARM926EJ-S。 在MTK助推山寨功能机火遍神州的那几年，主控芯片所使用的核全部都是ARM9。在iOS和安卓的应用商店诞生之前，功能手机全靠J2ME开发的应用来实现各种炫酷的功能。从某种意义上讲，在低端市场上，Jazelle是助力山寨机火爆的最大幕后功臣。 然而高性能ARM芯片的扛把子XScale，却被Intel于2006年6月卖给了Marvell。这是Intel实施x86-everywhere战略的一个步骤。Intel希望x86的生态也能进入到低功耗的移动领域，而不是用自己先进的工艺制程和设计能力帮ARM建设高端应用的生态。22个月之后，2008年4月，低功耗的Atom芯片诞生了。 高性能ARM芯片的扛把子换成了苹果。2004年，在卖光ARM股票的一年之后，乔布斯决定研发iPhone。2007年1月，在Intel放弃ARM之后仅半年，iPhone诞生了。苹果可不会采用低端市场上死守ARM9那种玩法，iPhone一代就采用了400MHz的ARM11；2009年的iPhone 3GS，升级为600MHz的Cortex A8；2010年的iPhone4，苹果自研的A4芯片升级为1GHz的Cortex A8。接下来苹果自研芯片性能一路狂飙的历程，大家都很熟悉了。 从ARM6到ARM11，这些IP核都是按照兼顾移动设备、汽车电子和嵌入式这三个市场的思路来设计的。从2003年起，ARM把产品线有针对性地划分为A、R、M三个系列，分别对应上述三个市场，而且IP核的名字都统一加上了Cortex的前缀。Cortex A8就是A系列的第一个作品。iPhone 3GS和iPhone4令Cortex A8大火，但让ARM一飞冲天的推手，却是iPhone的竞争对手——安卓（Android）。 有很多文章介绍安卓如何诞生，如何在移动设备领域干掉了除iOS之外的全部对手，毋须赘述。这里只想强调一个被普遍忽略的事实：安卓从诞生之初，就要求应用程序采用Java编写，并且跑在Dalvik虚拟机上；但iPhone上的应用，都是原生的ARM程序。要知道Android手机的处理器性能相对iPhone并无优势。 山寨之王MTK于2009年2月推出的首款智能手机芯片MT6516，采用406MHz的ARM9；2008年~2010年间由HTC推出的那几款卖得很好的Android手机，也无非是ARM11和Cortex A8的核，几百兆的频率，这种级别的处理器跑虚拟机还是蛮吃力的。另外虚拟机占用内存大的缺点，也不利于用户体验和降低成本。 谷歌宁可冒着让安卓出师不利的风险，也要推广Dalvik虚拟机。这是为什么？谷歌内部的决策过程我们无从得知。一个合理的猜测是，谷歌不愿看到手机领域里ARM一家独大，它希望给MIPS、x86等其它CPU一个机会。J2ME的成功，让谷歌看到完全建立在虚拟机上的手机应用生态，是完全可能的。 Dalvik虚拟机可以跑Java，但并不采用JVM那种基于堆栈的字节码，而是改用一种基于寄存器的方案。这么做当然是为了规避SUN公司（后被Oracle收购）的专利，同时也让无法直接运行JVM字节码的MIPS、x86能够实现轻量级的JIT编译器，无须Jazelle这样的技术。从另外一个角度讲，MIPS在电视、机顶盒、游戏机市场上占优，x86在桌面市场近乎垄断，支持它们，也意味着安卓有可能进军电视和桌面。 安卓对所有CPU而言，都是巨大的机会，谁抓住了这个机会，就可以一举改变竞争格局，实现霸业。 只可惜MIPS公司太不给力，一直也没有搞定靠谱的MIPS版Android。等到2011年1月，Synopsys公司给自家的ARC处理器移植好Dalvik虚拟机和浏览器用的V8虚拟机、Android环境已完备的时候，MIPS都还没动静。顺便说一句，Intel曾经的南桥芯片里都有ARC处理器，它是Active Management Technology（AMT）的重要基石。 这个时候，北京的君正公司坐不住了。君正靠做低成本的MP4播放器起家，2011年5月在创业板上市。君正拥有MIPS的架构级授权，对自己研发的XBurst处理器非常自信，准备靠它进攻手机和平板市场。2011年7月，基于君正JZ4760的MIPS智能手机通过Android兼容性测试。2011年12月，基于君正JZ4770平台的平板电脑，被谷歌选为Android4.0的首发产品，一时风光无限。 ARM的强大软件生态此时起到了护城河的作用。基于君正的平板，软件兼容性出了问题。原因在于谷歌没有强求所有的应用都跑在Dalvik虚拟机上，对于部分对性能有苛刻要求的app，例如游戏，谷歌允许用CPU的原生指令集来开发，为此还提供了NDK（Native Development Kit）。对于那些包含了ARM原生指令的游戏，君正的平板要么不支持，要么用emulator支持，总之用户体验都不好。 ARM生态圈里，在2011年，正好有两家芯片厂商异军突起：全志和瑞芯微，它们分别推出了采用Cortex A8处理器的A10芯片和RK2918芯片，成本极低，主打平板和安卓电视盒子。君正的平板梦被它们粉碎了，之后只好转战安卓手表，消沉了很多年。对于MIPS而言，还有一个坏消息是，在它们的强力助推下，电视盒子市场也成了ARM的天下。经营不善的MIPS于2012年卖给了Imagination，Imagination不但没能依靠MIPS在CPU市场中有所作为，反而在GPU市场里也败给了ARM，在2017年被迫整体卖身，MIPS业务卖回给了硅谷公司。 2012~2016年，Intel在安卓市场上挑战ARM，也失败了。于是安卓给CPU带来的红利，全部被ARM吃掉了。随着手机越来越重要，ARM也越来越重要，它所推出的最新的Cortex A系列处理器，被手机芯片争相采用。ARM生态也越来越强大，它的触角，慢慢伸出了手机领域。 渗透 2011年1月，微软在CES宣布要为ARM架构开发Windows 8 RT操作系统。在2012年年底，几乎和Intel芯手机上市的同时，包括微软自家的Surface RT在内的一大批二合一平板设备上市了。Windows 8 RT不支持所有之前为x86平台开发的应用程序，这成为它最大的软肋，相关的产品慢慢销声匿迹了。ARM渗透桌面市场的第一次尝试失败了。 最近微软和高通所推出的ARM芯的Windows 10，吸取了教训，用Eumlation的机制来支持旧有的x86桌面程序。这次尝试能否成功，我们拭目以待。 2009年，ARM推出了Cortex A9处理器，并且用40nm的工艺制造了双核的样片，跑到了2GHz。这是ARM第一次推出乱序超标量的处理器核，而乱序超标量是Intel实现高性能的关键技术，这是非常振奋人心的消息。2010年，Marvell推出了1.6GHz的4核A9的服务器芯片Armada XP。2013年，这款芯片被部署在百度的存储服务器上，这是ARM服务器第一次大规模商用。但Marvell并未继续推出新的服务器芯片。2011年，一家创业公司Calxeda采用Cortex A9，推出了共有480个CPU核的ARM服务器。但它的成就还不如Armada XP，2013年公司就倒闭了。 2012年，AMD收购了一家做高密度服务器的厂商SeaMicro，准备把它所采用的CPU核由Intel的Atom换成ARM架构的CPU。但直到2014年AMD才推出8核Cortex A57的服务器芯片Opteron A1100，之后从来也没有认真卖过它。2015年AMD就放弃了SeaMicro这个子品牌，不再做高密度服务器了。 ARM进攻服务器市场的第一次尝试失败了。Marvell和Calxeda都采用的是32位的ARM核，先天不足；AMD则三心二意，毕竟自己还有x86 Server的生意。另外服务器市场对于单核单线程的运算能力也有很高的要求，仅仅有低功耗和高通量（high throughput）是不够的。 在ARMv8这一64位指令集发布之后，Cavium和AppliedMicro这两家老牌网络芯片厂商不约而同地将自己原先芯片中的架构换成了ARMv8。因为产品的需要，Cavium和AppliedMicro都有自行设计处理器微架构的能力，前者做MIPS处理器，后者做PowerPC处理器。它们两家做ARMv8处理器时，也都采用了只授权指令集，微架构自研的模式。Cavium共推出过两代基于ARM的产品（2014、2016年），AppliedMicro推出过三代（2013、2015、2017年）。随着产品性能逐渐接近Intel的Xeon E5，它们渐渐不再满足于原先的网络领域，开始觊觎服务器市场。 最让人期待的还是高通的Centriq芯片，2015年年底量产24核版本，2016年年底量产升级48核版本，还得到了微软的强力支持。考虑到高通还和贵州成立了合资公司华芯通，Centriq很可能成为在国内大规模商用的第一款ARM服务器芯片。 另外具有国防背景的天津飞腾公司，也有ARM服务器芯片的产品，只是不知道这些产品何时能在通用市场上铺货。 其他确定在研发ARM Server芯片的大厂还包括Broadcom和华为，进度上要略慢一些。 ARM阵营对服务器发起的第二波冲击，阵容要强大得多豪华得多。因此ARM才敢于宣称，在2021年拿下25%的服务器市场份额。 要做好Server CPU，ARM架构还有些功课要一点一点补。多Socket服务器所需要的一致性协议，业界刚刚取得共识准备采用CCIX，但还没有具体的产品出来。做云端虚拟机所必备的虚拟化支持，ARM还有些性能问题。x86处理器提升Throughput的利器超线程技术，ARM阵营尚不能支持。Intel芯片近年来陆续增加的安全特性，也够ARM追赶一阵子的。但目前看来，ARM已经没有致命的短板，蚕食掉Intel的服务器市场份额是板上钉钉的事情，唯一的悬念是究竟多少份额？ 未来ISA将不那么重要从长远看，半导体厂商对建立于ISA之上的生态系统的掌控力会变弱，而ISA本身，会变得越来越不重要。这是软件技术发展的趋势决定的，如前所述，这些技术在90年代末就已经初有小成了。 第一是**Web**技术。网页开发领域，有一个大家视若无睹的奇迹：最后居然只有Javascript一种开发语言屹立至今。要知道在服务器端和移动App领域，开发语言多如过江之卿。其中原因我也分析不出。反正js的挑战者（微软的VBScript和谷歌的Dart）都失败了。网页开发领域面临的主要问题是浏览器差异大，API不太兼容。这个问题慢慢在缓解中，一来浏览器战争大局已定，Android和PC上的Chrome，以及iPhone和Mac上的safari是胜者；二来很多网页应用是跑在App里面的，例如微信和支付宝里，这种场景下Javascript的API已经被特定厂商规范过了。 由于开发语言和API的高度统一，H5（HTML5+Javascript）已经成了兼容所有硬件的最通用的软件开发平台。曾经有人鼓吹H5会赶走移动端和PC端的原生程序，后来被打脸了。但是移动端和PC端的原生App中，越来越多的界面是用H5生成的了，微信、支付宝、京东、淘宝、爱奇艺、有道词典……统统都是这样。 Javascript吞噬一切的进程还在持续。2007年，Stack Overflow的联合创始人Jeff Atwood曾经提出过一条Atwood定律：任何能够用JavaScript实现的应用系统，最终都必将用JavaScript实现。十年过去了，此定律基本奏效。把Javascript的一个子集当作汇编语言的asm.js及其后续的WebAssembly，更加使得网页应用有媲美原生应用的潜力，在浏览器里跑Unity3D的游戏都不是问题。 独立的应用程序仍然会是移动和桌面端的主流，因为没有独立程序，不方便做弹窗广告，不方便启动后台进程收集用户信息，不方便引诱用户安装其它独立程序。但Web的能力的确在快速提升，Web Component技术实现了类似GUI库的Widget复用，如今在浏览器里实现Office和IDE的功能都毫无问题（office365.com、docs.google.com、editor.construct.net、腾讯文档）；而WebGL已经能支持Unity3D这种大型游戏框架。 照此趋势发展下去，独立应用程序仅仅会作为一个包装而存在，开发者写一套H5，加上不同的包装，就成了PC、Mac、Android、iOS上的独立应用程序，不加包装，就是网站。微软去年开源的ReactXP，就是为了实现这一目标。 这意味着什么？不但底层的CPU被OTT了，操作系统也被OTT了。因为移植一个应用程序到各个平台上，几乎没有什么难度。谁将是生态系统的掌控者？若干个超级App，像微信、QQ、支付宝这样的。它们不但包装自家的应用，其它开发者也可以把自己的应用放在这个包装里面，借重超级App的广泛覆盖度，抵达最终用户。前文提到了，如果微信小程序获得成功，腾讯必然会重拾Q+的野心，把QQ变成桌面上各种H5应用的App Store。 如果真的会这样，微软岂不是会比Intel还着急？拜托，微软已经不是二十年前主要靠卖Windows和Office的光盘赚钱的那家公司了，未来它会专注于云计算。但Intel还和二十年前一样在卖芯片。 第二是编译技术尤其是虚拟机的发展。如今的编程语言太多了，80年代那种搞定C语言编译器就OK的好日子早已过去。任何一个新CPU架构要想在移动、桌面、服务器市场站稳脚跟，都得搞定无数的编译器（包括虚拟机用的JIT编译器），这是个坏消息。但好消息是，搞定这些编译器基本就差不多了，不用劝说开发者重写汇编代码。 老一代程序员对x86处理器架构和汇编都非常熟悉。求伯君当年开发WPS时，手写几十万行汇编；雷军读本科时，是系里20多年来拿过《汇编语言程序设计》满分成绩的两个学生之一；梁肇新开发超级解霸时，把MMX汇编玩得出神入化。感兴趣的读者可以看看梁的《编程高手箴言》，那里面，描绘了一个对现在的程序员而言，完全陌生的世界。在那个世界里，你开发的PC应用程序想要移植到Mac平台上，几乎要完全重写。 如今高层次的编程语言接管了一切，汇编语言从很多学校的本科课程里消失了，入门教材也从C改成了Java，甚至是Javascript或Python。程序员完全不熟悉底层的CPU。即使是真的需要拼性能的场合，编译器也在很大程度上代替了手写汇编。ARM的工程师告诉我说，ARM在开发开源的Compute Library过程中，主要依靠在C源码中加入标注来指导编译器生成SIMD指令，而不是像梁肇新那样手写。 在这种情况下，软件平台厂商就变得非常强势，因为他们知道，应用开发商只需付出重新编译一遍的代价。比如苹果，就要求所有的App都改为64位的。这样，未来苹果在手机CPU里放弃对32位应用的支持时，甚至都不会有人感觉得到。这对于x86生态系统而言，简直是天方夜谭，显然微软对此非常眼馋，并且尝试在Windows 10 S中复制这种掌控力。 至于谷歌，Android把所有应用都跑在虚拟机上的尝试虽然失败了，但如果未来它再针对AR/VR、AI或机器人发布一个什么软件平台的话，就很有可能完全禁止原生程序。 而Oracle，正在努力开发可以支持所有编程语言、能把所有CPU给OTT掉的全新VM：GraalVM。我们拭目以待。 第三是**Emulation**技术的发展。虽然眼下ARM阵营中靠Emulation进攻Intel的先锋是高通，但最可怕的选手其实是NVidia。NVidia拥有最厉害的Emulation技术，而且江湖传言Denver处理器的初衷就是针对x86的。当初NVidia的Tegra处理器曾被拿来做Windows 8 RT的二合一平板。如今Denver处理器跑Windows 10绝不会让人意外，那么它会怎么跑呢？肯定是直接在底层硬件上做x86的Emulation，而不是在Emulate出来的ARM指令集上再做一层Eumulation。 Denver处理器前些年没有跳出来抢Intel的饭碗，很大程度上是因为NVidia还在做Intel平台的主板芯片组，另外NVidia还没有那么强大。如今NVidia也不做芯片组生意了，还借AI的东风，股价扶摇直上。说不定哪天，NVidia就会放出Denver处理器的x86 Emulator，做到单线程性能不输Xeon，强攻服务器市场。想想看，在单芯片上集成GPU和x86版的Denver，云计算厂商能不动心？ 如果未来Emulation技术进一步发展并且被越来越多的厂商掌握，很可能会出现这种情况：CPU本身是某种外界不了解的指令集，官方发布时，只能Emulate某种开放的指令集，例如RISCV；但是用户可以给它安装不同的Emulator，让它变成x86-64处理器，或者ARM64处理器。在软件定义一切的时代，这并不是多么疯狂的想象。 总之，CPU依然不可或缺，但CPU用谁家的，是什么指令集，会越来越不重要。软件的发展，会在用户和底层的CPU之间加入足够大的缓冲带，CPU的差异，越来越难以被用户察觉到。 展望：让CPU不再难此文在最后修改之时，看到了梁宁的文章《一段关于国产芯片和操作系统的往事》，里面写到： 就像10多年前一样，只要搞定知识产权问题，选择技术路线，找会干的人，投入干，CPU/芯片就能够做出来。搞不定的依然是操作系统。差距大的依然是生态。当年，绕得过Intel，跨不过微软。如今，绕得过Arm，做不出安卓。 我也曾在北大参与过国产CPU的研发，生态之难体会颇深，真的，只是烧钱做芯片，无论烧多少都无法挑战Intel和ARM，何况过去二十年真的没烧多少。 但我并没有梁宁那么悲观，毕竟技术的潮流无法抗拒，借用马化腾的一句名言“可能你什么错都没有，最后就是错在自己太老了”。 Intel和ARM如此强大而且极少犯错，我们如此弱小就算它们犯错也无法利用——但我们可以欺负它们的“老”。 在此借新智元的宝地，向小马哥呼吁一声： 请借助腾讯的强大生态，把CPU和OS这两个老大难问题给OTT掉吧！ 做法非常简单，把Q+桌面再重新搞起来，做一款完全使用Javascript&amp;Webassembly编程的操作系统，里面用腾讯文档来替代Office，各种微信小程序都支持起来，适当支持游戏（但要加入家长监控系统）。补贴芯片厂，让它们使用ARM或RISC-V外加国产Imagination gpu做SoC，生产类似Surface这样的二合一平板。底层CPU使用的ISA完全不可见，上层编程完全用H5。这样，就帮祖国把CPU和OS这两个陈年大洞都补上了。 芯片要下苦功，别凡事都指望模式创新。这不假。但偏偏CPU真的面临一个十倍速变革的机会，真的有靠模式创新而胜出的机会，为什么不试试呢？如果腾讯不去尝试一下，谁还有资格呢？促进祖国的微电子发展功德无量，相信这次不会有人说腾讯垄断之类的闲话。 【加入社群】 新智元 AI 技术 + 产业社群招募中，欢迎对 AI 技术 + 产业落地感兴趣的同学，加小助手微信号&#58; aiera2015_1 入群；通过审核后我们将邀请进群，加入社群后务必修改群备注（姓名 - 公司 - 职位；专业群审核较严，敬请谅解）。 转载来源：为中国芯万字投书马化腾：从Intel和ARM争霸战，看看做芯片有多难]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>编程语言</tag>
        <tag>IBM</tag>
        <tag>英特尔</tag>
        <tag>ARM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法与产品：抖音、快手的“气质”成因]]></title>
    <url>%2F2018%2F974c8151%2F</url>
    <content type="text"><![CDATA[视频与用户画像的匹配程度热度发布时间根据用户数据和内容标签计算两者的匹配程度，是每个内容产品的算法核心，已经被总结很多次了。 同一类型的两款产品，从功能上看，似乎没有明显差别，但为什么给人的“感觉”却是完全不同呢？ 算法快抖的视频内容分为推荐（发现）、附近（同城）和关注三个模块，这里主要说明推荐模块的算法机制。 视频与用户画像的匹配程度1. 热度（赞、评论、转发等）1. 发布时间根据用户数据和内容标签计算两者的匹配程度，是每个内容产品的算法核心，已经被总结很多次了，其理论大体一致，在本社区搜索“算法”关键词就能找到，这里就不再赘述了，下面主要介绍热度和发布时间两点。 打开你的抖音，你会看到系统已经为你推荐好了一系列内容，再仔细观察一下，你会发现这些视频的获赞数量基本都在50万以上，中位数大概在100万（刷多了会减少）。 而打开快手呢？ 你会发现视频获赞数量基本维持在1万到10万这个区间，有的甚至会出现几千几百，但很难找到过10万的视频。 出现这种差距，难道是因为快手用户少吗？ 显然不是，快手的用户已经是其他短视频产品的用户之和了。之所以出现这种状况，其实是因为快手算法特有的“热度权重“。 视频发布初期，随着其热度提高，曝光机会也会跟着提高，此时，“热度权重”起到“择优去劣”的作用。而在视频热度达到一定阈值后，它的曝光机会将不断降低，此时，“热度权重”起到“择新去旧”的作用（其实是为了给用户平等的展示机会，后面会讲到）。 与此同时，快抖对于“发布时间”的看法也是不一样的。 在抖音，你会发现很多视频其实几个月前就发布了（验证这一点，只需要在评论区不断下翻即可，可根据早期评论的发布时间进行推断）。因为用户一般不会在乎短视频是不是最新的，只要足够精彩即可。 而在快手，大部分视频都是近期发布的，再远的视频也是一个月内（在视频界面右下方有时间标注）。 那么，前面提到的“热度权重”和“发布时间权重”对于用户来讲又会有怎样的影响呢？ 首先，短视频的用户大体分两种：一种是“看视频”的看官，一种是“拍视频”的制作方。这里，我们把看官的注意力比作一个蛋糕，而制作方比作分蛋糕的人。 首先，我们来看分蛋糕的人。在抖音，分到大量蛋糕的用户还会继续加快分蛋糕的速度（高热度会不断提高曝光机会），头部用户集中了大量的用户注意力资源，这种中心化会让普通制作者、草根制作者难以被关注（这与微博颇为类似）。 而在快手，头部用户分到的蛋糕被设了上限（高热度和旧视频曝光机会会大大降低），因此会有更多的人分到蛋糕，这也体现了快手的理念——希望所有用户都能展示自我，任何一位普通用户都有被关注的权利。 对于看官来说，抖音给了他们大量的优质资源，这些都是经过大量用户检验，而放到推荐模块的内容池的视频。而快手只是经过初步检验就根据用户喜好开始推荐了，所以会有很多小众和“乡土”的内容。 抖音和快手，一个是精致的台上表演，一个是平凡的街边才艺。 相对来说，抖音是看官导向的，而快手则更偏向于制作方，尤其是草根用户。这也就不难理解为什么快手会沦落到被整改的尴尬境地，因为“三俗”生产者总能找到自己的市场。 产品除了算法，我认为以下两点也是快抖气质差异的诱因。 录制功能1. 交互设计 1. 先音乐后录制的妙处与其他短视频不同，抖音的录制功能别具一格，先选音乐再根据音乐录视频，而不只是充当背景音乐。 每当视频的动感与音频的调子相重合时，会大大刺激观众的感官，带来不一样的体验。同时，也产生了更多玩法，比如：对口型、拍同款等，增加了趣味性、可看性。因此，抖音会给人一种“酷炫”的感觉（但是拍摄门槛也抬高了）。 2. 不断上滑的“沉浸式体验”一打开抖音，便进入了播放界面，接着依靠上下滑动来更换视频，嗯 … 这种状态可以维持一个多小时 … 这种懒人式交互大大提升了用户粘性，不过也削弱了用户改变“状态”的意愿，即附近模块、关注模块的使用几率将会降低。由此，用户的注意力又被“粘”在了头部用户的优质内容上，中心化进一步加剧。 与之相反的，快手的推荐（发现）对用户并没有那么大的粘性，三个模块的交互方式相当，都是瀑布流布局，并且快手的启动页是用户上一次退出的页面。 比如：上一次在同城离开，下一次启动页会是同城模块，关注模块也是如此，这样，用户选择的自由度“无形”地增加了。同时，快手也因其同城和关注的高使用频率，而在社交属性上更胜一筹，而不仅仅是一个娱乐软件。 其实快抖的算法与交互设计是相辅相成的，抖音的算法决定了它的视频更加优质，因此不需要用户做太多的选择，适合逐个播放，也减少了用户操作负担和选择负担。而快手视频的优质密度没有那么大，需要用户选择播放，在操作上会繁琐一些。 回忆一下我们使用抖音的时候，是不是一般会看完整个视频再播放下一个，很少掠过。而使用快手的时候，我们通常要掠过几个，才能选出自己想看的视频。 因此，“滚动播放”更适合抖音，而瀑布流适用于快手（其实快手也可以尝试美拍的“瀑布流+滚动播放相关视频”的交互设计，或者抖音附近模块的“瀑布流+滚动播放下一个视频”的交互设计）。 结尾除了算法和产品设计，还有着其他因素导致快抖的风格差异，比如：运营和品牌公关。 不过从效果上看，算法和产品设计更像是产品的“基因”，从最开始就影响着“两个宝宝”的未来走向（抖音的精致范和快手的平民化）。 如何设计出我们想要的产品，让“宝宝”长成我们想要的样子，抖音和快手的实例值得我们借鉴。 本文由 &#64; 信管专业学生 原创发布于人人都是产品经理。未经许可，禁止转载 题图来自网络 转载来源：算法与产品：抖音、快手的“气质”成因]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>软件</tag>
        <tag>蛋糕</tag>
        <tag>甜品</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何判断一个人是杰出的聪明人还是平庸的普通人？]]></title>
    <url>%2F2018%2F39e0aa89%2F</url>
    <content type="text"><![CDATA[埃隆马斯克曾在一次采访中描述了他是如何理解因果关系的：“我会从概率的角度来看待未来，它就像一个概率的分支流。 转载来源：如何判断一个人是杰出的聪明人还是平庸的普通人？]]></content>
  </entry>
  <entry>
    <title><![CDATA[为什么“兴趣广泛”的通才更有可能获得成功？详解通才的7大优势]]></title>
    <url>%2F2018%2F8e15e6e3%2F</url>
    <content type="text"><![CDATA[http&#58;//36kr.com/coop/toutiao/5129242.html?ktm_source=toutiao&amp;tt_from=weixin&amp;tt_group_id=6546697597971595790 为什么“兴趣广泛”的通才更有可能获得成功？详解通才的7大优势 转载来源：为什么“兴趣广泛”的通才更有可能获得成功？详解通才的7大优势]]></content>
  </entry>
  <entry>
    <title><![CDATA[textgenrnn：只需几行代码即可训练文本生成网络]]></title>
    <url>%2F2018%2F22dc3d88%2F</url>
    <content type="text"><![CDATA[本文是一个GitHub项目，介绍了textgenrnn，一个基于Keras/TensorFlow的Python3模块。 本文是一个 GitHub 项目，介绍了 textgenrnn，一个基于 Keras/TensorFlow 的 Python 3 模块。只需几行代码即可训练文本生成网络。 项目地址：https&#58;//github.com/minimaxir/textgenrnn?reddit=1 通过简简单单的几行代码，使用预训练神经网络生成文本，或者在任意文本数据集上训练你自己的任意规模和复杂度的文本生成神经网络。 textgenrnn 是一个基于 Keras/TensorFlow 的 Python 3 模块，用于创建 char-rnn，具有许多很酷炫的特性： 它是一个使用注意力权重（attention-weighting）和跳跃嵌入（skip-embedding）等先进技术的现代神经网络架构，用于加速训练并提升模型质量。- 能够在字符层级和词层级上进行训练和预测。- 能够设置 RNN 的大小、层数，以及是否使用双向 RNN。- 能够对任何通用的输入文本文件进行训练。- 能够在 GPU 上训练模型，然后在 CPU 上使用这些模型。- 在 GPU 上训练时能够使用强大的 CuDNN 实现 RNN，这比标准的 LSTM 实现大大加速了训练时间。- 能够使用语境标签训练模型，能够更快地学习并在某些情况下产生更好的结果。能够在字符层级和词层级上进行训练和预测。 能够对任何通用的输入文本文件进行训练。 在 GPU 上训练时能够使用强大的 CuDNN 实现 RNN，这比标准的 LSTM 实现大大加速了训练时间。 你可以使用 textgenrnn，并且在该 Colaboratory Notebook（https&#58;//drive.google.com/file/d/1mMKGnVxirJnqDViH7BDJxFqWrsXlPSoK/view?usp=sharing）中免费使用 GPU 训练任意文本文件。 示例 &#91;Spoiler&#93; Anyone else find this post and their person that was a little more than I really like the Star Wars in the fire or health and posting a personal house of the 2016 Letter for the game in a report of my backyard. 该模型可以很容易地在新的文本上进行训练，甚至可以在仅仅输入一次数据之后生成合适的文本。 Project State Project Firefox 这个模型的权重比较小（占磁盘上 2 MB 的空间），它们可以很容易地被保存并加载到新的 textgenrnn 实例中。因此，你可以使用经过数百次数据输入训练的模型。（实际上，textgenrnn 的学习能力过于强大了，以至于你必须大大提高温度（Temperature）来得到有创造性的输出。） Why we got money “regular alter”Urburg to Firefox acquires Nelf Multi ShamnKubernetes by Google’s Bern 您还可以训练一个支持词级别嵌入和双向 RNN 层的新模型。 使用方法 textgenrnn 可以通过 pip 从 pypi（https&#58;//pypi.python.org/pypi/textgenrnn）中安装： 你可以在该 Jupyter Notebook（https&#58;//github.com/minimaxir/textgenrnn/blob/master/docs/textgenrnn-demo.ipynb）中查看常见的功能和配置选项的演示案例。- /datasets 包含用于训练 textgenrnn 的 Hacker News 和 Reddit data 示例数据集。- /weights 包含在上述的数据集上进一步预训练的模型，它可以被加载到 textgenrnn 中。- /output 包含从上述预训练模型中生成文本的示例。/datasets 包含用于训练 textgenrnn 的 Hacker News 和 Reddit data 示例数据集。 /output 包含从上述预训练模型中生成文本的示例。 神经网络架构及实现 textgenrnn 基于 Andrej Karpathy 的 char-rnn 项目（https&#58;//github.com/karpathy/char-rnn），并且融入了一些最新的优化，如处理非常小的文本序列的能力。 本文涉及到的预训练模型遵循 DeepMoji 的神经网络架构（https&#58;//github.com/bfelbo/DeepMoji/blob/master/deepmoji/model_def.py）的启发。对于默认的模型，textgenrnn 接受最多 40 个字符的输入，它将每个字符转换为 100 维的字符嵌入向量，并将这些向量输入到一个包含 128 个神经元的长短期记忆（LSTM）循环层中。接着，这些输出被传输至另一个包含 128 个神经元的 LSTM 中。以上所有三层都被输入到一个注意力层中，用来给最重要的时序特征赋权，并且将它们取平均（由于嵌入层和第一个 LSTM 层是通过跳跃连接与注意力层相连的，因此模型的更新可以更容易地向后传播并且防止梯度消失）。该输出被映射到最多 394 个不同字符的概率分布上，这些字符是序列中的下一个字符，包括大写字母、小写字母、标点符号和表情。（如果在新的数据集上训练一个新模型，可以配置所有上面提到的数值参数。） 或者，如果可以获得每个文本文档的语境标签，则可以在语境模式下训练模型。在这种模式下，模型会学习给定语境的文本，这样循环层就会学习到非语境化的语言。前面提到的只包含文本的路径可以借助非语境化层提升性能；总之，这比单纯使用文本训练的模型训练速度更快，且具备更好的定量和定性的模型性能。 软件包包含的模型权重是基于（通过 BigQuery）在 Reddit 上提交的成千上万的文本文档训练的，它们来自各种各样的 subreddit 板块。此外，该网络还采用了上文提到的非语境方法，从而提高训练的性能，同时减少作者的偏见。 当使用 textgenrnn 在新的文本数据集上对模型进行微调时，所有的层都会被重新训练。然而，由于原始的预训练网络最初具备鲁棒性强得多的「知识」，新的 textgenrnn 最终能够训练地更快、更准确，并且可以学习原始数据集中未出现的新关系。（例如：预训练的字符嵌入包含所有可能的现代互联网语法类型中的字符语境。） 此外，重新训练是通过基于动量的优化器和线性衰减的学习率实现的，这两种方法都可以防止梯度爆炸，并且大大降低模型在长时间训练后发散的可能性。 注意事项 即使使用经过严格训练的神经网络，你也不能每次都能得到高质量的文本。这就是使用神经网络文本生成的博文（http&#58;//aiweirdness.com/post/170685749687/candy-heart-messages-written-by-a-neural-network）或推文（https&#58;//twitter.com/botnikstudios/status/955870327652970496）通常生成大量文本，然后挑选出最好的那些再进行编辑的主要原因。 不同的数据集得到的结果差异很大。因为预训练的神经网络相对来说较小，因此它不能像上述博客展示的 RNN 那样存储大量的数据。为了获得最佳结果，请使用至少包含 2000-5000 个文档的数据集。如果数据集较小，你需要在调用训练方法和／或从头开始训练一个新模型时，通过调高 num_epochs 参数来对模型进行更长时间的训练。即便如此，目前也没有一个判断模型」好坏」的启发式方法。 你并不一定需要用 GPU 重新训练 textgenrnn，但是在 CPU 上训练花费的时间较长。如果你使用 GPU 训练，我建议你增加 batch_size 参数，获得更好的硬件利用率。 未来计划 更多正式文档；- 一个使用 tensorflow.js 的基于 web 的实现（由于网络规模小，效果特别好）；- 一种将注意力层输出可视化的方法，以查看神经网络是如何「学习」的；- 有监督的文本生成模式：允许模型显示 top n 选项，并且由用户选择生成的下一个字符/单词（https&#58;//fivethirtyeight.com/features/some-like-it-bot/）；- 一个允许将模型架构用于聊天机器人对话的模式（也许可以作为单独的项目发布）；- 对语境进行更深入的探索（语境位置 + 允许多个语境标签）；- 一个更大的预训练网络，它能容纳更长的字符序列和对语言的更深入理解，生成更好的语句；- 层次化的作用于词级别模型的 softmax 激活函数（Keras 对此有很好的支持）；- 在 Volta／TPU 上进行超高速训练的 FP16 浮点运算（Keras 对此有很好的支持）。一个使用 tensorflow.js 的基于 web 的实现（由于网络规模小，效果特别好）； 有监督的文本生成模式：允许模型显示 top n 选项，并且由用户选择生成的下一个字符/单词（https&#58;//fivethirtyeight.com/features/some-like-it-bot/）； 对语境进行更深入的探索（语境位置 + 允许多个语境标签）； 层次化的作用于词级别模型的 softmax 激活函数（Keras 对此有很好的支持）； 使用 textgenrnn 的项目 Tweet Generator：训练一个为任意数量的 Twitter 用户生成推文而优化的神经网络。 转载来源：textgenrnn：只需几行代码即可训练文本生成网络]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>GitHub</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[朝鲜买房指南]]></title>
    <url>%2F2018%2Fd462d30b%2F</url>
    <content type="text"><![CDATA[买套房不容易 转载来源：朝鲜买房指南]]></content>
      <tags>
        <tag>地球知识局</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三四线的房子，都被这些人买走了（100城数据分析）]]></title>
    <url>%2F2018%2F8f1a9488%2F</url>
    <content type="text"><![CDATA[请登陆wallstreetcn.com，或下载华尔街见闻APP，文中观点不构成投资建议。2017年以来，三四线城市楼市迎来了一轮普遍可见的成交热销和价格上涨。 来源：华尔街见闻（ID：wallstreetcn），更多精彩资讯请登陆wallstreetcn.com，或下载华尔街见闻APP，文中观点不构成投资建议。 2017年以来，三四线城市楼市迎来了一轮普遍可见的成交热销和价格上涨。 三四线楼市那么热，房子都被哪些人买走了？这些购买者是投资还是自住？他们是当地人还是外地人？ 近期，克而瑞研究中心（CRIC）调研100座三四线城市，对购房人群个体特征和购房偏好进行了多角度研究，见闻君为大家带来了脱水版报告。（文中数据及图片均来自 CRIC） 01 购房者来源：本地人为主 从购房客户来源来看，三四线城市一般还是以本地客户为主，本地客户平均占比超过八成，外地客户接近20%，比一二线典型城市高出9个百分点。 从区域来看，华南的三四线城市吸引的外地跨市购房投资客相对较多，外地客户占比最多，达到近三成，比全国均值高出近一成。这一方面是因为华南民间投资氛围更加浓厚，购房溢出需求更为强烈，另一方面也是因为华南区划内城市相对密集，广东、广西三线城市距离核心城市距离更近，核心城市需求外溢的距离成本相对较低。 外地购房客户占比最高的五个城市为三亚、佛山、东莞、鄂州和廊坊，三亚的外地客户占比高达5成，其余四市的外来客户占比也都在4成以上。 其中，值得一提的是湖北省鄂州市，外地客群占比达到63%，主要来自武汉。2017年鄂州房价涨幅高达31%，主要原因是顺丰机场建设利好。 除三亚等少数旅游城市以外，大多数三四线城市的外地客源还是来自于房价水平更高的一二线城市，具体购房动机方面不一而足，或是出于返乡置业需要，或是因为核心城市边界扩张、或是为了资产配置的投资性需求需要。 02 购房者年龄：35岁以上近6成 25岁至50岁的客户是三四线购房者的主力，占比最高的客户年龄段为35-40岁，占整体购房者数量的22%。 正是有更多外来成年客户的涌入，三四线购房者平均年龄更大一些， 35岁以上购房者占比达到了57%，比一二线高出3个百分点。 分区域来看，华北的购房客群年轻化较为明显，西南、东北区域客户整体购房年龄偏大。 03 购房谁做主：以男性为主转向夫妻 购房决策正在从以男性决策为主逐渐向夫妻共同决定转变，占比均为34%。 按各区域表现来看，华北男性主导占比最大，达到4成；而女性在购房决策中的占比在各区域之间差异不大。 04 购房动机：刚需客群仍是主流 在购房用途方面，整体来看仍然以首次置业、首次改善为主，基本符合目前市场“房住不炒”的主旋律，但投资需求的占比也在逐渐加大。 从各区看，华东、华南的客户投资意识显然领先于全国其他区域，西北区域市场发展相对缓慢，投资型购房的占比较低，首次置业及首次改善的客户占比高达8成。 从住宅拥有情况来看，只拥有1套房的客户占比还是最高的，占总购房客户的39%，拥有1-2套房产是常态，说明更多人仍处于刚需或者置换的阶段。 拥有房屋套数达到四套及以上客户占比最高的五个城市为遵义、北海、三亚、揭阳和莱芜。 05 资金来源：首套贷款近半 2017年的购房客户中，背负首套房贷的客户占比最高，有49%的客户使用首套贷款，其次为使用二套贷款的客户占比为31%，而全款购房的客户则较少，仅占总客户的2成左右。 二套贷款使用占比较高的区域为华东、西南和华南，均达到了35%及以上。使用二套贷款的客户越多，说明该区域客户在购房市场上更加活跃，投资性购房行为也更多。 在2017年三四线城市市场热度提高，表现优异，除了政策推动以外，三四线城市积极推行的货币化安置也起到了较大作用，甚至有3%的项目中有40%以上客户为货币化安置客户。 06 购房偏好：90-120㎡、50-100万最受欢迎 从面积来看，三四线城市的居民在购房上依旧以首购和改善类刚性需求为主， 90-120平方米的产品依旧是各区域购房者的最爱，占总比的33%。 从价格来看，各个区域三四线城市的购房者的主要偏好仍是50-100万类型的产品，其中以西北地区和华中地区为最，占比分别为51%和50%。 从总体上看，三四线城市的购房者对三房类型的产品购买意愿最为强烈，近半成（占比为48.61%）的购房者都对三房类产品感兴趣。 ▼ 欢迎转发和点赞支持见闻君 转载来源：三四线的房子，都被这些人买走了（100城数据分析）]]></content>
      <categories>
        <category>房产</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>购房</tag>
        <tag>CRIC</tag>
        <tag>房产</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[专访｜基于LSTM与TensorFlow Lite，kika输入法是如何造就的]]></title>
    <url>%2F2018%2F0aeec824%2F</url>
    <content type="text"><![CDATA[近日，机器之心采访了 kika 的高级技术总监黄康，他向我们讲述了 kika 开发输入法 AI 引擎（项目代号：Alps）所采用的深度学习模型以及在移动端轻量化部署遇到的各种挑战。本文从输入法与语言模型开始介绍了 kika Alps 项目的理论支持与实践挑战，并重点讨论了轻量化部署方法。 深度学习模型由于强大的表征能力在很多任务上都有非常优秀的表现，但也因为模型大小和计算量很难轻量化部署到移动端。这也是目前很多研发团队都在思考如何解决的难题。 一般在我们借助 TensorFlow、MXNet、和 Caffe2 等框架构建深度学习模型后，它在服务器训练与推断往往会有非常好的效果。但如果我们将模型部署到移动端，即使只执行推断过程，也会因为硬件条件和系统环境而遇到各种各样的问题。此外，目前关注于移动端的解决方案如 TensorFlow Mobile、TensorFlow Lite 等在一定程度上并不完善（TF Mobile 的内存管理与 TF Lite 的 Operators 的缺失），在实践中可能需要更多的修正与完善。 关注于输入法的 kika 成功地将基于循环神经网络的深度学习模型应用到安卓版的手机输入法引擎中，在克服工程化问题的情况下大大提升了输入体验：不仅使基于上下文的词预测更加准确，同时还使得词纠错功能更加强大。 在构建这样的输入法引擎过程中，kika 不仅需要考虑使用 LSTM 还是 GRU 来实现高效的语言模型，同时还需要探索如何使整个方案更轻量化以及如何快速的进行部署。本文首先介绍了输入法及 kika 所采用的语言模型，并在随后展示了 Android 移动端轻量化部署所遇到的工程化挑战。最后，本文介绍了 kika 压缩模型所采用的稀疏词表征方法与 K-means 参数量化方法，它们是轻量化部署深度学习模型的重要前提。 输入法与语言模型 输入法最重要的部分就是输入法引擎，kika 很多算法和项目都围绕它展开。一般而言，输入法引擎的输入包含两部分，即已经键入的词组和当前正在输入的词汇，前者可以视为上下文，而未完成的后者可称为键码。输入法引擎的输出是给定所有上下文和当前输入键码所『预测』的词，它也包含两部分，即当前输入词汇的补全和纠错。实现这样的功能也就是输入法最为核心的模块，kika 最开始是使用谷歌半开源的 LatinIME 来实现这样的功能，但这种基于 n-gram 的方法并不能实现顶尖的用户体验，因此经过研究与开发才有了现在基于循环神经网络（RNN）的解决方案。 输入法引擎这种给定上下文和当前键码以预测下一个词的方法其实可以看成语言建模，一般来说，语言模型旨在定义自然语言中「标记」的概率分布，这种标记可以是单词、字符甚至是字节。根据 kika 介绍，LatinIME 构建语言模型的方法是 n-gram，这种模型定义了一个条件概率分布，即给定前 n-1 个单词后第 n 个词的条件概率。因为假定当前词出现的概率只与前面 n-1 个词相关，那么 n-gram 可以使用这种条件概率的乘积来定义较长序列的概率分布： 虽然 n-gram 一直以来都是统计语言模型的核心模块，但它还是有很多局限性。对于输入法而言，较小的 n（二元语法与三元语法）不足以捕捉整个上下文信息来执行预测，而增大 n 又会使计算量成指数级增加。此外，kika 还希望引擎实现其它一些智能功能，例如根据上下文自动纠错或排序等。因此，kika 选择了更强大的循环神经网络构建语言模型。 为了构建强大的语言模型，kika 选择了长短期记忆单元（LSTM）作为网络的基础。LSTM 作为标准循环神经网络的变体在语言模型上有非常好的性能，它引入自循环的巧妙构想来更新「记忆」，若通过门控控制这样的自循环，那么累积的历史记忆或时间尺度就可以动态地改变。直观来说，LSTM 会通过门控选择需要保留的上下文信息或记忆，并用于预测当前输入的词。每当输入一个词，输入门会控制当前输入对最终预测有用的信息，而遗忘门会控制前面输入词对最终预测有用的信息，最后的输出门则会直接控制前两部分最终有效的信息。 kika 表明最开始 LSTM 只是用来实现标准的语言模型，它不会将正在输入的键码作为模型输入。这一套早期方案使用 LSTM 语言模型根据上下文预测当前词，而键码部分仍然使用传统基于 n-gram 和字典等的解决方案。后来 kika 使用一种新的策略将两部分结合在一起，因此模型不仅能接受上下文的输入，同时还能接受键码的输入。这种通用解决方案的架构如下图所示，它和一般的单词级语言模型和字符级语言模型都不一样，可以说是结合了两种架构。 如上图所示，首先 LSTM 会对前面输入的词进行建模，并输出对应的隐藏状态和记忆而作为后面字符级语言模型的先验输入。后面从 Start Flag 开始对键码实现字符级的建模而最终得出预测。 根据 kika 的解释，最后这种方案统一了两种输入。它的基本思想首先考虑到前面的 LSTM 语言模型除了要根据隐藏状态预测当前时间步的输出，同时还会向后传递这个隐藏状态。且 kika 表示若网络有良好的训练，那么这个隐藏状态是可以包含足够的语意信息，因此我们可以将它作为后面字符级 LSTM 网络的初始状态。这相当给循环神经网络一个初始量，然后再接受键码的输入而作出最终的词预测和词纠错等。 其实这里还有一个非常有意思的问题，即为什么 kika 会采用 LSTM 而不是 GRU。因为我们知道若需要将深度学习模型部署到移动端，那么我们要严格控制模型与计算量的大小，kika 所采用的稀疏词表征与参数量化等方法能有效控制模型大小，这一点将在后文展开。但 LSTM 的结构比 GRU 要复杂，门控也需要得更多，因此 LSTM 的参数会比 GRU 多，那么 kika 为什么不采用 GRU 控制参数数量？ kika 就这一点对机器之心做了详细的解答。黄康说：「在层数和单元数均一致的情况下，GRU 要比 LSTM 少一些参数和矩阵运算，因此，模型体积和训练速度方面都会有一定的优势。为了严谨的进行效果对比，我们做了两组实验。其中第一组是将 LSTM 和 GRU 的超参数设置一致，结果是： GRU 的效果明显差于 LSTM，同时，由于整体模型体积的主要贡献来源于前后两个巨大的词嵌入矩阵，模型体积方面的优势也不明显。」 但在同样超参数的情况下，GRU 的实际参数数量明显少于 LSTM。因此，kika 继续做了第二组实验，在保证基本一致的参数数量而放开网络架构约束的情况下，最后得到的结论是：LSTM 与 GRU 的模型大小基本一致，效果也基本一致，实际上，在 kika 的应用场景下，LSTM 的效果略好，但也仅仅是略好一点点。此外，由于 GRU 在当时也是比较新的结构，因此在体积和效果没有优势的情况下 kika 还是倾向于选择更温和的 LSTM，从而把主要精力用于模型结构的调整与参数调优方面。其实最近 kika 也在做一些网络架构和基本单元方面的调研，因为最近在 GRU 之后又出现了非常多训练简单且高效的单元。在 kika 当前的开发过程中也出现了一些场景更为复杂的 NLP/NLU 应用，因此也在考虑采用一些训练时间上更为友好的网络结果。对于如何选择网络结构，黄康表示：「我们内部有共识，考虑新结构有一个基本原则：我们会采用类似机器翻译的复杂任务去验证此种网络是否真实有效，才会考虑在工程上采用。」 总体而言，kika 花了很大一部分时间完成参数调优，因而能基于一体化的 LSTM 实现效果非常好的输入法引擎。当然只是构建模型还远远不够，将这种深度学习模型部署到移动端还面临着非常多的挑战，例如深度学习框架的选择和模型压缩的方法等等。 轻量化部署的工程挑战 在 kika，轻量化部署包括以下四个方面：模型压缩、快速的响应时间、较低的内存占用以及 较小的 so 库（shared object，共享库）大小等。除了优化模型的设计之外，压缩模型大小的方法主要是稀疏词表征与量化，这一部分我们将在后一部分展开讨论。 响应时间与内存是去年 kika 的工作重点，它主要是需要对 TensorFlow Mobile 和 Lite 做大量的修补。最后是动态链接库文件（.so），它定义了所有需要的运算和操作。因为整个输入法的核心代码是 C++ 完成的，而它在安卓设备中是以一个库（.so 文件）的形式存在的，它的大小直接影响了安装包的大小（由于 Android 加载 so 的机制，也会影响到内存的开销）。 针对响应时间与内存，kika 最开始是基于 TensorFlow Mobile 做一些修补和改进。黄康说：「TensorFlow Mobile 有一个非常好的优势，即它在底层使用了一套很成熟很稳定的矩阵运算库。因此，我们的主要精力放在 TensorFlow Mobile 在底层矩阵运算库之上的部分。它在矩阵运算库之间采用了很多封装与调用，但是没有考虑到很多实际工业化中遇到的问题，尤其是在内存保护这一块做得相当一般。」 TF Mobile 的内存管理与内存保护设计得并不完善，存在两个主要的问题：1. 内存保护机制不完善，在实际内存不足的情况（尤其对于一部分低端机型），容易引发内存非法操作。2. 内存大小控制机制存在明显的问题，例如模型本身在计算时只有 20MB，但加载到内存之后的运行时峰值可能会达到 40 到 70MB。据 kika 的数据，基于 TF Mobile 的解决方案大概有 1% 的场景（如游戏中调起输入法）由于内存大小限制的原因会加载不了深度学习模型，只能回退到非深度的解决方案。 2017 年 11 月，谷歌正式发布了 TensorFlow Lite，这对于移动端深度学习模型来说是非常重要的框架。在 TF Lite 开源后，kika 马上就进行了测试，并重点关注内存管理模块。黄康表示：「TF Lite 的内存管理上确实有非常大的改进，加载不了深度学习模型的场景会成百倍地减少。但它最大的问题就是 Operator 的不全，它基本上只定义了最基础的运算和操作。所以 kika 为了在内存上减少 20 多 MB 的开销，我们自行编写了大量的 Operator。但目前这个还是有一定的风险，因为如果我们修改了模型结构，那还是需要手写新的运算。」 工程化挑战最后一个问题就是动态链接库的大小，这一部分还会涉及到参数量化方法的实现，我们会在参数量化方法那边讨论。其实 TF Mobile 还有一个缺点，即它会将很多冗余的操作与运算都会打包到 .so 文件中，因此也就导致了动态链接库过大。kika 为了让 .so 文件尽可能小，开发了一套全新的工具，用于自动的判断到底哪些操作与运算的定义是模型实际需要的。 稀疏词表征 深度学习模型在输入法客户端部署的一个重要问题就是模型大小，我们需要将参数数量与计算量限制绝大部分移动设备可接受的范围内。kika 发现模型体积的主要矛盾体现在词嵌入矩阵中。因此，如果能够压缩词嵌入矩阵的大小，那么就能有效地控制模型大小。kika 采用了稀疏词表征的方法以压缩词嵌入矩阵的大小，从而大幅度减少 LSTM 语言模型的参数与计算量。 其实对于语言模型，甚至是自然语言处理而言，词嵌入是非常重要的成分，我们可以使用 300 到 500 维的向量表示词表中数以万计的词汇。这种方法不会像 one-hot 编码那样使用超高维的向量表示一个词，可以说词嵌入将词的表征由|V|维减少到几百维，其中|V|表示词汇数量。但是当我们使用词嵌入作为语言模型的输入时，我们会发现尽管每个词的维度只有 n，但需要|V|个向量，而 |V| 通常要比 n 高好几个量级。因此，稀疏词表征就尝试使用少量词向量（少于|V|）而表征 |V| 个词。 这种方法的直观概念即我们的词表可以分为常见词与非常见词，而一般单个词可以由多个词定义，因此非常见词可以使用多个常见词表示。根据这样的观点，我们可以使用一组常见词的词嵌入向量作为基础，再通过组合而表示所有词的词嵌入向量。因此，我们能使用少量词嵌入向量表示大量词汇。又因为每一个词的表征都只使用少量的常见词来定义，所以这种表示方法是非常稀疏的，这也就是稀疏词表征的直观概念。 若我们将词表 V 分割为两个子集 B 和 C，第一个子集 B 为基向量集，它包含了固定数量的常见词。而 C 包含了所有不常见的词，因此现在需要使用 B 的词嵌入向量以线性组合的方式编码 C 中的词。这一过程可通过最小化由基向量集学习重构的词表征和完整表征之间的距离而学习，一般来说整个过程可表示为： 使用全部词汇训练一个词嵌入矩阵。 按词频选取最常见的 |B| 个词嵌入向量，并组成过完备基矩阵。 非常见词的预测可表示为 B 中所有词嵌入向量的稀疏组合，即 其中 w hat 为预测的非常见词词向量、U 为常见词词向量，而 x 为稀疏矩阵。 最小化预测词向量和实际词向量间的距离来学习稀疏表征，即 其中第一项表示通过稀疏表示 x 预测的词向量与完整词向量（w）间的 L2 距离。后一项为 L1 正则化，它会将矩阵 x 中的元素推向 0，从而实现稀疏表示。 在 kika 的论文 Sparse Word Representation for RNN Language Models on Cellphones 中，他们使用了以下伪代码展示了稀疏表示的学习算法： 这个算法很大的特点是实现了一个二元搜索来确定α，因为我们不能直接控制稀疏矩阵 x 的稀疏程度，所以我们根据稀疏矩阵的非零元素数来控制α的变化。整个稀疏词表征算法需要输入过完备基矩阵 U（常见词）、完整词嵌入矩阵 w、稀疏程度 s 和作为终止条件的容忍度 tol。 其中 s 是非常重要的一个参数，它控制了一个词最多需要多少个过完备基向量表征。kika 表示：「s 是一种权衡，如果参数较大，那么压缩比就会很小，模型达不到预期效果。如果参数较小，那么重构的词表征就不能有效地表示所有词。」正因为需要进行精调来确定 s 及其它超参数，kika 表明总体模型调优时间是训练时间的 4 到 5 倍，所以整个稀疏词表征的训练过程还是比较挺长的。 如上算法所示，首先我们会确定α的搜索范围，然后取α的中间值并最小化损失函数而求得稀疏表示 x，并统计 x 中每一个列向量的非零元素数，它们代表了一个词需要多少个常见词表示。如果 k 大于 s，那么非零的元素就过多，我们需要加大 α 以增强 L1 正则化的效果。这样的二元搜索直到α的上下界距离小于参数 tol 才会终止，且一般迭代几次就能快速收敛到合适的 α 来控制 x 的稀疏性。在完成 x 的学习后，我们将每一列稀疏向量抽取为对应的索引与权重，索引代表使用哪些基向量或常见词，而权重代表它们定义某个词的重要性。 又因为前面的二元搜索将 k 限制为不大于 s，所以有可能 k 是小于 s 的，因此我们需要使用零将这些向量补全。经过上面的步骤，最终我们会产生包含 s 个元素的等长向量 indices 和 weights。储存这两种向量而不直接储存稀疏矩阵 x* 能节省很多空间，这对于减小安装包大小有非常重要的作用。 论文中给出的词嵌入恢复算法以一种串行密集运算的方式进行展示，这可以令读者清晰地理解重构过程： 若给定 U、indices 和 weights，一个词的词嵌入重构可直接利用索引取对应的基向量，并与对应的权重求加权和。这种线性组合非常简单且高效，也是线性代数中非常直观的表示方法。因为任何秩为 n 的矩阵都可以由 n 个线性不相关的向量或基表示出来，完整的词嵌入矩阵也就能由过完备基的线性组合表示。算法 1.2 最后返回的 v 就是我们线性组合多个常见词词嵌入而重构出来的完整词嵌入向量。 以上是 kika 采用的稀疏词表征方法，它可以有效减少模型参数和计算量，但我们还能进一步使用参数量化来压缩模型的存储大小。 量化 一般而言，应用的安装包大小对于用户体验非常重要，这一点对于移动端尤为突出。因此，我们可以使用参数量化的方法来减小安装包大小。kika 也曾尝试使用 TensorFlow 封装的压缩方法，但仍发现一些难以解决的问题，因此他们最终使用 k-means 方法重新构建参数量化而解决包体增大的问题。 kika 最开始尝试使用官方的 tf.quantize 执行参数量化，并用 tf.dequantize 恢复参数。这个方法非常迅速，基本上几十兆的模型只需要分钟级的时间就能完成压缩。但 kika 发现这种方法有一个非常大的问题，即如果当我们希望读取量化后的模型时，TensorFlow 会引入大量的 Operator，这势必会造成动态链接库（.so）的体积增大，因而会加大安装包的大小。因为动态链接库包含了所有 TF 定义的加法、减法、卷积和归一化等模型需要使用的运算，因此调用 TF 的量化方法同样会将相关的运算添加到动态链接库中。 根据 kika 的实验，使用 TF 官方的量化方法大概会使动态链接库增加 1 到 2 MB 的体积，对应的安装包大小也会增加这么多。由于这样的原因，kika 最后选择基于 k-means 的方法实现参数量化。简单而言，这个方法会先使用 k-means 将相似的向量聚类在一起，然后储存聚类中心，原参数矩阵就只需要存储聚类中心的索引就行了。kika 表明这种方法的有点在于不会额外增加动态链接库和安装包的大小。因此下面将简要介绍这种基于 k-means 的参数量化方法。 量化即从权重中归纳一些特征，这些特征会储存在码表（codebook）并以具体数值表示某一类权重，而原来的权重矩阵只需要存储索引来表示它们属于哪一类特征就行了，这种方法能很大程度上降低存储成本。 kika 使用的标量量化算法基本思路是，对于每一个 m×n 维的权重矩阵 W，首先将其转化为包含 m×n 个元素的向量 w。然后再对该权重向量的元素聚类为 k 个集群，这可借助经典的 k 均值聚类算法快速完成： 现在，我们只需储存 k 个聚类中心 c_j，而原权重矩阵只需要记录各自聚类中心的索引就行。在韩松 ICLR 2016 的最佳论文中，他用如下一张图非常形象地展示了量化的概念与过程。 如上所示权重矩阵的所有参数可以聚类为 4 个类别，不同的类别使用不同的颜色表示。上半部分的权重矩阵可以取聚类中心，并储存在 centroids 向量中，随后原来的权重矩阵只需要很少的空间储存对应的索引。下半部是韩松等研究者利用反向传播的梯度对当前 centroids 向量进行修正的过程。 稀疏词表征与参数量化是 kika 控制参数大小的主要方法，黄康表示：「实际上模型的大小可以分为两阶段，首先如果原模型是 40MB 的话，稀疏词表征可以将模型减少到 20MB 左右，这个大小是实际在内存中的大小。而进一步采用参数量化可以将大小压缩到 4MB 左右，它解决的问题是 APK 安装包大小，APK 大小也是非常重要的，毕竟作为输入法这样的应用，APK 的大小是非常重要的。不论使不使用参数量化，模型最终在计算上需要的内存就是稀疏词向量表征后的大小。」 最后两部分基本上就是 kika 解决模型大小的方案，它们令深度学习模型在实践中有了应用的可能。当然，要将深度学习模型嵌入输入法和移动端会有很多的挑战，仅仅控制模型大小是不够的，因此也就有了上文 kika 在内存大小、响应时间和动态链接库等方面的努力。 整个模型效果和工程化实践都是 kika 在过去 2 年来对输入法引擎的探索，未来还有很多优化与提升的方向，例如使用新型循环单元或新型强化学习来根据用户习惯调整输入法等。这些新功能与新方向将赋予输入法引擎更多的特性，也能适应性地为不同的用户提供最好的体验。 转载来源：专访｜基于LSTM与TensorFlow Lite，kika输入法是如何造就的]]></content>
      <categories>
        <category>军事</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Word</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Hexo博客进阶篇--API和一些小部件（四） - 个人文章 - SegmentFault 思否]]></title>
    <url>%2F2018%2F0c171a79%2F</url>
    <content type="text"><![CDATA[搭建Hexo博客进阶篇–API和一些小部件（四） - 个人文章 - SegmentFault 思否 转载来源：搭建Hexo博客进阶篇–API和一些小部件（四） - 个人文章 - SegmentFault 思否]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据科学家需要了解的5种聚类算法]]></title>
    <url>%2F2018%2F108a61a6%2F</url>
    <content type="text"><![CDATA[编者按：聚类是一种涉及数据点分组的机器学习技术。给定一组数据点，我们可以使用聚类算法将每个数据点到分类到图像中的特定组中。理论上，同一组中的数据点应具有相似的属性和特征，而不同组中的数据点的属性和特征则应高度不同。聚类是无监督学习的一种方法，是用于多领域统计数据分析的常用技术。 在数据科学中，我们可以通过聚类分析观察使用聚类算法后这些数据点分别落入了哪个组，并从中获得一些有价值的信息。那么今天，我们就跟着机器学习工程师George Seif来看看数据科学家需要掌握的5种实用聚类算法以及它们的优缺点。 K-Means聚类K-Means（k-平均或k-均值）可以称的上是知名度最高的一种聚类算法，它常出现在许多有关数据科学和机器学习的课程中。在代码中非常容易理解和实现！让我们来看下面这幅动图。 K-Means聚类 首先，我们确定要几个的聚类（cluster，也称簇），并为它们随机初始化一个各自的聚类质心点（cluster centroids），它在上图中被表示为“X”。要确定聚类的数量，我们可以先快速看一看已有的数据点，并从中分辨出一些独特的数据。1. 其次，我们计算每个数据点到质心的距离来进行分类，它跟哪个聚类的质心更近，它就被分类到该聚类。1. 需要注意的是，初始质心并不是真正的质心，质心应满足聚类里每个点到它的欧式距离平方和最小这个条件。因此根据这些被初步分类完毕的数据点，我们再重新计算每一聚类中所有向量的平均值，并确定出新的质心。1. 最后，重复上述步骤，进行一定次数的迭代，直到质心的位置不再发生太大变化。当然你也可以在第一步时多初始化几次，然后选取一个看起来更合理的点节约时间。其次，我们计算每个数据点到质心的距离来进行分类，它跟哪个聚类的质心更近，它就被分类到该聚类。 最后，重复上述步骤，进行一定次数的迭代，直到质心的位置不再发生太大变化。当然你也可以在第一步时多初始化几次，然后选取一个看起来更合理的点节约时间。 K-Means的优点是速度非常快，因为我们所做的只是计算数据点和质心点之间的距离，涉及到的计算量非常少！因此它的算法时间复杂度只有O(n)。 另一方面，K-Means有两个缺点。一是你必须一开始就决定数据集中包含多少个聚类。这个缺点并不总是微不足道的，理想情况下，我们的目标其实是用一种算法来分类这些数据，并从结果中观察出一些规律，而不是限制几个条件强行聚类。二是一开始质心点的选取是随机的，算法可能会初始化出差异巨大的点。这个缺点导致的结果是质心点的位置不可重复且缺乏一致性。 K-Medians是与K-Means相关的另一种聚类算法，不同之处在于它使用簇的中值向量来重新计算质心点。该方法对异常值不敏感（因为使用中值），但在较大数据集上运行时速度会慢很多，因为每次计算中值向量，我们都要重新排序。 Mean-Shift聚类Mean shift算法，又称均值漂移算法，这是一种基于核密度估计的爬山算法，可用于聚类、图像分割、跟踪等。它的工作原理基于质心，这意味着它的目标是定位每个簇/类的质心，即先算出当前点的偏移均值，将该点移动到此偏移均值，然后以此为新的起始点，继续移动，直到满足最终的条件（找出最密集的区域）。如果没理解，请看下图。 Mean-Shift聚类 为了理解均值漂移，我们可以像上图一样想象二维空间中的一组数据点，然后先随机选择一个点C，以它为圆心画一个半径为r的圆开始移动。之前提到了，这是个爬山算法，它的核函数会随着迭代次数增加逐渐向高密度区域靠近。1. 在每轮迭代中，算法会不断计算圆心到质心的偏移均值，然后整体向质心靠近。漂移圆圈内的密度与数据点数成正比。到达质心后，算法会更新质心位置，并继续让圆圈向更高密度的区域靠近。1. 当圆圈到达目标质心后，它发现自己无论朝哪个方向漂移都找不到更多的数据点，这时我们就认为它已经处于最密集的区域。1. 这时，算法满足了最终的条件，即退出。在每轮迭代中，算法会不断计算圆心到质心的偏移均值，然后整体向质心靠近。漂移圆圈内的密度与数据点数成正比。到达质心后，算法会更新质心位置，并继续让圆圈向更高密度的区域靠近。 这时，算法满足了最终的条件，即退出。 这里我们主要介绍了一个漂移圆圈的思路，如下图所示，其实Mean shift算法事实上存在多个圆形区域，图中黑点代表质心，而灰点则是数据点。 和K-Means算法相比，Mean-Shift不需要实现定义聚类数量，因为这些都可以在计算偏移均值时得出。这是一个巨大的优势。同时，算法推动聚类中心在向密度最大区域靠近的效果也非常令人满意，这一过程符合数据驱动型任务的需要，而且十分自然直观。如果要说Mean-Shift有什么缺点，那就是对高维球区域的半径r的定义，不同选择可能会产生高度不同的影响。 具有噪声的基于密度的聚类方法（DBSCAN）DBSCAN是一种基于密度的聚类算法，它与mean-shift类似，但又有一些显著优势。我们先来看看下面这幅花哨的图。 DBSCAN笑脸聚类 首先，DBSCAN算法会以任何尚未访问过的任意起始数据点为核心点，并对该核心点进行扩充。这时我们给定一个半径/距离ε，任何和核心点的距离小于ε的点都是它的相邻点。1. 如果核心点附近有足够数量的点，则开始聚类，且选中的核心点会成为该聚类的第一个点。如果附近的点不够，那算法会把它标记为噪声（之后这个噪声可能会成为簇中的一部分）。在这两种情形下，选中的点都会被标记为“已访问”。1. 一旦聚类开始，核心点的相邻点，或者说以该点出发的所有密度相连的数据点（注意是密度相连）会被划分进同一聚类。然后我们再把这些新点作为核心点，向周围拓展ε，并把符合条件的点继续纳入这个聚类中。1. 重复步骤2和3，直到附近没有可以扩充的数据点为止，即簇的ε邻域内所有点都已被标记为“已访问”。1. 一旦我们完成了这个集群，算法又会开始检索未访问过的点，并发现更多的聚类和噪声。一旦数据检索完毕，每个点都被标记为属于一个聚类或是噪声。如果核心点附近有足够数量的点，则开始聚类，且选中的核心点会成为该聚类的第一个点。如果附近的点不够，那算法会把它标记为噪声（之后这个噪声可能会成为簇中的一部分）。在这两种情形下，选中的点都会被标记为“已访问”。 重复步骤2和3，直到附近没有可以扩充的数据点为止，即簇的ε邻域内所有点都已被标记为“已访问”。 与其他聚类算法相比，DBSCAN有一些很大的优势。首先，它不需要输入要划分的聚类个数。其次，不像mean-shift，即使数据点非常不同，它也会将它们纳入聚类中，DBSCAN能将异常值识别为噪声，这就意味着它可以在需要时输入过滤噪声的参数。第三，它对聚类的形状没有偏倚，可以找到任意大小和形状的簇。 DBSCAN的主要缺点是，当聚类的密度不同时，DBSCAN的性能会不如其他算法。这是因为当密度变化时，用于识别邻近点的距离阈值ε和核心点的设置会随着聚类发生变化。而这在高维数据中会特别明显，因为届时我们会很难估计ε。 EM聚类 均值→质心，方差→椭圆聚类，权重→聚类大小。 K-Means算法的主要缺点之一是它直接用了距离质心的平均值。我们可以从下图中看出这样做为什么不好——图的左侧是两个半径不同的同心圆，K-Means没法处理这个问题，因为这些聚类的平均值非常接近；图的右侧是一个中心对称的非圆形分布，K-Means同样解决不了它，因为如果单纯依靠均值判断，算法无法捕捉更多特征。 K-Means的两个失败案例 高斯混合模型（GMM）比K-Means算法具有更好的灵活性。它是多个高斯分布函数的线性组合，理论上可以拟合出任意类型的分布，通常用于解决同一集合下的数据包含多个不同的分布的情况。对于GMM，我们假设数据点满足不同参数下的高斯分布——比起均值，这是一个限制较少的假设。我们用两个参数来描述聚类的形状：均值和标准差！以二维分布为例，标准差的存在允许聚类的形状可以是任何种类的椭圆形。因此这个算法的思想是：如果数据点符合某个高斯分布，那它就会被归类为那个聚类。 为了找到每个聚类的高斯参数，我们要用到一种名为期望最大化（EM）的优化算法。下图是高斯混合模型的聚类过程，那么，你知道怎么在其中运用EM算法吗？ 首先，我们确定聚类的数量（如K-Means），并随机初始化每个聚类的高斯分布参数。你也可以尝试通过快速查看数据来为初始参数提供更好的猜测，但从上图可以看出，这其实不是很必要，因为算法会很快进行优化。1. 其次，根据每个聚类的高斯分布，计算数据点属于特定聚类的概率。如果数据点越接近高斯质心，那它属于该聚类的概率就越高。这很直观，因为对于高斯分布，我们一般假设大部分数据更靠近聚类质心。1. 在这些概率的基础上，我们为高斯分布计算一组新的参数，使聚类内数据点的概率最大化。我们用数据点位置的加权和来计算这些新参数，其中权重就是数据点属于聚类的概率。为了可视化这个过程，我们可以看看上面的图片，特别是黄色的聚类。第一次迭代中，它是随机的，大多数黄点都集中在该聚类的右侧。当我们按概率计算加权和后，虽然聚类的中部出现一些点，但右侧的比重依然很高。随着迭代次数增加，黄点在聚类中的位置也完成了“右下→左下”的移动。因此，标准差的变化调整着聚类的形状，以使它能更适合数据点的分布。1. 迭代步骤2和步骤3，直至收敛。其次，根据每个聚类的高斯分布，计算数据点属于特定聚类的概率。如果数据点越接近高斯质心，那它属于该聚类的概率就越高。这很直观，因为对于高斯分布，我们一般假设大部分数据更靠近聚类质心。 迭代步骤2和步骤3，直至收敛。 论智注：对于上述第3步，请结合混合高斯模型定义公式理解。如果我们设K为模型的个数，πk为第k个高斯的权重，即第k个高斯的概率密度函数，其均值为μk，方差为σk。我们对此概率密度的估计就是要求πk、μk和σk各个变量。当求出的表达式后，求和式的各项的结果就分别代表样本x属于各个类的概率。在做参数估计的时候，常采用的方法是最大似然。——引自 姜文晖《聚类(1)——混合高斯模型》 GMM有两个关键优势。首先它比K-Means更灵活，由于标准差的引入，最后聚类的形状不再局限于圆形，它还可以是大小形状不一的椭圆形——K均值实际上是GMM的一个特例，其中每个聚类的协方差在所有维上都接近0。其次，权重的引入为同一点属于多个聚类找到了解决方案。如果一个数据点位于两个聚类的重叠区域，那我们就可以简单为它定义一个聚类，或者计算它属于X聚类的百分比是多少，属于Y聚类的百分比是多少。简而言之，GMM支持混合“成员”。 谈及缺点，和K-Means相比，GMM每一步迭代的计算量比较大。另外，它的求解办法基于EM算法，因此有可能陷入局部极值，需要经过多次迭代。 层次聚类层次聚类实际上可以被分为两类：自上而下和自下而上。其中自下而上算法（Bottom-up algorithms）首先会将每个数据点视为单个聚类，然后连续合并（或聚合）成对的聚类，直到所有聚类合并成包含所有数据点的单个聚类。它也因此会被称为hierarchical agglomerative clustering 或HAC。该算法的聚类可以被表示为一幅树状图，树根是最后收纳所有数据点的单个聚类，而树叶则是只包含一个样本的聚类。在讲解具体步骤前，我们先看看整个过程的图解。 层次聚类 首先，我们把每个数据点看作是一个聚类，即如果数据集中有X个数据点，它就有X个聚类。然后我们设置一个阈值作为衡量两个聚类间距离的指标：如果距离小于阈值，则合并；如果距离大于阈值，迭代终止。1. 在每轮迭代中，我们会把两个聚类合并成一个聚类。这里我们可以用到average linkage，它的思路是计算所有分属于两个目标聚类的数据点之间距离，然后求一个平均值。每次我们会根据设定的阈值选取平均距离最小的两个聚类，然后把它们合并起来，因为按照我们的标准，它们是最相似的。1. 重复步骤2，直到我们到达树根，即最后只有一个包含所有数据点的聚类。通过这种方式，我们可以选择要几个聚类，以及什么时候停止聚类。在每轮迭代中，我们会把两个聚类合并成一个聚类。这里我们可以用到average linkage，它的思路是计算所有分属于两个目标聚类的数据点之间距离，然后求一个平均值。每次我们会根据设定的阈值选取平均距离最小的两个聚类，然后把它们合并起来，因为按照我们的标准，它们是最相似的。 层次聚类不要求我们指定聚类的数量，由于这是一个构建树的过程，我们甚至可以选择那种聚类看起来更合适。另外，该算法对距离阈值的选择不敏感，无论怎么定，算法始终会倾向于给出更好地聚类结果，而不像其他算法很依赖参数。根据层次聚类的特点，我们可以看出它非常适合具有层次结构的数据，尤其是当你的目标是为数据恢复层次时。这一点是其他算法无法做到的。与K-Means和GMM的线性复杂性不同，层次聚类的优势是以较低的效率为代价，因为它具有O(n3)的时间复杂度。 结论以上就是数据科学家需要知道的5个聚类方法。在文章的最后，就让我们以一幅聚类图做结，直观展示这些算法和其他算法的完美表现！ 转载来源：数据科学家需要了解的5种聚类算法]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>卡尔·高斯</tag>
        <tag>技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你的时间，要么姓张，要么姓张——张小龙和张一鸣的对立统一 - 简书]]></title>
    <url>%2F2018%2F11d5a891%2F</url>
    <content type="text"><![CDATA[对于中国大部分互联网创业者而言，他们公司的最终结局——“要么姓马，要么姓马”；而对于中国大部分网民而言，他们在手机上的时间——“要么姓张，要么姓张” 张小龙和张一鸣，这两个技术男各自掌管的微信和头条系APP占据了这个国家人民手机中最长的在线时长，他们有太多共同点：同属技术出身、都不善言辞、相同的异常低调、双双迅速成长为全能型选手……. 他们又有太多的不同点：一个出生于1969年，一个出生于1983年；一个弗兰人，一个胡建人；一个产品经理，一个企业家；一个技术中带着浓浓的文艺气息，另一个则有着技术原教旨主义的偏执。 人决定产品，今天，我们就尝试从这两个人的角度去窥视这个占据了中国最多“国民总时间”产品各自背后的人文逻辑。 1 艺术家张小龙VS机器人张一鸣 将杰克逊的名言放到微信的启动画面；将崔健的《一无所有》放到微信的版本更新页；将许巍的《蓝莲花》设置为QQ邮箱的背景音乐；将热爱摇滚作为招聘产品经理的重要加分项…….. 张小龙的文艺情结深入骨髓，尽管他非常克制，但客观上他为给微信这款产品打上了自己深深的文艺烙印。 事实上，那些崔健、杰克逊、许巍这些符号只是我们能看到的张小龙文艺的表面标志，而背后则是他把这种人文精神注入产品，微信极其简洁、克制—— 消息没有已读状态；朋友圈不鼓励发纯文字；摇一摇快速识别音乐，包括摇一摇那个来复枪的音效；甚至细心的人会发现转发一篇文章，如果文字是一个个输入的就会全部显示，如果是复制粘贴的就会折叠成两行。 这些都是张小龙人文精神的直观体现，很多人把东方的张小龙和自由世界的乔布斯相提并论并非毫无根据，张小龙的确是受过乔布斯影响的，他公开说过：老乔是Intel格鲁夫《只有偏执狂才能生存》的证明人；他读《乔布斯传》，把其中段落摘录到饭否上，下边是张小龙摘录的几段： “他无比遗憾的意识到，这些工具的力量，恐怕无法与鲍勃迪伦的音乐相比，它的生命无法与迪斯尼的《白雪公主》相比，100年后，还会有孩子看《海底总动员》而露出笑颜，100年后还有谁会记得iPhone、iPod，如果可以，他愿意用所有的技术交换与苏格拉底共处一个下午的时光。” “当你慢慢变老，会发现有些事情是在你的能力范围之外的。技术并不改变这个世界。我们出生，短暂停留，然后死去。自古以来都是如此。技术改变不了什么。但是，一件事情，不是非得改变世界，才是重要的。” “他曾经以为自己是可以改变世界的。人都是使用工具的，如果你给他们好的工具，他们会用这些工具做出了不起的事情。比如电脑。他曾经想象着，有一天，我们能在工具中融入亚里士多德或爱因斯坦的基本观点。想象一下，这将对年轻人的成长带来何等帮助？” 从这个意义上来说，张小龙是一个艺术家，一个为纯技术出身极客，却浑身散发出艺术家的气质，这本身就足够有趣。 和张小龙的艺术气质不同，年轻的后辈张一鸣则是一个极其理性的技术原教旨主义者，正是坚信算法超越主观分发的效率让其创办了今日头条，其理性的决策贯穿其产品技术决策的每一个细节。 头条发布一个新APP，其名字都必须打N个包放到各大应用市场进行多次A/B测试而决定，张一鸣告诉同事：哪怕你有99.9%的把握那是最好的一个名字，测一下又有神马关系呢？ 在张一鸣的世界里，只有效用，当记者问他：你上次发火是神马时候？他回答，我几乎不会发火，发火没有效用；他用极其理性的方式思考和解决问题。 早年创业时张一鸣的公司技术用的是Python，那时候Python使用还没有像今天在技术圈那么广泛，因此招到好的工程师就变得困难，张一鸣没有像其他公司一样去拉勾等垂直招聘网站上发启事，他有他独特的技术解决方案——去百度买和Python相关的几个独有的关键词（如一些函数和库之类的）。这些词很冷门，很便宜，也很有效。 张一鸣说：在机场的人看机场的内容，火车站的人看火车站的内容，如果说让机场的人看到了火车站的内容，那是技术问题。 他坦言，头条不会做出网易那样“有态度”的新闻客户端，而要做一个“没有态度”的资讯应用，他关注的分发效率。 有人评价他为“拥有交易员级别的冷血唯物主义者”，用户的每一次点击、浏览行为都会变成头条服务器里冰冷的数据，一项项双盲测试的结果是每一次产品和策略升级唯一的衡量指标，从某种意义上说，头条的产品经理是算法，而头条仅次于微信的平均用户时长证明了这种纯理性的唯物主义策略极其有效。 如果你认为张一鸣纯理性决策只适用于工作中，那么你就错了——在生活中张一鸣也是这样一个原教旨主义者。 他甚至将年龄作为X轴，颜值、收入、身体状况等其他指标作为Y轴，画出曲线函数，发现29岁左右通常是体力下降的拐点，于是，并没有体育爱好的他从29岁开始了每周一次的游泳。 他甚至像调试算法一样反复实验自己的时间管理方法并得出结论——人在轻度喜悦和轻度沮丧的时候效率最高，同时这种效率最高的前提是有充足的睡眠。 甚至他对爱情的看法也闪烁着技术男独有的算法思维：“世界上可能有两万个人适合你, 然后你只要找到那两万分之一就好了，就是你在可接受的那个范围寻找近似最优解。” 从这个意义上说，张一鸣大脑就像一颗冷静运转的CPU，他的每一步行动都由这个CPU由某个模型精准计算并指导，我想，人工智能大概说的就是这个意思吧！ 这种纯理性思维的优势是显而易见的，头条的攻城略地与此息息相关，但客观上的确从某种程度上放大了人性中的弱点，劣币驱逐良币的现象很难避免，因为在纯算法过程中，无所谓劣币和良币，一切都是CTR、留存率和用户时长，在这个纯数字游戏中，有时候马拉个币也是良币。 灯塔国的小扎的国会听证会和头条张一鸣彻夜无眠写道歉信，从某种意义上是我们对技术的反思，但我相信，这次的遭遇其实没办法改变张一鸣这种深入骨髓的纯理性的思维，我猜，在他脑海中只是会给他原来的思维函数中增加——“监管”、“社会主义核心价值观”这两个新增变量，并调大二者的影响因子——在祖国做生意，“看不见的手”还是要服从“看得见的手”。 《财经》杂志的小晚有一次在上海徐汇采访张一鸣的时候问了这样一个问题：请用几个字定位一下你自己！张一鸣慢条斯理地回答：“我现在在上海徐汇区中金国际广场，第9楼。” 嗯，定位真TM准确啊，就差报经纬度了！ 2 专注的张小龙VS进激的张一鸣 在大众眼中，张小龙这个名字一直是和微信联系在一起的，这些年张小龙一直专注于微信，我们几乎看不到微信团队出的其他独立产品，微信读书算是为数不多的例外之一。 核心源于微信之大足以撑起技术男张小龙最狂野的梦想，我们看到的表象是微信一直在做加法——朋友圈、支付、购物、游戏、公众号、小程序，然而对微信这个如此庞大的流量黑洞而言，腾讯帝国的每一块业务都会以最大力度削尖脑袋往微信里放，在面对的海量需求和最终上线的需求，小龙拒过的需求连起来估计能绕地球三圈。 仅仅2014年，腾讯就有超过120个业务在排队接入微信，从这个意义上说，张小龙一直在做减法，但即便如此，微信新推的功能依然避免不了存在“失败”的案例—— 微信的”对讲”功能在坚持了很多个版本之后下线了，而该功能发布的时候的宣传语为——“这一次，我们要重新定义对讲机”；微信的安卓设计样式在发布几个版本之后也改回来了；微信的“看一看”用户数并没有达到预期………加法与减法，专注与扩张，在张小龙身上实现了对立统一。 早在2012年，沉默的张小龙就提出——“微信是一种生活方式”。那时微信才诞生一年，还在念书的我在深圳大学北门外的广告牌上看到这句略显浮夸的文案，回头瞄了一眼高耸入云的腾讯大厦，心中打了N个问号，如今，恐怕没有人对句话有任何怀疑，微信成为这个国家数字生活最底层的基础设施，而这背后是既专注又进击的张小龙。 和张小龙的专注微信这一单一产品相比，张一鸣在这两年显得无比激进——国际化、短视频化、垂直化四面开火，成为内容领域的新的全民公敌；火山对标快手，悟空问答对标知乎，懂车帝对标汽车之家，微头条对标微博，钠镁股票对标炒股APP，头条甚至已经在做音频和教辅类产品了，加上被投资各类产品，头条的产品线如今早已达到了3位数。 “在连接人与信息这条路上，他要做的是聚合所有信息平台。不拘泥于文字、图片、视频，甚至以后任何未知形式的表达；也不限制在交通、股票、娱乐等维度。” 国际化也是其增长的重要命题，在张一鸣眼中，算法不分国界，头条的国际化是早有预谋，2015年，张一鸣出硅谷考察了一番，得出的结论是中美互联网差异已然很小，在这一点上，猎豹的傅盛给过张一鸣启发，他甚至直接从傅盛的手中直接把News Republic买下来了，如今的张一鸣正在默默练习英文，为出海积蓄能量。 我们认为头条最大的优势是算法**，然而实际上它最大的优势是一套结合了算法、产品、运营、增长、广告为核心的强悍打法**，头条的广告技术团队和用户产品技术团队是一块的，他们既为用户产品提供算法，也为广告提供算法，其广告商业化在任何一个头条产品极早的阶段就被纳入考虑，量一起来，广告也随即起来。 这一点和其他完全靠融资继续走的创业公司路数绝然不同，在头条广告收入早已反哺投资和扩张的时候，很多创业公司还在继续D轮、E轮继续烧呢。 张一鸣自己则说：头条其实不算多元化，我们没有去做房地产，我们没有去开超市，我们做的产品，本质上还是对接人和信息。 3 产品经理张小龙VS企业家张一鸣 毫无疑问，作为微信的掌舵人，张小龙的角色更像是一位产品经理，或者说产品架构师，他最大的工作是定义微信； 而很显然，现在的张一鸣产品和技术依然是他的重心，但他必须考虑融资、估值、现金流、站队、公关、商业化甚至IPO等系列企业家需要考虑的问题，而微信的这些问题由小马哥专业的团队操刀。 为什么大众把张小龙称奉为产品之神，而不把马化腾、扎克伯格、周鸿祎、王兴成为产品之神，后者们的产品甚至更加成功？ 某种意义上是因为张小龙符合了大众对于产品经理最完美的想象——文艺、感性、专注，即在大众印象中，张小龙的工作显得更加纯粹，而大众很难了解到的其实是这份看似性感的工作背后充斥着复杂、纠结、权衡—— 张小龙曾经举过一个例子，2016年微信大会前一天，一个“我与微信的故事”的线上页面提前泄露了，海量用户瞬间涌入导致页面挂掉了，于是谣言四起，说这个页面会窃取用户的银行卡信息，于是在短短几个小时内，有超过百万级的用户解绑了银行卡……. 当你是国民基础设施的时候，你任何一个部分都不能出差错，而这没有一点内功是应对不了滴。 的确，和张一鸣相比，宣称不知道Feed为何物的张小龙显得更加从容，这份从容的背后固然有微信不必为下一轮融资、估值等主题伤神的原因，然而张小龙也有他作为产品经理的巨大挑战，而这些挑战随便挑一个出来对微信而言都是灵魂拷问： 公众号生态固化，流量集中效应明显，以账号为中心的分发效率遭客观上弱势于算法分发效率。 微信作为腾讯帝国的基石，尽管它代表腾讯在支付、广告、游戏、图文内容生态领域高歌猛进，但在移动内容不可避免地视频化的大背景下，微信在短视频分发领域没有建树。 小程序作为承载微信操作系统的野心，对独立性要求较高的创业者而言心存顾忌，尽管在过去一年以平均每周一个新能力的频率更新，但能否形成足够多元健康的生态依然存在不确定性。 腾讯不断增加的变现压力，和微信极简的产品理念冲突日益明显，而这显然已经超越了一个产品经理的范畴. 从这个意义上说，作为产品经理张小龙的思维半径并不会比作为企业家的张一鸣窄多少。 今天的产品之神张小龙曾经也经历过多次脱胎换骨——从亲自写Foxmail每一行代码的纯技术男到技术团队的管理者，从沉重的Foxmail的客户端思维转变到QQ邮箱的Web思维，从QQ邮箱的PC转变到移动领域的微信，从技术管理者转变到产品定义者，其中的任何一次转变对于一个普通人而言都是要经历蜕皮的，而张小龙处变不惊、定力如磐。 张一鸣在酷讯、海内、饭否都是CTO一职，对技术的迷恋让其曾经对投资人王琼说：我更适合做CTO，请一个人来帮我做CEO，然而事实上从“99房”开始，他就开始独当一面，以极快的速度迭代了自己的认知和能力。 从开始纯真地说出“算法没有价值观”到面对公关危机虚心向极客公园主编张鹏请教，从只给面试者出算法题到倾力挖角Uber干将柳甄，从面对媒体攻击只会说“他们怎么能这样呢？”到现在滴水不漏的道歉信，如今的张一鸣早已在狂奔中成为打过硬仗的年轻企业家。 他内心坚定——我创办头条并不是成为腾讯的员工。这句简洁的回应背后是无畏的勇气。 在UC还没有被阿里收购的时候，UC的俞永福也曾经许下豪言——“从今开始，只有UC收购谁的消息，而不有UC被收购的消息”，张一鸣转发了这条微博并回附上三个字：赞勇气，半年之后，UC被阿里全资收购，和TMD中的美团、滴滴不同，张一鸣一开始就没有选择站队。 2018四个月没过完，对于头条而言是跌宕起伏，一方面抖音以摧枯拉朽之势高歌猛进，一方面一直顺风顺水的头条遇到了史上最严监管—— 央媒曝光违规广告、党报发评论文章、总局下架内涵段子，阵势之大、前所未有，企业家张一鸣遇到了真正的挑战，曾经在外界看来几乎看不到情绪波动的他也在第二天的道歉信中坦言“一夜无眠”，这份措辞严谨以至于称得上范文的道歉信显然并非出自理工男张一鸣之手，他的团队公关团队早已比2014年措手不及的版权风波更加成熟。 4 60后张小龙VS80后张一鸣 张小龙和张一鸣这个两个名字联系起来的场合不多，而据观察，两人貌似也没有实质上的交集，在饭否上频繁发博的张小龙可能也没有联系过饭否的技术男张一鸣，除了在去年11月在西安举办的一个叫“程序员节”的大会上，张小龙和张一鸣同时入选“中国十大功勋程序员”，同时入选的还有求伯君、王选民、雷军、丁磊。 这个在技术圈其实并没有太大影响的大会还把张一鸣划分为“中国第四代程序员”，我不清楚这个代际划分的具体标准，但二者的成长时代背景的差异的确也从某种意义上影响了他们的人生： 张小龙出生于1969年，差不多是中国最早的程序猿之一，和出生于1983年的张一鸣不同，张小龙上大学的1991年互联网在祖国还不知道何物，那时候的英雄是写出WPS的求伯君，而张小龙在华科的专业也并非计算机而是电信，那时候的电信行业就像今天的互联行业那么热。 我们不知道张小龙是否受到嬉皮士文化影响的，但毫无疑问，他是一个爱玩的人，龙哥的青春里，游戏和球类占据了很大一部分时间，网球、台球、DOOM、红警都能达到业余高手的水准，就连最近微信的小程序“跳一跳”他的记录能也能达到让大部分人绝望的6000分。 张小龙在上世纪末以一己之力写出200万用户的Foxmail有着明显的个人英雄主义情节，200万在那个时代是一个天文数字，那时还是IT记者的李学凌曾写道，2002年，只要你在黄庄路大喊一声：我是Foxmail的张小龙，必然有一大群过来索要签名。 张小龙在职业上也略显慵懒，在写出Foxmail的很长一段时间，他都处于失业状态，在经历了较长时间的无工作状态的张小龙甚至想过去美国看一看机会，甚至当时的人民日报评论foxmail时称张小龙为“百万台电脑后面藏着的悲剧人物”。 工作上的随性一直延续到现在，坊间传闻张小龙以“起不来”为理由不去深圳开每周一次的腾讯例会，最后是马化腾派专车将其接去。 “哥做的不是产品，哥做的是发挥潜力的自由”，张小龙在饭否上写道。 和张小龙不同，出生于优渥家庭80后张一鸣尽管算不上是互联网的原住民，但他很早就接触了互联网，它是宿舍里第一个买电脑网上冲浪的人，事实上他在大学的兼职之一就是帮同学攒机，正是因为配电脑，他认识了他现在的太太。 同时，在职业选择上，80后张一鸣也和60后张小龙有明显区别，他在高考填报志愿的时候就显示了他的职业性，他设定了四个硬指标： 综合性大学，因为纯理工女生少； 冬天要下雪，他的家乡福建龙岩看不到雪； 要在海边，他喜欢吃海鲜。 要离家远，他要离开父母。 就像一个程序一样，输入条件一运算，运行结果只有一条：南开大学，18岁的张一鸣就这样开始了他南开的求学生涯，注意：四个指标中没有在大多数人看来唯一的指标——自己能考的上的。 许多年后，当他回忆起南开大学的求学生涯，印象最为深刻的他认为在南开培养了他延迟满足的秉性，在南开他耐得住寂寞，漫长的大学生活伴随它的是程序和书，他是一个重度信息摄入者，他有5个Kindle。 在他回忆大学生活的自述里，没有娱乐这个关键词，在张小龙玩游戏打台球的年纪里，张一鸣一个月已经能靠配电脑赚2000块了，那时的大学校园，诗歌已经消失，取而代之的是创业英雄。 和张小龙随性的职业生涯相比，张一鸣的职业生涯近乎标准：毕业后加入垂直搜索酷讯，成为003号员工；接着短暂加入微软；然后是在同乡王兴的海内、饭否担任技术负责人；接着创办房产搜索“九九房”……..这是一份让VC极其青睐的履历，理性的张一鸣没有时间拿去停歇和浪费。 时代的烙印早已深深打在了两位沉默寡言的技术男身上，而随着移动互联的大潮演进，他们之间会不会必有一仗？ 你猜……… 作者卫夕，一名兴趣极其广泛的广告产品经理，**“卫夕聊广告，不止聊广告”，只写深度长文，每周一篇长文深度剖析广告及互联网的常识、逻辑或思维。合作、交流请简信联系作者。** 转载来源：你的时间，要么姓张，要么姓张——张小龙和张一鸣的对立统一 - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[瑜伽，被“异化”了还是被“误读”了？]]></title>
    <url>%2F2018%2F13985a81%2F</url>
    <content type="text"><![CDATA[瑜伽，似乎是一个永远被关注的话题。 自从瑜伽进入中国以来，围绕瑜伽究竟是健身还是伤身的话题，就一直没有停止过。爱她的，趋之若鹜，恨她的，嗤之以鼻。用冰火两重天来形容大家对瑜伽的看法，一点都不为过。 这不，刚刚生完宝宝的曹蕊，看着身上的赘肉正在发愁，朋友告诉她练练瑜伽吧，不仅减肥而且塑身，最关键的是还能提高气质。曹蕊心动了，正要去健身房报名时，突然看到了“无数中国女人，正被瑜伽毁掉身体……”以及“辟谣:瑜伽正在毁掉中国女人?信息不实!”正反两篇文章。曹蕊瞬间懵圈了“什么情况？瑜伽到底是好呢还是不好呢？” 瑜伽一词由印度梵语而来，有“结合”“和谐”的含义。是一种达到身体、心灵与精神和谐统一的运动形式。 在印度，瑜伽被认为是一门以感觉语言科学体系为基础理论的学修科。而在国内，瑜伽则是一种健身手段。 “瑜伽在我国被异化了。”中华医学会运动医疗分会候任主委陈世益教授一针见血地指出，原本一项很好的运动，现在不仅被注入了太多的商业气息，而且被当成了时尚。 尽管都叫瑜伽，但此瑜伽非彼瑜伽 据了解，这项源自古印度的修行方式，目前已经成为一个价值百亿的庞大全球产业。仅在美国，就有1500万人在有规律地练习瑜伽。自1985年，瑜伽正式进入我国以来。有统计显示，目前90%以上的健身房都开设有瑜伽课程，学员已经覆盖到不同年龄阶段的人群，从老到少，无一不对瑜伽狂热。 因为瑜伽动作相对柔和，有助身心放松，对现代人减压非常有效等一系列好处，瑜伽的拥趸越来越多。但与此同时，针对瑜伽的争议也一直就没有停止过。 近几年，有多篇文章和相关专家纷纷指出，“瑜伽病”已成新病种，主要以肌肉韧带拉伤、软骨撕裂为主，还有关节错位、脊椎错位以及关节炎症、神经痛等。 “所谓疾病，在医学上是有严格的定义的。”小汤山医院康复科主任武亮对记者表示，现在报道称的所谓“瑜伽病”，无非是瑜伽练习中所产生的一些可能造成伤害的综合体现，基本上属于局部发生的问题。这些既不是练习瑜伽后必然导致的情况，也不是全身性的问题。如果说成“瑜伽病”，则会让人产生很大的误解。“尽管，没有“瑜伽病”这个病种。但是瑜伽伤害还是有可能的，我们应该尽量力去避免。” 武亮直言，“瑜伽病”源于练习不当。练习瑜伽时应该充分考虑自己的柔韧、平衡和力量素质，一定要遵循量力而行的运动原则。 从运动生理学和解剖学来说，人体的每一个关节都有自己的活动范围，长期超过这一范围的高强度活动，往往会给关节带来近期或远期的损害。 “人体的脊柱结构也是如此，不适当的过度弯曲和牵拉，会造成脊椎损伤，严重的甚至会造成脊椎骨折、滑脱，椎间盘突出，伤及脊髓和神经。”火箭军总医院骨科主治医生朱泽兴博士透露，很多运动损伤为积累损伤，时间长、起病隐蔽，待发现时往往为时已晚。 优胜美地瑜伽的创始人郝宇晖女士客观地分析指出，近年来，消费市场升级，国人越来越注重身心的和谐健康，开始关注瑜伽领域，而目前中国瑜伽市场中瑜伽教学带来的瑜伽伤害问题层出不穷，这些业态已经偏离了古老瑜伽体系的修习和哲学内核。“因为中国的瑜伽市场很大，经营者的准入门槛低，所以对于瑜伽概念和练习的误区是非常深的。要想避免瑜伽伤害，应该从培养正确练习瑜伽的意识开始。” 瑜伽能减肥、塑身，那是你想多了 瑜伽运动之所以“大热”，跟很多人为它所赋予的减肥、塑形、排毒、美容等“附加值”不无关系。 “的确，很多练瑜伽的人都被美轮美奂的照片所吸引，但并不是每个人都能达到照片里的效果。”武亮不无幽默地说，如果你指望着通过瑜伽进行减肥或塑身，只能说你的期待有些跑偏了。 陈世益也持相同的态度。“目前，没有太多证据表明练瑜伽可以减肥和塑形。” 有研究表明，根据不同的瑜伽类型，每小时的卡路里消耗在50-150Kcal，而消耗一公斤脂肪的热量是7716大卡，因此要减去一公斤脂肪，需要通宵练瑜伽约三天三夜。瑜伽对减肥的作用是忽略不计的。也许你会说某些瑜伽实际上强度也很大，好吧，确实有些瑜伽比其他瑜伽更耗费体能，但每小时也不会超过200大卡的，对减肥来说是不值一提。 瑜伽圈有个著名的自黑笑话，说的就是一个胖子想练瑜伽减肥，最后变成了一个柔软的胖子。 其实，瑜伽既不能减脂，同样也不能增肌。 所谓“塑形”，其实就是增肌+减脂。减少全身赘肉，增肌目标肌肉，已达到臀部挺翘性感。因此，女性想要身材凹凸有致，就得同时增肌和减脂，而想要增肌，则需要做肌肉产生位移的等张收缩，而瑜伽这种“静力性收缩”，对肌肥大的刺激效果是忽略不计的。 虽然瑜伽训练本身对增肌效果并不明显，但如果作为一种辅助训练，极大地增加身体各关节柔韧性后，运动轨迹被大大加长了，在力量训练中，更长的运动轨迹就意味着更充分的肌肉刺激和更好的肌肉增长效果，这种效果是显而易见且绝对有效的，理论上的增肌效果可以提升10%-20%。可以肯定地说，练习瑜伽可以很好地增强身体协调性以及平衡能力。 对此，陈世益呼吁，要回归到理性上来，不要把太多想法寄予到瑜伽上，否则受伤的就是你。 你不是她，不要追求无谓的极致 刚从领导岗位退下来的辛女士，在朋友的推荐下报了瑜伽班。 作为新学员，60岁的辛女士总觉得跟不上节奏，争强好胜一辈子的她，为了不落别人的后面在家偷偷苦练。一天，辛女士正在做下腰的动作时，突然听到“咔嗒”一声清脆的响声，回过身来就隐隐觉得腰不舒服。开始她并没当回事，只是做了热敷，贴了膏药，但疼痛始终没有得到缓解。 直到实在疼得受不了了，辛女士才来医院检查。结果发现腰椎发生压缩性骨折，需要接受微创手术，对发生骨折的腰椎进行固定填充。 “在门诊，因为练瑜伽受伤的病人时不时地就能遇到。”朱泽兴已是见怪不怪，普通的肌肉拉伤居多，髋部及腰部受伤的也不少见。 之所以会出现这种情况，是因为成人的关节、韧带、肌肉、神经血管，尤其是脊髓都已经定型，过度使用就会造成损伤。特别是处于退行性病变高发期的中老年人，大都存在关节的老化问题，体质较为脆弱，如果锻炼过程中稍不注意，颈椎、骨骼就很容易受伤。 “不当运动导致出现问题的病人很多，每周都能碰到一两例。”武亮指出，运动伤的发生，大多是因为患者没有进行热身准备，缺乏专业性的指导，更重要的是对不良运动没有良好的防范意识和警觉意识。 瑜伽很多动作都是身体的极致伸展，但需要提醒的是，每个人身体条件不同，练习的程度也应有所不同，练习时一定要尊重自我的感觉，不要盲目攀比，要始终根据自己的实际能力来做瑜伽的动作。切勿盲目追求一些高难度的体位动作，以免伤害自己。任何运动都有风险，绝不能因噎废食。只要你做到量力而行，瑜伽是很安全的运动。 郝宇晖也认为，太多练习者不顾自己的自身条件去一味地效仿别人他就肯定会受伤。如果练习者的腰椎不好，还做大量的前屈体式；如果颈椎不好，却偏要做头倒立；如果髋骨很紧，依然执着地做莲花盘……自然就会受伤，其实瑜伽就是看自己、做自己能够做到的练习。“瑜伽最终是为了提高心理和精神需求达到身体心灵和谐联结的本源。” 郝宇晖再三强调。 “瑜伽伤害并不是不可避免的，”在浙江大学在读哲学博士，资深瑜伽教师闻风看来，经营者不应将瑜伽神化，任何运动如果处理不当都会导致伤害的发生。一方面，习练者要有自我保护的意识；另一方面，瑜伽教练必须对自己的学员负责任。毕竟，瑜伽体式练习的最核心要素，是通过呼吸培养清晰的觉知，获得稳定的心智，回归当下，以脱离焦虑和压力，堪破世间幻象得到真知。“瑜伽练习是我们每个人自己的事，它无竞争、不攀比。” 转载来源：瑜伽，被“异化”了还是被“误读”了？]]></content>
      <categories>
        <category>健康</category>
      </categories>
      <tags>
        <tag>美体</tag>
        <tag>健身</tag>
        <tag>减肥</tag>
        <tag>骨折</tag>
        <tag>健康</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么中国神药总是一抓一个准？]]></title>
    <url>%2F2018%2F622e5183%2F</url>
    <content type="text"><![CDATA[为什么中国神药总是一抓一个准？ 转载来源：为什么中国神药总是一抓一个准？]]></content>
      <tags>
        <tag>冀连梅药师</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信红包订单存储架构变迁的最佳实践]]></title>
    <url>%2F2018%2F16838e0f%2F</url>
    <content type="text"><![CDATA[微信红包订单存储架构变迁的最佳实践 转载来源：微信红包订单存储架构变迁的最佳实践]]></content>
      <tags>
        <tag>CSDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么“兴趣广泛”的通才更有可能获得成功？详解通才的7大优势]]></title>
    <url>%2F2018%2F1b54df58%2F</url>
    <content type="text"><![CDATA[为什么“兴趣广泛”的通才更有可能获得成功？详解通才的7大优势 转载来源：为什么“兴趣广泛”的通才更有可能获得成功？详解通才的7大优势]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用开源项目的正确姿势，都是血和泪的总结！]]></title>
    <url>%2F2018%2F1e5b86f2%2F</url>
    <content type="text"><![CDATA[使用开源项目的正确姿势，都是血和泪的总结！ 转载来源：使用开源项目的正确姿势，都是血和泪的总结！]]></content>
      <tags>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优质博文集锦-云栖社区-阿里云]]></title>
    <url>%2F2018%2F214a417c%2F</url>
    <content type="text"><![CDATA[优质博文集锦-云栖社区-阿里云 转载来源：优质博文集锦-云栖社区-阿里云]]></content>
  </entry>
  <entry>
    <title><![CDATA[一个老教师眼中的在线直播和录播课程-教育频道-手机搜狐]]></title>
    <url>%2F2018%2F05d2d21a%2F</url>
    <content type="text"><![CDATA[一个老教师眼中的在线直播和录播课程-教育频道-手机搜狐 转载来源：一个老教师眼中的在线直播和录播课程-教育频道-手机搜狐]]></content>
  </entry>
  <entry>
    <title><![CDATA[一个老教师眼中的在线直播和录播课程_搜狐教育_搜狐网]]></title>
    <url>%2F2018%2F3b410d1e%2F</url>
    <content type="text"><![CDATA[一个老教师眼中的在线直播和录播课程搜狐教育搜狐网 转载来源：一个老教师眼中的在线直播和录播课程搜狐教育搜狐网]]></content>
  </entry>
  <entry>
    <title><![CDATA[用数据做酷的事！手把手教你搭建问答系统]]></title>
    <url>%2F2018%2F86f4b533%2F</url>
    <content type="text"><![CDATA[本文介绍了如何基于 SQuAD 数据集搭建问答系统及其重要组件。 我最近很愉快地完成了斯坦福深度学习自然语言处理课程（CS224N），学到了很多新的东西。在结课项目中我基于斯坦福问答数据集（SQuAD）实现了一个问答系统。在这篇博客中，我将为大家介绍搭建问答系统所需要的主要模块。 完整代码 GitHub 地址：https&#58;//github.com/priya-dwivedi/cs224n-Squad-Project SQuAD 数据集 斯坦福问答数据集（SQuAD）是一个全新的阅读理解数据集，由众包人员基于一系列维基百科文章的提问和对应的答案构成，其中每个问题的答案是相关文章中的文本片段或区间。SQuAD 包含关于 500 多篇文章的超过 100000 个问答对，规模远远超过其他阅读理解数据集。 最近一段时间，各种类型的模型在 SQuAD 数据集上的效果获得了快速的发展，其中最新的一些模型在问答任务中甚至取得了和人类相当的准确率。 SQuAD 数据集中的语境、问题和答案的示例 语境：阿波罗计划于 1962 至 1972 年间进行，期间得到了同期的双子座计划（1962 年 - 1966 年）的支持。双子座计划为阿波罗计划成功必需的一些太空旅行技术做了铺垫。阿波罗计划使用土星系列火箭作为运载工具来发射飞船。这些火箭还被用于阿波罗应用计划，包括 1973 年到 1974 年间支持了三个载人飞行任务的空间站 Skylab，以及 1975 年和前苏联合作的联合地球轨道任务阿波罗联盟测试计划。 问题：哪一个空间站于 1973 到 1974 年间承载了三项载人飞行任务？ 答案：Skylab 空间站 SQuAD 的主要特点： i) SQuAD 是一个封闭的数据集，这意味着问题的答案通常位于文章的某一个区间中。 ii) 因此，寻找答案的过程可以简化为在文中找到与答案相对应部分的起始索引和结束索引。 iii) 75% 的答案长度小于四个单词。 机器理解模型关键组件 i) 嵌入层 该模型的训练集包括语境以及相关的问题。二者都可以分解成单独的单词，这些单词会被转换成使用预训练向量（如 GloVe）的词嵌入。想了解更多关于词嵌入的信息，参考《教程 | 用数据玩点花样！如何构建 skim-gram 模型来训练和可视化词向量》。同 one hot 向量相比，用词嵌入方式对单词进行表示可以更好地捕捉语境信息。考虑到没有足够的数据，我使用了 100 维的 GloVe 词嵌入并且在训练过程中没有对它们进行修改。 ii) 编码器层 RNN 编码器 我们将基于 RNN 的编码器加入到了模型的下一层当中。我们希望语境中的每一个单词能和它前后的单词产生联系。双向 GRU/LSTM 可以帮助我们达到这一目标。RNN 的输出是一系列向前、向后的隐藏向量，然后我们会将它们级联起来。类似地，我们可以使用相同的 RNN 编码器创建问题隐藏向量。 iii）注意力层 现在我们有了一个语境隐藏向量和问题隐藏向量。我们需要将这两个向量结合起来，以找到问题的答案。这时就需要用到注意力层。注意力层是问答系统的关键组成部分，因为它能帮助确定对于给定的问题我们应该「注意」文中的哪些单词。让我们从最简单的注意力模型开始： 点积注意力 CS224N 中基本注意力的可视化分析 点积注意力等于每个语境向量 c_i 乘每个问题向量 q_j 的结果向量 e^i（上图中的注意力分数）。之后，我们对 e^i 调用 softmax 函数来得到 α^i（上图中的注意力分布）。softmax 保证了所有 e^i 的和是 1。最终，我们计算出 a_i：注意力分布 α^i 与对应问题向量（上图中的注意力输出）的积。点积注意力也可以用下面的式子来描述： 上面提到的注意力已作为基线注意力机制在 GitHub 代码中实现。 更复杂的注意力——BiDAF 注意力 你可以用上述基本注意力层来运行 SQuAD 模型，但恐怕结果不尽人意。更复杂的注意力才能产出更好的性能。 我们来了解一下 BiDAF 论文（https&#58;//arxiv.org/abs/1611.01603）。该论文的主要观点是注意力应该是双向的——从语境到问题和从问题到语境。 我们首先计算相似度矩阵 S ∈ R^N×M，它包含每对语境和问题隐藏状态 (c_i , q_j) 的相似度分数。这里 c_i ◦ q_j 代表数组元素对应相乘，w_sim ∈ R 6h 是权重向量。S_ij 用下面的式子来表述： 之后，我们将展示 C2Q 注意力（与上面提到的点积注意力类似）。我们对 S 逐行调用 softmax 函数来获得注意力分布 α^i，用它得到问题隐藏状态 q_j 的加权和，最后得出 C2Q 注意力的输出 a_i。 现在，我们来执行 Q2C 注意力。对于每一个语境位置 i ∈ &amp;#1231, . . . , N&amp;#125，我们取相似度矩阵对应行的最大值： 之后我们对结果向量 m ∈ R^N 调用 softmax 函数，而这将给出关于语境位置的注意力分布 β ∈ R^N。之后，我们使用 β 得到语境隐藏状态的加权和 c_i，这也是 Q2C 注意力的输出结果 c’。以下是相关公式： 最终对于每一个语境位置 c_i，我们结合 C2Q 注意力和 Q2C 注意力的输出，下面是相关公式： 如果你觉得这一段令人费解，不用担心，注意力确实是一个复杂的话题。你可以试着一边喝茶，一边阅读这篇 BiDAF 论文。 iv) 输出层 我们就快成功了。模型的最后一层是一个 softmax 输出层，它帮助我们找出答案区间的开始和结束索引。我们通过结合语境隐藏状态和之前层的注意力向量来得到混合的结果。这些混合的结果最终会成为全连接层的输入，该层使用 softmax 来得到 p_start 向量（具备开始索引的概率）以及 p_end 结束（具备结束索引的概率）。我们知道大部分答案从开始索引到结束索引最多 15 个单词，由此我们可以寻找使 p_start 与 p_end 乘积最大的开始和结束索引。 损失函数是开始和结束位置的交叉熵损失之和。它使用 Adam Optimizer 来获得最小值。 我构建的最终模型比上面描述的要复杂一点，在利用测试集测试时获得了 75 分的 F1 分数。还行！ 下一步 关于未来探索的一些想法： 由于 CNN 运行起来比 RNN 快得多，并且更容易在 GPU 上并行计算，因此我最近一直都在用基于 CNN 的编码器而非上述 RNN 编码器进行实验。- 其他的注意力机制，如 Dynamic Co-attention（https&#58;//arxiv.org/abs/1611.01604）其他的注意力机制，如 Dynamic Co-attention（https&#58;//arxiv.org/abs/1611.01604） 转载来源：用数据做酷的事！手把手教你搭建问答系统]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>机器学习</tag>
        <tag>可视化</tag>
        <tag>火箭</tag>
        <tag>斯坦福大学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微头条]]></title>
    <url>%2F2018%2Fbb00f6dd%2F</url>
    <content type="text"><![CDATA[微头条 转载来源：微头条]]></content>
  </entry>
  <entry>
    <title><![CDATA[美国再爆惊天大丑闻：窃取5000万Facebook用户数据，为了操控人心]]></title>
    <url>%2F2018%2F2e56afc8%2F</url>
    <content type="text"><![CDATA[美国再爆惊天大丑闻：窃取5000万Facebook用户数据，为了操控人心 转载来源：美国再爆惊天大丑闻：窃取5000万Facebook用户数据，为了操控人心]]></content>
      <tags>
        <tag>假装在纽约</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么东北人总让你快乐]]></title>
    <url>%2F2018%2F32a87ea0%2F</url>
    <content type="text"><![CDATA[为什么东北人总让你快乐 转载来源：为什么东北人总让你快乐]]></content>
      <tags>
        <tag>新世相</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket协议深入探究]]></title>
    <url>%2F2018%2Fcbaa330e%2F</url>
    <content type="text"><![CDATA[一、内容概览WebSocket的出现，使得浏览器具备了实时双向通信的能力。本文由浅入深，介绍了WebSocket如何建立连接、交换数据的细节，以及数据帧的格式。此外，还简要介绍了针对WebSocket的安全攻击，以及协议是如何抵御类似攻击的。 二、什么是WebSocketHTML5开始提供的一种浏览器与服务器进行全双工通讯的网络技术，属于应用层协议。它基于TCP传输协议，并复用HTTP的握手通道。 对大部分web开发者来说，上面这段描述有点枯燥，其实只要记住几点： WebSocket可以在浏览器里使用1. 支持双向通信1. 使用很简单支持双向通信 1、有哪些优点 说到优点，这里的对比参照物是HTTP协议，概括地说就是：支持双向通信，更灵活，更高效，可扩展性更好。 支持双向通信，实时性更强。1. 更好的二进制支持。1. 较少的控制开销。连接创建后，ws客户端、服务端进行数据交换时，协议控制的数据包头部较小。在不包含头部的情况下，服务端到客户端的包头只有2~10字节（取决于数据包长度），客户端到服务端的的话，需要加上额外的4字节的掩码。而HTTP协议每次通信都需要携带完整的头部。1. 支持扩展。ws协议定义了扩展，用户可以扩展协议，或者实现自定义的子协议。（比如支持自定义压缩算法等）更好的二进制支持。 支持扩展。ws协议定义了扩展，用户可以扩展协议，或者实现自定义的子协议。（比如支持自定义压缩算法等） 对于后面两点，没有研究过WebSocket协议规范的同学可能理解起来不够直观，但不影响对WebSocket的学习和使用。 2、需要学习哪些东西 对网络应用层协议的学习来说，最重要的往往就是连接建立过程、数据交换教程。当然，数据的格式是逃不掉的，因为它直接决定了协议本身的能力。好的数据格式能让协议更高效、扩展性更好。 下文主要围绕下面几点展开： 如何建立连接1. 如何交换数据1. 数据帧格式1. 如何维持连接如何交换数据 如何维持连接 三、入门例子在正式介绍协议细节前，先来看一个简单的例子，有个直观感受。例子包括了WebSocket服务端、WebSocket客户端（网页端）。完整代码可以在 这里 找到。 这里服务端用了ws这个库。相比大家熟悉的socket.io，ws实现更轻量，更适合学习的目的。 1、服务端 代码如下，监听8080端口。当有新的连接请求到达时，打印日志，同时向客户端发送消息。当收到到来自客户端的消息时，同样打印日志。 2、客户端 代码如下，向8080端口发起WebSocket连接。连接建立后，打印日志，同时向服务端发送消息。接收到来自服务端的消息后，同样打印日志。 3、运行结果 可分别查看服务端、客户端的日志，这里不展开。 服务端输出： 客户端输出： 四、如何建立连接前面提到，WebSocket复用了HTTP的握手通道。具体指的是，客户端通过HTTP请求与WebSocket服务端协商升级协议。协议升级完成后，后续的数据交换则遵照WebSocket的协议。 1、客户端：申请协议升级 首先，客户端发起协议升级请求。可以看到，采用的是标准的HTTP报文格式，且只支持GET方法。 重点请求首部意义如下： Connection&amp;#58; Upgrade：表示要升级协议- Upgrade&amp;#58; websocket：表示要升级到websocket协议。- Sec-WebSocket-Version&amp;#58; 13：表示websocket的版本。如果服务端不支持该版本，需要返回一个Sec-WebSocket-Versionheader，里面包含服务端支持的版本号。- Sec-WebSocket-Key：与后面服务端响应首部的Sec-WebSocket-Accept是配套的，提供基本的防护，比如恶意的连接，或者无意的连接。Upgrade&amp;#58; websocket：表示要升级到websocket协议。 Sec-WebSocket-Key：与后面服务端响应首部的Sec-WebSocket-Accept是配套的，提供基本的防护，比如恶意的连接，或者无意的连接。 注意，上面请求省略了部分非重点请求首部。由于是标准的HTTP请求，类似Host、Origin、Cookie等请求首部会照常发送。在握手阶段，可以通过相关请求首部进行 安全限制、权限校验等。 2、服务端：响应协议升级 服务端返回内容如下，状态代码101表示协议切换。到此完成协议升级，后续的数据交互都按照新的协议来。 备注：每个header都以\r\n结尾，并且最后一行加上一个额外的空行\r\n。此外，服务端回应的HTTP状态码只能在握手阶段使用。过了握手阶段后，就只能采用特定的错误码。 3、Sec-WebSocket-Accept的计算 Sec-WebSocket-Accept根据客户端请求首部的Sec-WebSocket-Key计算出来。 计算公式为： 将Sec-WebSocket-Key跟258EAFA5-E914-47DA-95CA-C5AB0DC85B11拼接。1. 通过SHA1计算出摘要，并转成base64字符串。通过SHA1计算出摘要，并转成base64字符串。 伪代码如下： 验证下前面的返回结果： 五、数据帧格式客户端、服务端数据的交换，离不开数据帧格式的定义。因此，在实际讲解数据交换之前，我们先来看下WebSocket的数据帧格式。 WebSocket客户端、服务端通信的最小单位是帧（frame），由1个或多个帧组成一条完整的消息（message）。 发送端：将消息切割成多个帧，并发送给服务端；1. 接收端：接收消息帧，并将关联的帧重新组装成完整的消息；接收端：接收消息帧，并将关联的帧重新组装成完整的消息； 本节的重点，就是讲解数据帧的格式。详细定义可参考 RFC6455 5.2节 。 1、数据帧格式概览 下面给出了WebSocket数据帧的统一格式。熟悉TCP/IP协议的同学对这样的图应该不陌生。 从左到右，单位是比特。比如FIN、RSV1各占据1比特，opcode占据4比特。1. 内容包括了标识、操作代码、掩码、数据、数据长度等。（下一小节会展开）内容包括了标识、操作代码、掩码、数据、数据长度等。（下一小节会展开） 2、数据帧格式详解 针对前面的格式概览图，这里逐个字段进行讲解，如有不清楚之处，可参考协议规范，或留言交流。 FIN：1个比特。 如果是1，表示这是消息（message）的最后一个分片（fragment），如果是0，表示不是是消息（message）的最后一个分片（fragment）。 RSV1, RSV2, RSV3：各占1个比特。 一般情况下全为0。当客户端、服务端协商采用WebSocket扩展时，这三个标志位可以非0，且值的含义由扩展进行定义。如果出现非零的值，且并没有采用WebSocket扩展，连接出错。 Opcode&#58; 4个比特。 操作代码，Opcode的值决定了应该如何解析后续的数据载荷（data payload）。如果操作代码是不认识的，那么接收端应该断开连接（fail the connection）。可选的操作代码如下： %x0：表示一个延续帧。当Opcode为0时，表示本次数据传输采用了数据分片，当前收到的数据帧为其中一个数据分片。- %x1：表示这是一个文本帧（frame）- %x2：表示这是一个二进制帧（frame）- %x3-7：保留的操作代码，用于后续定义的非控制帧。- %x8：表示连接断开。- %x8：表示这是一个ping操作。- %xA：表示这是一个pong操作。- %xB-F：保留的操作代码，用于后续定义的控制帧。%x1：表示这是一个文本帧（frame） %x3-7：保留的操作代码，用于后续定义的非控制帧。 %x8：表示这是一个ping操作。 %xB-F：保留的操作代码，用于后续定义的控制帧。 Mask&#58; 1个比特。 表示是否要对数据载荷进行掩码操作。从客户端向服务端发送数据时，需要对数据进行掩码操作；从服务端向客户端发送数据时，不需要对数据进行掩码操作。 如果服务端接收到的数据没有进行过掩码操作，服务端需要断开连接。 如果Mask是1，那么在Masking-key中会定义一个掩码键（masking key），并用这个掩码键来对数据载荷进行反掩码。所有客户端发送到服务端的数据帧，Mask都是1。 掩码的算法、用途在下一小节讲解。 Payload length：数据载荷的长度，单位是字节。为7位，或7+16位，或1+64位。 假设数Payload length === x，如果 x为0~126：数据的长度为x字节。- x为126：后续2个字节代表一个16位的无符号整数，该无符号整数的值为数据的长度。- x为127：后续8个字节代表一个64位的无符号整数（最高位为0），该无符号整数的值为数据的长度。x为126：后续2个字节代表一个16位的无符号整数，该无符号整数的值为数据的长度。 此外，如果payload length占用了多个字节的话，payload length的二进制表达采用网络序（big endian，重要的位在前）。 Masking-key：0或4字节（32位） 所有从客户端传送到服务端的数据帧，数据载荷都进行了掩码操作，Mask为1，且携带了4字节的Masking-key。如果Mask为0，则没有Masking-key。 备注：载荷数据的长度，不包括mask key的长度。 Payload data：(x+y) 字节 载荷数据：包括了扩展数据、应用数据。其中，扩展数据x字节，应用数据y字节。 扩展数据：如果没有协商使用扩展的话，扩展数据数据为0字节。所有的扩展都必须声明扩展数据的长度，或者可以如何计算出扩展数据的长度。此外，扩展如何使用必须在握手阶段就协商好。如果扩展数据存在，那么载荷数据长度必须将扩展数据的长度包含在内。 应用数据：任意的应用数据，在扩展数据之后（如果存在扩展数据），占据了数据帧剩余的位置。载荷数据长度 减去 扩展数据长度，就得到应用数据的长度。 3、掩码算法 掩码键（Masking-key）是由客户端挑选出来的32位的随机数。掩码操作不会影响数据载荷的长度。掩码、反掩码操作都采用如下算法： 首先，假设： original-octet-i：为原始数据的第i字节。- transformed-octet-i：为转换后的数据的第i字节。- j：为i mod 4的结果。- masking-key-octet-j：为mask key第j字节。transformed-octet-i：为转换后的数据的第i字节。 masking-key-octet-j：为mask key第j字节。 算法描述为： original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。 j = i MOD 4transformed-octet-i = original-octet-i XOR masking-key-octet-j 六、数据传递一旦WebSocket客户端、服务端建立连接后，后续的操作都是基于数据帧的传递。 WebSocket根据opcode来区分操作的类型。比如0x8表示断开连接，0x0-0x2表示数据交互。 1、数据分片 WebSocket的每条消息可能被切分成多个数据帧。当WebSocket的接收方收到一个数据帧时，会根据FIN的值来判断，是否已经收到消息的最后一个数据帧。 FIN=1表示当前数据帧为消息的最后一个数据帧，此时接收方已经收到完整的消息，可以对消息进行处理。FIN=0，则接收方还需要继续监听接收其余的数据帧。 此外，opcode在数据交换的场景下，表示的是数据的类型。0x01表示文本，0x02表示二进制。而0x00比较特殊，表示延续帧（continuation frame），顾名思义，就是完整消息对应的数据帧还没接收完。 2、数据分片例子 直接看例子更形象些。下面例子来自MDN，可以很好地演示数据的分片。客户端向服务端两次发送消息，服务端收到消息后回应客户端，这里主要看客户端往服务端发送的消息。 第一条消息 FIN=1, 表示是当前消息的最后一个数据帧。服务端收到当前数据帧后，可以处理消息。opcode=0x1，表示客户端发送的是文本类型。 第二条消息 FIN=0，opcode=0x1，表示发送的是文本类型，且消息还没发送完成，还有后续的数据帧。1. FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。1. FIN=1，opcode=0x0，表示消息已经发送完成，没有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。服务端可以将关联的数据帧组装成完整的消息。FIN=0，opcode=0x0，表示消息还没发送完成，还有后续的数据帧，当前的数据帧需要接在上一条数据帧之后。 七、连接保持+心跳WebSocket为了保持客户端、服务端的实时双向通信，需要确保客户端、服务端之间的TCP通道保持连接没有断开。然而，对于长时间没有数据往来的连接，如果依旧长时间保持着，可能会浪费包括的连接资源。 但不排除有些场景，客户端、服务端虽然长时间没有数据往来，但仍需要保持连接。这个时候，可以采用心跳来实现。 发送方-&gt;接收方：ping- 接收方-&gt;发送方：pong接收方-&gt;发送方：pong ping、pong的操作，对应的是WebSocket的两个控制帧，opcode分别是0x9、0xA。 举例，WebSocket服务端向客户端发送ping，只需要如下代码（采用ws模块） 八、Sec-WebSocket-Key/Accept的作用 前面提到了，Sec-WebSocket-Key/Sec-WebSocket-Accept在主要作用在于提供基础的防护，减少恶意连接、意外连接。 作用大致归纳如下： 避免服务端收到非法的websocket连接（比如http客户端不小心请求连接websocket服务，此时服务端可以直接拒绝连接）1. 确保服务端理解websocket连接。因为ws握手阶段采用的是http协议，因此可能ws连接是被一个http服务器处理并返回的，此时客户端可以通过Sec-WebSocket-Key来确保服务端认识ws协议。（并非百分百保险，比如总是存在那么些无聊的http服务器，光处理Sec-WebSocket-Key，但并没有实现ws协议。。。）1. 用浏览器里发起ajax请求，设置header时，Sec-WebSocket-Key以及其他相关的header是被禁止的。这样可以避免客户端发送ajax请求时，意外请求协议升级（websocket upgrade）1. 可以防止反向代理（不理解ws协议）返回错误的数据。比如反向代理前后收到两次ws连接的升级请求，反向代理把第一次请求的返回给cache住，然后第二次请求到来时直接把cache住的请求给返回（无意义的返回）。1. Sec-WebSocket-Key主要目的并不是确保数据的安全性，因为Sec-WebSocket-Key、Sec-WebSocket-Accept的转换计算公式是公开的，而且非常简单，最主要的作用是预防一些常见的意外情况（非故意的）。确保服务端理解websocket连接。因为ws握手阶段采用的是http协议，因此可能ws连接是被一个http服务器处理并返回的，此时客户端可以通过Sec-WebSocket-Key来确保服务端认识ws协议。（并非百分百保险，比如总是存在那么些无聊的http服务器，光处理Sec-WebSocket-Key，但并没有实现ws协议。。。） 可以防止反向代理（不理解ws协议）返回错误的数据。比如反向代理前后收到两次ws连接的升级请求，反向代理把第一次请求的返回给cache住，然后第二次请求到来时直接把cache住的请求给返回（无意义的返回）。 强调：Sec-WebSocket-Key/Sec-WebSocket-Accept 的换算，只能带来基本的保障，但连接是否安全、数据是否安全、客户端/服务端是否合法的 ws客户端、ws服务端，其实并没有实际性的保证。 九、数据掩码的作用 WebSocket协议中，数据掩码的作用是增强协议的安全性。但数据掩码并不是为了保护数据本身，因为算法本身是公开的，运算也不复杂。除了加密通道本身，似乎没有太多有效的保护通信安全的办法。 那么为什么还要引入掩码计算呢，除了增加计算机器的运算量外似乎并没有太多的收益（这也是不少同学疑惑的点）。 答案还是两个字：安全。但并不是为了防止数据泄密，而是为了防止早期版本的协议中存在的代理缓存污染攻击（proxy cache poisoning attacks）等问题。 1、代理缓存污染攻击 下面摘自2010年关于安全的一段讲话。其中提到了代理服务器在协议实现上的缺陷可能导致的安全问题。猛击出处。 “We show, empirically, that the current version of the WebSocket consent mechanism is vulnerable to proxy cache poisoning attacks. Even though the WebSocket handshake is based on HTTP, which should be understood by most network intermediaries, the handshake uses the esoteric “Upgrade” mechanism of HTTP &#91;5&#93;. In our experiment, we find that many proxies do not implement the Upgrade mechanism properly, which causes the handshake to succeed even though subsequent traffic over the socket will be misinterpreted by the proxy.”&#91;TALKING&#93; Huang, L-S., Chen, E., Barth, A., Rescorla, E., and C. Jackson, “Talking to Yourself for Fun and Profit”, 2010, 在正式描述攻击步骤之前，我们假设有如下参与者： 攻击者、攻击者自己控制的服务器（简称“邪恶服务器”）、攻击者伪造的资源（简称“邪恶资源”）- 受害者、受害者想要访问的资源（简称“正义资源”）- 受害者实际想要访问的服务器（简称“正义服务器”）- 中间代理服务器受害者、受害者想要访问的资源（简称“正义资源”） 中间代理服务器 攻击步骤一： 攻击者浏览器 向 邪恶服务器 发起WebSocket连接。根据前文，首先是一个协议升级请求。1. 协议升级请求 实际到达 代理服务器。1. 代理服务器 将协议升级请求转发到 邪恶服务器。1. 邪恶服务器 同意连接，代理服务器 将响应转发给 攻击者。协议升级请求 实际到达 代理服务器。 邪恶服务器 同意连接，代理服务器 将响应转发给 攻击者。 由于 upgrade 的实现上有缺陷，代理服务器 以为之前转发的是普通的HTTP消息。因此，当协议服务器 同意连接，代理服务器 以为本次会话已经结束。 攻击步骤二： 攻击者 在之前建立的连接上，通过WebSocket的接口向 邪恶服务器 发送数据，且数据是精心构造的HTTP格式的文本。其中包含了 正义资源 的地址，以及一个伪造的host（指向正义服务器）。（见后面报文）1. 请求到达 代理服务器 。虽然复用了之前的TCP连接，但 代理服务器 以为是新的HTTP请求。1. 代理服务器 向 邪恶服务器 请求 邪恶资源。1. 邪恶服务器 返回 邪恶资源。代理服务器 缓存住 邪恶资源（url是对的，但host是 正义服务器 的地址）。请求到达 代理服务器 。虽然复用了之前的TCP连接，但 代理服务器 以为是新的HTTP请求。 邪恶服务器 返回 邪恶资源。代理服务器 缓存住 邪恶资源（url是对的，但host是 正义服务器 的地址）。 到这里，受害者可以登场了： 受害者 通过 代理服务器 访问 正义服务器 的 正义资源。1. 代理服务器 检查该资源的url、host，发现本地有一份缓存（伪造的）。1. 代理服务器 将 邪恶资源 返回给 受害者。1. 受害者 卒。代理服务器 检查该资源的url、host，发现本地有一份缓存（伪造的）。 受害者 卒。 附：前面提到的精心构造的“HTTP请求报文”。 2、当前解决方案 最初的提案是对数据进行加密处理。基于安全、效率的考虑，最终采用了折中的方案：对数据载荷进行掩码处理。 需要注意的是，这里只是限制了浏览器对数据载荷进行掩码处理，但是坏人完全可以实现自己的WebSocket客户端、服务端，不按规则来，攻击可以照常进行。 但是对浏览器加上这个限制后，可以大大增加攻击的难度，以及攻击的影响范围。如果没有这个限制，只需要在网上放个钓鱼网站骗人去访问，一下子就可以在短时间内展开大范围的攻击。 十、写在后面WebSocket可写的东西还挺多，比如WebSocket扩展。客户端、服务端之间是如何协商、使用扩展的。WebSocket扩展可以给协议本身增加很多能力和想象空间，比如数据的压缩、加密，以及多路复用等。 篇幅所限，这里先不展开，感兴趣的同学可以留言交流。文章如有错漏，敬请指出。 作者：程序猿小卡 转载来源：WebSocket协议深入探究]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>程序员</tag>
        <tag>比尔·盖茨</tag>
        <tag>镜音双子</tag>
        <tag>Origin</tag>
        <tag>环境污染</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lady Gaga为何零出场费演出？天价广告位销路如何？超级碗的这些事你需要知道]]></title>
    <url>%2F2018%2F33817910%2F</url>
    <content type="text"><![CDATA[Lady Gaga为何零出场费演出？天价广告位销路如何？超级碗的这些事你需要知道 转载来源：Lady Gaga为何零出场费演出？天价广告位销路如何？超级碗的这些事你需要知道]]></content>
      <tags>
        <tag>虎嗅网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国平安，精致的利己主义者]]></title>
    <url>%2F2018%2F76f53715%2F</url>
    <content type="text"><![CDATA[中国平安，精致的利己主义者 转载来源：中国平安，精致的利己主义者]]></content>
      <tags>
        <tag>慧保天下</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习精要之CapsuleNets理论与实践（附Python代码）]]></title>
    <url>%2F2018%2F352ec6fd%2F</url>
    <content type="text"><![CDATA[摘要： 本文对胶囊网络进行了非技术性的简要概括，分析了其两个重要属性，之后针对MNIST手写体数据集上验证多层感知机、卷积神经网络以及胶囊网络的性能。 神经网络于上世纪50年代提出，直到最近十年里才得以发展迅速，正改变着我们世界的方方面面。从图像分类到自然语言处理，研究人员正在对不同领域建立深层神经网络模型并取得相关的突破性成果。但是随着深度学习的进一步发展，又面临着新的瓶颈——只对成熟网络模型进行加深加宽操作。直到最近，Hinton老爷子提出了新的概念——胶囊网络（Capsule Networks），它提高了传统方法的有效性和可理解性。 本文将讲解胶囊网络受欢迎的原因以及通过实际代码来加强和巩固对该概念的理解。 为什么胶囊网络受到这么多的关注？对于每种网络结构而言，一般用MINST手写体数据集验证其性能。对于识别数字手写体问题，即给定一个简单的灰度图，用户需要预测它所显示的数字。这是一个非结构化的数字图像识别问题，使用深度学习算法能够获得最佳性能。本文将以这个数据集测试三个深度学习模型，即：多层感知机（MLP）、卷积神经网络（CNN）以及胶囊网络（Capsule Networks）。 多层感知机（MLP） 使用Keras建立多层感知机模型，代码如下： 在经过15次迭代训练后，结果如下： 可以看到，该模型实在是简单！ 卷积神经网络（CNN） 卷积神经网络在深度学习领域应用十分广泛，表现优异。下面构建卷积神经网络模型，代码如下： 打印模型参数概要： 从上图可以发现，CNN比MLP模型更加复杂，下面看看其性能： 可以发现，CNN训练耗费的时间比较长，但其性能优异。 胶囊网络（Capsule Network） 胶囊网络的结构比CNN网络更加复杂，下面构建胶囊网络模型，代码如下： 转载来源：深度学习精要之CapsuleNets理论与实践（附Python代码）]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>深度学习</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>编译器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++扩展之Python直接调用讯飞语言]]></title>
    <url>%2F2018%2F3592bb46%2F</url>
    <content type="text"><![CDATA[Python作为一门脚本语言有着非常好的易用性，但是很多人会病垢或纠结它的性能，不过Python与C/C++有着很好的沟通，很多对性能要求高的算法都可以用C/C++实现后供Python调用。 Python通过C/C++进行扩展有很多方法： 直接调用动态库.so- CPython使用C语言API编写模块include- 使用boost_python封装C++类- 使用SWIG扩展PythonCPython使用C语言API编写模块include 使用SWIG扩展Python 以Python使用科大讯飞语言识别的Linux接口来介绍Python如何调用动态库.so文件。 1. Linux下生成动态库.so文件 以下是c实现的一个简单函数(mylib.c)： extern &quot;C&quot; {&lt;br&gt;int sum(int a, int b) {&lt;br&gt;return a+b;&lt;br&gt; }&lt;br&gt;} 在shell中执行如下命令就会得到mylib.so动态库： g++ -fPIC -shared -o libmylib.so mylib.c 2. 使用Python调用动态库 #! /usr/bin/env python&lt;br&gt;&lt;br&gt;import ctypes&lt;br&gt;import os&lt;br&gt;&lt;br&gt;mylib = ctypes.CDLL(os.getcwd() + &#39;/libmylib.so&#39;)&lt;br&gt;print mylib.sum(2,6) 3. Python调用科大讯飞语音识别API 加载动态库： xflib = ctypes.cdll.LoadLibrary(&#39;msc/libmsc.so&#39;) 在Python里面调用C函数时主要是注意参数的类型。语音识别的接口如下：接口函数： const char* MSPAPI QISRSessionBegin( const char* grammarList, const char*&lt;br&gt;params, int* errorCode ) 返回的是一个char指针作为sessionID以供后续接口使用，在Python里面要用ctypes.c_voidp类型： ret = ctypes.c_int()&lt;br&gt;sessionId = ctypes.c_voidp()&lt;br&gt;sessionId = xflib.QISRSessionBegin(None, param1, ret) 调用其它接口函数时，还可能用到如下ctypes的类型和接口： ctypes.create_string_buffer()- ctypes.addressof()- ctypes.byref()- ctypes.string_at()- ctypes.c_char_p()- ctypes.c_uint()ctypes.addressof() ctypes.string_at() ctypes.c_uint() 关于ctypes的更详细说明可以参考官方文档 转载来源：C/C++扩展之Python直接调用讯飞语言]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>C语言</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动驾驶安全员究竟都干什么？我今天去百度Apollo体验了一天]]></title>
    <url>%2F2018%2F363fb4a9%2F</url>
    <content type="text"><![CDATA[自动驾驶安全员究竟都干什么？我今天去百度Apollo体验了一天 转载来源：自动驾驶安全员究竟都干什么？我今天去百度Apollo体验了一天]]></content>
  </entry>
  <entry>
    <title><![CDATA[Kaggle百万美元大赛优胜者：用CNN识别CT图像检测肺癌]]></title>
    <url>%2F2018%2F37cd7d9a%2F</url>
    <content type="text"><![CDATA[王小新 编译自GitHub 量子位 出品 | 公众号 QbitAI 今年，Kaggle网站举办了一场用肺部CT图像进行肺癌检测的比赛Data Science Bowl 2017，提供百万美元奖金池。美国国家癌症研究所为比赛提供了高分辨率的肺部CT图像，在比赛中，参赛者根据给定的一组病人肺部CT三维图像，预测癌症风险。 Julian de Wit和Daniel Hammack合作完成的解决方案获得了比赛的第二名。Wit最近写了一篇博客来介绍他们的方案。他们通过3D卷积神经网络，来构建结节探测器，预测患癌可能性。Wit在64位的Windows10系统下，结合TensorFlow 0.12.0和Keras库实现该网络模型。 BTW，第2名的奖金是20万美元。 以下内容编译自Wit的文章： 初步了解和制定计划在决定参赛之前，我观看了一个Bram van Ginneken关于肺部CT图像的介绍视频，有了基本的了解。我试图直接观察一些CT扫描样本，发现这是一个很难的问题，难度与大海捞针相当。视频中提到，图像的信噪比大约为1:1000。论坛中的一些讨论也提到，神经网络不能直接从这些原始图像中学习到有用信息。目前只有1300个训练样本及对应的癌症标签，这与网络提取出的图像实际特征相差甚远。 我们希望获得更高信噪比的训练集，或是找到标签和图像特征之间更直接的关系，来训练神经网络。幸运的是，比赛组织者指出，可以借鉴一个先前举办的比赛LUNA16。在LUNA16数据集中，医生为800多个病人CT图像中精心标记了1000多个肺结节。当然，LUNA16比赛也提供没有标记结节的数据集。 因此，你可以从整体CT图像中的标记周围裁剪出小型3D图像块，最终可以用更小的3D图像块与结节标记直接对应。结节大小是癌症的一个影响因素，数据集也说明了结节的大小，所以我认为这是一个有用的信息。 图1：方法网络示意图 我还注意到LUNA16数据集是由另一个公开数据集LIDC-IDRI转化过来的。在原始数据集中，医生不仅要检测结节，而且还评估了结节的恶性程度和其他指标。我们发现，恶性程度是评估患癌风险的最佳指标，也是神经网络可以学习的。 最终的计划方案是训练一个神经网络来检测结节，并评估结节的恶性程度。在预测时，网络通过滑动窗口来遍历整体CT图像，分别判断每个滑动窗口的区域包含恶性信息的可能性。最后基于这种信息和其他特征，估计该患者发展成癌症的可能性。 数据预处理和创建训练集在预处理中，要使扫描图像的尺度尽可能一致。我首先重新缩放了CT图像，使每个像素点只表示1x1x1毫米的体积。我们也尝试了一些其他尺度的实验，最终确定了采用1毫米的尺度，这能很好地平衡计算精度和计算负荷。对于CT图像，像素强度可以用Hounsfield来表示，一般叫做亨氏单位。论坛里提到，要尽量降低像素强度，即最大化hounsfield值，然后归一化处理。同时还要确保所有CT扫描都具有相同的方向，因为CT图像旋转超过45度，意味着在图像采集过程中出现错误。 极大部分关于结节检测的文献都是先从CT扫描图像中分离出肺组织。然而目前没有合适的分割方法，能够很好地处理隐藏在肺组织边缘周围的结节和肿块。在CT图像中，这些区域会直接被删除，更不用说使用结节探测器进行类型判定。我想要训练一个U-net网络，来更好地分割肺部。与传统的分割方法相比，U-net网络能够更有效地解决实际的图像分割问题，在同为Kaggle举办的卫星图像分割比赛中被广泛地使用。当我观察这些CT图像时，我认为可以通过肺组织的边缘，构建框架来找到肺结节。这么做可能是有用的，最后我决定对原始图像进行训练和预测。在调整训练数据后，该网络效果不错，似乎没有负面影响。 在这个竞赛中，给定了训练数据，可能没有很大的发挥空间。然而处理训练集是必须的，但不是最重要的那部分工作。我使用样本中的标签，自动生成训练集的标签，也采用主动学习方法，添加部分人工标记。以下是带有标记的不同数据集。 表1：标记后的训练集 LIDC数据集中被正面标记的数量是LUNA16数据集样本数的五倍。因为这些标记是4名医生的综合注释，所以一个结节可能被标记了4次。但LUNA16也忽略了不到3名医生标注的结节。我决定在训练集中保留这些被忽视的结节，因为他们也提供了宝贵的结节恶性信息。 LUNA16 v2数据集的标签是直接从LUNA16传来，一般是多个结节检测系统错误标出的假阳性结节。要注意的是，部分结节是上面提到的不到3名医生标记的结节。我保留了这些结节标记，是为了平衡那些可疑的假阳性结节。 为了得到肺部轮廓，我需要得到非肺组织的底片。我使用了论坛中提到的简单肺分割算法，在分割掩码边缘周围进行采样标注，从而分割得到肺部组织。 在进行第一轮训练之后，我在LUNA16数据集上进行结节预测，得到了所有假阳性结节，也并入LUNA16 v2数据集中。 随着比赛的进行，我想建立第二个模型。对于这个模型，我做了放射科医生的工作，在NDSB数据集上训练网络。我手动地从癌症样本中选择明显的阳性结节，并从非癌症样本中选择假阳性结节，用这些数据训练了第二个模型。我希望效果不错，但我是一个不合格的放射科医生，实际上第二个模型比无手动标注的模型要糟糕得多。但是结合这两个模型，这个得到的融合模型比单独的模型效果更好，所以我保留了第二个模型。 我简单地建立了一个结节观察器，来调试所有的标记。在观察时，我注意到医生忽略了一些大于3cm的大结节。在LIDC数据集的说明文档中，我发现医生被要求忽略掉大于3cm的结节。我担心这些被忽视的结节区域会迷惑分类器，故删除了相重叠的底片。下面是肺部CT图像的一些截图。 图2：图像中的标记。 左上：LUNA16 v2数据，右上：非肺组织的边缘， 左下：假阳性的区域，右下：被移除的无标注区域。 3D卷积神经网络的训练方法和网络结构在一个高质量的训练集下，我们仍需要多次调整来有效地训练神经网络。数据集的两类样本量严重不平衡，正反两类样本量的比为5000：500000，且正面例子的大小和形状有很大差异。我曾考虑使用U-net网络，但2D U-net不能完全利用结节本身的三维结构信息，3D U-net网络的训练过程非常缓慢而且不灵活。我不使用U-net的主要原因是不需要建立细粒度的概率图，而只是一个粗略的检测器。在CT图像的滑动窗口中，建立小型的3D Convnet，这更加轻便和灵活。 我的第一个目标是训练一个可作为基础的结节检测器。我先要对正面例子进行过采样，将正反两类的样本比上调到1:20。为了提高模型的泛化能力，我尝试了一些图像增强操作，但是只有一些无损的操作是有用的。最后我用了大量的转化操作和所有3D翻转操作。 设计好分类器后，我想训练一个用于估计恶化程度的回归模型。将肿瘤恶化程度分为从1（很可能不是恶性）到5（很可能是恶性的）。为了强调肿瘤的恶性程度，我将标签平方，范围扩大为从1到25。最开始，我考虑了分阶段的一种方法，用第一个网络来分类节点，然后训练另一个网络估计结节的恶化程度。为了缩短计算时间，我尝试只用一个网络，以多任务学习的方法，同时进行训练这两个任务。当编程实现后，我发现这个方法简单快速，网络的效果也很好。 通常，神经网络的结构是比赛和案例研究中最重要的成果之一。对于这场比赛，我在神经网络的结构上花费的时间相对较少，因为已经有很多优秀网络可供参考。刚开始我使用了一些简单的VGG网络和Resnet网络的相似结构，但是它们的性能大致相同。然后我尝试用一个预训练好的C3D网络，原有的网络权重根本没有帮助，但直接初始化权重后，这种网络结构的效果很好。基于C3D网络进行若干次调整后，我得到最终的分类评估网络。 我首先调整了输入大小，设置为32x32x32 mm。这看起来可能太小，但是在后续的网络层中加入一些技巧，发现这种维度的实际效果很好。这个想法是保持一切轻量化，并在比赛结束后再建立一个更大输入维度的网络。但是由于Daniel的网络输入是64x64x64 mm，我决定保持目前的输入大小，使网络的输出互补。接下来我立即对z轴进行平均池化操作，使得每个体素表示2mm的区域。这进一步减少了网络的参数量，并没有影响到精度，因为在大多数扫描中，z轴会比x轴和y轴更粗糙。最后，我在网络顶部引入了64个节点的全连接层。这里，我们不是直接预测恶性肿瘤，而是通过训练图片的中级特征，输出结节的恶化程度。 表2：3D Convnet的网络结构示意图 有趣的插曲：“奇怪组织”检测器看着论坛的帖子，我发现所有的团队都在做类似的工作，我也在寻找一个能直接上手的方法。在观察CT扫描图像时，我发现了一些其他的事情。与LUNA16数据集一样，大部分的工作集中在识别肺结节上。然而，当癌症发展时，它们转变成肺肿块或更复杂的组织。并且我注意到，当扫描图像中有很多“奇怪组织”时，它发展为癌症的概率更大。此外，在很多CT图像中，我的结节探测器没有发现任何结节，这造成了一些很不好的假阴性现象。 在训练集中有10例存在上述现象，其中的5例为癌症病例。为了解决这些严重的假阴性，在扫描时，需要检测获得奇怪组织的数量。很幸运，在LUNA16数据集上包含了很多这样的样本，所以我很快对数据集进行标记并训练了一个U-net网络。加入奇怪组织检测器后，效果不错，我因此提高了本地CV值和LB上的排名。因为它对于不同的模型提升不同，很难评定实际效果，但我认为它大约提升了0.002-0.005。说实话，我认为这种改进是一个创新性的补充。以下是一些包含有奇怪组织的样本。 图3：带有奇怪组织的CT图像样本。 肺气肿基本上是由吸烟导致的，我也试图建立一个肺气肿检测器。论坛上的医生都说，当肺气肿存在时，患有癌症的概率升高。有一些简单的算法公布了如何评估CT扫描中肺气肿区域的数量，设置hounsfield单位为950，来扫描CT图像。然而，我应用这种方法后，发现效果并不好。然后我标记了一些例子来训练一个U-net，发现效果不错，但是我的本地CV值没有丝毫提升。我的猜测是，因为肺部出现问题，进行扫描得到数据集中的许多病例，因此很多肺气肿样本没有看做是肺结节和癌症病例。我不能确定这个想法的正确性。 最后一步：癌症预测训练好网络后，下一步是让神经网络检测结节并估计其恶化程度。我建立的CT结节观察器很容易查看网络结果。我觉得神经网络的效果很好：它检测到了许多我完全忽视的结节，而我只看到很少量的假阳性结节。但是还存在一个严重的问题：由于它错过了一些非常大的明显结节，所以影响了对于假阴性的得分，有时使LogLoss升高了3.00。作为尝试，我试图对CT图像进行了两次降采样，看看检测器是否会检测大结节。值得注意的是，它的效果非常好。因此，我调整了网络结构，让网络预测3个尺度，分别为1，1.5和2.0。我觉得值得花这么多的时候来改善这方面的性能。 图4：在缩放1x的左图中，没有很好地检测到大结节；但是在2x放大的右图时，效果较好。矩形的大小表示坚持到的恶性肿瘤。 鉴于这些数据和一些其他特征，我想训练一个以梯度推进的分类器来预测一年内癌症的发病率，这是比较容易实现的。但是问题在于，排行榜的得分是基于给定的200名患者，这里面意外地包含了大量异常患者。经过一些调整后，我通过交叉验证得到了本地的平均值为0.39-0.40，而排行榜得分在0.44和0.47之间变化。此时很难将排行榜得分与本地CV值相关联。提高了本地CV值可能导致LB评分的降低，反之亦然。 我花了很多时间来研究本地CV值和LB评分的关系。我没有成功，所以我只使用能同时改进CV值和LB排名的技巧和特征。这是一场两阶段的比赛，而且与实际的训练集相比，第二阶段的数据存在与LB数据集更相似的可能。在这个地方，很多队伍也只能碰运气，结果显示排行榜上的很多队伍模型处于过拟合状态。最后我只使用7个特征来训练梯度推进器，分别是3个尺度下的最大恶性结节及其Z轴的位置和样本中奇怪组织的数量。 我也融合了两个模型来提高效果。第一个模型是在完整的LUNA16数据集上训练的。第二次，我试图从NDSB训练集中选择明显的阳性样本和假阳性样本，应用主动学习来训练。由于我不是放射科医师，所以我为了保险起见，只选择癌症病例的阳性例子和非癌症病例的阴性例子。我做错了，因为第二个模型比没有额外标注的LUNA16模型更糟糕。通过平均两个模型的输出，对LB排名有了很好的推动作用，并且显著提高了本地CV值。 与Daniel合作在进行机器学习比赛时，将不同角度的解决方案组合在一起往往是个好主意。我和Daniel在以前的医疗比赛中一起合作过，知道他是一个非常聪明的人，且他的参赛思路一般和我不同。他是从研究的角度来看问题，而我一般以工程的角度来看问题。当我们合作时，我们确信结合两者互补的方法，能有一个很棒的解决方案。 我们这次组队，一开始就发现两个人对LIDC数据集中的恶性信息有完全相同的观察角度，解决方案也很相似，感到有点失望。不过幸运的是，剩余部分的设计方法完全不同，结合后显著改进了LB排名和本地CV值。下面列举出一些主要的区别。 表3：Julian和Daniel之间设计方法的差异 强强联合是一个很好的选择。虽然我因为LB得分感到担忧，但Daniel觉得应该主要关注本地CV值。所以最终我减少研究本地CV值和LB的匹配关系，并着重于改进本地CV值。在最后的排行榜上，证明这是一个很好的决定，因为在最后，第二阶段的排行榜与本地CV值相当匹配，我们获得了比赛的第二名。尽管有许多队伍，在第一阶段取得了很好的排行榜得分，后来被证明模型过拟合。 总结与感想我们在观察网络对CT图像的结节检测时，模型效果很好。第一阶段，logloss为0.43，公开排行榜的ROC准确率为0.85，第二阶段，logloss为0.40，私人数据集的ROC准确率更高。这让我很兴奋，因为在这个数据集上，我们的模型已经是一位训练有素的放射科医生了。 对于放射科医师来说，这个自动结节检测的模型可能很有帮助，因为在实际判断中，部分结节容易被忽视。模型对肿瘤恶化程度的评估效果也很好，但训练样本量只有1000个，所以应该有很大的改进空间。 在Daniel和我合作的解决方案中，应用了相当多的工程办法，许多步骤和决定是基于经验和直觉来确定的。我们没有足够的时间来准确地验证所有方法的效果。下面提出进一步研究的一些建议。 1. 建立放射科医师基准线。根据一个放射学家在这个数据集上的具体表现，建立一个具有参考意义的基准。 2. 对NDSB数据集的恶性肿瘤标注。在这场比赛中，训练样本只有约1000个结节。输入更多精确标记的例子，肯定进一步提升算法准确度。 3. 尝试更多不同的神经网络结构。我花了很少时间来选择效果最佳的网络结构，可能会错过一些效果更好的结构。 相关资源这次比赛的Kaggle地址（含说明、数据集等）：https://www.kaggle.com/c/data-science-bowl-2017/ 文中提到的另一个比赛LUNA16：https://luna16.grand-challenge.org/ 该项目的完整程序请查看GitHub链接：https://github.com/juliandewit/kaggle_ndsb2017 Dan Hammack也公布了他的代码：https://github.com/dhammack/DSB2017/ （完） 招聘 量子位正在招募编辑记者、运营、产品等岗位，工作地点在北京中关村。相关细节，请在公众号对话界面，回复：“招聘”。 One More Thing… 今天AI界还有哪些事值得关注？在量子位（QbitAI）公众号会话界面回复“今天”，看我们全网搜罗的AI行业和研究动态。笔芯~ 转载来源：Kaggle百万美元大赛优胜者：用CNN识别CT图像检测肺癌]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>肺癌</tag>
        <tag>癌症</tag>
        <tag>Kaggle</tag>
        <tag>肺气肿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GIF界的谷歌，凭什么靠 6 秒钟广告进账几十亿？]]></title>
    <url>%2F2018%2F8cdbcd6f%2F</url>
    <content type="text"><![CDATA[GIF界的谷歌，凭什么靠 6 秒钟广告进账几十亿？ 转载来源：GIF界的谷歌，凭什么靠 6 秒钟广告进账几十亿？]]></content>
      <tags>
        <tag>36氪</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[新论文：首个基于决策树集成的自动编码器，表现优于DNN]]></title>
    <url>%2F2018%2F48ca02d0%2F</url>
    <content type="text"><![CDATA[新论文：首个基于决策树集成的自动编码器，表现优于DNN 转载来源：新论文：首个基于决策树集成的自动编码器，表现优于DNN]]></content>
  </entry>
  <entry>
    <title><![CDATA[中兴禁运令有感]]></title>
    <url>%2F2018%2F48d10726%2F</url>
    <content type="text"><![CDATA[中兴禁运令有感 转载来源：中兴禁运令有感]]></content>
      <tags>
        <tag>Dribbler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一文简述ResNet及其多种变体]]></title>
    <url>%2F2018%2F4d745c83%2F</url>
    <content type="text"><![CDATA[本文主要介绍了 ResNet 架构，简要阐述了其近期成功的原因，并介绍了一些有趣的 ResNet 变体。 在 AlexNet [1] 取得 LSVRC 2012 分类竞赛冠军之后，深度残差网络（Residual Network, 下文简写为 ResNet）[2] 可以说是过去几年中计算机视觉和深度学习领域最具开创性的工作。ResNet 使训练数百甚至数千层成为可能，且在这种情况下仍能展现出优越的性能。 因其强大的表征能力，除图像分类以外，包括目标检测和人脸识别在内的许多计算机视觉应用都得到了性能提升。 自从 2015 年 ResNet 让人们刮目相看，研究界的许多人在深入探索所其成功的秘密，许多文献中对该模型做了一些改进。本文分为两部分，第一部分为不熟悉 ResNet 的人提供一些背景知识，第二部分将介绍我最近阅读的一些论文，关于 ResNet 的不同变体和对 ResNet 架构的理解。 重新审视 ResNet 根据泛逼近定理（universal approximation theorem），只要给定足够的容量，单层的前馈网络也足以表示任何函数。但是，该层可能非常庞大，网络和数据易出现过拟合。因此，研究界普遍认为网络架构需要更多层。 自 AlexNet 以来，最先进的 CNN 架构已经越来越深。AlexNet 只有 5 个卷积层，而之后的 VGG 网络 [3] 和 GoogleNet（代号 Inception_v1）[4] 分别有 19 层和 22 层。 但是，网络的深度提升不能通过层与层的简单堆叠来实现。由于臭名昭著的梯度消失问题，深层网络很难训练。因为梯度反向传播到前面的层，重复相乘可能使梯度无穷小。结果就是，随着网络的层数更深，其性能趋于饱和，甚至开始迅速下降。 增加网络深度导致性能下降 在 ResNet 出现之前有几种方法来应对梯度消失问题，例如 [4] 在中间层添加了一个辅助损失作为额外的监督，但其中没有一种方法真正解决了这个问题。 ResNet 的核心思想是引入一个所谓的「恒等快捷连接」（identity shortcut connection），直接跳过一个或多个层，如下图所示： 残差块 ResNet 架构 [2] 的作者认为，堆叠层不应降低网络性能，因为我们可以简单地在当前网络上堆叠恒等映射（该层不做任何事情），得到的架构将执行相同的操作。这表明较深的模型所产生的训练误差不应该比较浅的模型高。他们假设让堆叠层适应残差映射比使它们直接适应所需的底层映射要容易一些。上图中的残差块明确表明，它可以做到这一点。 事实上，ResNet 并不是第一个利用快捷连接的模型，Highway Networks [5] 就引入了门控快捷连接。这些参数化的门控制流经捷径（shortcut）的信息量。类似的想法可以在长短期记忆网络（LSTM）[6] 单元中找到，它使用参数化的遗忘门控制流向下一个时间步的信息量。ResNet 可以被认为是 Highway Network 的一种特殊情况。 然而，实验结果表明 Highway Network 的性能并不比 ResNet 好，这有点奇怪。Highway Network 的解空间包含 ResNet，因此它的性能至少应该和 ResNet 一样好。这表明，保持这些「梯度高速路」（gradient highway）的畅通比获取更大的解空间更为重要。 按照这种思路，[2] 的作者改进了残差块，并提出了一种残差块的预激活变体 [7]，梯度可以在该模型中畅通无阻地通过快速连接到达之前的任意一层。事实上，使用 [2] 中的原始残差块训练一个 1202 层的 ResNet，其性能比 110 层的模型要差。 残差块的变体 [7] 的作者在其论文中通过实验表明，他们可以训练出 1001 层的深度 ResNet，且性能超越较浅层的模型。他们的训练成果卓有成效，因而 ResNet 迅速成为多种计算机视觉任务中最流行的网络架构之一。 ResNet 的最新变体以及解读 随着 ResNet 在研究界的不断普及，关于其架构的研究也在不断深入。本节首先介绍几种基于 ResNet 的新架构，然后介绍一篇论文，从 ResNet 作为小型网络集合的角度进行解读。 ResNeXt Xie et al. [8] 提出 ResNet 的一种变体 ResNeXt，它具备以下构建块： 左：[2] 中 ResNet 的构建块；右：ResNeXt 的构建块，基数=32 ResNext 看起来和 [4] 中的 Inception 模块非常相似，它们都遵循了「分割-转换-合并」的范式。不过在 ResNext 中，不同路径的输出通过相加合并，而在 [4] 中它们是深度级联（depth concatenated）的。另外一个区别是，[4] 中的每一个路径互不相同（1x1、3x3 和 5x5 卷积），而在 ResNeXt 架构中，所有的路径都遵循相同的拓扑结构。 作者在论文中引入了一个叫作「基数」（cardinality）的超参数，指独立路径的数量，这提供了一种调整模型容量的新思路。实验表明，通过扩大基数值（而不是深度或宽度），准确率得到了高效提升。作者表示，与 Inception 相比，这个全新的架构更容易适应新的数据集或任务，因为它只有一个简单的范式和一个需要调整的超参数，而 Inception 需要调整很多超参数（比如每个路径的卷积层内核大小）。 这个全新的结构有三种等价形式： 在实际操作中，「分割-变换-合并」范式通常通过「逐点分组卷积层」来完成，这个卷积层将输入的特征映射分成几组，并分别执行正常的卷积操作，其输出被深度级联，然后馈送到一个 1x1 卷积层中。 密集连接卷积神经网络 Huang 等人在论文 [9] 中提出一种新架构 DenseNet，进一步利用快捷连接，将所有层直接连接在一起。在这种新型架构中，每层的输入由所有之前层的特征映射组成，其输出将传输给每个后续层。这些特征映射通过深度级联聚合。 除了解决梯度消失问题，[8] 的作者称这个架构还支持特征重用，使得网络具备更高的参数效率。一个简单的解释是，在论文 [2] 和论文 [7] 中，恒等映射的输出被添加到下一个模块，如果两个层的特征映射有着非常不同的分布，那么这可能会阻碍信息流。因此，级联特征映射可以保留所有特征映射并增加输出的方差，从而促进特征重用。 遵循该范式，我们知道第 l 层将具有 k （l-1）+ k_0 个输入特征映射，其中 k_0 是输入图像的通道数目。作者使用一个叫作「增长率」的超参数 (k) 防止网络过宽，他们还用了一个 11 的卷积瓶颈层，在昂贵的 3*3 卷积前减少特征映射的数量。整体架构如下表所示： 用于 ImageNet 的 DenseNet 架构 深度随机的深度网络 尽管 ResNet 的强大性能在很多应用中已经得到了证实，但它存在一个显著缺点：深层网络通常需要进行数周的训练时间。因此，把它应用在实际场景的成本非常高。为了解决这个问题，G. Huang 等作者在论文 [10] 中引入了一种反直觉的方法，即在训练过程中随机丢弃一些层，测试中使用完整的网络. 作者使用残差块作为他们网络的构建块。因此在训练期间，当特定的残差块被启用，它的输入就会同时流经恒等快捷连接和权重层；否则，就只流过恒等快捷连接。训练时，每层都有一个「生存概率」，每层都有可能被随机丢弃。在测试时间内，所有的块都保持被激活状态，并根据其生存概率进行重新校准。 从形式上来看，H_l 是第 l 个残差块的输出结果，f_l 是由第 l 个残差块的加权映射所决定的映射，b_l 是一个伯努利随机变量（用 1 或 0 反映该块是否被激活）。在训练中： 当 b_l=1 时，该块为正常的残差块；当 b_l=0 时，上述公式为： 既然我们已经知道了 H_(l-1) 是 ReLU 的输出，而且这个输出结果已经是非负的，所以上述方程可简化为将输入传递到下一层的 identity 层： 令 p_l 表示是第 l 层在训练中的生存概率，在测试过程中，我们得到： 作者将线性衰减规律应用于每一层的生存概率，他们表示，由于较早的层提取的低级特征会被后面的层使用，所以不应频繁丢弃较早的层。这样，规则就变成： 其中 L 表示块的总数，因此 p_L 就是最后一个残差块的生存概率，在整个实验中 p_L 恒为 0.5。请注意，在该设置中，输入被视为第一层 (l=0)，所以第一层永远不会被丢弃。随机深度训练的整体框架如下图所示： 训练过程中，每一层都有一个生存概率 与 Dropout [11] 类似，训练随机深度的深度网络可被视为训练许多较小 ResNet 的集合。不同之处在于，上述方法随机丢弃一个层，而 Dropout 在训练中只丢弃一层中的部分隐藏单元。 实验表明，同样是训练一个 110 层的 ResNet，随机深度训练出的网络比固定深度的性能要好，同时大大减少了训练时间。这意味着 ResNet 中的一些层（路径）可能是冗余的。 作为小型网络集合的 ResNet [10] 提出一种反直觉的方法，即在训练中随机丢弃网络层，并在测试中使用完整的网络。[14] 介绍了一种更加反直觉的方法：我们实际上可以删除已训练 ResNet 的部分层，但仍然保持相对不错的性能。[14] 还用同样的方式移除 VGG 网络的部分层，其性能显著降低，这使得 ResNet 架构更加有趣。 [14] 首先介绍了一个 ResNet 的分解图来使讨论更加清晰。在我们展开网络架构之后，很明显发现，一个有着 i 个残差块的 ResNet 架构有 2**i 个不同路径（因为每个残差块提供两个独立路径）。 根据上述发现，显然移除 ResNet 架构中的部分层对其性能影响不大，因为架构具备许多独立有效的路径，在移除了部分层之后大部分路径仍然保持完整无损。相反，VGG 网络只有一条有效路径，因此移除一个层会对该层的唯一路径产生影响。（如 [14] 中的实验所揭示的。） 作者的另一个实验表明，ResNet 中不同路径的集合有类似集成的行为。他们在测试时删除不同数量的层，测试网络性能与删除层的数量是否平滑相关。结果表明，网络行为确实类似集成，如下图所示： 当被删除的层数增加时，误差值随之增长 最终，作者研究了 ResNet 中路径的特征： 很明显，路径的可能长度分布遵循二项分布，如下图 (a) 所示。大多数路径流经 19 到 35 个残差块。 为了研究路径长度与经过路径的梯度大小之间的关系，得到长度为 k 的路径的梯度大小，作者首先向网络输入了一批数据，并随机采样 k 个残差块。当梯度被反向传播时，它们在采样残差块中仅通过权重层进行传播。(b) 表明随着路径长度的增加，梯度大小迅速下降。 现在将每个路径长度的频率与其期望的梯度大小相乘，以了解每个长度的路径在训练中起到多大作用，如图 (c) 所示。令人惊讶的是，大多数贡献来自于长度为 9 到 18 的路径，但它们只占所有路径的一小部分，如 (a) 所示。这是一个非常有趣的发现，它表明 ResNet 并没有解决长路径的梯度消失问题，而是通过缩短有效路径的长度训练非常深层的 ResNet 网络。 结论 本文主要介绍了 ResNet 架构，简要阐述了其近期成功的原因，并介绍了几篇论文，它们叙述了一些有趣的 ResNet 变体，或提供了富有洞察力的解释。希望这篇文章有助于大家理解这项开创性的工作。 本文所有的图表均来自于参考文献中的原始论文。 References: [1]. A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems,pages1097–1105,2012. [2]. K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. arXiv preprint arXiv:1512.03385,2015. [3]. K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556,2014. [4]. C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,pages 1–9,2015. [5]. R. Srivastava, K. Greff and J. Schmidhuber. Training Very Deep Networks. arXiv preprint arXiv:1507.06228v2,2015. [6]. S. Hochreiter and J. Schmidhuber. Long short-term memory. Neural Comput., 9(8):1735–1780, Nov. 1997. [7]. K. He, X. Zhang, S. Ren, and J. Sun. Identity Mappings in Deep Residual Networks. arXiv preprint arXiv:1603.05027v3,2016. [8]. S. Xie, R. Girshick, P. Dollar, Z. Tu and K. He. Aggregated Residual Transformations for Deep Neural Networks. arXiv preprint arXiv:1611.05431v1,2016. [9]. G. Huang, Z. Liu, K. Q. Weinberger and L. Maaten. Densely Connected Convolutional Networks. arXiv:1608.06993v3,2016. [10]. G. Huang, Y. Sun, Z. Liu, D. Sedra and K. Q. Weinberger. Deep Networks with Stochastic Depth. arXiv:1603.09382v3,2016. [11]. N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever and R. Salakhutdinov. Dropout: A Simple Way to Prevent Neural Networks from Overfitting. The Journal of Machine Learning Research 15(1) (2014) 1929–1958. [12]. A. Veit, M. Wilber and S. Belongie. Residual Networks Behave Like Ensembles of Relatively Shallow Networks. arXiv:1605.06431v2,2016. 转载来源：一文简述ResNet及其多种变体]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>Pages</tag>
        <tag>盗梦空间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[千人千面智能淘宝店铺背后的算法研究登陆人工智能顶级会议AAAI 2017]]></title>
    <url>%2F2018%2F4ed85306%2F</url>
    <content type="text"><![CDATA[千人千面智能淘宝店铺背后的算法研究登陆人工智能顶级会议AAAI 2017 转载来源：千人千面智能淘宝店铺背后的算法研究登陆人工智能顶级会议AAAI 2017]]></content>
      <tags>
        <tag>阿里技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React应用架构设计]]></title>
    <url>%2F2018%2F45be0725%2F</url>
    <content type="text"><![CDATA[本节将开始详细分析如何搭建一个React应用架构。 一. 前言现在已经有很多脚手架工具，如create-react-app，支持一键创建一个React应用项目结构，很方便，但是享受方便的同时，也失去了对项目架构及技术栈完整学习的机会，而且通常脚手架创建的应用技术架构并不能完全满足我们的业务需求，需要我们自己修改，完善，所以如果希望对项目架构有更深掌控，最好还是从0到1理解一个项目。 二. 项目结构与技术栈我们这次的实践不准备使用任何脚手架，所以我们需要自己创建每一个文件，引入每一个技术和三方库，最终形成完整的应用，包括我们选择的完整技术栈。 第一步，当然是创建目录，如果你还没有代码，可以从Github获取： 生成项目结构如下图： 1、 src为应用源代码目录； 2、 webpack为webpack配置目录； 3、 webpack.config.js为webpack配置入口文件； 4、 package.json为项目依赖管理文件； 5、 yarn.lock为项目依赖版本锁文件； 6、 .babelrc文件，babel的配置文件，使用babel编译React和JavaScript代码； 7、 eslintrc 和 eslintignore 分别为eslint语法检测配置及需要忽略检查的内容或文件； 8、 postcss.config.js 为CSS后编译器postcss的配置文件； 9、 API.md为API文档入口； 10、 docs为文档目录； 11、 README.md为项目说明文档； 接下来的工作主要就是丰富src目录，包括搭建项目架构，开发应用功能，还有自动化，单元测试等，本篇主要关注项目架构的搭建，然后使用技术栈实践开发几个模块。 2.1 技术栈 项目架构搭建很大部分依赖于项目的技术栈，所以先对整个技术栈进行分析，总结： 1、 react和react-dom库是项目前提； 2、 react路由； 3、 应用状态管理容器； 4、 是否需要Immutable数据； 5、 应用状态的持久化； 6、 异步任务管理； 7、 测试及辅助工具或函数； 8、 开发调试工具； 根据以上划分决定选用以下第三方库和工具构成项目的完整技术栈： 1、react，react-dom； 2、react-router管理应用路由； 3、redux作为JavaScript状态容器，react-redux将React应用与redux连接； 4、Immutable.js支持Immutable化状态，redux-immutable使整个redux store状态树Immutable化； 5、使用redux-persist支持redux状态树的持久化，并添加redux-persist-immutable拓展以支持Immutable化状态树的持久化； 6、使用redux-saga管理应用内的异步任务，如网络请求，异步读取本地数据等； 7、使用jest集成应用测试，使用lodash，ramda等可选辅助类，工具类库； 8、可选使用reactotron调试工具 针对以上分析，完善后的项目结构如图： 三. 开发调试工具React应用开发目前已经有诸多调试工具，常用的如redux-devtools，Reactron等。 3.1 redux-devtool redux-devtools是支持热重载，回放action，自定义UI的一款Redux开发工具。 首先需要按照对应的浏览器插件，然后再Redux应用中添加相关配置，就能在浏览器控制台中查看到redux工具栏了。 然后安装项目依赖库： 然后在创建redux store时将其作为redux强化器传入createStore方法： 在开发环境下获取redux-devtools提供的拓展组合函数；1. 创建store时使用拓展组合函数组合redux中间件和增强器，redux-dev-tools便获得了应用redux的相关信息；创建store时使用拓展组合函数组合redux中间件和增强器，redux-dev-tools便获得了应用redux的相关信息； 3.2 Reactotron Reactotron是一款跨平台调试React及React Native应用的桌面应用，能动态实时监测并输出React应用等redux，action，saga异步请求等信息，如图： 首先安装： 然后初始化Reactotron相关配置： 然后启使用console.tron.overlay方法拓展入口组件： 至此就可以使用Reactotron客户端捕获应用中发起的所有的redux和action了。 四. 组件划分React组件化开发原则是组件负责渲染UI，组件不同状态对应不同UI，通常遵循以下组件设计思路： 1、 布局组件：仅仅涉及应用UI界面结构的组件，不涉及任何业务逻辑，数据请求及操作； 2、 容器组件：负责获取数据，处理业务逻辑，通常在render()函数内返回展示型组件； 3、 展示型组件：负责应用的界面UI展示； 4、 UI组件：指抽象出的可重用的UI独立组件，通常是无状态组件； 五. Redux现在的任何大型web应用如果少了状态管理容器，那这个应用就缺少了时代特征，可选的库诸如mobx，redux等，实际上大同小异，各取所需，以redux为例，redux是最常用的React应用状态容器库，对于React Native应用也适用。 Redux是一个JavaScript应用的可预测状态管理容器，它不依赖于具体框架或类库，所以它在多平台的应用开发中有着一致的开发方式和效率，另外它还能帮我们轻松的实现时间旅行，即action的回放。 1、 数据单一来源原则：使用Redux作为应用状态管理容器，统一管理应用的状态树，它推从数据单一可信来源原则，所有数据都来自redux store，所有的数据更新也都由redux处理； 2、 redux store状态树：redux集中管理应用状态，组织管理形式就好比DOM树和React组件树一样，以树的形式组织，简单高效； 3、 redux和store：redux是一种Flux的实现方案，所以创建了store一词，它类似于商店，集中管理应用状态，支持将每一个发布的action分发至所有reducer； 4、 action：以对象数据格式存在，通常至少有type和payload属性，它是对redux中定义的任务的描述； 5、 reducer：通常是以函数形式存在，接收state（应用局部状态）和action对象两个参数，根据action.type(action类型)执行不同的任务，遵循函数式编程思想； 6、dispatch：store提供的分发action的功能方法，传递一个action对象参数； 7、 createStore：创建store的方法，接收reducer，初始应用状态，redux中间件和增强器，初始化store，开始监听action； 5.1 中间件（Redux Middleware） Redux中间件，和Node中间件一样，它可以在action分发至任务处理reducer之前做一些额外工作，dispatch发布的action将依次传递给所有中间件，最终到达reducer，所以我们使用中间件可以拓展诸如记录日志，添加监控，切换路由等功能，所以中间件本质上只是拓展了store.dispatch方法。 5.2 增强器（Store Enhancer） 有些时候我们可能并不满足于拓展dispatch方法，还希望能增强store，redux提供以增强器形式增强store的各个方面，甚至可以完全定制一个store对象上的所有接口，而不仅仅是store.dispatch方法 最简单的例子代码如上，新函数接收redux的createStore方法和创建store需要的参数，然后在函数内部保存store对象上某方法的引用，重新实现该方法，在里面处理完增强逻辑后调用原始方法，保证原始功能正常执行，这样就增强了store的dispatch方法。 可以看到，增强器完全能实现中间件的功能，其实，中间件就是以增强器方式实现的，它提供的compose方法就可以组合将我们传入的增强器拓展到store，而如果我们传入中间件，则需要先调用applyMiddleware方法包装，内部以增强器形式将中间件功能拓展到store.dispatch方法 5.3 react-redux Redux是一个独立的JavaScript应用状态管理容器库，它可以与React、Angular、Ember、jQuery甚至原生JavaScript应用配合使用，所以开发React应用时，需要将Redux和React应用连接起来，才能统一使用Redux管理应用状态，使用官方提供的react-redux库。 react-redux库提供Provider组件通过context方式向应用注入store，然后可以使用connect高阶方法，获取并监听store，然后根据store state和组件自身props计算得到新props，注入该组件，并且可以通过监听store，比较计算出的新props判断是否需要更新组件。 5.4 createStore 使用redux提供的createStore方法创建redux store，但是在实际项目中我们常常需要拓展redux添加某些自定义功能或服务，如添加redux中间件，添加异步任务管理saga，增强redux等： 5.5 redux与Immutable redux默认提供了combineReducers方法整合reduers至redux，然而该默认方法期望接受原生JavaScript对象并且它把state作为原生对象处理，所以当我们使用createStore方法并且接受一个Immutable对象作应用初始状态时，reducer将会返回一个错误，源代码如下： 如上表明，原始类型reducer接受的state参数应该是一个原生JavaScript对象，我们需要对combineReducers其进行增强，以使其能处理Immutable对象，redux-immutable即提供创建一个可以和Immutable.js协作的Redux combineReducers。 如上代码，可以看见我们传入的initialState是一个Immutable.Map类型数据，我们将redux整个state树丛根源开始Immutable化，另外传入了可以处理Immutable state的reducers和sagas。另外每一个state树节点数据都是Immutable结构，如AppReducer： 这里默认使用Immutable.fromJS()方法状态树节点对象转化为Immutable结构，并且更新state时使用Immutable方法state.merge()，保证状态统一可预测。 六. React路由在React web单页面应用中，页面级UI组件的展示和切换完全由路由控制，每一个路由都有对应的URL及路由信息，我们可以通过路由统一高效的管理我们的组件切换，保持UI与URL同步，保证应用的稳定性及友好体验。 6.1 react-router React Router是完整的React 路由解决方案，也是开发React应用最常使用的路由管理库，只要用过它，绝对会喜欢上它的设计，它提供简单的API，以声明式方式实现强大的路由功能，诸如按需加载，动态路由等。 1、声明式：语法简洁，清晰； 2、按需加载：延迟加载，根据使用需要判断是否需要加载； 3、动态路由：动态组合应用路由结构，更灵活，更符合组件化开发模式； 6.2 动态路由与静态路由 使用react-router v4版本可以定义跨平台的应用动态路由结构，所谓的动态路由（Dynamic Routing）即在渲染过程中发生路由的切换，而不需要在创建应用前就配置好，这也正是其区别于静态路由（Static Routing）所在，动态路由提高更灵活的路由组织方式，而且更方便编码实现路由按需加载组件。 在react-router v2和v3版本中，开发React应用需要在开始渲染前就定义好完整的应用路由结构，所有的路由都需要同时初始化，才能在应用渲染后生效，会产生很多嵌套化路由，丧失了动态路由的灵活性和简洁的按需加载编码方式。 6.3 react-router v4.x 在react-router 2.x和3.x版本中，定义一个应用路由结构通常如下： 很简单，但是所有的路由结构都需要在渲染应用前，统一定义，层层嵌套；而且如果要实现异步按需加载还需要在这里对路由配置对象进行修改，使用getComponentAPI，并侵入改造该组件，配合webpack的异步打包加载API，实现按需加载： 1、 路由层层嵌套，必须在渲染应用前统一声明； 2、 API不同，需要使用getComponent，增加路由配置对象的复杂性； 3、 只是一个声明路由的辅助标签，本身无意义； 而使用react-router v4.x则如下： 相比之前版本，减少了配置化的痕迹，更凸显了组件化的组织方式，而且在渲染组件时才实现该部分路由，而如果期望按需加载该组件，则可以通过封装实现一个支持异步加载组件的高阶组件，将经过高阶组件处理后返回的组件传入即可，依然遵循组件化形式： 1、 灵活性：路由可以在渲染组件中声明，不需依赖于其他路由，不需要集中配置； 2、 简洁：统一传入component，保证路由声明的简洁性； 3、 组件化：作为一个真实组件创建路由，可以渲染； 6.3.1 路由钩子方 另外需要注意的是，相对于之前版本提供 onEnter, onUpdate, onLeave 等钩子方法API在一定程度上提高了对路由的可控性，但是实质只是覆盖了渲染组件的生命周期方法，现在我们可以通过路由渲染组件的生命周期方法直接控制路由，如使用 componentDidMount 或 componentWillMount 代替 onEnter。 6.4 路由与Redux 同时使用React-Router和Redux时，大多数情况是正常的，但是也可能出现路由变更组件未更新的情况，如： 1、 我们使用redux的 connect 方法将组件连接至redux：connect(Home); 2、 组件不是一个路由渲染组件，即不是使用 Route&gt; 组件形式： 声明渲染的； 这是为什么呢？，因为Redux会实现组件的 shouldComponentUpdate 方法，当路由变化时，该组件并没有接收到props表明发生了变更，需要更新组件。 那么如何解决问题呢？，要解决这个问题只需要简单的使用react-router-dom 提供的 withRouter方法包裹组件： 6.5 Redux整合 在使用Redux以后，需要遵循redux的原则：单一可信数据来源，即所有数据来源都只能是reudx store，react路由状态也不应例外，所以需要将路由state与store state连接。 6.5.1 react-router-redux 连接React Router与Redux，需要使用 react-router-redux 库，而且react-router v4版本需要指定安装 &#64;next 版本和 hsitory 库： 然后，在创建store时，需要实现如下配置： 1、 创建一个history对象，对于web应用，我们选择browserHisotry，对应需要从 history/createBrowserHistory 模块引入 createHistory 方法以创建history对象； 2、 添加 routerReducer 和 routerMiddleware 中间件“，其中 routerMiddleware 中间件接收history对象参数，连接store和history，等同于旧版本的 syncHistoryWithStore ； 在渲染根组件时，我们抽象出两个组件： 1、 初始化渲染根组件，挂载至DOM的根组件，由 组件包裹，注入store； 2、 路由配置组件，在根组件中，声明路由配置组件，初始化必要的应用路由定义及路由对象； 上面的 组件是项目的路由组件： 首先使用 react-router-redux 提供的 ConnectedRouter 组件包裹路由配置，该组件将自动使用 组件注入的 store，我们需要做的是手动传入 history 属性，在组件内会调用 history.listen 方法监听浏览器 LOCATION_CHANGE 事件，最后返回 react-router 的 组件，处理作为 this.props.children 传入的路由配置。 6.5.2 dispatch切换路由 配置上面代码后，就能够以dispatch action的方式触发路由切换和组件更新了： 这个reducer所做的只是将App导航路由状态合并入store。 七. redux持久化我们知道浏览器默认有资源的缓存功能并且提供本地持久化存储方式如localStorage，indexDb，webSQL等，通常可以将某些数据存储在本地，在一定周期内，当用户再次访问时，直接从本地恢复数据，可以极大提高应用启动速度，用户体验更有优势，我们可以使用localStorage存储一些数据，如果是较大量数据存储可以使用webSQL。 另外不同于以往的直接存储数据，启动应用时本地读取然后恢复数据，对于redux应用而言，如果只是存储数据，那么我们就得为每一个reducer拓展，当再次启动应用时去读取持久化的数据，这是比较繁琐而且低效的方式，是否可以尝试存储reducer key，然后根据key恢复对应的持久化数据，首先注册Rehydrate reducer，当触发action时根据其reducer key恢复数据，然后只需要在应用启动时分发action，这也很容易抽象成可配置的拓展服务，实际上三方库redux-persist已经为我们做好了这一切。 7.1 redux-persist 要实现redux的持久化，包括redux store的本地持久化存储及恢复启动两个过程，如果完全自己编写实现，代码量比较复杂，可以使用开源库 redux-persist，它提供 persistStore 和 autoRehydrate 方法分别持久化本地存储store及恢复启动store，另外还支持自定义传入持久化及恢复store时对store state的转换拓展。 7.1.1 持久化store 如下在创建store时会调用persistStore相关服务- RehydrationServices.updateReducers()： 该方法内实现了store的持久化存储： 会在localStorage存储一个reducer版本号，这个是在应用配置文件中可以配置，首次执行持久化时存储该版本号及store，若reducer版本号变更则清空原来存储的store，否则传入store给持久化方法 persistStore 即可。 该方法主要实现store的持久化以及分发rehydration action &#58; 1、 订阅 redux store，当其发生变化时触发store存储操作； 2、 从指定的StorageEngine（如localStorage）中获取数据，进行转换，然后通过分发 REHYDRATE action，触发 REHYDRATE 过程； 接收参数主要如下： 1、 store&#58; 持久化的store； 2、 config：配置对象 1）storage：一个 持久化引擎，例如 LocalStorage 和 AsyncStorage； 2）transforms： 在 rehydration 和 storage 阶段被调用的转换器； 3） blacklist： 黑名单数组，指定持久化忽略的 reducers 的 key； 3、 callback：ehydration 操作结束后的回调； 7.1.2 恢复启动 和persisStore一样，依然是在创建redux store时初始化注册rehydrate拓展： 该方法实现的功能很简单，即使用 持久化的数据恢复(rehydrate) store 中数据，它其实是注册了一个autoRehydarte reducer，会接收前文persistStore方法分发的rehydrate action，然后合并state。 当然，autoRehydrate不是必须的，我们可以自定义恢复store方式： 7.1.3 版本更新 需要注意的是redux-persist库已经发布到v5.x，而本文介绍的以v5.x为例，v4.x参考此处，新版本有一些更新，可以选择性决定使用哪个版本。 7.2 持久化与Immutable 前面已经提到Redux与Immutable的整合，上文使用的redux -persist默认也只能处理原生JavaScript对象的redux store state，所以需要拓展以兼容Immutable。 7.2.1 redux-persist-immutable 使用redux-persist-immutable库可以很容易实现兼容，所做的仅仅是使用其提供的 persistStore 方法替换redux-persist所提供的方法： 7.2.2 transform 我们知道持久化store时，针对的最好是原生JavaScript对象，因为通常Immutable结构数据有很多辅助信息，不易于存储，所以需要定义持久化及恢复数据时的转换操作： 如上，输出对象中的in和out分别对应持久化及恢复数据时的转换操作，实现的只是使用 fromJS() 和 toJS() 转换Js和Immutable数据结构，使用方式如下： 八. Immutable在项目中引入Immutable以后，需要尽量保证以下几点： 1、 redux store整个state树的统一Immutable化； 2、 redux持久化对Immutable数据的兼容； 3、 React路由兼容Immutable； 8.1 Immutable与React路由 前面两点已经在前面两节阐述过，第三点react-router兼容Immutable，其实就是使应用路由状态兼容Immutable，在React路由一节已经介绍如何将React路由状态连接至Redux store，但是如果应用使用了Immutable库，则还需要额外处理，将react-router state转换为Immutable格式，routeReducer不能处理Immutable，我们需要自定义一个新的RouterReducer： 将默认初始路由状态转换为Immutable，并且路由变更时使用Immutable API操作state。 8.2 seamless-Immutable 当引入Immutable.js后，对应用状态数据结构的使用API就得遵循Immutable API，而不能再使用原生JavaScript对象，数组等的操作API了，诸如，数组解构（&#91;a, b&#93; = &#91;b, c&#93;），对象拓展符（…）等，存在一些问题： 1、Immutable数据辅助节点较多，数据较大： 2、必须使用Immutable语法，和JavaScript语法有差异，不能很好的兼容； 3、和Redux，react-router等JavaScript库写协作时，需要引入额外的兼容处理库； 针对这些问题，社区有了 seamless-immutable 可供替换选择： 1、更轻：相对于Immutable.js seamless-immutable 库更轻小； 2、语法：对象和数组的操作语法更贴近原生JavaScript； 3、和其他JavaScript库协作更方便； 九. 异步任务流管理最后要介绍的模块是异步任务管理，在应用开发过程中，最主要的异步任务就是数据HTTP请求，所以我们讲异步任务管理，主要关注在数据HTTP请求的流程管理。 9.1 axios 本项目中使用axios作为HTTP请求库，axios是一个Promise格式的HTTP客户端，选择此库的原因主要有以下几点： 能在浏览器发起XMLHttpRequest，也能在node.js端发起HTTP请求；1. 支持Promise；1. 能拦截请求和响应；1. 能取消请求；1. 自动转换JSON数据；支持Promise； 能取消请求； 9.2 redux-saga redux-saga是一个致力于使应用中如数据获取，本地缓存访问等异步任务易于管理，高效运行，便于测试，能更好的处理异常的三方库。 Redux-saga是一个redux中间件，它就像应用中一个单独的进程，只负责管理异步任务，它可以接受应用主进程的redux action以决定启动，暂停或者是取消进程任务，它也可以访问redux应用store state，然后分发action。 9.2.1 初始化saga redux-saga是一个中间件，所以首先调用 createSagaMiddleware 方法创建中间件，然后使用redux的 applyMiddleware 方法启用中间件，之后使用compose辅助方法传给 createStore 创建store，最后调用 run 方法启动根saga： 9.2.2 saga分流 在项目中通常会有很多并列模块，每个模块的saga流也应该是并列的，需要以多分支形式并列，redux-saga提供的 fork 方法就是以新开分支的形式启动当前saga流： 如上，首先收集所有模块根saga，然后遍历数组，启动每一个saga流根saga。 9.2.3 saga实例 以AppSaga为例，我们期望在应用启动时就发起一些异步请求，如获取文章列表数据将其填充至redux store，而不等待使用数据的组件渲染完才开始请求数据，提高响应速度： takeLatest：在AppSaga 内使用 takeLatest 方法监听 REQUEST_POST_LIST action，若短时间内连续发起多次action 则会取消前面未响应的action，只发起最后一次action； getPostListSaga子Saga：当接收到该action时，调用getPostListSaga并将payload传递给它，getPostListSaga 是AppSaga的子级Saga，在里面处理具体异步任务； getPostList &#58; getPostListSaga 会调用getPostList 方法，发起异步请求, 拿到响应数据后，调用 receivePostListActionCreator，创建并分发action，然后由reducer处理相应逻辑； getPostList 方法内容如下： put 是redux-saga提供的可分发action方法，take，call等都是 redux-saga 提供的API。 之后便可以在项目路由根组件注入ActionCreator，创建action，然后saga就会接收进行处理了。 9.3 saga与Reactotron 前面已经配置好可以使用Reactotron捕获应用所有redux和action，而redux-saga是一类redux中间件，所以捕获sagas需要额外配置，创建store时，在saga中间件内添加sagaMonitor服务，监听saga&#58; 十. 总结本文较详细的总结了个人从0到1搭建一个项目架构的过程，对React， Redux应用和项目工程实践都有了更深的理解及思考，在大前端成长之路继续砥砺前行。 注：文中列出的所有技术栈，博主计划一步一步推进，目前源码中使用的技术有React，React Router，Redux，react-redux，react-router-redux，Redux-saga，axios。后期计划推进Immutable，Reactotron，Redux Persist。 完整项目代码见github 参考1、 React 2、 Redux 3、 React Router v4 4、 redux-saga 5、 Redux Persist 转载来源：React应用架构设计]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>编程语言</tag>
        <tag>JavaScript</tag>
        <tag>Git</tag>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Twitter也在用的分布式日志系统 值得一用]]></title>
    <url>%2F2018%2F51d03556%2F</url>
    <content type="text"><![CDATA[日志，可以说是程序员最熟悉的一种数据结构了。网络设备、系统及服务程序等，在运作时都会产生一个叫log的事件记录;每一行日志都记载着日期、时间、使用者及动作等相关操作的描述。它存在于大家每天的工作中，是一组只追加，严格有序的记录序列。日志是一种很有效的数据结构，可用来解决很多分布式系统的问题。 在5月11日-13日，北京国际会议中心隆重举行的第八届中国数据库技术大会(DTCC 2017)——开源技术分会场上，Twitter消息组技术主管郭斯杰向大家分享了“Apache DistributedLog(分布式日志系统)的强一致性简化”。 ▲Twitter消息组技术主管郭斯杰 郭斯杰毕业于中科院计算所，加入 Twitter 之前，就职于 Yahoo。专注于分布式消息中间件和分布式存储系统方向。同时，他也是Apache DistributedLog的联合创始人，Apache BookKeeper的PMC Chair。 郭斯杰先生在演讲中指出了目前分布式系统中存在的一些挑战：磁盘/服务器的年故障率高达10%、不可用、不一致以及Split-Brains(“脑裂”现象)。 脑裂现象指：本来一个大脑的两半球互相配合，变成了分裂成两个独立的大脑，都认为对方已死。在集群环境中，有这么几种可能造成”Split-Brain”现象：1、在集群环境中的节点间的心跳线同时断掉后，集群系统所处于的一种特殊状态。例如节点1和2组成一个集群，突然1和2间的心跳同时都断了，如果此前节点1正在运行应用，心跳都断掉后2开始去接管应用，强行加载数据，此时就是split-brain。2、集群中节点因为处理器忙或者其他原因暂时停止响应时，其他节点可能误认为该节点“已死”。后果：节点间争夺共享磁盘(即资源)的访问权，都对共享文件系统产生读写操作，从而导致共享磁盘文件系统损坏。 在谈到这些问题的解决办法时，郭斯杰首先表示，目前有一些算法的使用已获得了大家的共识，如Paxos、Zab、Raft……等等。但在此之后，仍有许多困扰。关于命令问题，哪种改变应该首先考虑?至于确定性，命令不会改变，甚至不会多次读取。还有一个问题是，如何保持复制日志的一致性? 为真正解决这些问题，郭斯杰向大家分享了Apache DistributedLog。该系统具有如下特性： 高性能。Apache DistributedLog可以在具有大量并发日志的持久写入中提供毫秒延迟，并且可以从数千个客户端处理每秒大量的读和写操作。- 持久性和一致性。消息被持久化到磁盘上，并复制以存储多个副本以防止数据丢失。在严格的排序下，它们保证了写入者和读取者之间的一致性。- 高效的扇入和扇出。Apache DistributedLog提供了一个高效的服务层,优化运行的多租户数据中心环境便或纱等。服务层能够支持大规模的读(扇入)和写(扇出)。- 不同的工作负载。Apache DistributedLog支持各种工作负载，从那些对延迟敏感的联机事务处理(OLTP)应用程序(如分布式数据库和内存复制状态机),实时摄取和计算，到分析处理。- 多租户。为了支持多租户的大量日志，Apache DistributedLog专为I/O在实际工作负载中隔离而设计。- 分层体系架构。Apache分布式日志系统有一个现代的分层架构设计，它将无状态的服务层与有状态的存储层分离。支持大规模写入(扇入)和读取(扇出),允许扩展存储独立的CPU和内存。持久性和一致性。消息被持久化到磁盘上，并复制以存储多个副本以防止数据丢失。在严格的排序下，它们保证了写入者和读取者之间的一致性。 不同的工作负载。Apache DistributedLog支持各种工作负载，从那些对延迟敏感的联机事务处理(OLTP)应用程序(如分布式数据库和内存复制状态机),实时摄取和计算，到分析处理。 分层体系架构。Apache分布式日志系统有一个现代的分层架构设计，它将无状态的服务层与有状态的存储层分离。支持大规模写入(扇入)和读取(扇出),允许扩展存储独立的CPU和内存。 ▲Apache DistributedLog软件栈 ▲日志流解析 在接受笔者采访，谈及Apache DistributedLog的未来规划时，郭斯杰先生表示也将顺应“时代趋势”走开源的路线。去年五月份，他们就已经将Apache DistributedLog开源，并且希望以开源的方式壮大社区，同时也在推动与如雅虎、百度等公司的合作，以期共同推动技术的进步，帮助他人更好地适应自己的应用场景。 最后，郭斯杰先生以一个互联网行业技术人员的身份，向广大的“同僚”们提出了自己关于职业发展方向的一些建议。郭斯杰认为，计算机领域是一个非常细分的领域，作为此领域内的人士，最重要的应该是抓住自己的兴趣点。如果对底层技术比较感兴趣，可以深入到其中，通过参与社区的方式去学习了解相关的底层技术。而对于上层技术比较感兴趣的人，则可通过参与开源技术锻炼自己的技术能力，提升自身水平。 转载来源：Twitter也在用的分布式日志系统 值得一用]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>Twitter</tag>
        <tag>Apache</tag>
        <tag>数据结构</tag>
        <tag>雅虎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[李彦宏给百度的AI战略开了一剂猛药 拉来陆奇能带来什么？]]></title>
    <url>%2F2018%2F521f3b6d%2F</url>
    <content type="text"><![CDATA[李彦宏给百度的AI战略开了一剂猛药 拉来陆奇能带来什么？ 转载来源：李彦宏给百度的AI战略开了一剂猛药 拉来陆奇能带来什么？]]></content>
      <tags>
        <tag>腾讯科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫框架scrapy抓取旅行家网所有游记！从此出游不发愁！ - CSDN博客]]></title>
    <url>%2F2018%2F85a49d22%2F</url>
    <content type="text"><![CDATA[Scrapy是一个用 Python 写的 Crawler Framework ，简单轻巧，并且非常方便。Scrapy 使用 Twisted 这个异步网络库来处理网络通讯，架构清晰，并且包含了各种中间件接口，可以灵活的完成各种需求。 以上是网上摘录的一段介绍scrapy框架的文字，大过年的，懒癌高发期… 安装scrapy，pip可以解决你的问题： pip install scrapy。 这里插一句，如果你运行代码后看到这个错误： 1ImportError&amp;#58; No module named win32api 深坑出现，你需要安装pywin32，如果已经安装了pywin32，还出现错误，你仍需手动将你python安装目录下\Lib\site-packages\pywin32_system32下：pythoncom27.dll, pywintypes27.dll两个文件复制到c&#58;\windows\system32下！当然如果不是windows系统的话，请无视！ 话不多说，开始我们的爬虫吧！ 首先来分析网页结构： 1、url&#58;https&#58;//you.autohome.com.cn 打开旅行家的主页，这里我用的是火狐浏览器，看下图 点击精彩游记，然后跳出游记页面， 然后在点击全部游记，我们的目标就出现了，拉到最下面，一共3993页，1页20篇 很简单的一个网站 2、我们开始分析每页的数据，直接打开F12抓包，然后刷新网页或者点击其他页，看看服务器返回的请求都有哪些！ 找到一个get请求，里面是json格式的内容，里面有游记的作者、标题、缩略图等等内容，ok，我们可以开始写代码了！ Ps&#58;这里我们只做个简单的页面目录的爬虫，就不一 一抓取文章内容了（如果有需要的小伙伴可以自行添加相关内容）。 3、打开cmd新建一个scrapy框架，命令为：scrapy startproject autohome ,然后系统自动帮我们建立好相关的目录和py文件，我们仍需手动建立一个spider.py（文件名可自取）来放入我们的爬虫 先打开item.py，这里存放的是我们的目标，告诉爬虫我们要爬取的内容是什么！代码如下： 然后打开setting.py（如无必要，不要修改这里的内容），将ROBOTSTXT_OBEY的值改为False（不改的话，有些内容爬不到，这里是选择是否遵循robots协议）,然后将你的UA写入下面的头部信息中！ 其他都不用管了。最后打开spider文件夹，在这里我们要开始写我们的爬虫了！ 4、打开新建的py文件，先导入用到的模块 （导入模块后有错误提示可以不用理会），写入如下代码： 第6行的name是唯一的，可自行命名 第7行为定义爬虫的范围，也就是允许执行的url范围是：autohome.com.cn，注意这里是列表形式 第9.10.11行为抓取的内容所在url，通过yield Request返回，上图未截全部分为： 1yield Request(&apos;https&amp;#58;//you.autohome.com.cn/summary/getsearchresultlist?ps=20&amp;pg=&amp;#123&amp;#125&amp;type=3&amp;tagCode=&amp;tagName=&amp;sortType=3&apos;.format(pg),self.parse) 因为只有3993页，直接for循环取到所有页码，定义了start_requests函数后可省略start_urls列表也就是起始列表 第14行开始定义爬取方法 第15行，将json格式的内容赋值给一个变量 第16行，初始化导入的Items文件中所定义的类 第17-24行，循环json格式的内容，并将相应的值赋值给item，这里item是一个字典格式，然后返回给items文件 到这里就写完了这个爬虫，为方便使用，我们直接将结果写入json格式 打开cmd，命令：scrapy crawl autohome -o autohome.json -t json 因为我们爬取的内容很少，所以速度还是很快的 大概十来分钟吧，数据就抓取完成！来看看结果，因为是json格式，截取一小段找个在线解析的网页就可以看了 验证一下： So easy! 喜欢就关注下呗(；°○° )！ 爬虫07 爬取阿里旅行特价机票- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/B/3/C/3_yemoweiliang.jpg&quot; alt=&quot;yemoweiliang&quot; title=&quot;yemoweiliang&quot;&gt; - yemoweiliang - 2016-09-01 19&amp;#58;26&amp;#58;07 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;2723 Python爬虫源码—爬取猫途鹰官方旅游网站信息- 2018年04月10日 00&amp;#58;00 用phpspider框架做爬虫分析旅游数据- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/F/6/9/3_u010852160.jpg&quot; alt=&quot;u010852160&quot; title=&quot;u010852160&quot;&gt; - u010852160 - 2016-10-18 18&amp;#58;25&amp;#58;50 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;11551 Python网络爬虫专业级框架_scrapy- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/7/2/A/3_lu_yongchao.jpg&quot; alt=&quot;lu_yongchao&quot; title=&quot;lu_yongchao&quot;&gt; - lu_yongchao - 2017-03-25 22&amp;#58;01&amp;#58;56 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;1675 scrapy 安装包- 2017年07月30日 16&amp;#58;47 - 17.27MB - 下载 Python 爬虫-爬取阿里旅行特价机票信息（1）- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/7/A/9/3_vvbbbbb.jpg&quot; alt=&quot;VVBBBBB&quot; title=&quot;VVBBBBB&quot;&gt; - VVBBBBB - 2016-07-29 11&amp;#58;01&amp;#58;01 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;5927 python爬虫（上）–请求——关于旅游网站的酒店评论爬取（传参方法）- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/D/B/D/3_qq_29245097.jpg&quot; alt=&quot;qq_29245097&quot; title=&quot;qq_29245097&quot;&gt; - qq_29245097 - 2016-07-01 22&amp;#58;17&amp;#58;24 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;11619 Python爬虫框架Scrapy：爬取校花网- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/3/C/9/3_python233.jpg&quot; alt=&quot;python233&quot; title=&quot;python233&quot;&gt; - python233 - 2017-04-20 19&amp;#58;23&amp;#58;27 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;1145 scrapy爬虫框架教程（一）– Scrapy入门- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/2/B/C/3_woodenrobot.jpg&quot; alt=&quot;woodenrobot&quot; title=&quot;woodenrobot&quot;&gt; - woodenrobot - 2017-01-01 18&amp;#58;52&amp;#58;00 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;684 Python爬虫框架scrapy抓取旅行家网所有游记！从此出游不发愁！ - &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/0/0/A/3_programmer_yf.jpg&quot; alt=&quot;programmer_yf&quot; title=&quot;programmer_yf&quot;&gt; - programmer_yf - 2018-02-22 15&amp;#58;43&amp;#58;54 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;33 个人资料 &lt;dl class=&quot;inf_bar clearfix&quot;&gt; &lt;dt class=&quot;csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_381&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/programmer_yf&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/0/0/A/3_programmer_yf.jpg&quot; class=&quot;avatar_pic&quot;&gt; &lt;/a&gt; &lt;/dt&gt;&lt;dd&gt; &lt;h3 class=&quot;csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_380&quot;&gt;&amp;#91;programmer_yf&amp;#93;(https&amp;#58;//blog.csdn.net/programmer_yf)&lt;/h3&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;1&quot;&gt; &lt;dt&gt;原创&lt;/dt&gt; &lt;dd&gt;1&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;0&quot;&gt; &lt;dt&gt;粉丝&lt;/dt&gt; &lt;dd id=&apos;fan&apos;&gt;0&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;0&quot;&gt; &lt;dt&gt;喜欢&lt;/dt&gt; &lt;dd&gt;0&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;0&quot;&gt; &lt;dt&gt;评论&lt;/dt&gt; &lt;dd&gt;0&lt;/dd&gt; &lt;/dl&gt; 等级： &lt;a href=&quot;https&amp;#58;//blog.csdn.net/home/help.html#level&quot; title=&quot;1级,点击查看等级说明&quot; target=&quot;_blank&quot;&gt; &lt;img class=&quot;grade-img&quot; src=&quot;https&amp;#58;//csdnimg.cn/jifen/images/xunzhang/jianzhang/blog1.png&quot; alt=&quot;1级,点击查看等级说明&quot;&gt; &lt;/a&gt; 访问量： 34 积分： 12 排名： 230万+ // 判断并设置用户名位置，没有博客专家与关注按钮时，用户名居中 $medals_children = $(‘.medals’).children().length; $span_add_follow = $(‘#span_add_follow’).length; if($medals_children === 0 &amp;&amp; $span_add_follow === 0)&amp;#123 $(‘.inf_bar dd’).css(‘vertical-align’,’10px’) &amp;#125 文章搜索 文章分类 python (1) 文章存档 &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2018年2月&amp;#93;(https&amp;#58;//blog.csdn.net/programmer_yf/article/month/2018/02) (1) &lt;/li&gt; 阅读排行 &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/programmer_yf/article/details/79347186&quot; title=&quot;Python爬虫框架scrapy抓取旅行家网所有游记！从此出游不发愁！&quot;&gt; Python爬虫框架scrapy抓取旅行家网所有游记！从此出游不发愁！ &lt;/a&gt; (32) &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn btn-like csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_373&quot; target=&quot;_self&quot; title=&quot;点赞&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-dianzan&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &amp;#91;0&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn csdn-tracking-statistics tracking-click btn-collect&quot; data-mod=&quot;popu_374&quot; target=&quot;_self&quot; title=&quot;收藏&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-shoucang&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn btn-pinglun csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_544&quot; title=&quot;评论&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-pinglun&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_tsina outside left-fixed-btn&quot; data-cmd=&quot;tsina&quot; title=&quot;分享到新浪微博&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-xinlang&quot;&gt;&lt;/i&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_weixin outside left-fixed-btn&quot; data-cmd=&quot;weixin&quot; title=&quot;分享到微信&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-weixin&quot;&gt;&lt;/i&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_qzone outside left-fixed-btn&quot; data-cmd=&quot;qzone&quot; title=&quot;分享到QQ空间&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-QQ&quot;&gt;&lt;/i&gt; &lt;/li&gt; 转载来源：Python爬虫框架scrapy抓取旅行家网所有游记！从此出游不发愁！ - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法与产品：抖音、快手的“气质”成因]]></title>
    <url>%2F2018%2F55d84e14%2F</url>
    <content type="text"><![CDATA[同一类型的两款产品，从功能上看，似乎没有明显差别，但为什么给人的“感觉”却是完全不同呢？ 算法快抖的视频内容分为推荐（发现）、附近（同城）和关注三个模块，这里主要说明推荐模块的算法机制。 视频与用户画像的匹配程度1. 热度（赞、评论、转发等）1. 发布时间根据用户数据和内容标签计算两者的匹配程度，是每个内容产品的算法核心，已经被总结很多次了，其理论大体一致，在本社区搜索“算法”关键词就能找到，这里就不再赘述了，下面主要介绍热度和发布时间两点。 打开你的抖音，你会看到系统已经为你推荐好了一系列内容，再仔细观察一下，你会发现这些视频的获赞数量基本都在50万以上，中位数大概在100万（刷多了会减少）。 而打开快手呢？ 你会发现视频获赞数量基本维持在1万到10万这个区间，有的甚至会出现几千几百，但很难找到过10万的视频。 出现这种差距，难道是因为快手用户少吗？ 显然不是，快手的用户已经是其他短视频产品的用户之和了。之所以出现这种状况，其实是因为快手算法特有的“热度权重“。 视频发布初期，随着其热度提高，曝光机会也会跟着提高，此时，“热度权重”起到“择优去劣”的作用。而在视频热度达到一定阈值后，它的曝光机会将不断降低，此时，“热度权重”起到“择新去旧”的作用（其实是为了给用户平等的展示机会，后面会讲到）。 与此同时，快抖对于“发布时间”的看法也是不一样的。 在抖音，你会发现很多视频其实几个月前就发布了（验证这一点，只需要在评论区不断下翻即可，可根据早期评论的发布时间进行推断）。因为用户一般不会在乎短视频是不是最新的，只要足够精彩即可。 而在快手，大部分视频都是近期发布的，再远的视频也是一个月内（在视频界面右下方有时间标注）。 那么，前面提到的“热度权重”和“发布时间权重”对于用户来讲又会有怎样的影响呢？ 首先，短视频的用户大体分两种：一种是“看视频”的看官，一种是“拍视频”的制作方。这里，我们把看官的注意力比作一个蛋糕，而制作方比作分蛋糕的人。 首先，我们来看分蛋糕的人。在抖音，分到大量蛋糕的用户还会继续加快分蛋糕的速度（高热度会不断提高曝光机会），头部用户集中了大量的用户注意力资源，这种中心化会让普通制作者、草根制作者难以被关注（这与微博颇为类似）。 而在快手，头部用户分到的蛋糕被设了上限（高热度和旧视频曝光机会会大大降低），因此会有更多的人分到蛋糕，这也体现了快手的理念——希望所有用户都能展示自我，任何一位普通用户都有被关注的权利。 对于看官来说，抖音给了他们大量的优质资源，这些都是经过大量用户检验，而放到推荐模块的内容池的视频。而快手只是经过初步检验就根据用户喜好开始推荐了，所以会有很多小众和“乡土”的内容。 抖音和快手，一个是精致的台上表演，一个是平凡的街边才艺。 相对来说，抖音是看官导向的，而快手则更偏向于制作方，尤其是草根用户。这也就不难理解为什么快手会沦落到被整改的尴尬境地，因为“三俗”生产者总能找到自己的市场。 产品除了算法，我认为以下两点也是快抖气质差异的诱因。 录制功能1. 交互设计 1. 先音乐后录制的妙处与其他短视频不同，抖音的录制功能别具一格，先选音乐再根据音乐录视频，而不只是充当背景音乐。 每当视频的动感与音频的调子相重合时，会大大刺激观众的感官，带来不一样的体验。同时，也产生了更多玩法，比如：对口型、拍同款等，增加了趣味性、可看性。因此，抖音会给人一种“酷炫”的感觉（但是拍摄门槛也抬高了）。 2. 不断上滑的“沉浸式体验”一打开抖音，便进入了播放界面，接着依靠上下滑动来更换视频，嗯 … 这种状态可以维持一个多小时 … 这种懒人式交互大大提升了用户粘性，不过也削弱了用户改变“状态”的意愿，即附近模块、关注模块的使用几率将会降低。由此，用户的注意力又被“粘”在了头部用户的优质内容上，中心化进一步加剧。 与之相反的，快手的推荐（发现）对用户并没有那么大的粘性，三个模块的交互方式相当，都是瀑布流布局，并且快手的启动页是用户上一次退出的页面。 比如：上一次在同城离开，下一次启动页会是同城模块，关注模块也是如此，这样，用户选择的自由度“无形”地增加了。同时，快手也因其同城和关注的高使用频率，而在社交属性上更胜一筹，而不仅仅是一个娱乐软件。 其实快抖的算法与交互设计是相辅相成的，抖音的算法决定了它的视频更加优质，因此不需要用户做太多的选择，适合逐个播放，也减少了用户操作负担和选择负担。而快手视频的优质密度没有那么大，需要用户选择播放，在操作上会繁琐一些。 回忆一下我们使用抖音的时候，是不是一般会看完整个视频再播放下一个，很少掠过。而使用快手的时候，我们通常要掠过几个，才能选出自己想看的视频。 因此，“滚动播放”更适合抖音，而瀑布流适用于快手（其实快手也可以尝试美拍的“瀑布流+滚动播放相关视频”的交互设计，或者抖音附近模块的“瀑布流+滚动播放下一个视频”的交互设计）。 结尾除了算法和产品设计，还有着其他因素导致快抖的风格差异，比如：运营和品牌公关。 不过从效果上看，算法和产品设计更像是产品的“基因”，从最开始就影响着“两个宝宝”的未来走向（抖音的精致范和快手的平民化）。 如何设计出我们想要的产品，让“宝宝”长成我们想要的样子，抖音和快手的实例值得我们借鉴。 本文由 @ 信管专业学生 原创发布于人人都是产品经理。未经许可，禁止转载 题图来自网络 转载来源：算法与产品：抖音、快手的“气质”成因]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>软件</tag>
        <tag>蛋糕</tag>
        <tag>甜品</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代币创建教程 » 论坛 » EthFans | 以太坊爱好者]]></title>
    <url>%2F2018%2F5803123d%2F</url>
    <content type="text"><![CDATA[代币创建教程 » 论坛 » EthFans | 以太坊爱好者 转载来源：代币创建教程 » 论坛 » EthFans | 以太坊爱好者]]></content>
  </entry>
  <entry>
    <title><![CDATA[在steem上赚钱的模式有哪些？ - 简书]]></title>
    <url>%2F2018%2F32842c40%2F</url>
    <content type="text"><![CDATA[在steem上赚钱的模式有哪些？ - 简书 转载来源：在steem上赚钱的模式有哪些？ - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[【应用】基于IPFS和GeoHash构建具有地理位置价值服务的DDApp（理论篇） – ipfs]]></title>
    <url>%2F2018%2F1d38106f%2F</url>
    <content type="text"><![CDATA[【应用】基于IPFS和GeoHash构建具有地理位置价值服务的DDApp（理论篇） – ipfs 转载来源：【应用】基于IPFS和GeoHash构建具有地理位置价值服务的DDApp（理论篇） – ipfs]]></content>
  </entry>
  <entry>
    <title><![CDATA[专家：建议中国搞x86与Intel竞争的，都是在忽悠国家的钱]]></title>
    <url>%2F2018%2F5b4f123c%2F</url>
    <content type="text"><![CDATA[新智元专栏 作者：筋斗云 【新智元导读】为美国制裁中兴事件，对国内集成电路产业影响多大？芯片的基本生态是谁先做出一个超出同行的东西，大家都会自动地转入这个生态。即便ARM这样成功的公司背后，是无数产业链公司艰辛的活着。本文作者有多年芯片从业经验，他认为：所有建议中国搞x86的，与Intel竞争的，在行业内看来，都是忽悠国家/VC 钱的。 中兴事件对集成电路有多大的影响？ 作为行业内的人来说，基本没有影响。 这个行业产业链和生态最重要，因为硅片的NRE成本高，单价成本低。所以这个生态基本是谁先做出一个超出同行的东西，大家都会自动地转入这个生态。 这个类似于从A城市修了一条道到B城市。修道路成本极高，过路费的价格不高，而且过路费还在不断下降中。 现在你自己要重新修一条路，你的道路比别人窄，收费更贵，人家又修了B到C。你自己跑自己的路还比对手的路又慢又贵，你怎么进行竞争？ Intel和思科在当年占了硅谷一半以上的利润，无数的VC想再做个Intel出来，没有一个成功的。ARM现在成功背后，是无数类似的竞争公司的艰辛活着。欧洲、日本搞了多年，没搞出一个新的Intel。美国搞了多年，没搞出一个新的ARM。（最近RISC-V又在搞） 所有建议中国搞x86，与Intel竞争的，在行业内看来，都是忽悠国家/VC 钱的。 那么正确的道路是什么呢？弯道超车，大家一起竞争造新路。 路是无限的，而钱是有限的。如果我们把钱拿去重新造CPU，让美帝在新路上独家制造，收未来的过路费，我觉得这才是美帝最得意的阴谋了。（估计川普没这么聪明） 所以，我们不应该花大钱去造x86 CPU这样行为，不要去重新造一条同样的路。而是要往前一起造新路，因为这个时候你能拉到客户收过路费。 最近的新路有： 1、5G芯片。国家应该大力支持这方面的资金投入，特别是对企业的研究经费，如果能够对失败/成功项目的科研经费进行100%补贴。企业会大大增加新品研发的。 2、AI芯片。这个Google很奇特地没有加入战场，我们还有一定时间的余地。Google修了一条高速，开发了TPU，但是它只是自己用，不销售，也不收“过路费”。（其实这是AI公司头顶的一把剑，等到做出来了，谷歌可能又开源或者开卖芯片。） 3、数字货币。目前数字货币芯片已经占到台积电的10%，我预估未来还会上升。这是一个新品，而中国在此领先的。可惜去年9月的政策等在削弱这个领先。三星等在大幅度追赶。 4、低功耗GPU芯片。这个GPU不是为了显卡，而是为了类似VR/AR的新应用。 5、ARM服务器、RISC-V等，建议国家让企业多看着先预研，如果起来了，中国就自然地用新品替换了x86服务器等了。 数字货币最好的办法是监管和准入证，监管类似期货，普通投资者自然排除在外。目前这种扑灭的模式，如果遇到数字货币类似PC/通讯/手机这样大产业，我们会又一次上演拱手让人的悲剧。（我们数字货币软件已经如此了，数字货币金融创新基本全在美日了。就算矿机这个领域，三星也进入，三星有fab，极大优势。） 到底什么是新路，旧路还有多少油水，值不值得投入。这个每年看看fab的流片大致就知道了，其实并不是那么难理解的。 超越，说起来很简单，但是要考虑一个行业的特点，就不是那么容易了。很好的事是，集成电路是一个飞速发展的行业，旧路的大小基本定了，最发展的大多是新路。华为等在手机芯片上的切入，就是这种新路上的突破。比特大陆的崛起，也是因为它一直走的是条新路。趁着美日韩等还没注意时，就先修好了一条高速路。 中国在新路上多投入，别制造障碍，随着新路的繁荣，旧路过路费慢慢占比就少了。 那种别人有我一定要有的思维模式，会导致我们在旧路上投入过高，反而是歧路。 那些认为投入就能产出的，我建议先不计一切代价，先搞个国足世界杯冠军，因为显然这个要更容易些。 转载来源：专家：建议中国搞x86与Intel竞争的，都是在忽悠国家的钱]]></content>
  </entry>
  <entry>
    <title><![CDATA[为什么全球顶尖成功人士都会遵循“5小时法则”？]]></title>
    <url>%2F2018%2F5d969a54%2F</url>
    <content type="text"><![CDATA[全球最顶尖的5家公司的创始人 比尔·盖茨、史蒂夫·乔布斯、沃伦·巴菲特、杰夫·贝佐斯、拉里·佩奇，他们都是博学的通才，他们都有两种不同寻常的特质。在研究了白手起家的亿万富翁多年之后，我发现有两种特质在他们获得如今的财富、成功、影响力和名声方面发挥了关键作用。事实上，我自己也非常相信这两种特质，所以我在自己的生活中创办公司、成为一个更好的作家、做一个更好的丈夫、实现财务安全的过程中都会利用这两种特质。这些成功人士拥有的两种共同特质分别是： （1）他们都是如饥似渴的学习者。 （2）他们都是通才。 下面让分别阐述一下这两个特质，并分享一些简单的技巧，从而让你自己在日常生活中也能利用它们。 首先，这两种特质的定义。我把一个如饥似渴的学习者定义为一个遵循“5小时原则”的人，即每周至少花5个小时来学习。我将通才定义为一个能在至少三个不同领域里都能胜任的人，并将这几个领域的技能都整合到一个技能组合中，使他们成为所在领域内前1%的顶尖人才。如果你不断学习和模拟这两个特质，并且认真对待它们，我相信它们会对你的生活产生巨大的影响，并会加速你获得成功的脚步。当你变成一个如饥似渴的学习者时，那么你过去所学到的所有知识的价值就会呈现复合效应。当你成为一个通才时，你就能开发出综合技能的能力，并开发出一套独特的技能组合，这能够帮助你获得竞争优势。 根据比尔盖茨自己的估计，他每周都会读完一本书，这个习惯已经坚持了52年，其中很多书籍都是与软件或商业无关的书籍。此外，在他的整个职业生涯中，他每年还会有一个为期两周的阅读假期，这两周时间专门用来阅读。在1994年的接受《花花公子》的采访中，我们发现他已经把自己当成了一个博学的通才了： 花花公子：你不喜欢自己被称为是一名商人吗？- 盖茨：不喜欢。在我的所有思考时间中，我将10%的思考时间用于商业思考。商业并没有那么复杂，我不想将商人的身份放在我的名片上。- 花花公子：那么你会将什么写在你的名片上呢？- 盖茨：科学家。当我读到一些伟大的科学家的故事，比如克里克和沃森是如何发现DNA的时候，我就会非常兴奋。商业成功的故事无法让我获得同样的乐趣和快感。盖茨：不喜欢。在我的所有思考时间中，我将10%的思考时间用于商业思考。商业并没有那么复杂，我不想将商人的身份放在我的名片上。 盖茨：科学家。当我读到一些伟大的科学家的故事，比如克里克和沃森是如何发现DNA的时候，我就会非常兴奋。商业成功的故事无法让我获得同样的乐趣和快感。 盖茨将自己视为一位科学家，这是非常有意思的，因为他从大学辍学了，并在辍学后就一直扎根于软件行业。 有趣的是，埃隆·马斯克也不认为自己是个商人。在最近一次接受CBS的采访中，马斯克说他认为自己更像是一个设计师、工程师、技术专家，甚至是巫师。 这样的例子不胜枚举。众所周知，拉里·佩奇会花时间与谷歌的每一个人进行深度交流，从谷歌的门卫到核聚变科学家，并总是希望自己能从他们身上学到些什么。 沃伦·巴菲特是这样描述自己获得成功的关键的：“每天阅读500页书。知识的运作方式是：知识会慢慢累积呈复合效应，就像复利一样。” 杰夫·贝佐斯是通过实验进行大规模学习的方式来打造他的整个公司的，并且他在一生中都是一个如饥似渴的阅读者。 最后，史蒂夫·乔布斯将各种学科结合在一起，并将之视为苹果的竞争优势，他曾经这样说过：“单靠科技是远远不够的，必须要让科技与人文科学以及人性相结合，其成果必须能够让用户产生共鸣。” 当然，上面五家顶尖公司的创始人并不是唯一拥有这两种特质的成功人士。正如我之前写过的，如果我们把这份名单扩大到其他白手起家的亿万富翁，我们很快就会看到奥普拉·温弗瑞、雷·达利奥、大卫·鲁本斯坦、菲尔·耐特、霍华德·马克斯、马克·扎克伯格、埃隆·马斯克、查尔斯·科赫和其他很多拥有类似特质和习惯的成功人士。 为什么世界上最忙碌的人会把最宝贵的时间投入到学习与和他们所在领域看起来无关的知识上，比如核聚变、字体设计、科学家传记和医生回忆录? 他们每个人都掌管着一个由全世界成千上万最聪明的人组成的公司。他们把自己生活和公司业务中的几乎每一项任务都委派给了最优秀、最聪明的人去负责。那么他们为什么还要坚持学习大量知识呢？ 在写了几篇试图回答这些问题的文章之后，这就是我最终得出的结论：“在最高层次上，学习并不是一件你为工作做准备的事情，学习本身就是最重要的工作。它是你要打造的一个核心能力。这是一件你永远不能委派给别人去做的东西。这是关系到企业进步和长远成功的终极驱动力之一。“ 当我意识到这一点的时候，我在想：在如今这样一个日益复杂、快速变化、先进的知识经济时代，为什么大家没有在‘我们在一生中都应该成为贪婪的学习者和博学的通才’上达成共识并认为这是我们理所应当做的事情呢？为什么大部分普通人都将可以学习视为一种可做可不做的事情呢？ 我认为，这主要和我们在学校、大学和社会上被反复灌输的三个强有力信息有关，这些信息在过去可能是事实，但现在已经不再是了，它们现在已经变成三条谎言了。下面我们就来看看如何一一打破这三条谎言： （1）谎言1：学科是分类知识的最好方法。 （2）谎言2：大部分学习都发生在学校/大学。 （3）谎言3：你必须选择一个领域并且专攻这个领域。 这些观念是如此有害，它们摧毁了我们对学习和知识的直觉，最终阻碍我们创造我们想要的成功。如果我们能意识到它们，我们就能像世界上最成功的人所做的那样去纠正它们。 谎言1：学科是分类知识的最好方法。 我们的教育体系建立在这样一种模型上，即将知识分为不同学科——数学、阅读、历史和科学等。从幼儿园开始，我们接收到的信息就是，这些科目最好是能各自单独学习。 我们甚至将这些学科细分为更小的学习领域，例如，将经济学进一步细分为微观经济学和宏观经济学。这种将学科领域进行分解并分开教学的范例叫做简化论。尽管它仍然是我们社会的标准，但它实际上已经开始在一些更进步的国家发生变化了。 简化论能带来很多益处。在关系紧密领域内，想法能够得到迅速而高效地传播，因为每个人都属于同一种文化，都说着同样的语言。研究一个系统的各个部分要比研究一个复杂的整体系统要更为容易。这种范式在很多重大的发现中发挥了非常重要作用。 但简化论的一个关键缺点在于，不同领域之间的连接变得非常模糊，所带来的结果就是所谓的“负学习迁移”，即学习一件东西会使学习其他东西变得更加困难，因为我们所学到的概念与特定的研究领域是如此紧密地联系在一起。如果你在学习第二语言的时候陷入了困境，因为你所学的第二语言的语法、语序、时态或复数的规则与你的母语的规则不匹配，你就会经历负学习迁移。 简化论的另一个缺点是，在一个专业领域之外的人很难理解这个领域内发生的事情。不妨想象一下一个神经外科医生试图向一个平面设计师解释大脑手术的进展，会发生什么。每个领域都有各自的语言和文化，所以在一个领域里独特的见解并不适用于另一个领域，尽管不同领域内的见解经常可以而且应该是彼此适用的。这就导致了回音室的出现。 生物学家James Zull在他的书《The Art of the Changing Brain》里解释了为什么学习迁移如此复杂。“通常情况下，我们没有将一个主题和另一个主题连接起来的神经网络。它们是分开建立的，特别是如果我们在将知识分解成数学、语言、科学和社会科学等不同部分的标准课程中学习。” 因为没有人教我们去看所有这些知识的共同根源，所以我们看不到它们之间的内在联系。 埃隆·马斯克强烈地感到我们的教育体系无法教给孩子们学习所有这些学科知识的共同根源，他创建了自己的学校，并让自己的所有孩子都进入这个学校。 埃隆·马斯克在接受北京电视台采访时称，由于不喜欢他的孩子的学校，因此他便自己建了一所学校。这所学校被命名为Ad Astra，意思是“奔向星辰”。这所学校规模极小，相对比较隐秘。它没有自己的网站，也没有创建社交网帐号。曾经撰写过一篇关于洛杉矶私立学校的文章的克里斯蒂娜·西蒙（Christina Simon）深入了解了Ad Astra学校。她说她认识了一位与马斯克的孩子上同一所学校的孩子的母亲。这位母亲对西蒙说，相对比较新的Ad Astra学校规模很小，还处于测试阶段。这所学校目前只接纳了少数孩子，他们的父母亲都是SpaceX的员工。马斯克在接受采访时说，Ad Astra学校创立了一年多，现有14名学生。Ad Astra学校未区分年级，一年级和三年级的学生之间是没有明显区别的。他说：“让所有的孩子在同一时间通过相同的年级考试，就像装配线一样。” 他说：“有人喜欢英语或语言，有人喜欢数学，有人喜欢音乐。人各有志，各有所长。因此，根据他们的态度和能力来因材施教就显得非常重要了。”马斯克为他的孩子办了退学手续，为了创办Ad Astra学校甚至还挖走了一名教师。他说：“我认为这些事情都是应该做的，但我没有看到普通学校去做这些事。”马斯克认为，普通学校在教授学生如何解决问题上犯了一个根本性的错误。马斯克说：“教授解决问题的方法或者讲解问题本身而非解决问题的工具，这一点很重要。” 他说：“假设你想教别人引擎的工作原理，传统的做法是说，’我们将讲授有关螺丝刀和扳手的所有知识。’这是一种截然不同的教学方式。” 相反，马斯克认为直接给学生们提供一台引擎然后在学生们面前拆卸它，这种教授方式会更有意义。马斯克解释说：“我们如何将它分解开来？你需要一把螺丝刀，然后一件非常重要的事情随之发生了，那就是工具的关联性变得很明显了。” 多年来，我了解到有一种更深层的方法来分类知识，一种学习基本原理的方法，它适用于所有领域，并教授让人终生受用的技能。这些基本原理被称为思维模型。 让我们来看看一个思维模型，叫做“压力和恢复”。在锻炼中，压力和恢复的现象是锻炼使我们变得更强壮的原因所在：它暂时使我们的肌肉和心血管系统超过了它们现在的承受能力，并在恢复过程中重建自己。有了这种思维模式，我们就可以在其他领域寻找到这种思维模型。例如，它解释了为什么经历了某些类型的困难能够帮助我们变得更加强大。在心理学领域，这被称为创伤后成长。在社会心理学领域，这些痛苦的经历被称为多样化的经历。在成年人的发展中，他们被称为最优冲突。通过这些例子，我们可以看到同一个底层思维模型在不同的应用领域里是如何被赋予不同的名称的。 思维模型是将学科联系在一起的无形的思想网络。 这正是很多世界顶尖学习者和通才在如今的知识经济中获得成功的秘密所在。 真相：将知识按思维模型分类与将知识按学科分类是同样重要的，因为思维模型是将不同学科连接起来的底层基础。 谎言2：大部分学习发生在学校/大学。 “自学是唯一的教育形式。”——Mark Twain 我确信，教育最根本的问题之一就是学校与学习的归并融合。事实上，学校只是学习发生的一个环境。在我们的生活中，几乎所有的学习都发生在学校之外：在家里，在操场上，在运动场上，在旅行中，在我们读的书和我们喜欢的爱好里，特别是在我们的工作中。然而，我们却被训练成只将正规教育视为真正的教育。 在军事和执法部门，把在学校里学到的东西和现实世界里发生的事情混为一谈都被认为是“训练伤痕”。在《Algorithms To Live By》这本书中，引用一些有关这些伤痕的极端例子，显示它们会带来多严重的后果：在现实枪战中，警察只开枪两次就把枪放进枪套里（就像他们在训练中所做的那样)。在一个令人惊恐的例子中，一名警察从袭击者手中夺过枪，然后本能地将枪还给他，就像他在警察学院的训练过程中一次又一次做的那样。同样的道理，我们在学校里学习到的一些技能，这些技能要么无法转移到现实世界中，要么会阻碍我们在现实世界中的表现。 例如，相信我们中的大多数人都会认同，在课堂上，那些遵守纪律和规则的人会因此得到奖励。但在现实世界中，关键的领导特质包括冒险和原创思维，这两个特质都是与我们在课堂上学的东西相违背的。简而言之，我们接受的大部分正规教育都是为了将我们培养成追随者，而不是领导者。 下面我分享一下我是如何在我自己的生活中揭露“学校等于学习”这个谎言的。 我童年的大部分时间都是在学习中度过的，所以我的GPA绩点很高，也就顺理成章进入一所很好的大学。因为从小到大，大人们都一直给我灌输这样的理念：一所好大学是通往美好生活的门票，我对这一点也深信不疑。我的求学之路也非常顺利，我被理想中的学校录取了：沃顿商学院和纽约大学斯特恩商学院。刚开始的时候，我非常努力地完成每一项学习任务，并在每一项研究课题上都付出了大量心血。但后来我读到一份研究报告，这份报告显示，大多数美国总统、国会议员、参议员甚至大学校长毕业时的GPA绩点都很低。一项对700名百万富翁的调查显示，他们的平均GPA绩点是2.9。事实上，我所在大学的校长是以2.1的GPA绩点毕业的。此外，我了解到，我的大多数创业榜样都没能完成大学学业，即使他们完成了大学学业，他们也不会将其视为他们所获得的成功的重要因素。 “这是咋回事？我被骗了一辈子。我想成为一名企业家，但分数并不重要。”我暗自纳闷。 自那一天起，我就停止了为了分数而读书的日子。我的平均GPA绩点下降到2.9，当教授置仅仅为了让我不要闲下来而给我布置作业的时候，我就会直接跳过这些作业。相反，我设计了自己的学习书籍、要参加的会议，并旁听了我感兴趣的课程。幸运的是，我做了一个很好的赌注。当我面试实习的时候，只有一次面试是让我提供GPA绩点的。尽管我的GPA绩点很低，但我还是得到了实习机会。在工作场合，我从来没有被问过我是在哪所学校就读的。 这些年来，我的思维变得更加微妙。下面是我目前对正规教育的看法： （1）最具影响力的领导者、艺术家和科学家几乎都对学习有一种内在的热爱，那种近乎痴迷地热爱，这种痴迷贯穿了他们的一生。无论他们有多忙，他们都会抽出时间来学习。1991年，比尔·盖茨在接受采访中曾自豪地这样，虽然他经常工作到深夜，但深夜回到家后还是会花点时间用来阅读。当埃隆·马斯克想要雇佣世界上最聪明的人时，他更关心的是候选人的技能组合，而不是学位。 （2）中学和高等教育一般都没有鼓励学生自主学习或培养终身学习的习惯。事实上，为了考试或者是进入一所好的大学而学习往往会培养外在的动机，而这实际上会阻碍内在的动机。正规的教育通常不擅长向学生展示不同学科之间的联系，也不擅长教学生如何在现实世界中应用他们所学到的东西去得到他们想要的结果。 （3）正规教育的最重要成果是让学生热爱学习并拥有自主学习的能力。一个自主学习的学习者能够识别他们所面临的问题并对问题进行优先级划分，识别那些他们可以学习的用来解决这些问题的知识并对这些知识进行优先级划分，坚持每周至少学习5个小时的时间，并将他们学到的东西应用到现实世界的挑战中。一旦一个人爱上了学习，他们就会终身学习。当然，几十年终身学习的积累要比四年大学积累的东西要多得多。 （4）妖魔化正规教育并不是真正的解决之道。多年来，我已经在数百所高中和大学发表过演讲，演讲对象从最精英的人群到最弱势的人群都有，我的观点已经软化了。我有两个孩子在上小学。他们的老师改变了我们孩子的生活。我在教育系统中遇到过许多了不起的老师，他们提供了变革的经验。这些教师中，很多人收入严重不足、不受尊重，却是社会中最有价值的贡献者。在整个系统中，有一些机构也很了不起。立法者制定了更严格的考试规定，导致了为了考试而教学和学习的文化的出现，这仅仅是因为他们希望学校系统更加可靠。这是一个复杂而重要的挑战。 真相：在我们的生活中，大多数的学习都是在学校之外完成的，在获得成功的过程中，自主学习能力是比分数和学位更重要的因素。 谎言3：你必须选择一个领域并且专攻这个领域。 在亚当·斯密的代表作《国富论》这本书的第一页中，他以一个别针工厂为例，说明了专业化的力量。在这个工厂里，只有10名员工，每天却能生产出令人震惊的48000个别针，这就是分工的结果，每个人只专注于制作流程中的其中一个部分。史密斯估计，如果这10个工人中的每一个人都亲自参与整个制作流程中的每一步的话，那么这个工厂每天只能制作出200个别针。换句话说，专业化将他们的效率提高了240倍。 我们几乎所有人都被灌输这样的观念，要想在生活中出人头地，就必须专攻一个领域。当你看到上面的别针工厂的例子，这就不足为奇了。在工业时代，生产力是通过定量产出来衡量的。对于那些仍在制造业工作的人来说，这种模式仍然适用。 但我们大多数人现在都生活中知识经济中，在这个经济中，生产力不是用数量来衡量的，而是用创造性的产出来衡量的。产生创造性想法的最好方法之一就是学习和综合你所在领域内的其他人还不知道的有价值的技能和概念。在知识经济中，学习跨领域的不同兴趣和技能，然后将你的见解运用到你的核心专业里，换句话说，也就是成为一个现代的博学通才，这才能让你真正脱颖而出。 在《为什么“兴趣广泛”的通才更有可能获得成功？详解通才的7大优势》这篇文章中，我详细解释了为什么在现代知识经济的大环境中每个人都应该成为一个通才，并列出了通才的7大优势，这7大优势分别是：（1）通过融合两种及以上的技能能够让你成为一流的人才；（2）大多数创造性突破是通过非典型技能组合实现的；（3）学习并精通一项新技能比以往更加容易和迅速；（4）比以往更加容易开创一个新领域、新行业或者全新的技能组合；（5）它可以为你的未来职业发展保驾护航，让你的技能不会过时；（6）它可以帮你解决更为复杂的问题；（7）它可以帮你脱颖而出，在全球经济中有效竞争。 真相：专业化是工业经济的关键。在当前的知识经济中，学习掌握了至少三个领域的知识并能将它们整合到一个技能组合中的现代型通才将会有更大的优势，这能够使他们成为自己所在领域中前1%的顶尖人才。 需要记住的三大新真相 综上所述，我们过去的学习方式已经不再适用于快速变化的知识经济了。相反，要记住这些新的真相： （1）除了按照学科来分类知识外，按照思维模型来分类知识同样重要甚至更重要。因为思维模型是将不同学科连接起来的底层基础。 （2）大部分学习都是在学校之外完成的，在获得成功的过程中，自主学习能力是比成绩和学位更重要的因素。 （3）在当前的知识经济中，学习掌握了至少三个领域的知识并能将它们整合到一个技能组合中的现代型通才将会有更大的优势，这能够使他们成为自己所在领域中前1%的顶尖人才。 这就是为什么那些喜欢阅读和学习的通才以及那些研究思维模型的人都能变得如此成功的原因所在。这也解释了为什么世界上这么多顶尖CEO、亿万富翁、科学家和成功人士都具有这些共同的特质。 现在就下定决心，不要把所有的时间都花在一个狭窄领域的细节知识上，因为这只能让自己看不到世界其他地方、其它领域发生的事情，这将阻碍你快速适应新发展的能力。 相反，要在终身学习上进行投入，每周至少花五个小时在你的领域之外进行学习和探索，学习你的同事还不知道的技能和概念。此外，一定要学习思维模型，这些底层基础知识是所有领域知识的基础，而且基本不会随时时间的推移发生变化。将自己训练成为一名对思维模型有深入了解的自学成才型通才，做到这些将是在现代知识经济中获得成功的关键。 原文链接：https://medium.com/the-mission/the-founders-of-the-worlds-five-largest-companies-all-follow-the-5-hour-rule-and-they-re-9ca82e93f3fc 编译组出品。 转载来源：为什么全球顶尖成功人士都会遵循“5小时法则”？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>巴菲特</tag>
        <tag>成功的秘密</tag>
        <tag>比尔·盖茨</tag>
        <tag>伊隆·马斯克</tag>
        <tag>乔布斯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步教你开发、部署第一个去中心化应用 - 宠物商店 - Tiny熊 - 博客园]]></title>
    <url>%2F2018%2F5e4d58ac%2F</url>
    <content type="text"><![CDATA[一步步教你开发、部署第一个去中心化应用 - 宠物商店 - Tiny熊 - 博客园 转载来源：一步步教你开发、部署第一个去中心化应用 - 宠物商店 - Tiny熊 - 博客园]]></content>
  </entry>
  <entry>
    <title><![CDATA[IPFS搭建分布式文件系统 - 访问控制 - 秦鹏飞 - 博客园]]></title>
    <url>%2F2018%2Fd1edad43%2F</url>
    <content type="text"><![CDATA[IPFS搭建分布式文件系统 - 访问控制 - 秦鹏飞 - 博客园 转载来源：IPFS搭建分布式文件系统 - 访问控制 - 秦鹏飞 - 博客园]]></content>
  </entry>
  <entry>
    <title><![CDATA[IPFS挖矿实战演习之Storj – ipfs]]></title>
    <url>%2F2018%2F23e13995%2F</url>
    <content type="text"><![CDATA[IPFS挖矿实战演习之Storj – ipfs 转载来源：IPFS挖矿实战演习之Storj – ipfs]]></content>
  </entry>
  <entry>
    <title><![CDATA[爱奇艺正式递交IPO申请：小米持股8.4%股权 为第二大股东]]></title>
    <url>%2F2018%2F1e605a41%2F</url>
    <content type="text"><![CDATA[雷帝网 雷建平 2月28日报道 爱奇艺今日正式递交招股书，招股书显示，爱奇艺已申请在纳斯达克证券市场挂牌交易，证券代码为“IQ”。 爱奇艺拟募集资金15亿美元，此次上市募集的资金主要目的是加强品牌认知度，吸引并留存优秀员工，为他们提供股权激励，并获得更多资金。 具体如下：50%用于扩展和加强内容，10%用于加强技术，40%为运营资金及其他公司事务，此外，将运用一部分募集资金收购及购买产品、服务、科技。 爱奇艺会员数达到5080万 招股书显示，爱奇艺2017年总营收为173.784亿（26.710亿美元），较2016年的112.374亿增长54.6%。爱奇艺2015年的营收为53.186亿元。 其中，爱奇艺2017年会员收入为65.360亿（10.046亿美元），较2016年的37.622亿增长73.7%。爱奇艺2015年的会员服务收入为9.96亿。 爱奇艺的会员服务收入占总收入百分比从2015年的18.7%上升至2016年的33.5%，并在2017年进一步上升至37.6%。 从2011年起，爱奇艺开始探索视频会员服务的广大市场空间。2016年6月，爱奇艺宣布有效VIP会员数突破2000万。 2017年8月初百度公布2017年第二季度财报，披露爱奇艺会员数超过3000万。 而此次招股书披露，截至2017年12月31日，爱奇艺付费会员数为5080万，其会员业务规模增长幅度接近Netflix2017年全年2400万的新增会员数量。 爱奇艺的在线广告收入从2015年的33.999亿增长至2016年的56.504亿，同比增长66.2%，2017年为81.589亿（12.540亿美元），同比增长44.4%。 当前，中国在线视频平台主要靠会员服务和网络广告创造收入。爱奇艺收入结构的变化，也说明通过衍生产品变现预计将是另一个日益重要的收入来源。 以往严重依赖网络广告收入的在线视频产业，正在向一个更均衡的多元化创收模式转变。 据美国电影协会 统计，2016 年北美电影票房总收入为 114亿美元，而同期 Netflix 国内会员服务收入约为 51 亿美元。 这说明会员收入会在爱奇艺收入中的比例进一步的提升。 根据介绍，为了满足特别是用户对长尾内容的兴趣，爱奇艺向数千家专业内容提供商授权引进内容，并建立了庞大且多元化的专业制作内容库。 截至2017年12月31日，爱奇艺的内容库共拥有70,000 多部网络剧集、综艺节目、电影、儿童节目、纪录片、动画片、体育赛事和其他各种类型的节目，涵盖 30 多个内容类别。 李彦宏曾表示爱奇艺亏损比对手要少 爱奇艺2015年、2016年、2017年净亏分别为25.75亿、30.74亿和37.369亿（5.744亿美元），爱奇艺这三年的净亏损率分别为-48%、-27%、-22%。 可以看出，与收入的高速增长相比，爱奇艺的亏损增长控制得较好，2016年与2017年的净亏损增长幅度均在20%左右、大幅低于总收入的增速。 对于爱奇艺亏损的现状，百度CEO李彦宏在百度电话会议上有一个说法：爱奇艺依然处于市场领导者地位，在日活跃用户数，平均观看时长，付费用户数和盈利水平方面都是第一。 李彦宏说，“虽然爱奇艺还没有取得盈利，我们的亏损要比竞争对手要少。” 实际上，大型视频网站亏损是行业现状，优酷土豆、腾讯视频也不能避免。 根据阿里财报，阿里大文娱2017年第四季亏损38.28亿，阿里大文娱包括优酷土豆、UC、阿里影业等多个版块，但显而易见的亏损大头是优酷土豆。 爱奇艺归属普通股东的净收益从亏损变盈利 爱奇艺2015年归属于普通股东净收益-49.17亿、2016年为-79.49亿，2017年为9.72亿元。 之所以爱奇艺2017年归属于普通股东净收益为正，主要是计入了可赎回可转换优先股增值50.73亿元，又扣除了B轮优先股偿清及再发行3.63亿元。 而在2015年，爱奇艺可赎回可转换优先股增值为-23.42亿元，2016年，爱奇艺可赎回可转换优先股增值为为-48.74亿元。 可赎回优先股是指是指在发行后一定时期可按特定的赎买价格由发行公司收回的优先股票；可转换优先股是指发行后，在一定条件下允许持有者将它转换成普通股或其他种类优先股。 在新上市的公司中， 如果此前的认股权证没有转换为普通股，则认股权证公允价值变动将会使得公司净利润的产生较大波动。 爱奇艺Q4营收48.17亿元 同比增长53% 爱奇艺2017年第四季度营收为48.17亿元，较上一季度小幅下降3%，但较上年同期增长53%，爱奇艺2016年第四季度营收为31.55亿，也低于其上个季度。 爱奇艺2017年第四季度会员收入为19.29亿元，同比增长53%，较上一季度增长14%，占总收入的比例达到40.1%。 爱奇艺2017年第四季度净亏损为6.1亿元，较上一季度亏损10.5亿元下降35%，较上年同期亏损9.47亿元下降了35%。 爱奇艺2017年第四季度的净利润率为-12.7%。由于爱奇艺的营收增长幅度要大幅领先于爱奇艺的亏损幅度，这使得近年来爱奇艺的净亏损率逐渐在收窄。 百度持有爱奇艺近70%股权 百度当前持有爱奇艺69.6%股权，为爱奇艺最大股东，爱奇艺创始人、CEO龚宇持股为1.8%。 2014年11月，小米和顺为资本联合宣布，双方以18亿元（3亿美元）入股爱奇艺，爱奇艺大股东百度也追加对爱奇艺的投资。 此次小米持股也披露出来，持有爱奇艺8.4%股权。 2017年2月，爱奇艺完成15. 3 亿美元可转债认购，参与可转债认购的除百度外，还有高瓴资本、博裕资本、润良泰基金、IDG、光际资本、红杉等，这笔可转债已转化为爱奇艺股权。 当前，百度CEO李彦宏、集团总裁、COO陆奇、小米联合创始人、小米电视负责人王川在爱奇艺董事会。 爱奇艺还于2018 年1月19日与百度签署了主业务合作协议。 根据主业务合作协议，爱奇艺与百度一致同意在包括但不限于人工智能、智能设备/DuerOS（百度开发的对话式人工智能系统和开发平台）、云服务、在线广告、互联网流量、数据和内容领域开展相互合作，并在合作领域内相互将对方作为最优先的战略伙伴。 根据主业务合作协议，百度将为爱奇艺提供 6.5 亿（9990 万美元）的贷款，在授予之日届满五周年时到期。爱奇艺在2018年1月19日与百度就该贷款签署了贷款协议。该贷款免息。 2018年2月12日，爱奇艺还与百度的全资子公司百度控股有限公司签署一项股份购买协议，根据该协议，爱奇艺将向百度控股有限公司累计发行36,860,691股B类普通股。该项交易预计在2018年5月31日之前交割。 作为发行该股份的对价并受制于股份购买协议规定的条件，百度将针对其及其附属机构在线电影票和演出门票业务，对爱奇艺进行用户流量的导流、技术支持、授予爱奇艺特定域名和特定知识产权许可等。 随着爱奇艺递交上市招股书，意味着在经历长达8年的奋斗之后，爱奇艺创始人、CEO龚宇和百度将成为赢家，爱奇艺迈入新的里程碑，2018年，中国互联网还将迎来一个上市潮。 ————————————————— 雷帝触网由资深媒体人雷建平创办，其为头条签约作者，若转载请写明来源。 转载来源：爱奇艺正式递交IPO申请：小米持股8.4%股权 为第二大股东]]></content>
      <categories>
        <category>财经</category>
      </categories>
      <tags>
        <tag>IPO</tag>
        <tag>爱奇艺</tag>
        <tag>小米科技</tag>
        <tag>纳斯达克</tag>
        <tag>阿里影业</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设计区块链项目的通证（token）模型]]></title>
    <url>%2F2018%2F06001821%2F</url>
    <content type="text"><![CDATA[2018年将是区块链的认知元年。过去一个多月，我自己对区块链与Token模式的认知发生了几次升级，不敢说认知有多深，但是想明白了之后我已经准备All in了。 这篇文章谈一谈我对Token模式的1.0思考。 Token是什么区块链最重要的应用就是价值在互联网上直接流通。通过实体或虚拟资产的Token化，将资产上链，实现资产的液化，能直接通过网络来跨国界、短时差、低成本进行资产交易与转移。 很多人把Token译为“代币”，我更认同元道先生翻译的版本——“通证”。我特别不愿意用代币这个词，因为不是所有Token都具有货币的属性，当然具有货币属性的Token也不见得仅仅只有货币一种属性。Token是一种可流通的加密数字权益证明。这意味着什么？意味着现实世界的各种权益证明（股权、债券、积分、票据等）都可以Token化，放到数字世界里去流通，这件事的想象空间太大了。 虽然已经有一大批先驱们都已经通过Token发行赚的盆满钵满了，但是Token经济的普及依然阻力重重，很多人并没有理解Token的真正价值。 ICO市场Token众生相ICO市场，就是一个江湖。门派林立，各揣心思，牛鬼蛇神，乱象丛生。翻阅了近百份白皮书，体验过若干Token交易之后，我有一个初步的总结。Token项目的三个段位、九种类型（请原谅我还是称为“币”了）。 段位一：垃圾Token 1、空气币 这类Token，完全没有映射到真实资产，存在故意欺诈的行为，其发行Token然后ICO的动机，完全就是来骗钱的，根本没有考虑生态的健康成长。在韭菜成堆、没有监管的市场，简直是这些骗子套利的天堂，各种CX币层出不穷。不过，这个注定不会持久。这是监管首先要打击的对象。 2、鸡肋币 这类Token，虽然映射了资产，但是却是毫无意义的资产，这些资产要么没有升值空间，要么没有流通能力，也注定了生态不可能生长起来。发行这种Token去ICO的组织，可能无意欺诈，但是跟欺诈也没什么区别。 3、侏儒币 这类Token，多是因为生态经济模型设计不科学或者团队能力不支撑，导致生态模式难以为继。即使成功ICO了，也不代表有未来，生态没有未来，Token怎会有长远的价值？比如，激励机制不合理、比如应用场景缺乏，都会使得生态成长乏力。 处在这个段位的Token，是没有投资价值的。但是当前市场上90%的项目都在这个阵营里。希望各路参与者能够擦亮眼睛。 段位二：普通Token 4、积分币 这种Token，本质上就是企业内部发行的积分，你说有价值么？对于使用者而言，有一点价值，至少可以积分换购。对于投资者而言呢？能升值么？升值的逻辑在哪？很多Token发行者根本来不及思考这些问题，却发现这样居然也能被疯抢？就会产生“ICO融资简直太爽了”这种错觉，这只是短暂的趋势红利而已。你的积分，换成Token，如果不去与其他资产打通来置换流动性，真的没什么投资价值，只是新瓶装旧酒而已。 5、会员币 这种Token，类似会员卡。我们大多数人去理发店都会办一张卡，新开的理发店店员会跟你说，现在办卡充值1000抵1200，你一盘算，还挺划算，反正你每个月要理一次，而且这个店开在你们楼下估计也不会轻易跑路，你就办了个理发卡。很多Token，指向的其实都是系统的使用权，只不过我提前预售这个使用权，所以才会有折扣（这个折扣再低也不会低于成本价）。那么，你觉得这种Token的投资价值如何？大多数的产品或者服务的使用权是没有稀缺性的，这种Token的上涨空间是不是很容易计算？你愿意接受吗？ 当然，这里面也有极端一点的例子。比如茅台，茅台酒如果发行产品Token（总量与动态产能挂钩），我相信很多人还是非常愿意持有的。这种Token就有一定的投资价值。 这种Token，对多数消费者而言，是有吸引力的。但是对于投资者而言，就不见得是最佳选择了。 6、分红币 这种Token，除了给到生态使用者类似会员卡优惠的福利之外，还会拿出一部分利润给生态参与者来分享，参与者购买Token，置换的是“使用权+分红权”。某中心化交易所就是这种设计逻辑。坦白来说，这种设计逻辑，我认为不是最理想的机制。 使用权Token的升值逻辑前面已经讲过。给到使用者以更优惠的使用权（比如预充值给折扣），这一点也无可厚非。 我们说一下利润回购这个逻辑。承诺利润回购或者分红的，估计是希望给到发行的Token以升值预期，但是，消费者真的相信股东会和董事会控制之下中心化机构的“利润回购”？很多不透明的因素在里面，很难让人信服。 而且，即使就是“分红权”，那也不应该是阳光普照，一定要奖励生态的关键建设者。华为的虚拟受限股也并没有奖励到每个人，以奋斗者为本嘛。 处在这个段位的Token，你觉得值得投吗？我觉得大部分的长期投资价值都不大（投资价值不大不意味着其Token没有使用价值，这是两码事），极个别除外（使用权具有稀缺性）。当前市场上9%的Token是在这个阵营。 段位三：价值Token 到了这个段位的Token，才是真正具有投资价值的。这也是区块链与Token经济学与生产关系真正融合的部分。什么叫生产关系？百科上是这么说的：生产关系，人们在物质资料的生产过程中形成的社会关系。生产资料所有制的形式是最基本的，起决定作用的生产关系。生产资料所有制是指人们在生产资料所有、占有、支配和使用等方面所结成的经济关系。 所以，真正有威力的Token，一定触及到深层次的生产关系。生产关系的关键就是“生产资料所有制”，必然会涉及到股权，只是这个东西又不是传统概念里股份公司制度之下的股权。 就像当年股份制公司诞生一样，人们也很难用当时的词语来准确描述它。Token也一样。人们现在很难用一个合适的词语来描述Token到底代表什么。很多人说这些Token非债非股，确实Token不是传统意义上的债权和股权，但是其通过Token形式把债权和股权投射进来了。不然，为什么会升值？那些没有将这些权益投射进来的Token，长期看也是没有升值空间的。 有投资价值的Token，至少是三权合一 第一，物权属性，代表了使用权，可交付产品或服务 第二，货币属性，可流通，至少在生态系统内是硬通货 第三，股权属性，可增值，长期收益可期，升值空间较大 如果非要排序的话，股权属性第一，物权属性第二，货币属性第三。 以太坊，就是典型的例子。以太坊可以被视作区块链世界类似于Windows和Android的底层操作系统。以太坊之上，会搭建各种各样的应用，这些应用在执行任务、提供服务时，需要调用以太坊底层的计算资源——这些都不是免费的。调用资源应用的用户需要支付的 “货币”就是代币“以太币”（Ether）。 你拥有了“以太币”，意味着你拥有这个系统的使用权；同时因为这个生态物种足够多样，你需要通过“以太币”这个交易媒介跟别人进行交换生产资料，这时“以太币”就有了货币属性，同时，“以太币”本身总量不是无穷无尽的，总量是相对有限的，那么在以太坊上搭建的应用越多，那应用所调用的资源也就越多，从而需要支付的以太币需求也就越大，这会使得在市场上流通的以太币价格越来越高。 Token的价值，长期一定取决其生态成长能力。 随着监管趋严，垃圾Token越没有市场了。良币终会驱逐劣币。没有价值依托的Token，很快就会被淘汰。而Token的价值，长期取决于其生态的成长潜力。 Token模式的组织，是天然的生态型组织（这个我多少有点发言权，也不枉几年对平台生态型商业模式的探索）。区块链时代的生态组织，大致可以分成这几种类型。一种是底层的技术生态，一种是中间层的商业生态，还有一种是应用层的社群生态。这三个领域都有诞生生态型组织的潜力，也意味着这三类组织发行的Token将具有较强的成长性。 （以下排名不分先后） 7、底层技术生态Token 诸多公有链，都在做这个领域的事。这也是最迫切需要被突破的，有了成熟的技术基础设施，区块链应用才得以广泛普及。 这类的Token也不少了，除了以太坊，还有EOS、NEO、Qtum、IOTA等等。现在处于军阀混战时期，远未到一统江山的时候。 虽然这种Token值得投，但是哪个值得投？或者值得长期持有？这还真是一个问题。 有人说交易所也是一个不错的阶段性机会，的确，但是交易所的Token有多大价值，取决于其将多少权益投射到这个Token里。不是每个交易所的Token都有投资价值的。 8、中层商业生态Token 这一类Token，探索的人有不少，但是真正搞明白的不多。大家都还是拘泥于传统互联网时代的商业模式，做一个媒体，或者一个工具，思维没有跳出来。思考一下，如果做一个区块链时代的阿里巴巴，应该怎么做？沿着旧地图，肯定找不到新大陆。本人要启动的创业项目就在这个领域，后面找时间专门分析一下这个领域的机会。 9、社群垂直生态Token 这一类Token，也有一定的投资价值。Token是非常好的社群商业连接器和润滑剂，传统的社群没能运转的很大因素是机制问题，Token恰好完美解决这个问题。 处在这个段位的Token，是具有长期投资价值的（对于价值投资者）。但到底哪个Token是你的菜，就看你的洞察能力了。当前市场上只有1%的Token处于这个阵营。 价值型Token该怎样判断？只有价值型Token才具备长期投资价值。那么该如何拥抱价值型Token呢？ 第一，如何判断其生态的远期成长能力？ 1、你这个新生态在解决什么问题？ 能否清晰定义原来存在的问题？关键的痛点？引入新生态之后能够带来什么改观？ 这个与创业要思考用户和痛点的逻辑是一样的。如果你没有在解决问题，区块链再神也救不了你。 只有一个提醒，思考生态的视角不要局限于商业，还要着眼于社会问题。因为Token生态的本质是一个社群经济体。 2、生态可能长成的规模有多大？ 再直白一点说，就是你这个生态未来会有多少人使用？使用的频次如何？ 区块链估值体系将从追求利润变成追求用户规模与互动频次。所以你的生态潜在规模不够的话，也会反过来影响到你Token的价值。 3、生态模型设计是否合理？ Token经济设计的核心理念，是把原来体系中耗散的交易成本集约起来，用技术手段把收益分散到体系内每一个参与者，使系统整体摩擦力不断下降，从而Token内在价值不断上升。如果Token机制设置不合理，是很难调动参与者的积极性的，参与者没有被调动起来，生态也不可能成长起来。 这里面重点提一句，关于Token的发行比例。很多Token发行方会一次性地把50%甚至更多的Token给到“黄牛型”的投资者，这势必会抬高生态真正使用者的参与成本，进而会影响到生态的建设。如果你是为了生态建设的话，着急融那么多钱干嘛呢？你的生态建设在这个阶段真的需要那么多钱吗？ 4、团队是否匹配？ 一是看团队的能力构成：有没有优秀的生态设计师？有没有优秀的技术开发团队？有没有优秀的运营团队？我自己的团队就是按照这个逻辑架构的。我算是生态设计师，但同时也需要区块链的技术人才，如果有靠谱的技术大牛欢迎看过来，我准备了好多橄榄树抛给你。 二是看团队的All in程度：我个人认为，Token模式下的创始团队的所有收益都应该与生态未来的预期成长有关，只能唯一体现在Token的升值上（因为已经给到你10%或者20%的一次性奖励了），如果不是这样，大家并没有构建成一个真正的利益共同体。 第二，如何衡量生态Token当下的价值空间？ 前两天一位和君老同学可月提了一个衡量Token价值的公式，我觉得很好，这里借用一下。 在Token模式当中，影响力决定组织/工具价值。交易场景下影响力直观的衡量方式，是流通价值，可以通过交易规模和流通频次计算当前价值=当前交易规模/1单位Token在当前的交易频次。 比如当前基于此Token的交易规模为￥100万；交易了1万次，每次1单位Token，那1单位Token在当前的交易频次就是1万次，当前价值就是￥100万/1万次=￥100。 极值价值=最大运用情况下的交易规模/1单位Token在此情况的交易频次。比如Token最大运用情况下交易规模为￥1亿；交易了100万次，每次0.01Token，那1单位Token在当前的交易频次就是1万次，当前价值就是￥1亿/1万次=￥1万。 当前预期价值是极值价值回溯到现在的价值，假设从当前到极限需要n年，每年经济增长率为r，那么，当前预期价值=极值价值/r的n次方。 价格应该是围绕当前预期价值上下波动的： Token的投资和股权投资都应当遵循价值导向的原则，只不过衡量价值的标准不一样了。一个是基于利润体现赚钱能力，一个是基于交易价值体现影响力。 不要小看这一变化，这种模型，让零和博弈变成了合作共赢！所有人的收益都与未来绑定，这才是真正的利益共同体。Token经济的核心，就是共赢！ ICO的监管重拳来袭，对于那些真正想借助区块链做事情的人，其实并没有什么影响，反而是好事！技术也好，模式也好，只是一种工具，用来做什么，还是背后的人。到最后，都是价值观的较量。 以上为一些不成熟思考，仅供交流。欢迎价值认同的各路伙伴与我联系，一起来探索区块链与Token经济，一起去推动更理想的社会图景！ 如需更多帮助，可私信小编（5年股龄，3年期龄，半年币龄），私信步骤：点击“区块链链长”头像，在其右边有一“私信”按钮，点击私信即可，如下图： 转载来源：如何设计区块链项目的通证（token）模型]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>经济</tag>
        <tag>设计师</tag>
        <tag>创业</tag>
        <tag>威力</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[特朗普为何执意要与中国打贸易战？-虎嗅网]]></title>
    <url>%2F2018%2F698d1f6a%2F</url>
    <content type="text"><![CDATA[虎嗅注：特朗普上台和“推特治国”标志着民粹主义在美国崛起。 而内部的民粹主义又往往表现为外部的经济民族主义和贸易保护主义。仔细分析民粹主义的几波浪潮不难发现，背后的原因实际上是社会贫富差距的扩大，少数人和企业掌握了绝大部分的财富。以美国为例，最富有的10%的人群，掌握了75%的资产。而大量的中产阶级没有享受到科技发展的果实。特朗普的对内对外的经济策略，正是迎合了这部分失意人群。而某种程度上，中国也正面临类似的困境。 本文转载自微信公众号“点拾投资”（ID：deepinsightapp），作者：朱昂，原标题为《吞噬一切的民粹主义，根源到底是什么？》。 过去一年，全球的民粹主义大规模抬头，以特朗普通过发推特影响全球股市的波动而达到了顶峰。 从定义上看，民粹主义指的是平民论者所拥护的政治和经济理念，这个理念拥护平民掌控政治，反对精英或贵族掌控政治。那么，每一次民粹主义崛起背后的原因是什么，其对全球和各国经济发展又会有什么影响？ 民粹主义创1930以来新高 其实许多人对于民粹主义的感受不会很深，在过去几十年中民粹主义的出现非常少，仅仅在某些发展中国家，比如委内瑞拉的查韦斯，菲律宾新任总统杜特尔特等。在发达国家中，很长一段时间民粹主义都消失了。 但是最近几年这个势头开始崛起，下图发现民粹主义已经达到了1930年的高度，那一次之后就引发了世界大战。这个图是基于所有发达国家政党中，民粹主义获得投票的比例。包括了美国、英国、日本、德国、法国等。当然数据统计口径会有些不同，1930年的情况不完全等同于现在。但是我们更多希望大家从这张图中，能够明白全球民粹主义在今天是多么的严重。 桥水在2017年3月的这份报告中，就精准预测到了民粹主义在未来一年对于全球经济的影响。 他们认为未来一年民粹主义对于经济影响会比传统的货币政策，财政政策更加重要，甚至将影响未来一年的全球关系。 通过对于10个国家，14次民粹主义事件的研究中，桥水也发现了一些共性，他们通过研究对于民粹主义有几个关键词定义：普通人掌权，攻击现有利益者，贫富差距拉大，人民对于政府的效率不满意，需要强大的个人来更好掌控政府，保护主义，国家主义，军事主义，企图影响甚至控制媒体。下图是1930年代左右，两次世界大战全球涌现的一批民粹主义领导人。当时的共性就是经济增长疲软，贫富差距扩大，债务比例较高，对于目前的政党和金融业进行攻击。 案例一：美国罗斯福总统 美国历史上有两位罗斯福总统，这位是30年代的Franklin D Roosevelt（后面一个是Teddy Roosevelt）。他并不完全算民粹主义，只能说半民粹。我们都知道1929年开始的大萧条，是美国历史上经济最糟糕的阶段，那时候其实和现在的美国经济有部分类似的地方。 1）债务达到了泡沫阶段，导致经济和市场见顶（1929和2007年） 2）利率水平接近0，带来经济衰退（1932年和2008年） 3）印钞带来的去杠杆（1933年和2009年） 4）股票市场经历一次反弹（1933年~1936年和2009年~2017年） 5）经济周期性复苏（1933年~1936年和2009年~2017年） 6）央行开始收紧，带来一轮自我循环的经济回落（1937年） 当时，美国经济特征就是贫富差距很大，和今天类似。当时全美最富有的前10%人群，拥有85%的资产，今天这个比例是75%，但也是创了过去50年的新高。当然，那时候的失业率远比今天高。 当时美国还有一个现象，就是移民人口比例非常高，这直接导致了后面有一段出台了禁止移民政策。当然，那时的美国移民，今天已经都是真正的美国人。他们并非有色人种移民，更多是来自欧洲的美国第一代移民。 案例二：意大利，墨索里尼 在第一次世界大战之后，意大利的经济严重下滑，通胀高企，失业率更高。而且一战之后大量的军人无所事事。当时许多人移民去了美国，但是后来美国的移民收紧，导致这些人更加没有去处了。在墨索里尼上台之前，四年内换了四个总理，国家主义情绪飙升，墨索里尼也是利用军队获得了最高权力。 墨索里尼的主要政策包括，控制私有企业，让国有经济占到经济的四分之三；贸易保护主义，提高很高的关税；公开禁止犹太人参与到经济中；控制媒体；强硬的外交政策；政府刺激经济。 案例三：德国，希特勒 可能是影响最大的民粹主义者，希特勒当政的背景也源于财富分配不均衡。在1920年代，德国最富有的前10%人口，拥有国家40%的收入。这个贫富差距，是德国历史上最高的一次。而且当时的失业率也达到了历史新高。当时德国的外交政策也很弱，在凡尔赛协议下，基本上被英国和法国压制，这让许多德国人忍受不了。纳粹的投票权越来越高。 于是，反对弱外交政策的希特勒获得选票越来越多。作为墨索里尼的学徒，曾经当过兵的希特勒获得呼声越来越高。 当年他给墨索里尼写过一封信，里面有一句话的原文是“What will rank Mussolini among the great men of this earth is his determination not to share Italy with the Marxists, but to destroy internationalism and save the fatherland from it.” 1932年4月的总统选举中，希特勒获得了37%的选票。纳粹获得选票的增量，在于那些之前不投票的选民，他们许多人是中低收入的工人，曾经的保守派，农民。在1930年代的那次选举中，新增的投票人数超过了400万，接近15%的增幅，他们都是来支持希特勒的。 希特勒上台后的主要政策就是中央集权主义。其中分为几个部分，第一控制了劳动力，劳工局；第二，工业企业的政府化；第三，大量印钞来创造需求；第四，限制汇率管制和价格控制。下图是德国股市在希特勒上任后的表现，股市基本上还是上涨的。 案例四：西班牙内战，弗朗西斯科·佛朗哥 佛朗哥出生于海军军官家庭。1928年任新成立的萨拉戈萨高等军事学院院长。1936年7月18日联合其他反动军官发动反政府武装叛乱，挑起西班牙内战。同年10月被推举为“国家元首”并任叛军总司令，晋大元帅。1937年4月成为长枪党党魁。由于得到德、意法西斯支持和英、法等国采取“不干涉”政策，以及军队武器装备和训练素质占优势，最终获得胜利。 1939年内战结束后，成为终身国家元首。第二次世界大战期间，取缔其他一切政党，实行法西斯独裁统治。名义上保持中立，但帮助希特勒侵略苏联。第二次世界大战后，他被各国孤立，但和美国保持亲密的盟友关系， 因为美国的援助，西班牙成为工业化的发达国家。1947年自任摄政王。1969年指定胡安·卡洛斯为王位继承人。1975年逝世于马德里。其死后胡安·卡洛斯登上王位，实行民主改革， 西班牙结束独裁统治。 再来看看西班牙经济在1920到1940年的情况。当时整个当权政府效率很低，政府的力量越来越小，军队的力量越来越大。到了1931年，整个国内的掌权者开始向左翼倾斜，在后面直接导致了西班牙的内战。在佛朗哥当权的时候，他也是实行集权统治，有很强的保护主义倾向，以及很强的国民主义政策。整个国民在经历了几次大战后，资产价格都大幅缩水，农业和工业经济同时萎缩，甚至出现了严重的自然灾害。下图是佛朗哥当政前，西班牙股票市场的走势。 案例五：日本，军事力量的崛起 在一战前的1912年，日本负有19亿日元债务，战后不但全部偿清，且进而成为拥有27.7亿日元的债权国。日本军国主义专靠战争掠夺而致富，这种暴发经济具有很大的虚弱性，潜伏着巨大的危机。虽然重工业为战争需求而畸形发展，但基础工业和轻工业相对落后。农村中仍处于寄生地主制统治之下，农业生产力很低，生产规模小，破产农民不断增加，城乡人民生活贫困。 1929年10月，自美国首先爆发的世界性经济危机，使尚未从金融危机中恢复过来的日本经济受到了新的冲击。 日本政府1929年11月宣布，自1930年1月11日开始实行“黄金解禁”，试图促进出口，振兴经济，同时实行通货紧缩政策，借以摆脱危机。 然而“黄金解禁”带来相反的结果，黄金外流1930年达27552万日元，1931年外流43310万日元。另一方面，通货紧缩又招致生产萎缩，原材料价格猛跌。据统计从1930年6月~1931年6月，原材料价格下跌21.6％，生产资料下跌29.3％，消费资料下跌16.7％。从股份市场看，以1924年1月的股票价格指数为100，则1929年6月为104，1930年6月下跌到74，同年10月进一步跌到63。 危机还进一步使日本金融业遭受打击。 据大藏省调查，全国普通银行774家之中，有58家被迫停业。许多中小资本被兼并或削弱，1930年~1931年，减削资本总额达73000万日元，被解散公司资金达104000万日元。大量工人失业，工资指数急剧下降，而一些大公司垄断组织资金膨胀，卡特尔和托拉斯进一步发展，危机还波及到日本的海外殖民地与半殖民地，满铁的收入也急剧减少，1931年还出现了创建以来的第一次赤字现象。 1919年，与意大利墨索里尼的法西斯组织出现的同时，日本法西斯的鼻祖北一辉，写出了《国家改造案原理大纲》（1923年发行时改名《日本改造法案大纲》），要求对日本实行法西斯主义的国家改造。翌年，北一辉与大川周明组建了日本第一个法西斯团体“犹存社”，该社以北一辉的《大纲》为指导纲领。他们的根本目标，是建立法西斯专制，要“基于天皇亲政的本义”，“打破以党利为主的国策下之政党政治陋习，以期亿兆一心，实现国民理想之皇国政治。下图是这个阶段日本股市的走势： 民粹主义抬头的共性：贫富差距加大 由于全球经济增速大幅度放缓，低利率伴随着相对的低通胀。各个央行都希望刺激消费，通过宽松的流动性拉高通胀。然而在低迷的实体经济增长背景下，通胀一直起不来，经济整体修复也是进二退一。导致央行必须不断保持宽松，来迎合“politically correct”（政治正确）。 过去的十年，我们也真正发现央行并不独立。宽松的货币背后是贫富差距拉大，越来越多的钱进入优质资产。拥有优质资产的人财富大规模提高。拥有优质资产的国家和其他国家拉开差距，拥有优质资产的公司也和普通公司拉开差距。这就是今天全球社会的根源。 我们先看下面这张图，就能认识到Trump为何有如此高支持率。 从2000年以来，美国家庭收入中位数水平是下滑的。美国家庭收入中，只有在最高收入前80%分位的人出现了增长。这背后就是美国的大部分中产并没有享受到过去十几年经济增长的果实。 相反，全球化带来的是他们工作被中国，被科技所替代。而金融，互联网领域中具有优质资产的人收入不断提高，特别是经历了金融危机后，美国家庭贫富差距加大。 在美国的同学也跟我说，原本那些拿着高工资的汽车生产线工人、邮递员、医院设备调试员等收入都出现了下滑。但是华尔街、硅谷最优秀的一批人收入大规模提高。上一轮互联网泡沫最优秀程序员的工资大概是25万美元，这一轮互联网泡沫大量程序员年收入已经超过了100万美元。而美国总统大选是一个popularity test（人气测试）。Trump的政治方案虽然听上去疯狂，但符合了大部分美国人的心意。利率不断降低所导致的贫富差距拉大，终于在今天的美国全面爆发。 2000年、2007年、2014年到今天美国家庭收入变化。50%分位家庭从2000年和2007年到今天的收入是下滑的。 在中国，类似的事情也在发生。持续宽松的信贷政策以及低利率带来了资产价格的泡沫。 过去几年最显著的就是北上广深房价上涨，中国楼市已经是目前人类最大的一次泡沫之一了。深圳的房价收入比高达38倍为全球最高，北京和上海也在30倍以上，排名第四和第五。 过去几个月，关于房价的研究和讨论远远超过股市。更可怕的是，在经济增速向下的大背景下，大部分人的收入已经难以高速增长。如此高的房价收入比，无法通过更高的收入增速来消化。而在这个过程中，显然拥有资产的富人财富继续增长，没有资产的穷人变得越来越难翻身。经济增速放缓，资产泡沫拉大贫富差距，社会流动固化，这也导致了中国目前一系列的问题。 公司贫富差距拉大 贫富差距的拉大不但发生在家庭，也同样发生在公司。低利率带来了更便宜的流动性，这些流动性不断涌向回报率更高的公司，最终导致优秀的公司获得的资源越来越大，大幅拉开和普通公司之间的距离。 今天，全球大约10%的上市公司掌握了80%的利润。收入规模在10亿美元以上的公司拥有全球60%的企业收入以及65%的市值。 大公司市值集中度提高在美国尤为明显。名义GDP中来自于前100大公司的占比从1994年的33%提高到了2013年的46%。另一边，美国上市公司数量从1997年的6797家大幅下滑到2013年的3485家。我们会看到一个现象，就是大公司越来越大。今天前100大公司的市值目前已经超过了16万亿美元，而这个数在2009年只有8.4万亿。我们会惊奇的看到类似于Facebook, 亚马逊这样的超级大盘股能够实现一年翻倍的行情，而许多中小市值的公司股价却下跌了70%以上。互联网被几大平台公司垄断后，创业反而越来越艰难。 最终特朗普是否会扭转这个趋势，带来一次财富重新分配？ 转载来源：特朗普为何执意要与中国打贸易战？-虎嗅网]]></content>
  </entry>
  <entry>
    <title><![CDATA[腾讯入局在线文档领域，初创公司还有机会逆袭吗？]]></title>
    <url>%2F2018%2F6bd1d4a4%2F</url>
    <content type="text"><![CDATA[摘要：4 月 18 日，腾讯正式发布在线文档工具「腾讯文档」，马化腾在朋友圈表示：这是一个意外惊喜，没有一丝丝的防备。 上周 4 月 12 日的媒体沟通会上，石墨文档正式对外公布，已于 2017 年完成近亿元的 B 轮融资，投资方为今日头条。4 月 18 日，腾讯也正式发布在线文档工具「腾讯文档」，马化腾在朋友圈表示：这是一个意外惊喜，没有一丝丝的防备。 腾讯文档入局，更「意外」的应该是刚刚站稳脚跟的同类产品。此前国内并没有成熟的在线文档产品，初创公司最大的优势之一就是出发早，而腾讯入局无疑会加速这一领域的竞争。 腾讯是带着资源、野心来的，在线协作工具需要的社交场景腾讯已经具备，各种资源、能力的接入也比创业团队更有优势。当然，有优势并不代表一定会成功。总体来看，在线文档在国内还处于起步阶段，腾讯这样的大玩家加入，更大的意义在于普及作用。 我们为什么要用在线文档？ 在线文档并不是一个新概念。国外的典型产品是 Google Docs，2007 年发布，至今已经有十年。2016 年，Google Docs 的活跃用户就超过了 3 亿，企业用户达 500 万，年收入超过 10 亿美元。在传统办公领域占据领导地位的微软，也在 2011 年推出了云端的 Office 365。从理论上讲，微软 Office 在全球的十几亿用户都是在线文档的潜在用户，市场潜力十分巨大。 在腾讯文档发布之前，国内并没有互联网巨头直接参与到在线文档的竞争，不过大家对这一市场已经早有关注。今日头条投资了石墨文档、金山 WPS 投资了一起写，就连微软也针对微信平台推出了 Office 365 微助理。 大家已经都意识到这是一片巨大的蓝海，但参与方式有所不同，这跟各家的基因有关。金山 WPS、微软 Office 本来就在做传统办公软件，Google 一直在布局自己的软件生态，腾讯则是以社交为切入点。 先不谈各自的目的，在线文档本身就是一种产品进化的产物。首先它是在线的，不需要额外下载软件，在浏览器就能使用，抛弃了本地文件，文件的管理更方便。第二，在线文档让协作和分享变得更自由，实时编辑、实时修改，减少了本地文件繁多造成的失误。第三，很重要的一点，在线文档比本地文件更安全，设备损坏、被偷，文件都不会丢失。尤其是涉及多人协作的时候，文档的查看、编辑权限都由用户自己控制。 石墨文档的创始人吴洁举过这样一个例子，现在任何一家企业员工离职 5 分钟之内就可以把文件资料全都拷走，而云端的文件批量下载时，是可以通过技术手段切断的，拷走的内容也可以打上水印。所以当企业员工统一用在线文档工具时，内部资料很安全，离职时也能回收，并且不会影响自己的个人资料。 腾讯做在线文档的优势 其实从目前的产品来看，腾讯文档和同类软件并没有太大区别，上面说的功能大家也几乎都有，那么腾讯做这件事的优势在哪里呢？ 石墨文档的吴洁曾提到，中国的创业公司做在线文档，是有一定技术壁垒的。国外把 Office 三件套做全的公司只有微软和谷歌，不算 PPT 的话还有 Quip，而 Quip 的创始人是 Facebook 的前 CTO，团队是硅谷最厉害的一批工程师。抛去这样的背景不讲，想做 Office 是很难的。在中国做在线文档，需要坚定的决心、长时间的投入，和关键的人才。 这些挑战对创业公司来说比较困难，而由腾讯来做，起步的优势、运营能力、未来的发展都有了很多的可能性。 腾讯文档的发布并不是临时起意，其实最早用户用 QQ 传文件，这就是一种办公的雏形。直到现在，QQ 上还有将近两亿的文档活跃用户，日均文件传输量超过 1.8 亿次。2017 年 4 月，腾讯推出主打办公的 TIM 客户端，进一步解决用户的办公问题，目前月活用户也已经突破两千万，内置的在线文档规模超过 1300 万。这次推出腾讯文档，腾讯有更大的野心，就是通过文档这样一个支点，去撬动办公背后一个足够支撑千亿市值的巨大市场。 腾讯的基因是社交，而在线文档又需要多人协同，所以微信、QQ 的关系链就成了腾讯文档最大的优势。腾讯文档的服务除了支持网页端、移动端两大平台，还和微信、QQ 全面打通。QQ 传输的文档可以一键转为在线文档进行编辑以及预览，微信上则有小程序的版本支持。比起其他同类产品的分享，腾讯文档不管是在查看、编辑体验，还是账号登录、分享上，都要便捷许多。 作为国内互联网的巨头，腾讯产品间的资源互补形成了一个庞大的生态，拿已经加入的翻译功能来说，接入的是「翻译君」的能力，类似的天气、地理等数据，都可以在闭环系统中提供。在线文档是核心，关系链是纽带。未来腾讯的 QQ 邮箱、多人语音都可以与在线文档产生融合，如果能达到这样的预期，腾讯完全可以自己搞出一套办公领域的产品矩阵。 对初创公司是好事还是坏事？ 对这个领域的初创公司来说，腾讯的入局是好事还是坏事？这很难说。正如前面提到的，两者目前在功能上并看不出太大区别，甚至石墨的某些细节功能、设计要做得更好。所以前期腾讯文档能带来的，一定是把整个在线文档的市场扩大，将更多潜在用户带入这个全新的领域。至于以后，与在线文档相近的笔记、协作类领域都诞生过独角兽，机会还是有的。只是腾讯文档一出现，初创公司的节奏就不得不加快了，整个产业会进入快速竞争的时期，玩家也会越来越多。 从目前国内的在线文档市场来看，现在各家抢的不是对方的市场，而是未开垦的潜在用户，腾讯十亿的用户无疑是个巨大的压力。据石墨文档的吴洁说，目前他们的盈利还主要靠在个人收费版和企业版上，内部也在推出 SDK 等一些商业化的产品。盈利对初创公司来说永远是个紧箍咒，相比之下腾讯文档少了很多束缚。 现在去谈谁是最后的赢家还很远，可以预见的是在线文档领域会涌入更多的玩家。好在在线文档还是个重体验的产品，所以虽然腾讯入局，机会也还是有的，未来这个领域会有更多的可能。 编辑：Rubberso ■ 转载来源：腾讯入局在线文档领域，初创公司还有机会逆袭吗？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>创业</tag>
        <tag>Google</tag>
        <tag>云计算</tag>
        <tag>移动互联网</tag>
        <tag>微软</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[来来来！教你自己发行空气币]]></title>
    <url>%2F2018%2Fe5349c69%2F</url>
    <content type="text"><![CDATA[正式开始前，需要准备： 1、科学上网的工具 2、chrome浏览器 第一步：在chrome浏览器上安装 metamask 的插件。 点击以下网址进行安装，点击添加至chrome。 https&#58;//chrome.google.com/webstore/detail/metamask/nkbihfbeogaeaoehlefnkodbefgpgknn 或者进入官网下载安装chrome插件： https&#58;//metamask.io 点击添加扩展程序 注：metamask除了是一个简单的钱包外，它可以使得Chrome浏览器和以太坊智能合约互动。 第二步：设置账号，点击chrome浏览器右上角的logo图标，同意隐私条款和使用条款。 输入并确认密码，创建账号 一定要把助记词保存好！ 账号创建好，可以向自己的地址转账，扫描二维码比较方便，也不容易出错，可以转0.02枚eth，用于发行代币 第三步：发行代币 进入下面网站： http&#58;//tokenfactory.surge.sh/#/factory 我以AIR 空气币 做范例，欲发行100W枚，第三栏数字 2 代表着后两位0的前边小数点，比如1E枚，数字填2，实际发行100W枚，代币名称：AIR。点击 Create Token： 如图所示：矿工费默认0.02ETH，我们可以调低到0.01ETH，降低费用，但执行速度会有些慢，耐心等待即可。矿工费尽量提前转进去，如果矿工费足够，点击绿色按钮，会显示：SUBMIT。 你可以在： https&#58;//etherscan.io 查询你的 metamask eth 地址找到你刚才的交易。找到 contract creation 这一笔。 搜索后出现： 点击0x一栏： 复制上图0x开头地址，将合约地址贴进去： http&#58;//tokenfactory.surge.sh/#/tokensearch 点击Go to Token,输入你想要转账的地址： 提前转一些矿工费，够用就好，坐等钱包入账。这样我的AIR空气币就算发行成功了。 转载来源：来来来！教你自己发行空气币]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>Chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从TPP破产到一带一路崛起，中国下了很大一盘棋！]]></title>
    <url>%2F2018%2F6f2a99aa%2F</url>
    <content type="text"><![CDATA[从TPP破产到一带一路崛起，中国下了很大一盘棋！ 转载来源：从TPP破产到一带一路崛起，中国下了很大一盘棋！]]></content>
      <tags>
        <tag>凤凰财经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[陈春花：2018 计划怎么定，之后怎么做？一文讲透]]></title>
    <url>%2F2018%2F04c2107a%2F</url>
    <content type="text"><![CDATA[陈春花：2018 计划怎么定，之后怎么做？一文讲透 转载来源：陈春花：2018 计划怎么定，之后怎么做？一文讲透]]></content>
      <tags>
        <tag>春暖花开</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我曾误删了公司的数据库，但还是活下来了]]></title>
    <url>%2F2018%2F71efaa3e%2F</url>
    <content type="text"><![CDATA[编者按：开发人员总以为自己误删了数据是天大的事情。的确如此，但是“罪不至死”。本文作者Zachary Kuhn在“Those two times where I clearly had no clue what I was doing as a developer”一文中分享了自己的亲身遭遇，并认为犯了错误不重要，重要的是要有所得。 上周我与同事们进行了一次关于职业生涯中搞砸了一些事情的简短谈话。这确实会沦为他人笑柄，却更给我们带来了珍贵的教训。重要的是，我们应该分享那些曾经的错误，这样其他人就可以从其中学习。下文是最近在我身上发生的例子。 为什么有如此多误删生产数据库的事情发生？ 几个月前，Reddit上有一篇文章，讲了一名初级开发人员在上班的第一天就删除了生产数据库的事。我们都很憷于读到这类犯了这类无法让人忘却的大错误的文章。因为我们离这些也不远，而大多数人都是“死里逃生”。 在我的第一份工作中，一位高级数据库管理员在上班第一天就误删了生产数据库。这类故事情节比比皆是。这个团队从一个星期的备份中恢复了他导致的错误，并让他继续工作。十年后，他们依然将其作为笑点。 今年早些时候，我被派去检查一个客户的生产数据上的问题。他们进行了小范围的非公开测试，结果网站上没有显示任何内容。我想查查是否是存在漏洞或是易损性问题导致了这一结果。 我通过了生产机器上的签名环节，然后打开了数据库。内容库（articles table）内空空如也。这证实了我们在网站上看到的情况是真实的。 用户库（users table）内依然有用户数据存在。真让人奇怪。所以情况是我们丢失了所有内容，但是至少测试用户的信息依然存在。我们给出的解释是这是一个测试行为，所以这些事情有可能发生。 接下来的几分钟一片混乱。我不记得自己做了什么。我不认为自己笨到在控制台上执行了删除用户库的操作。但是事实就是这么发生了，现在后台既没有了内容库，也没有了用户库。这真实下了我一大跳。 然后我的大脑就开始转动起来思考如何解决这个问题。我真的把用户库给删掉了吗？是的。我们存备份了吗？没有。我们应该如何告诉客户这个事情？不知道。 我犹记得自己走向项目经理那里，坐在她身边，向她解释了发生了什么事情时的场面。因为我们的内容库中没有内容，这就是为什么网站上空空如也的原因。同时，我还删除了用户库。他们现在需要重新邀请所有的用户，如果他们能够弄清楚谁是谁。 我回到了自己的办公室，垂头丧气。 不过，我还是没有接受这件事。我们一开始是如何失去这些东西的？ 我开始不停地往深处想。半是为了否认这件事，半是想要挽回面子。不久，我注意到了一些重要事情。 在服务器上还存在着其他5个数据库。其中一个数据库的名字和我刚才看到的数据库名字很像。 当我查看这个数据库的时候，发现所有的内容都在里面。用户库也安然无恙。结果证明，是一个配置变动无意中改变了生产设置，使站点指向了一个全新的数据库。我之前所看的用户信息是什么？种子数据。 真是谢天谢地。早上的神经紧张和胃酸让我觉得很不舒服，但是我们“恢复”了数据，并在坏消息传开之前找到了真正的问题。 从这件事中可以吸取很多教训。其中一点是关于最简单原则：我们总是在做的备份，也许是开发人员最有成效的挽救药。 继续前进但不要冲得过前 我最近犯的一个错误不太引人注目。事实上，这是一个经由小错误所引起的小错误最终导致了一场混乱的故事。 我们面临的是一个时间紧迫的项目。 在初次会议上，我们团队一致认为完成它会花费比预定时间多一倍的时间。这个最后期限一开始就对我们产生影响，让我宽松地通过了身份认证部分而留有更多时间去关注客户所实际关注的功能设计。 我只是在一个单一页面测试了身份验证测试，但是当时还不了解它们将如何被组合在一起。 把它单列出来是我做的一个错误决定。我忽略了一些重要事情： 用户在登陆之后会从cookie中加载内容，但是这个页面却试图在没有任何等待的情况下进行加载。根据事件的发生顺序，用户会得到带来服务器的反映，说其是未经授权的。1. 身份验证也未检查令牌是否过期。如果用户不经常访问这个网站。那么当其再一次访问时，网站需要用户登出再登入才会运行。1. 令牌应该基于每个请求进行更新，但是我从未花费时间去理解其发生前后的规则。所以，这又产生了一个时间问题。如果我们同时发送了几个请求，根据它们返回的顺序，用户会得到那个在后来的请求中无法使用的令牌。身份验证也未检查令牌是否过期。如果用户不经常访问这个网站。那么当其再一次访问时，网站需要用户登出再登入才会运行。 我们匆匆忙忙地赶着项目，却仍花费了比规定多一倍的时间。区别之处在于有更多的漏洞，并需要花更多时间去跟踪并修复这些漏洞。 这使我感到窘迫。之后因为整件事情变得比较糟糕哦而让我在公众场合感到羞愧。 我想说的是：在此之后，我花费了时间去学习认证程序。我现在了解了OAuth、JWT、刷新令牌和到期行为。我仔细研究了其他人所编写的身份验证代码。我能够在不同的语言和框架中建构身份验证程序。 将失败转化为未来的成功 这是我从那些表现糟糕的事情中所获得的经验。如果你愿意，那么几乎所有好的结果都会由此而来。 如果有人能从自己的错误中汲取教训，那么他就会比现在更优秀。我试着不去打击那些第一次犯错误的队友。他们通常都知道自己把事情搞的一团糟。 我也正尝试不对那些不断犯同样错误的人施加压力。他们仍然值得同情。 如果在错误中做到这4点，那么你就会不断成长： 嘲笑自己。1. 从中汲取经验教训。1. 改正错误。1. 分享自己的错误，让其他人也有所收获。从中汲取经验教训。 分享自己的错误，让其他人也有所收获。 最后，我想讲一个关于错误价值的轶事。20世纪初，IBM的首席执行官托马斯·J·沃森曾遇到过一名员工，这名员工的一系列糟糕决策让公司付出了巨大代价。当沃森被问到是否会解雇这名员工时，他回应道： “不，我刚在他身上花了60万美元的培训费。为什么要让别人白白捡去这个便宜？” 原文链接：https://medium.freecodecamp.org/the-times-ive-messed-up-as-a-developer-3c0bcaa1afd6 编译组出品。编辑：郝鹏程 转载来源：我曾误删了公司的数据库，但还是活下来了]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>DBA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一段关于国产芯片和操作系统的往事]]></title>
    <url>%2F2018%2F752ebcba%2F</url>
    <content type="text"><![CDATA[一段关于国产芯片和操作系统的往事 转载来源：一段关于国产芯片和操作系统的往事]]></content>
      <tags>
        <tag>梁宁-闲花照水录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链世界里的存储技术—IPFS - 简书]]></title>
    <url>%2F2018%2F27f84757%2F</url>
    <content type="text"><![CDATA[区块链世界里的存储技术—IPFS - 简书 转载来源：区块链世界里的存储技术—IPFS - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[任志强最新演讲万字文章：房地产可能的发展趋势（含48页PPT）]]></title>
    <url>%2F2018%2F781da653%2F</url>
    <content type="text"><![CDATA[任志强最新演讲万字文章：房地产可能的发展趋势（含48页PPT） 转载来源：任志强最新演讲万字文章：房地产可能的发展趋势（含48页PPT）]]></content>
  </entry>
  <entry>
    <title><![CDATA[简述表征句子的3种无监督深度学习方法]]></title>
    <url>%2F2018%2F7849c7a2%2F</url>
    <content type="text"><![CDATA[本文介绍了三种用于表征句子的无监督深度学习方法：自编码器、语言模型和 Skip-Thought 向量模型，并与基线模型 Average Word2Vec 进行了对比。 近年来，由于用连续向量表示词语（而不是用稀疏的 one-hot 编码向量（Word2Vec））技术的发展，自然语言处理领域的性能获得了重大提升。 Word2Vec 示例 尽管 Word2Vec 性能不错，并且创建了很不错的语义，例如 King - Man + Woman = Queen，但是我们有时候并不在意单词的表征，而是句子的表征。 本文将介绍几个用于句子表征的无监督深度学习方法，并分享相关代码。我们将展示这些方法在特定文本分类任务中作为预处理步骤的效果。 分类任务 用来展示不同句子表征方法的数据基于从万维网抓取的 10000 篇新闻类文章。分类任务是将每篇文章归类为 10 个可能的主题之一（数据具备主题标签，所以这是一个有监督的任务）。为了便于演示，我会使用一个 logistic 回归模型，每次使用不同的预处理表征方法处理文章标题。 基线模型——Average Word2Vec 我们从一个简单的基线模型开始。我们会通过对标题单词的 Word2Vec 表征求平均来表征文章标题。正如之前提及的，Word2Vec 是一种将单词表征为向量的机器学习方法。Word2Vec 模型是通过使用浅层神经网络来预测与目标词接近的单词来训练的。你可以阅读更多内容来了解这个算法是如何运行的：http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/。 我们可以使用 Gensim 训练我们自己的 Word2Vec 模型，但是在这个例子中我们会使用一个 Google 预训练 Word2Vec 模型，它基于 Google 的新闻数据而建立。在将每一个单词表征为向量后，我们会将一个句子（文章标题）表征为其单词（向量）的均值，然后运行 logistic 回归对文章进行分类。 我们的基线 average Word2Vec 模型达到了 68% 的准确率。这很不错了，那么让我们来看一看能不能做得更好。 average Word2Vec 方法有两个弱点：它是词袋模型（bag-of-words model），与单词顺序无关，所有单词都具备相同的权重。为了进行句子表征，我们将在下面的方法中使用 RNN 架构解决这些问题。 自编码器 自编码器是一种无监督深度学习模型，它试图将自己的输入复制到输出。自编码器的技巧在于中间隐藏层的维度要低于输入数据的维度。所以这种神经网络必须以一种聪明、紧凑的方式来表征输入，以完成成功的重建。在很多情况下，使用自编码器进行特征提取被证明是非常有效的。 我们的自编码器是一个简单的序列到序列结构，由一个输入层、一个嵌入层、一个 LSTM 层，以及一个 softmax 层组成。整个结构的输入和输出都是标题，我们将使用 LSTM 的输出来表征标题。在得到自编码器的表征之后，我们将使用 logistics 回归来预测类别。为了得到更多的数据，我们会使用文章中所有句子来训练自编码器，而不是仅仅使用文章标题。 我们实现了 60% 的准确率，比基线模型要差一些。我们可能通过优化超参数、增加训练 epoch 数量或者在更多的数据上训练模型，来改进该分数。 语言模型 我们的第二个方法是训练语言模型来表征句子。语言模型描述的是某种语言中一段文本存在的概率。例如，「我喜欢吃香蕉」（I like eating bananas）这个句子会比「我喜欢吃卷积」（I like eating convolutions）这个句子具备更高的存在概率。我们通过分割 n 个单词组成的窗口以及预测文本中的下一个单词来训练语言模型。你可以在这里了解到更多基于 RNN 的语言模型的内容：http://karpathy.github.io/2015/05/21/rnn-effectiveness/。通过构建语言模型，我们理解了「新闻英语」（journalistic English）是如何建立的，并且模型应该聚焦于重要的单词及其表征。 我们的架构和自编码器的架构是类似的，但是我们只预测一个单词，而不是一个单词序列。输入将包含由新闻文章中的 20 个单词组成的窗口，标签是第 21 个单词。在训练完语言模型之后，我们将从 LSTM 的输出隐藏状态中得到标题表征，然后运行 logistics 回归模型来预测类别。 这一次我们得到了 72% 的准确率，要比基线模型好一些，那我们能否让它变得更好呢？ Skip-Thought 向量模型 在 2015 年关于 skip-thought 的论文《Skip-Thought Vectors》中，作者从语言模型中获得了同样的直觉知识。然而，在 skip-thought 中，我们并没有预测下一个单词，而是预测之前和之后的句子。这给模型关于句子的更多语境，所以，我们可以构建更好的句子表征。您可以阅读这篇博客（https://medium.com/@sanyamagarwal/my-thoughts-on-skip-thoughts-a3e773605efa），了解关于这个模型的更多信息。 skip-thought 论文中的例子（https://arxiv.org/abs/1506.06726） 我们将构造一个类似于自编码器的序列到序列结构，但是它与自编码器有两个主要的区别。第一，我们有两个 LSTM 输出层：一个用于之前的句子，一个用于下一个句子；第二，我们会在输出 LSTM 中使用教师强迫（teacher forcing）。这意味着我们不仅仅给输出 LSTM 提供了之前的隐藏状态，还提供了实际的前一个单词（可在上图和输出最后一行中查看输入）。 这一次我们达到了 74% 的准确率。这是目前得到的最佳准确率。 总结 本文中，我们介绍了三个使用 RNN 创建句子向量表征的无监督方法，并且在解决一个监督任务的过程中展现了它们的效率。自编码器的结果比我们的基线模型要差一些（这可能是因为所用的数据集相对较小的缘故）。skip-thought 向量模型语言模型都利用语境来预测句子表征，并得到了最佳结果。 能够提升我们所展示的方法性能的可用方法有：调节超参数、训练更多 epoch 次数、使用预训练嵌入矩阵、改变神经网络架构等等。理论上，这些高级的调节工作或许能够在一定程度上改变结果。但是，我认为每一个预处理方法的基本直觉知识都能使用上述分享示例实现。 转载来源：简述表征句子的3种无监督深度学习方法]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Word</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>镜音双子</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日刷抖音三百条，让我重新认识今日头条]]></title>
    <url>%2F2018%2F78797b59%2F</url>
    <content type="text"><![CDATA[当我打开抖音，不知不觉中两个小时不见了，而在我刷了上百条抖音后，我重新认知了今日头条。 抖音成了香饽饽，相比较于快手在三四线城市的肆虐，抖音成为了一二线城市年轻用户的最爱。 这个现象让人疯狂，一二线白领、大学生，这批要求最多。眼光最高、套路最多、识别套路能力最强，多少个app都无法讨好的人群，被抖音收割了。 出于对于这件事情的兴趣，我也玩起了抖音，并且在15s的世界里被割下了大片时间，时间都去哪儿呢？ 音乐是抖音的切口，也是激发用户创造力的伴奏如果有人问什么是抖音，我们该如何在二十秒内准确描述它？ 抖音在对外的宣传资料里这样描述自己： 抖音短视频社区以音乐为切入点，搭配舞蹈、跑酷、表演等内容的创意表达形式，为用户创造丰富多样的玩法，让用户轻松快速地创作独特有张力的短视频，并在抖音社区与众多用户互动。 从这个定义里可以明确地得知几个信息点： 抖音是一个短视频，而且是以音乐作为创作基础的短视频。通过实际上手发现，15s的短视频决定了音乐必须实现定制。所以抖音购买音乐版权，创办音乐创作大赛，这一切目的的背后都是给用户提供更多的创作工具。 用户根据音乐这个创作工具需要自发地创作，这决定了这个产品一开始需要栽培的种子用户是富有想象力、创造力的人群。 轻松快速地制作短视频，意味着抖音必须提供足够多的创作工具，循环、慢拍、快进这些拍摄功能都是基本的。 在抖音社区与其他用户互动，社区意味着这是一个大舞台，但想要互动意味着需要连接多方，多方在这里可以简单理解为内容制作者和用户双方。连接必然涉及到推送机制，解决方案是今日头条的技术分发，同时结合常见的Follow机制。 从这个定义里，自然能够理解抖音做很多事情的必然性。 必然性之一：把生产工具打磨到足够好。 2017年3月前，抖音都没有大规模地进行宣传。这个时间段抖音在疯狂地迭代产品，也就是要完成工具的基本建设。 而今日头条在这一点上已经有类似经验，在今日头条早期，不断迭代头条号的后台编辑器，为内容创作者提供更好用的创作工具，这已经是这家公司打磨一款产品的基因。 必然性之二：和专业音乐人合作，定制短音乐。 音乐制作是一个门槛高的行业，而想要再制作15s的短视频配乐，同时这个音乐能够激发用户创造力，更是一件对专业人颇具挑战的任务。 在抖音的官网上，现在正在举行的抖音音乐计划，看起来就是这个需求的落地方案之一，而且从目前的方向来看，这件事情将会有很强的持续性。 必然性之三：通过运营降低生产成本，通过技术分发让用户获得“崇拜”。 在完成了工具的建设以后，急需要破除的一个门槛就是让用户学会使用这款工具，这和office套装才来到中国时一样，很多人都在学习如何使用word。 因此运营端必须首先面对这个现实：即使是15s短视频，只要涉及到拍摄，短视频都是一个门槛颇高的行业。 因此运营做的第一件事情就是出教程，教育和辅助用户如何拍摄出令人喜爱的抖音小视频？ 在这个环节，抖音的运营需要有很强的培训力和把控力，一边出教程，一边期待用户在这些基本功能上有新的创意发挥。就像学生时代老师教会了遣词造句的规则后，期待学生能够写出令人眼前一亮的语句。 把控力则体现在：面对每一支可能引发大规模模仿的音乐小视频，如何把控整体的调性？不能管理太多继而挫伤用户的创造性，又不能让用户过于狂热的创造性伤害到其他人。 当用户的创造力得到释放以后，从用户端来说，只有一种反馈能够促进它们继续沉迷在这个app中。 用户需要有奖励，对于内容创作者的奖励，曾经在今日头条上展现为现金，在抖音上则是“崇拜”。 因为所有人都需要钱，但是年轻人更需要“崇拜”。 在官方运营的推力下，聪明的用户将快速上手软件，并且有机会和官方一起去定义这款app的未来想象力。 究竟什么样的视频内容是既适合这个平台，又能得到官方认可并且大规模推荐的？ 这个答案一开始很难有定则，一定都是用户一开始百花齐放式创作，然后官方摸索着筛选出最适合抖音调性的内容风格，同时也让其他风格的内容给予一定量野蛮生长的空间。这些和app一起成长的抖音初期用户，一边享受着抖音带来的快乐，一边享受着其他粉丝赋予他们的“崇拜”。 品牌认知让有才华的人得到足够多的赞赏。 抖音的slogan为“让崇拜从这里开始”。我觉得这句slogan没有说完，完整的话术应该是让有才华的年轻人从这里开始享受崇拜。 这句话和今日头条提出的slogan背后含义如出一辙：你创作的，就是头条。 如果说今日头条的头条号平台是释放文字创作者的创造力的话，那么抖音短视频就是为了释放擅长视频拍摄者的创造力。 文字创作平台一开始就是写了无数年文章的中年人的天下，拍摄短视频这项技能，从一开始就掌握在伴随智能手机成长的年轻一代手里。在用手机创作短视频领域，中年人和年轻人并没有因为年龄的差距而有明显的经验差异性，相反年轻人在新事物上还存在更大的创造力。 打开抖音创作，不会有相对年龄比较大的人去选择一首欧美风格的音乐伴奏跳舞一曲。抖音的音乐创作工具，一开始就为了年轻人喜好的音乐风格去设计。 毕竟，音乐很容易切中很多年龄层，但创造力更大概率在年轻人群体手中，那抖音短视频是如何利用年轻人的创造力传播的呢？ 抖音宣传物料非常年轻人 品牌推广初期年轻人喜爱的明星，我们都聊一聊；年轻人喜欢的节目，我们都露露脸。 在所有分析抖音品牌推广的文章里，都会提到小悦悦，我不知道小悦悦的。微博发布是Marketing 推动，还是小悦悦自发的结果。 但是小悦悦实在是一个很好的推广开口，我们只需要仔细想想：小悦悦在现在年轻人中是个什么认知就可以理解，小悦悦的表情包存在于多少年轻人的手机里。 自从小悦悦发布以后，抖音开始窜进一大批年轻人的视野里。接下来的抖音名画H5、中国有嘻哈、快乐大本营、天天向上，包括举办线下活动idou夜，无一不是在疯狂推动这款产品在年轻人中的流行，最终这款产品彻底收服年轻人。 未来业务想象力音乐会吸引更多的声音，短视频也只是一种形式。 如果说从信息形式的角度想业务金字塔，音乐的底层是声音，对于声音这一信息形式的使用，是抖音往下拓根基的一个业务方向。 而我们也在目前的一些热门视频里，看到了基于不同场景带来的声音形式。往上则是音乐产业的想象力，我们以后能看到15s的完整音乐吗？甚至15s的音乐mv，非常期待音乐产业的创造力。 如果从另一个角度——短视频来分析。 短视频自身承载的绝对不仅仅是音乐，而抖音热门里也的确存在不少纯画面、生活中的短小纪录片优质内容，这也是短视频自身存在的多元空间。 从不同角度出发，向上和向下去拓展业务想象力，也给抖音带来了更大的商业合作空间。 想象一下声音是一门多大的生意？画面又是一门多大的生意呢？即使不去拓展这些业务空间，至少在未来推广商，从声音、画面这些角度有了新的合作点。 未来业务的挑战娱乐不俗气？年轻人群体是焦点，但不是世界的全部。 从运营的角度来看：内容生产、内容分发、用户沉淀、转化消费是UGC内容型工具发展的四个阶段。 在内容生产和内容分发的阶段，抖音比今日头条早期更早更快地迎来了人群的爆发，接下来在用户沉淀和转化消费上，如何制定运营策略？是抖音整个运营策略中下一步需要面临的挑战，优秀的运营端的摸索也可能去反哺商业化策略。 从市场角度来看：抖音极具爆发力的发展带来了一个互联网奇迹以外，也带来了很大的挑战。即使把15岁至30岁的年轻人全部收割，这个群体的数量也就约为2.8亿（2013年中国人口数据），这个数量和今日头条自身和快手对比也是不够的。 最大的挑战同时会出现在这群年轻人手里，极具创造力的年轻人必然会释放出强大的传播转化，一旦有更多的非年轻群体用户，开始将这个平台视为另一个快手来娱乐。 那么，在同一块场地，如何平衡打篮球的年轻人和跳广场舞的老年人满足自己的消费需求？这将成为后期内容定调的一个难题。 而且这种趋势已经开始有了萌芽，从最近首页信息流刷出来的抖音内容来看，明显有比年前的内容掉了一个档次。 抖音甩狗头 重新认知今日头条去中心化的背后是给予平等的机会。 抖音的成功既是短视频趋势的，又有音乐这一天才想法的切入点，结合自身团队的能力，能发展到今天，有很多是值得所有人向抖音团队学习的。 同时抖音的发展同时让我重新认知了今日头条，因为今日头条的去中心化的技术分发机制。 我们回过头来再仔细看今日头条对自己的介绍： 《今日头条》是一款基于数据挖掘的推荐引擎产品，它为用户推荐有价值的、个性化的信息，提供连接人与信息的新型服务。 今日头条的本质是：人与信息的连接服务，依靠的是数据挖掘，提供的是个性化有价值的信息。 这句话决定了今日头条没有版面推荐机制、去中心化，给予每个人都可能上热门的机会。每个人创造的自己擅长的内容，将推给和自己有相同喜好的群体。 这一切都来源于去中心化的分发技术。 在阶层流动越来越固化的今天，给予每个人平等的机会这件事儿原本应该是一个顶层设计，但是由于各种原因，这件事儿如果在互联网上最终依靠技术来解决。 其实这才回到了互联网一开始给人无数信心的年代——这个世界是平的。 门户时代的版面位置、头版头条这种代表着少数人控制话语权的时代，已经一去不复返了，留给无数远离北上广的有创造力有才华的年轻人一个念头——即使丝毫不认识互联网企业里的任何一个员工，一个有创造力的年轻人都将在这个平台获得更多的曝光和收入。 年轻人在这里创造，并且在这里收获崇拜，这是抖音。 有才华的人在这里创造内容，并且在这里收获更多的物质和精神满足，这是今日头条。 作者：生椒牛肉，微信：361793303， 微博：@生椒牛肉 链接：https://www.jianshu.com/p/7794f94a8fa7 本文由 @生椒牛肉 授权发布于人人都是产品经理，未经作者许可，禁止转载 转载来源：日刷抖音三百条，让我重新认识今日头条]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>产品运营</tag>
        <tag>移动互联网</tag>
        <tag>今日头条</tag>
        <tag>智能手机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一夜身价暴涨千倍，程序员如何发布自己的 ICO？]]></title>
    <url>%2F2018%2F416073bf%2F</url>
    <content type="text"><![CDATA[ERC20 Token 合约开发现在我们的项目目录大概是这个样子： contracts/- Migrations.solMigrations.sol migrations/ 1_initial_migration.jstest/ package.json truffle-config.js 或 truffle.js 我们在编写智能合约时，需要在 contracts 目录下新建相应的智能合约文件。 在以太坊开发智能合约的编程语言叫做 Solidity (https&#58;//goo.gl/hCHh3w)。它是一种在语法上非常类似 JavaScript 的语言，其后缀名为 .sol 。 例如在这里我们可以创建一个名为 GitCoin.sol 的文件，命令如下。 // *nixtouch GitCoin.sol// wincopy NUL &gt; GitCoin.sol ERC20（Ethereum Request for Comments NO.20）(https&#58;//goo.gl/aX4x5F) 是官方发行的 token 标准。 如果你希望你发布的 token 能够在以太坊网络上流通、上市交易所、支持以太坊钱包，在开发 token 的合约时就必须遵从这一规范。 ERC20 规定了合约中的一系列变量、方法、事件，你可以参考官网教程 Create your own CRYPTO-CURRENCY with Ethereum (https&#58;//www.ethereum.org/token) 当中的示例代码： pragma solidity ^0.4.16; interface tokenRecipient &amp;#123 function receiveApproval(address _from, uint256 _value, address _token, bytes _extraData) public; &amp;#125contract TokenERC20 &amp;#123 // Public variables of the token string public name; string public symbol; uint8 public decimals = 18; // 18 decimals is the strongly suggested default, avoid changing it uint256 public totalSupply; // This creates an array with all balances mapping (address =&gt; uint256) public balanceOf; mapping (address =&gt; mapping (address =&gt; uint256)) public allowance; // This generates a public event on the blockchain that will notify clients event Transfer(address indexed from, address indexed to, uint256 value); // This notifies clients about the amount burnt event Burn(address indexed from, uint256 value); /** * Constrctor function * * Initializes contract with initial supply tokens to the creator of the contract */ function TokenERC20( uint256 initialSupply, string tokenName, string tokenSymbol ) public &amp;#123 totalSupply = initialSupply * 10 uint256(decimals); // Update total supply with the decimal amount balanceOf&#91;msg.sender&#93; = totalSupply; // Give the creator all initial tokens name = tokenName; // Set the name for display purposes symbol = tokenSymbol; // Set the symbol for display purposes &amp;#125 / * Internal transfer, only can be called by this contract */ function _transfer(address _from, address _to, uint _value) internal &amp;#123 // Prevent transfer to 0x0 address. Use burn() instead require(_to != 0x0); // Check if the sender has enough require(balanceOf&#91;_from&#93; &gt;= _value); // Check for overflows require(balanceOf&#91;_to&#93; + _value &gt; balanceOf&#91;_to&#93;); // Save this for an assertion in the future uint previousBalances = balanceOf&#91;_from&#93; + balanceOf&#91;_to&#93;; // Subtract from the sender balanceOf&#91;_from&#93; -= _value; // Add the same to the recipient balanceOf&#91;_to&#93; += _value; Transfer(_from, _to, _value); // Asserts are used to use static analysis to find bugs in your code. They should never fail assert(balanceOf&#91;_from&#93; + balanceOf&#91;_to&#93; == previousBalances); &amp;#125 /** * Transfer tokens * * Send `_value` tokens to `_to` from your account * * &amp;#64;param _to The address of the recipient * &amp;#64;param _value the amount to send */ function transfer(address _to, uint256 _value) public &amp;#123 _transfer(msg.sender, _to, _value); &amp;#125 /** * Transfer tokens from other address * * Send `_value` tokens to `_to` on behalf of `_from` * * &amp;#64;param _from The address of the sender * &amp;#64;param _to The address of the recipient * &amp;#64;param _value the amount to send */ function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) &amp;#123 require(_value &lt;= allowance&#91;_from&#93;&#91;msg.sender&#93;); // Check allowance allowance&#91;_from&#93;&#91;msg.sender&#93; -= _value; _transfer(_from, _to, _value); return true; &amp;#125 /** * Set allowance for other address * * Allows `_spender` to spend no more than `_value` tokens on your behalf * * &amp;#64;param _spender The address authorized to spend * &amp;#64;param _value the max amount they can spend */ function approve(address _spender, uint256 _value) public returns (bool success) &amp;#123 allowance&#91;msg.sender&#93;&#91;_spender&#93; = _value; return true; &amp;#125 /** * Set allowance for other address and notify * * Allows `_spender` to spend no more than `_value` tokens on your behalf, and then ping the contract about it * * &amp;#64;param _spender The address authorized to spend * &amp;#64;param _value the max amount they can spend * &amp;#64;param _extraData some extra information to send to the approved contract */ function approveAndCall(address _spender, uint256 _value, bytes _extraData) public returns (bool success) &amp;#123 tokenRecipient spender = tokenRecipient(_spender); if (approve(_spender, _value)) &amp;#123 spender.receiveApproval(msg.sender, _value, this, _extraData); return true; &amp;#125 &amp;#125 /** * Destroy tokens * * Remove `_value` tokens from the system irreversibly * * &amp;#64;param _value the amount of money to burn */ function burn(uint256 _value) public returns (bool success) &amp;#123 require(balanceOf&#91;msg.sender&#93; &gt;= _value); // Check if the sender has enough balanceOf&#91;msg.sender&#93; -= _value; // Subtract from the sender totalSupply -= _value; // Updates totalSupply Burn(msg.sender, _value); return true; &amp;#125 /** * Destroy tokens from other account * * Remove `_value` tokens from the system irreversibly on behalf of `_from`. * * &amp;#64;param _from the address of the sender * &amp;#64;param _value the amount of money to burn */ function burnFrom(address _from, uint256 _value) public returns (bool success) &amp;#123 require(balanceOf&#91;_from&#93; &gt;= _value); // Check if the targeted balance is enough require(_value &lt;= allowance&#91;_from&#93;&#91;msg.sender&#93;); // Check allowance balanceOf&#91;_from&#93; -= _value; // Subtract from the targeted balance allowance&#91;_from&#93;&#91;msg.sender&#93; -= _value; // Subtract from the sender’s allowance totalSupply -= _value; // Update totalSupply Burn(_from, _value); return true; &amp;#125&amp;#125 我只是想割韭菜而已，用得着写几百行代码吗？ 当然不必，这时我们就需要使用到智能合约开发框架 OpenZeppelin (https&#58;//openzeppelin.org)，安装命令如下。 npm install zeppelin-solidity –save GitCoin.sol 引入 OpenZeppelin，代码如下。 // 声明 solidity 编译版本pragma solidity ^0.4.18;// 引入框架为我们提供的编写好的 ERC20 Token 的代码import “zeppelin-solidity/contracts/token/StandardToken.sol”;// 通过 is 关键字继承 StandardTokencontract GitToken is StandardToken &amp;#123 string public name = “GitToken”; // Token 名称 string public symbol = “EGT”; // Token 标识 例如：ETH/EOS uint public decimals = 18; // 计量单位，和 ETH 保持一样就设置为 18 uint public INITIAL_SUPPLY = 10000 * (10 ** decimals); // 初始供应量 // 与 contract 同名的函数为本 contract 的构造方法，类似于 JavaScript 当中的 constructor function GitToken() &amp;#123 totalSupply = INITIAL_SUPPLY; // 设置初始供应量 balances&#91;msg.sender&#93; = INITIAL_SUPPLY; // 将所有初始 token 都存入 contract 创建者的余额 &amp;#125&amp;#125 好了，至此一个可以用来交易的符合 ERC20 标准的 token 就编写完毕了。 就这么简单？就这么简单！当然智能合约的功能不止如此，token 中可以玩转设计的地方也不止这些。 不过我们要稍微放在后面一些来讨论，接下来还是赶快着手 ICO 合约开发，为我们的项目募集资金吧。 ICO Crowdsale 合约开发同样，以太坊官网文档在教程 CROWDSALE Raising funds from friends without a third party (https&#58;//www.ethereum.org/crowdsale) 中也为我们提供了用来 crowdsale 做 ICO 募资的示例代码： pragma solidity ^0.4.18;/** interface 的概念和其他编程语言当中类似，在这里相当于我们可以通过传参引用之前发布的 token 合约 我们只需要使用其中的转账 transfer 方法，所以就只声明 transfer/interface token &amp;#123 function transfer(address receiver, uint amount);&amp;#125contract Crowdsale &amp;#123 // 这里是发布合约时需要传入的参数 address public beneficiary; // ICO 募资成功后的收款方 uint public fundingGoal; // 骗多少钱 uint public amountRaised; // 割到多少韭菜 uint public deadline; // 割到啥时候 / 卖多贵，即你的 token 与以太坊的汇率，你可以自己设定 注意到，ICO 当中 token 的价格是由合约发布方自行设定而不是市场决定的 也就是说你项目值多少钱你可以自己编/uint public price;token public tokenReward; // 你要卖的 tokenmapping(address =&gt; uint256) public balanceOf;bool fundingGoalReached = false; // 是否达标bool crowdsaleClosed = false; // 售卖是否结束/ 事件可以用来记录信息，每次调用事件方法时都能将相关信息存入区块链中 可以用作凭证，也可以在你的 Dapp 中查询使用这些数据/event GoalReached(address recipient, uint totalAmountRaised);event FundTransfer(address backer, uint amount, bool isContribution); / Constrctor function* Setup the owner/function Crowdsale(address ifSuccessfulSendTo,uint fundingGoalInEthers,uint durationInMinutes,uint etherCostOfEachToken,address addressOfTokenUsedAsReward) &amp;#123beneficiary = ifSuccessfulSendTo;fundingGoal = fundingGoalInEthers 1 ether;deadline = now + durationInMinutes 1 minutes;price = etherCostOfEachToken 1 ether;tokenReward = token(addressOfTokenUsedAsReward); // 传入已发布的 token 合约的地址来创建实例&amp;#125 /** Fallback function* payable 用来指明向合约付款时调用的方法*/function () payable &amp;#123 require(!crowdsaleClosed);uint amount = msg.value;balanceOf&#91;msg.sender&#93; += amount;amountRaised += amount;tokenReward.transfer(msg.sender, amount / price);FundTransfer(msg.sender, amount, true);&amp;#125 /** modifier 可以理解为其他语言中的装饰器或中间件 当通过其中定义的一些逻辑判断通过之后才会继续执行该方法 _ 表示继续执行之后的代码/modifier afterDeadline() &amp;#123 if (now &gt;= deadline) _; &amp;#125 / Check if goal was reached* Checks if the goal or time limit has been reached and ends the campaign*/function checkGoalReached() afterDeadline &amp;#123 if (amountRaised &gt;= fundingGoal)&amp;#123fundingGoalReached = true; GoalReached(beneficiary, amountRaised); &amp;#125crowdsaleClosed = true;&amp;#125 /** Withdraw the funds* Checks to see if goal or time limit has been reached, and if so, and the funding goal was reached, sends the entire amount to the beneficiary. If goal was not reached, each contributor can withdraw the amount they contributed.*/function safeWithdrawal() afterDeadline &amp;#123 if (!fundingGoalReached) &amp;#123uint amount = balanceOf&amp;#91;msg.sender&amp;#93;; balanceOf&amp;#91;msg.sender&amp;#93; = 0; if (amount &gt; 0) &amp;#123 if (msg.sender.send(amount)) &amp;#123 FundTransfer(msg.sender, amount, false); &amp;#125 else &amp;#123 balanceOf&amp;#91;msg.sender&amp;#93; = amount; &amp;#125 &amp;#125 &amp;#125 if (fundingGoalReached &amp;&amp; beneficiary == msg.sender) &amp;#123 if (beneficiary.send(amountRaised)) &amp;#123 FundTransfer(beneficiary, amountRaised, false); &amp;#125 else &amp;#123 //If we fail to send the funds to beneficiary, unlock funders balance fundingGoalReached = false; &amp;#125 &amp;#125&amp;#125&amp;#125 至此我们的 ICO 合约也开发完毕了，基本上一行代码都没有写，只是改了几个参数，一个键盘上只有三个按键的程序员都能够完成这类智能合约的开发，没有比这更友好的编程体验了。 虽然 solidity 是一种非图灵完备的编程语言，但我们仍然能够用它编写许多逻辑。 上述的 ICO 示例代码写得算比较客气的一种，在最后的提款方法中，如果筹资达标，ICO 发布方则可以取走所有筹款，而如果未达标，参与者则能够取回自己的投资，由合约来持有所有款项。 但事实上，我们仍然可以随意修改其中的逻辑，看下面代码。 function () payable &amp;#123 require(!crowdsaleClosed); uint amount = msg.value; balanceOf&#91;msg.sender&#93; += amount; amountRaised += amount; tokenReward.transfer(msg.sender, amount / price); // 每次有人付款直接取走筹资 beneficiary.send(amountRaised); amountRaised = 0; FundTransfer(msg.sender, amount, true);&amp;#125// 删除剩余代码 补充说明与权限控制既然咱是铁了心来割韭菜的，如此简单的代码怎么能够满足咱的贪欲呢？一定要学比特币固定供给量吗？ 我是来卖 token 的呀，万一有一天卖完了怎么办，万一有人手里筹码比我自己都多了控盘怎么办，万一发的数量太多卖的不好怎么办？ 事实上解决这些问题的逻辑全部都可以写在智能合约里。 Ownable token 在我们的潜在观念里，区块链自有不可变属性。 这种不可变属性在一些狂热信徒的演绎当中变成了平权属性，甚至带有了共产主义色彩，仿佛拥抱区块链技术就能够为未来的人类文明带来希望，把人民从集权的手中解救出来。 然而事实上这种不可变性同样是两面的，它能够带来的也包括所有权的不可变性。 ERC20 标准只规定了我们的合约中应该包含哪些方法，而没有限制合约中不能出现哪些方法，因此在之前的基础上，我们还可以继续编写一些特殊的方法，赋予合约发布者一些管理员特权。 请看下面代码： contract Ownable &amp;#123 address public owner; function Ownable() public &amp;#123 owner = msg.sender; &amp;#125 // 通过 onlyOwner 我们可以限定一些方法只有所有者才能够调用 modifier onlyOwner &amp;#123 require(msg.sender == owner); _; &amp;#125 function transferOwnership(address newOwner) onlyOwner public &amp;#123 owner = newOwner; &amp;#125&amp;#125// 合约可以同时有多个继承contract GitToken is StandardToken, Ownable &amp;#123 … MintableToken 接下来我们来解决 token 不够卖的问题，万一我的 initial offer 卖断货了怎么办，万一我卖完一次还想卖怎么办？ 这时我们就需要把 token 编写成为 MintableToken，在我们想增发的时候就能增发，代码如下： // 用 onlyOwner 限定只有 token 的所有者才能够进行增发操作function mint(address _to, uint256 amount) onlyOwner public returns (bool) &amp;#123 totalSupply = totalSupply_.add(_amount); balances&#91;_to&#93; = balances&#91;_to&#93;.add(_amount); Mint(_to, _amount); Transfer(address(0), _to, _amount); return true;&amp;#125 BurnableToken 万一我们的 token 不小心发了太多，卖的时间久了贬值怎么办？ 当然是销毁了，可参照下面代码： /** Destroy tokens* Remove _value tokens from the system irreversibly* &#64;param _value the amount of money to burn*/function burn(uint256 _value) public returns (bool success) &amp;#123 require(balanceOf&#91;msg.sender&#93; &gt;= _value); // Check if the sender has enoughbalanceOf&#91;msg.sender&#93; -= _value; // Subtract from the sendertotalSupply -= _value; // Updates totalSupplyBurn(msg.sender, _value); return true;&amp;#125 万一有人手里的筹码太多，或者 token 被竞争对手买走了怎么办？没关系，我们还可以指定销毁某一账户中的 token，请看下面代码： /** Destroy tokens from other account* Remove _value tokens from the system irreversibly on behalf of _from.* &#64;param _from the address of the sender &#64;param _value the amount of money to burn*/function burnFrom(address _from, uint256 _value) public returns (bool success) &amp;#123 require(balanceOf&#91;_from&#93; &gt;= _value); // Check if the targeted balance is enoughrequire(_value &lt;= allowance&#91;_from&#93;&#91;msg.sender&#93;); // Check allowancebalanceOf&#91;_from&#93; -= _value; // Subtract from the targeted balanceallowance&#91;_from&#93;&#91;msg.sender&#93; -= _value; // Subtract from the sender’s allowancetotalSupply -= _value; // Update totalSupplyBurn(_from, _value); return true;&amp;#125 只要上述的方法全部都出现在合约里，我们发布的 token 就能够具备上述所有属性。 这样一来，不够的时候我们可以发钱，发多了可以销毁，我们成功创建了属于自己的一所中央银行，甚至看某人不爽还能够指定销毁其账户存款，这哪里是平权，简直是超级集权。 而事实上，在已发布的 ERC20 token 当中，例如排名第一的 EOS 的合约 (https&#58;//goo.gl/L2AmQP) 里也是存在类似方法的，如下所示。 function mint(uint128 wad) auth stoppable note &amp;#123 _balances&#91;msg.sender&#93; = add(_balances&#91;msg.sender&#93;, wad); _supply = add(_supply, wad);&amp;#125function burn(uint128 wad) auth stoppable note &amp;#123 _balances&#91;msg.sender&#93; = sub(_balances&#91;msg.sender&#93;, wad); _supply = sub(_supply, wad);&amp;#125 当然在其官方网站和白皮书中是标明了会发布多少 token，创始团队持有多少，投资人分配多少，公开发布多少，如何销毁等内容的。 但白皮书又不具备法律效力，token 的所有权也不在你手里，万一人家哪天想要跑路或者中途变卦岂是咱能拦得住的。 换个角度讲，假如你现在手里有一家可以印钱的公司，印多少就有多少，你印还是不印？ 通过这一部分内容的介绍，我只是想要证明，智能合约本身并不具备可无条件信任的特性，充其量就是一段没法改一直跑的程序而已。 你也可以在逻辑中加入管理员权限，token 的发布方并不比央行可信多少，只要所有者愿意可以随时进行修改。以太坊官方宣传的所谓 “trustless” 这一概念根本不成立。 没有第三方担保，没有法律法规的维护，仅凭智能合约本身你的投资得不到任何保证。智能合约的不可变性反而给割韭菜的一方提供了巨大的便利。 从前你看不惯某家公司还能够黑掉它的系统，获取管理员权限，如今所有程序都跑在区块链上，黑无可黑，集权永远都在合约发布者的手里。 讲到这里，希望你能理解这次分享的良苦用心，不要轻信任何 ICO 项目。 合约的发布及调试本地开发环境发布 合约开发完成之后，我们需要编译并发布合约至区块链网络中，只需要进行以下两步操作。 首先在 migrations 文件夹下新建 2-deploy-contract.js 文件，配置部署脚本如下。 // 引入我们编写的合约const GitCoin = artifacts.require(“./GitCoin.sol”)const GitCoinCrowdsale = artifacts.require(“./GitCoinCrowdsale.sol”)module.exports = function(deployer, network, accounts) &amp;#123 // 设定参数，此处的参数即使传入合约构造方法的参数，与你自己编写的合约保持一致 const ifSuccessfulSendTo = accounts&#91;0&#93; // 当前以太坊网络中的默认账户 const fundingGoalInEthers = 1000 const durationInMinutes = 36000000 const etherCostOfEachToken = 0.01 // 这里的 Promise 可以保证我们在发布完 token 合约之后再发布 ICO 合约，并将已发布 token 的地址作为参数传入 deployer.deploy(GitCoin).then(function() &amp;#123 return deployer.deploy(GitCoinCrowdsale, ifSuccessfulSendTo, fundingGoalInEthers, durationInMinutes, etherCostOfEachToken, GitCoin.address); &amp;#125);&#125; 接着在 truffle-config.js 或 truffle.js 中设置发布网络，脚本如下。 module.exports = &amp;#123 networks&#58; &amp;#123 development&#58; &amp;#123 host&#58; “127.0.0.1”, port&#58; 7545, // 与你本地的 ganache 设置保持一致 network_id&#58; “*” // Match any network id &amp;#125 &amp;#125&#125; 现在只需要开启 Ganache： 然后在命令行中输入： truffle compiletruffle migrate 你的合约就会顺利发布至测试网络中了。然后你可以输入： truffle console 这样就能够进入本地的命令行调试了： 所有的合约方法都是 Promise 对象truffle(development)&gt; GitCoinCrowdsale.deployed().then(inst=&gt;&amp;#123crowd=inst&amp;#125)truffle(development)&gt; GitCoin.deployed().then(inst=&gt;&amp;#123git=inst&amp;#125)truffle(development)&gt; crowd.sendTransaction(&amp;#123from&#58;web3.eth.accounts&#91;0&#93;,value&#58;web3.toWei(1, “ether”)&amp;#125)truffle(development)&gt; git.mint(web3.eth.accounts&#91;0&#93;,web3.toWei(100, “ether”)) 线上测试网络发布 以太坊网络分为测试网和主网，在正式发布主网之前，我们可以先发送到测试网络进行调试。 发布至以太坊网络也无需同步完整节点，我们可以使用 Infura 为我们提供的公共接口。 填写表单提交后，Infura 会为你提供专用的接口地址，然后我们只需要将网络地址填入到配置文件中，如下所示。 var HDWalletProvider = require(“truffle-hdwallet-provider”); // 在这里我们需要通过 js 调用以太坊钱包，通过 npm install truffle-hdwallet-provider 安装这个库var infura_apikey = “ubQWERwasd”; // infura 为你提供的 apikey 请与你申请到的 key 保持一致，此处仅为示例var mnemonic = “apple banana carray dog egg fault great”; // 你以太坊钱包的 mnemonic ，可以从 Metamask 当中导出，mnemonic 可以获取你钱包的所有访问权限，请妥善保存，在开发中切勿提交到 gitmodule.exports = &amp;#123 networks&#58; &amp;#123 development&#58; &amp;#123 host&#58; “127.0.0.1”, port&#58; 7545, network_id&#58; “*” &amp;#125, ropsten&#58; &amp;#123 provider&#58; function() &amp;#123 return new HDWalletProvider(mnemonic, “https&#58;//ropsten.infura.io/“+infura_apikey) &amp;#125, network_id&#58; 3, gas&#58; 3012388, gasPrice&#58; 30000000000 &amp;#125, main&#58; &amp;#123 provider&#58; function() &amp;#123 return new HDWalletProvider(mnemonic, “https&#58;//mainnet.infura.io/“+infura_apikey) &amp;#125, network_id&#58; 3, gas&#58; 3012388, gasPrice&#58; 1000000000 &amp;#125 &amp;#125&#125; 在以太坊网络中发布合约需要使用 ETH 支付矿工的 gas 费用，你可以在 Ethereum Ropsten Faucet (http&#58;//faucet.ropsten.be&#58;3001) 免费获取到用于 Ropsten 测试网络的 ETH。 由于网络环境的变化，不同的拥堵状况可能造成燃料费用和消耗的不同。 如果发布不成功，可以调整 gas/gasPrice 的数值，你可以通过 web3.getBlock(&#39;latest&#39;).gasLimit 这一数值判断当前网络的消耗。 在命令行输入如下命令： truffle migrate –network ropsten 通过 --network 设置发布的目标网络。 主网络发布 同理，在发布至主网络时，只需要执行如下命令。 truffle migrate –network main 但由于当前的以太坊网络的现实状况，如果设置燃料费太低，可能要等待数天后合约才会被网络确认，注意到我们编写的发布脚本是需要合约地址回调的。 介于这种状况，我们可以将 token 合约和 crowdsale 合约分开发布，只需要再新建 3-deploy-crowdsale.js 文件，脚本如下。 const LeekCoinCrowdsale = artifacts.require(“./GitCoinCrowdsale.sol”)module.exports = function(deployer, network, accounts) &amp;#123 const ifSuccessfulSendTo = accounts&#91;0&#93; const fundingGoalInEthers = 1000 const durationInMinutes = 36000 const etherCostOfEachToken = 0.01 const tokenAddress = ‘0x123456789ABCDFGHSDWDVC’ // 先单独发布 token 合约，上线成功后将其合约地址填在此处 deployer.deploy(GitCoinCrowdsale, ifSuccessfulSendTo, fundingGoalInEthers, durationInMinutes, etherCostOfEachToken, tokenAddress);&#125; 在发布至主网络时，可以分开两次进行，确保你设置的账户里有真实的 ETH 余额，注意设置好合理的 gas 数值，根据确认时间的长短，可能需要 0.08~1 ETH 不等。 上线合约验证无论是发布至以太坊的测试网络还是主网络，在发布完成之后都需要在 Etherscan (https&#58;//etherscan.io) 进行线上验证。 在 Etherscan 上打开你刚刚发布的合约地址，你可以看到如下内容： 点击 Verify And Publish 链接就可以进入验证页面： 在填写表单时有以下注意事项。 Compiler 选择最新版本；1. Optimization 选择 No。Optimization 选择 No。 虽然 solidity 支持 import 语法，但 Etherscan 对使用 import 进行开发的合约支持很鸡肋，目前它要求你需要把库文件也当作合约发布至网络才能够在表单中填写进行验证。 当然我们也可以选择手动把 import 库文件的内容手动复制粘贴到代码框里，注意要保留全部内容，包括 pragma 声明一行。 当然你也可以选择使用官方的 Remix (https&#58;//remix.ethereum.org/) 预先 concrete 你的合约文件，也可以安装 solidity compiler (https&#58;//goo.gl/aKsXxH) 在本地编译好再发布。 ICO 和 token 的合约如此简单，根本不需要这些玩意儿，所以此处不再赘述，感兴趣的同学可以自行研究。 Dapp 开发智能合约相当于我们的后端逻辑，以太坊的 EVM 就是我们的云服务器，Infura 为我们提供 API 接口，接下来我们就只需要给韭菜开发一个可以花钱消费的前端界面了。 ICO 项目的网站把握以下几个原则就好。 文字不要太多，页面要大片留白，简洁明了有现代感；1. 配色一定要深，加上动态几何图形，设计要有未来感；1. 开发团队全配齐，不是常春藤，没有硅谷背景的不要，一定要国际化；1. 各种站台大佬，海量媒体报道，一线互联网公司合作全放上去。配色一定要深，加上动态几何图形，设计要有未来感； 各种站台大佬，海量媒体报道，一线互联网公司合作全放上去。 言归正传，我们还是专注于技术。 web3.js 的使用web3.js (https&#58;//github.com/ethereum/web3.js) 为我们提供了一系列访问以太坊网络的 JavaScript 编程接口，完整的说明文档可以在 web3.js Doc (https&#58;//goo.gl/zp2yEQ) 中参阅。 我们一般通过如下脚本来初始化 web3 对象。 // 判断当前浏览器中有未注入 web3 对象if (typeof web3 !== ‘undefined’) &amp;#123 App.web3Provider = web3.currentProvider; web3 = new Web3(web3.currentProvider);&amp;#125 else &amp;#123 // 注意设置到你自己的 infura 地址 App.web3Provider = new Web3.providers.HttpProvider(‘https&#58;//ropsten.infura.io/ubQWERawsd’); web3 = new Web3(App.web3Provider);&amp;#125 Metamask 简介Metamask (https&#58;//metamask.io) 是一个浏览器插件，通过 Metamask 我们可以在浏览器中使用以太坊钱包，在访问 Dapp 应用时，也可以为其注入 web3 对象。 具体配合应用开发的文档可以在 MetaMask Compatibility Guide (https&#58;//goo.gl/7wKPtp) 查阅，一般我们通过如下脚本来监测 Metamask 状态获取以太坊账户。 var account = web3.eth.accounts&#91;0&#93;;var accountInterval = setInterval(function() &amp;#123 if (web3.eth.accounts&#91;0&#93; !== account) &amp;#123 account = web3.eth.accounts&#91;0&#93;; updateInterface(); &amp;#125&amp;#125, 100); truffle-contract 的使用web3.js 默认为我们提供的接口还是太底层，许多调用需要 hard code 设置参数，以太坊网络使用的 BigNumber 也需要我们手动转换。 我们可以选择使用 truffle-contract (https&#58;//github.com/trufflesuite/truffle-contract) 来调用更高一层的封装对象，并且在之前使用 truffle 开发构建的智能合约文件也能派上用场。 我们可以在 build/contracts/ 下找到编译好的 GitCoin.json 和 GitCoinCrowdsale.json 文件，之后可以在我们的应用中通过如下脚本获取合约对象。 var GitCoin; $.getJSON('contracts/GitCoin.json', function(data) &#123 // 获取编译好的合约文件 var GitCoinArtifact = data; // 通过 truffle-contract 获取合约对象 GitCoin = TruffleContract(GitCoinArtifact); // 将合约绑定至当前 web3 对象 GitCoin.setProvider(App.web3Provider); &#125); 之后我们就可以像在 truffle console 当中一样，对合约对象进行各种操作啦。 ICO 前端应用开发我们的 ICO 应用只需要解决一个核心需求，那就是买币；只需要两个核心功能，一个是选择买多少，另一个就是付款，所以我们的界面自然是相当简单，如下图所示。 然后再稍微美化一下，如下面两张图所示。 一场成功的 ICO，自然需要精雕细琢，完整的代码示例可以在 Leek Ecological Chain (http&#58;//lec.yubolun.com/) 找到，同时此网站也是上述教程的一个完整示例，你可以切换到 Ropsten 网络在本网站上购买 LEC (https&#58;//goo.gl/4uNskB) 韭菜币。 Dapp 部署既然我们开发的是 Dapp 去中心化应用，怎么能够部署在中心化的服务器上呢？这不是自掉身价吗？Dapp 自然有其部署的解决方案。 IPFS 简介IPFS 提供去中心化的点对点的 Web 服务。 说简单点，你可以把它理解成为一个 p2p 的网盘，你网站的静态文件可以发布到 IPFS 上面托管，而且只要 IPFS 的节点不挂，你的网站就永远都不会挂，而不像部署到单独服务器上。 同时 IPFS 上的一个文件也就对应着一个 hash 地址，普通用户可以通过公共的 http gateway 访问到你的页面，不像云服务器还要备案，正好也方便你割完韭菜跑路。 使用也非常简单，只需要在 Install Go IPFS (https&#58;//ipfs.io/docs/install) 下载安装。 发布应用只需要一行命令，把你 Dapp 的所有静态文件上传至 IPFS，命令如下。 ipfs add -r your-ico/# 返回 hash 地址，此处仅为示例added QWERabcd1234qwerABCD your-ico/ 然后你就能够通过 https&#58;//goo.gl/5SyBwN 访问你的网站。当然这样的域名十分不友好，为 IPFS 站点设置解析需要一些不常用的操作。 域名解析IPNS 你的站点必然包含多个文件，每个文件对应着独立的 hash 地址，而且你也不能保证你的网站只需要发布一次。 因此在网站发布后，我们需要使用 ipns 来获取到对应的唯一地址，之后的 DNS 解析也会对应到这一地址，同样只需要一行命令，如下所示。 站点发布后的 hash 地址，此处仅为示例ipfs name publish QWERabcd1234qwerABCD# 返回 ipns 地址Published to ABCDqwer1234abcdQWER之后你就能够通过 https&#58;//goo.gl/8YMLBi 访问你的站点了。在设置域名解析时，我们需要添加一条 TXT 类型的解析记录，解析值为： dnslink=/ipns/ABCDqwer1234abcdQWER 这样我们就能够通过 https&#58;//goo.gl/VjSm1K 访问你的 Dapp，这样是不是友好多了？ Nginx 反向代理 当然你也可能希望使用自己的独立域名，这时我们只需要使用 Nginx 设置反向代理即可。 server &amp;#123 listen 80; server_name yourico.com; location / &amp;#123 proxy_pass https&#58;//ipfs.io/ipns/yourico.com/; &amp;#125&amp;#125 写在后面以太坊官网，第一篇教程教你发 token，第二篇就教你卖 token，居心何在我也不好评判。 除了 ICO 还有 IMO/IFO ，IMO 你只用卖个路由器，IFO 只需要 fork 一份 Bitcoin 的代码，稍微调调参数，就不需要什么教程了。 程序员总是妄图通过技术手段解决社会问题，然而人性是不变的。以太坊希望建立一个 trustless 的网络，可惜被无数人滥用，巧立空气项目，搞空壳公司，逃避监管搞非法集资。 区块链和虚拟货币期望用点对点分布式的网络，脱离第三方，让世界上任何角落的两个人都能够低成本地进行交易，结果大量投机者涌入，导致网络堵塞，如今我们连一笔交易的矿工费都支付不起。 当然我信奉技术本身是无罪，就好像这篇教你割韭菜的文章一样，你是选择擦亮双眼，看清 ICO 的本质，从此势不两立；还是选择投机倒把，滥用以太坊技术，坠身同流合污？ 您可以在访问 https&#58;//github.com/discountry/gitcoin 查看完整的智能合约示例。 您可以访问 https&#58;//github.com/discountry/lec 查看完整的 Dapp 示例。 Read at your own risk. ————— 推荐阅读 ————— 点击图片即可阅读 &#91;&#93;(http&#58;//mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650694375&amp;idx=1&amp;sn=3b4bb615c18838cd9d858dfb1d4b49b1&amp;chksm=bea6133489d19a225d3ec5e02191bb53003bad618fa11fb1066ec3a98f9408bf585bbd573fec&amp;scene=21#wechat_redirect) &#91;&#93;(http&#58;//mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650694364&amp;idx=1&amp;sn=f6c6a74903d10c2a57782f7bad157440&amp;chksm=bea6130f89d19a192aaac7397b14ccf6a07941ebada94780ea6183b60639578e12d9566cea94&amp;scene=21#wechat_redirect) &#91;&#93;(http&#58;//mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650694362&amp;idx=1&amp;sn=c02759d5519c7ea7e4f47700a81cfea3&amp;chksm=bea6130989d19a1fcfa0628a16618497425688cbd897238e92bc8c7af543d645c9d04fdda0af&amp;scene=21#wechat_redirect) 转载来源：一夜身价暴涨千倍，程序员如何发布自己的 ICO？]]></content>
      <tags>
        <tag>CSDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[扒一扒装修行业的骗局（附实用装修建议）]]></title>
    <url>%2F2018%2F7a75ebea%2F</url>
    <content type="text"><![CDATA[扒一扒装修行业的骗局（附实用装修建议） 转载来源：扒一扒装修行业的骗局（附实用装修建议）]]></content>
      <tags>
        <tag>缓缓说</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用文本挖掘实现站点个性化推荐]]></title>
    <url>%2F2018%2F7bb4adc9%2F</url>
    <content type="text"><![CDATA[使用文本挖掘实现站点个性化推荐 转载来源：使用文本挖掘实现站点个性化推荐]]></content>
      <tags>
        <tag>CSDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【Python】IPFS的Python接口 - CSDN博客]]></title>
    <url>%2F2018%2F61075f30%2F</url>
    <content type="text"><![CDATA[相关库 pip install ipfsapi 参考地址：&#91;https&#58;//github.com/ipfs/py-ipfs-api&#93;(https&#58;//github.com/ipfs/py-ipfs-api) 接口示例12345678910111213141516171819202122232425262728293031323334353637import ipfsapi# 连接IPFS，需要先启动节点服务器daemonapi = ipfsapi.connect(&apos;127.0.0.1&apos;, 5001)# 查看节点IDapi.id()&amp;#123&apos;Addresses&apos;&amp;#58; &amp;#91;&apos;/ip4/127.0.0.1/tcp/4001/ipfs/QmS2C4MjZsv2iP1UDMMLCYqJ4WeJw8n3vXx1VKxW1UbqHS&apos;, &apos;/ip6/&amp;#58;&amp;#58;1/tcp/4001/ipfs/QmS2C4MjZsv2iP1UDMMLCYqJ4WeJw8n3vXx1VKxW1UbqHS&apos;&amp;#93;, &apos;AgentVersion&apos;&amp;#58; &apos;go-ipfs/0.4.10&apos;, &apos;ID&apos;&amp;#58; &apos;QmS2C4MjZsv2iP1UDMMLCYqJ4WeJw8n3vXx1VKxW1UbqHS&apos;, &apos;ProtocolVersion&apos;&amp;#58; &apos;ipfs/0.1.0&apos;, &apos;PublicKey&apos;&amp;#58; &apos;CAASpgIwgg ... 3FcjAgMBAAE=&apos;&amp;#125# 上传文件res = api.add(&apos;test.txt&apos;)&amp;#123&apos;Hash&apos;&amp;#58; &apos;QmWxS5aNTFEc9XbMX1ASvLET1zrqEaTssqt33rVZQCQb22&apos;, &apos;Name&apos;&amp;#58; &apos;test.txt&apos;&amp;#125# 上传目录res = api.add(&apos;fake_dir&apos;, recursive=True)&amp;#91;&amp;#123&apos;Hash&apos;&amp;#58; &apos;QmQcCtMgLVwvMQGu6mvsRYLjwqrZJcYtH4mboM9urWW9vX&apos;, &apos;Name&apos;&amp;#58; &apos;fake_dir/fsdfgh&apos;&amp;#125, &amp;#123&apos;Hash&apos;&amp;#58; &apos;QmNuvmuFeeWWpxjCQwLkHshr8iqhGLWXFzSGzafBeawTTZ&apos;, &apos;Name&apos;&amp;#58; &apos;fake_dir/test2/llllg&apos;&amp;#125, &amp;#123&apos;Hash&apos;&amp;#58; &apos;QmX1dd5DtkgoiYRKaPQPTCtXArUu4jEZ62rJBUcd5WhxAZ&apos;, &apos;Name&apos;&amp;#58; &apos;fake_dir/test2&apos;&amp;#125, &amp;#123&apos;Hash&apos;&amp;#58; &apos;Qmenzb5J4fR9c69BbpbBhPTSp2Snjthu2hKPWGPPJUHb9M&apos;, &apos;Name&apos;&amp;#58; &apos;fake_dir&apos;&amp;#125&amp;#93;# 查看文件内容res = api.cat(&apos;QmWxS5aNTFEc9XbMX1ASvLET1zrqEaTssqt33rVZQCQb22&apos;)&gt;&gt; hello ipfs!# 下载文件res = api.get(&apos;QmWxS5aNTFEc9XbMX1ASvLET1zrqEaTssqt33rVZQCQb22&apos;) 转载来源：【Python】IPFS的Python接口 - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[您要找的页面不存在 - 简书]]></title>
    <url>%2F2018%2F7ee06b97%2F</url>
    <content type="text"><![CDATA[您要找的页面不存在 - 简书 转载来源：您要找的页面不存在 - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[以太坊中的账户、交易、Gas和区块Gas Limit » 论坛 » EthFans | 以太坊爱好者]]></title>
    <url>%2F2018%2F7fbcbb4a%2F</url>
    <content type="text"><![CDATA[以太坊中的账户、交易、Gas和区块Gas Limit » 论坛 » EthFans | 以太坊爱好者 转载来源：以太坊中的账户、交易、Gas和区块Gas Limit » 论坛 » EthFans | 以太坊爱好者]]></content>
  </entry>
  <entry>
    <title><![CDATA[Google收购Kaggle！拿下最大机器学习及数据竞赛平台]]></title>
    <url>%2F2018%2F85d36b57%2F</url>
    <content type="text"><![CDATA[李林 舒石 编译整理 量子位·QbitAI 出品 全球最大的机器学习及数据科学竞赛平台Kaggle，即将被Google收入囊中。来自TechCrunch的消息透露，虽然这项收购的细节尚未披露，但基本确定会在明天召开的Google旧金山Cloud Next大会上对外宣布。 至于这两家对收购传闻的态度，Google依然是“不对传闻置评”，TechCrunch电话联系了Kaggle联合创始人、CEO Anthony Goldbloom，他的反应是“拒绝否认这项收购（declined to deny that the acquisition is happening）”。 Kaggle是2010年由Goldbloom和Ben Hamner联合创立的，现在平台上大约有100万名数据科学家，基本上可以说是举办数据科学和机器学习竞赛的不二之选。 月初，Google也用上了这个平台，他们在Kaggle上举办的YouTube视频分类比赛《Google Cloud &amp; YouTube-8M Video Understanding Challenge》依然在进行中，总奖金额10万美元，有235支队伍参与。这个比赛的目标，是更好的用算法对视频进行等级分类。 这个比赛所用的数据集，就是YouTube发布的700多万部YouTube视频，平均每个视频已经打上3.4个标签。比赛和Google云计算平台也有着密切的关联。 目前在Kaggle上奖金最高的比赛是《Data Science Bowl 2017》，总奖金额100万美元，目前有1377支队伍参与角逐。今年的主题是如何通过大数据和人工智能的方式，可以更早的对美国肺癌患者进行确诊以及展开干预。 比赛的数据集，是美国国家癌症研究所提供的数千组高分辨率肺部扫描数据。 Kaggle上参赛最多的挑战是《Titanic: Machine Learning from Disaster》。这个项目要求参赛者使用机器学习的工具，对泰坦尼克号上的乘客船员进行生存几率预测。其实这是Kaggle的一个入门挑战，适用于新手或者刚入门的数据科学家。 虽然Kaggle所处的行业竞争也很激烈，DrivenData、TopCoder、HackerRank等对手虎视眈眈，Kaggle依然借先发优势和对细分领域的专注保持着领先地位。 Google这次收购看中的可能是Kaggle的用户群体而非技术。这次收购，可以说是买下了最大、最活跃的数据科学家社区，Google能够借此提升这个人群的关注度。通过TensorFlow等开源项目，Google在做的也是这样的事情。 从TechCrunch获得的消息来看，Google会在收购后维持Kaggle平台的运营，保持原有品牌。 和其他竞赛平台一样，Kaggle上也有求职公告板，不知道Google对这一部分打算如何处置。 Kaggle自2010年成立以来，总共融资1250万美元（数据来自Crunchbase，另一家创投数据库PitchBook显示是1275万美元），投资方包括Index Ventures，SV Angel，Max Levchin，Naval Ravikant，Google首席经济学家Hal Varian，Khosla Ventures和尤里·米尔纳。 今天AI还搞了哪些大新闻？ 在量子位（QbitAI）公众号会话界面回复“今天”，看我们全网搜罗的AI新鲜资讯。比心❤~ 转载来源：Google收购Kaggle！拿下最大机器学习及数据竞赛平台]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>Kaggle</tag>
        <tag>YouTube</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊白皮书（原版译文） - 简书]]></title>
    <url>%2F2018%2F91ffc5b0%2F</url>
    <content type="text"><![CDATA[以太坊白皮书（原版译文） - 简书 转载来源：以太坊白皮书（原版译文） - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[npm 发布 2017 JavaScript 框架报告]]></title>
    <url>%2F2018%2F0626ec87%2F</url>
    <content type="text"><![CDATA[npm 发布 2017 JavaScript 框架报告 转载来源：npm 发布 2017 JavaScript 框架报告]]></content>
      <tags>
        <tag>前端大全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPFS+IPNS+个人博客搭建 - 简书]]></title>
    <url>%2F2018%2F0f00756f%2F</url>
    <content type="text"><![CDATA[IPFS+IPNS+个人博客搭建 - 简书 转载来源：IPFS+IPNS+个人博客搭建 - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何对非结构化文本数据进行特征工程操作？这里有妙招！]]></title>
    <url>%2F2018%2Fc4f43e43%2F</url>
    <content type="text"><![CDATA[雷锋网 AI 研习社按：本文是英特尔数据科学家 Dipanjan Sarkar 在 Medium 上发布的「特征工程」博客续篇。在本系列的前两部分中，作者介绍了连续数据的处理方法和离散数据的处理方法。本文则开始了一个新的主题，非结构化文本数据的传统处理方法。雷锋网 AI 研习社对原文进行了编译。 文本数据通常是由表示单词、句子，或者段落的文本流组成。由于文本数据非结构化（并不是整齐的格式化的数据表格）的特征和充满噪声的本质，很难直接将机器学习方法应用在原始文本数据中。在本文中，我们将通过实践的方法，探索从文本数据提取出有意义的特征的一些普遍且有效的策略，提取出的特征极易用来构建机器学习或深度学习模型。 研究动机想要构建性能优良的机器学习模型，特征工程必不可少。有时候，可能只需要一个优秀的特征，你就能赢得 Kaggle 挑战赛的胜利！对于非结构化的文本数据来说，特征工程更加重要，因为我们需要将文本流转化为机器学习算法能理解的数字表示。即使现在有高级的自动化特征工程，在把它们当作「黑盒子」应用之前，我们仍有必要去了解不同特征工程策略背后的核心思想。永远记住，「如果有人给了你一套修房子的工具，你应该知道什么时候该用电钻，什么时候该用锤子！」 理解文本数据我们虽然能够获得具有结构数据属性的文本数据，但它们为结构化数据，并不在今天的讨论范围之内。 在本文中，我们讨论以单词、短语、句子和整个文档的形式展现的文本流。从本质上讲，文本确实有一些句法结构，比如单词组成了短语，短语组成了句子，句子又组合成了段落。然而，与结构化数据集中固定的数据维度相比，文本文档没有固定的结构，因为单词有众多的选择，每个句子的长度也是可变的。本文就是一个很典型的案例。 特征工程的策略下面是一些流行且有效的处理文本数据的策略，这些方法也能应用在下游的机器学习系统中，用于提取有用的特征。大家可以在 GitHub中查看本文使用的所有代码。 首先加载一些基本的依赖关系和设置： import pandas as pdimport numpy as npimport reimport nltkimport matplotlib.pyplot as pltpd.options.display.max_colwidth = 200%matplotlib inline 下面是文档中的语料库，本文大部分内容都是基于该数据集的分析。语料库通常是属于一个或多个主题的文档的集合。 corpus = &#91;’The sky is blue and beautiful.’, ‘Love this blue and beautiful sky!’, ‘The quick brown fox jumps over the lazy dog.’, “A king’s breakfast has sausages, ham, bacon, eggs, toast and beans”, ‘I love green eggs, ham, sausages and bacon!’, ‘The brown fox is quick and the blue dog is lazy!’, ‘The sky is very blue and the sky is very beautiful today’, ‘The dog is lazy but the brown fox is quick!’ &#93; labels = &#91;’weather’, ‘weather’, ‘animals’, ‘food’, ‘food’, ‘animals’, ‘weather’, ‘animals’&#93; corpus = np.array(corpus) corpus_df = pd.DataFrame(&amp;#123’Document’&#58; corpus, ‘Category’&#58; labels&amp;#125) corpus_df = corpus_df&#91;&#91;’Document’, ‘Category’&#93;&#93; corpus_df 本文中应用的语料库案例 可以看到，我们已经从语料库中提取出几个不同类别的文档。在讨论特征工程之前，一如往常，首先得做数据预处理，删除一些不必要的字符、符号和标记。 文本预处理有很多种对文本数据进行清洗和预处理的方法。下面我将重点介绍在自然语言处理（NLP）流程中大量使用的方法。 删除标签：文本中通常会包含一些不必要的内容，比如 HTML 标签，这在分析文本时并没有太多价值。BeautifulSoup 库提供了清理标签的函数。- 清理重音字符：在许多文本语料库中，特别是在处理英文时，通常会遇到重音字符/字母。因此我们要确保将这些字符转换为标准的 ASCII 字符。一个简单的例子就是将 é 转换成 e。- 拓展缩写：在英文中，缩写基本上是单词或者音节的缩减版。缩减版通常是删除某些单词或者短语中特定的字母和声音而来。举例来说，do not 和 don’t , I would 和 I’d。将缩写单词转换为完整的原始形式有助于文本的标准化。- 删除特殊字符：特殊字符和非字母数字的符号通常会增加额外噪声。通常，可以通过简单的正则表达式来实现这一点。- 词干提取和词性还原：可以利用词干创造新的词汇，例如通过附加前缀和后缀等词缀来创造新的单词。这被称为词性变化。词干提取是将这个过程反过来。一个简单的例子是单词：WATCHES, WATCHING, 和 WATCHED，这些单词都把 WATCH 作为词根。词性还原与词干提取很相似，通过移除词缀以得到单词的基本形式。然而在词性还原里，单词的基本形式是词根（root word），而不是词干（root stem）。其不同之处在于词根（root word）总是字典上正确的词（即出现在词典中），但词干并不是这样。- 去除无用词：在从文本中构建有意义的特征时，没有意义的词被称为无用词。如果你在一个语料库中做一个简单的词频分析，这些无用词通常会以最大的频率出现。像 a , an 这样的词被认为是无用词。但是实际上并没有明确通用的无用词表，我们通常使用 nltk 的标准英语无用词表。大家也可以根据特定的需要添加无用词。清理重音字符：在许多文本语料库中，特别是在处理英文时，通常会遇到重音字符/字母。因此我们要确保将这些字符转换为标准的 ASCII 字符。一个简单的例子就是将 é 转换成 e。 删除特殊字符：特殊字符和非字母数字的符号通常会增加额外噪声。通常，可以通过简单的正则表达式来实现这一点。 去除无用词：在从文本中构建有意义的特征时，没有意义的词被称为无用词。如果你在一个语料库中做一个简单的词频分析，这些无用词通常会以最大的频率出现。像 a , an 这样的词被认为是无用词。但是实际上并没有明确通用的无用词表，我们通常使用 nltk 的标准英语无用词表。大家也可以根据特定的需要添加无用词。 除此之外，还可以使用其他的标准操作，比如标记化、删除多余的空格、文本大写转换为小写，以及其他更高级的操作，例如拼写更正、语法错误更正、删除重复字符等。 由于本文的重点是特征工程，我们将构建一个简单的文本预处理程序，其重点是删除特殊字符、多余的空格、数字、无用词以及语料库的大写转小写。 wpt = nltk.WordPunctTokenizer stop_words = nltk.corpus.stopwords.words(‘english’) def normalize_document(doc)&#58; # lower case and remove special characters\whitespaces doc = re.sub(r’&#91;^a-zA-Z\s&#93;’, ‘’, doc, re.I|re.A) doc = doc.lower doc = doc.strip # tokenize document tokens = wpt.tokenize(doc) # filter stopwords out of document filtered_tokens = &#91;token for token in tokens if token not in stop_words&#93; # re-create document from filtered tokens doc = ‘ ‘.join(filtered_tokens) return doc normalize_corpus = np.vectorize(normalize_document) 一旦搭建好基础的预处理流程，我们就可以将它应用在语料库中了。 norm_corpus = normalize_corpus(corpus)norm_corpusOutput——array(&#91;’sky blue beautiful’, ‘love blue beautiful sky’,’quick brown fox jumps lazy dog’,’kings breakfast sausages ham bacon eggs toast beans’,’love green eggs ham sausages bacon’,’brown fox quick blue dog lazy’, ‘sky blue sky beautiful today’,’dog lazy brown fox quick’&#93;,dtype=’ 上面的输出结果应该能让大家清楚的了解样本文档在预处理之后的样子。现在我们来开始特征工程吧! 词袋模型（Bag of Word）这也许是非结构化文本中最简单的向量空间表示模型。向量空间是表示非结构化文本（或其他任何数据）的一种简单数学模型，向量的每个维度都是特定的特征/属性。词袋模型将每个文本文档表示为数值向量，其中维度是来自语料库的一个特定的词，而该维度的值可以用来表示这个词在文档中的出现频率、是否出现（由 0 和 1 表示），或者加权值。将这个模型叫做词袋模型，是因为每个文档可以看作是装着单词的袋子，而无须考虑单词的顺序和语法。 from sklearn.feature_extraction.text import CountVectorizer cv = CountVectorizer(min_df=0., max_df=1.) cv_matrix = cv.fit_transform(norm_corpus) cv_matrix = cv_matrix.toarray cv_matrix 可以看到，文档已经被转换为数字向量，这样每个文档都由上述特征矩阵中的一个向量（行）表示。下面的代码有助于以一种更易理解的格式来表示这一点。 get all unique words in the corpus vocab = cv.get_feature_names # show document feature vectors pd.DataFrame(cv_matrix, columns=vocab) 词袋模型的文档特征向量 上面的表格应该更能助于理解！可以清楚地看到，特征向量中每个列（维度）都代表一个来自语料库的单词，每一行代表一个文档。单元格中的值表示单词（由列表示）出现在特定文档（由行表示）中的次数。因此，如果一个文档语料库是由 N 个单词组成，那么这个文档可以由一个 N 维向量表示。 N 元词袋模型（Bag of N-Gram Model）一个单词只是一个标记，通常被称为单元（unigram）或者一元（1-gram）。我们已经知道，词袋模型不考虑单词的顺序。但是如果我们也想要考虑序列中出现的短语或者词汇集合呢？N 元模型能够帮我们实现这一点。N-Gram 是来自文本文档的单词记号的集合，这些记号是连续的，并以序列的形式出现。二元表示阶数为二的 N-Gram，也就是两个单词。同理三元表示三个单词。N 元词袋模型是普通词袋模型的一种拓展，使得我们可以利用基于 N 元的特征。下面的示例展示了文档中二元的特征向量。 you can set the n-gram range to 1,2 to get unigrams as well as bigrams bv = CountVectorizer(ngram_range=(2,2)) bv_matrix = bv.fit_transform(norm_corpus) bv_matrix = bv_matrix.toarray vocab = bv.get_feature_names pd.DataFrame(bv_matrix, columns=vocab) 使用二元词袋模型的特征向量 在上面的例子中，每个二元特征由两个单词组成，其中的值表示这个二元词组在文档中出现的次数。 TF-IDF 模型在大型语料库中使用词袋模型可能会出现一些潜在的问题。由于特征向量是基于词的频率，某些单词可能会在文档中频繁出现，这可能会在特征集上掩盖掉其他单词。TF-IDF 模型试图通过缩放或者在计算中使用归一化因子来解决这个问题。TF-IDF 即 Term Frequency-Inverse Document Frequency，在计算中结合了两种度量：词频（Term Frequency）和逆文档频率（Inverse Document Frequency）。这种技术是为搜索引擎中查询排序而开发的，现在它是信息检索和 NLP 领域中不可或缺的模型。 在数学上，TF-IDF 可以定义为：tfidf = tf x idf，也可以进一步拓展为下面的表示： 在这里，tfidf（w, D）表示单词w 在文档D 中的 TF-IDF 分数。Tf（w,D）项表示单词w 在文档D 中的词频，这个值可以从词袋模型中获得。idf（w，D）项是单词w 的逆文档频率，可以由语料库中所有文档的总数量C 除以单词w 的文档频率df（w）的 log 值得到，其中文档频率是指语料库中文档出现单词w 的频率。这种模型有多种变种，但是给出的最终结果都很相似。下面在语料库中使用这个模型吧！ from sklearn.feature_extraction.text import TfidfVectorizer tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True) tv_matrix = tv.fit_transform(norm_corpus) tv_matrix = tv_matrix.toarray vocab = tv.get_feature_names pd.DataFrame(np.round(tv_matrix, 2), columns=vocab) 基于TF-IDF模型的文档特征向量 基于 TF-IDF 的特征向量与原始的词袋模型相比，展示出了缩放和归一化的特性。想要进一步深入了解该模型的读者可以参考 Text Analytics with Python的 181 页。 文档相似性文档相似性是使用从词袋模型或者 tf-idf 模型中提取出的特征，基于距离或者相似度度量判断两个文档相似程度的过程。 因此，可以使用在上一部分中提到的 tf-idf 模型提取出的特征，用其来生成新的特征。这些特征在搜索引擎、文档聚类以及信息检索等领域发挥着重要作用。 语料库中的配对文档相似性需要计算语料库中每两个文档对的文档相似性。因此，如果一个语料库中有 C 个文档，那么最终会得到一个 C*C 的矩阵，矩阵中每个值代表了该行和该列的文档对的相似度分数。可以用几种相似度和距离度量计算文档相似度。其中包括余弦距离/相似度、欧式距离、曼哈顿距离、BM25相似度、jaccard 距离等。在我们的分析中，我们将使用最流行和最广泛使用的相似度度量：余弦相似度，并根据 TF-IDF 特征向量比较文档对的相似度。 from sklearn.metrics.pairwise import cosine_similarity similarity_matrix = cosine_similarity(tv_matrix) similarity_df = pd.DataFrame(similarity_matrix) similarity_df 文档对的相似性矩阵(余弦相似度) 余弦相似度给出了表示两个文档特征向量之间角度的余弦值的度量。两个文档特征向量之间的角度越低，两个文档的相似度就越高，如下图所示： 仔细观察相似度矩阵可以清楚地看出，文档（0，1 和 6），（2，5 和 7）之间非常相似，文档 3 和 4 略微相似。这表明了这些相似的文档一定具有一些相似特征。这是分组或聚类的一个很好的案例，可以通过无监督的学习方法来解决，特别是当需要处理数百万文本文档的庞大语料库时。 具有相似特征的文档聚类聚类是利用无监督学习的方法，将数据点(本场景中即文档)分类到组或者 cluster 中。我们将在这里利用一个无监督的层次聚类算法，通过利用我们之前生成的文档相似性特征，将我们的玩具语料库中的类似文档聚合到一起。有两种类型的层次聚类方法，分别是凝聚方法（agglomerative）和分裂方法（divisive）。这里将会使用凝聚聚类算法，这是一种自下而上（bottom up）的层次聚类算法，最开始每个文档的单词都在自己的类中，根据测量数据点之间的距离度量和连接准则（linkage criterion），将相似的类连续地合并在一起。下图展示了一个简单的描述。 连接准则决定了合并策略。常用的连接准则有 Ward, Complete linkage, Average linkage 等等。这些标准在将一对 cluster 合并在一起（文档中低层次的类聚类成高层次的）时是非常有用的，这是通过最优化目标函数实现的。我们选择 Ward 最小方差作为连接准则，以最小化总的内部聚类方差。由于已经有了相似特征，我们可以直接在样本文档上构建连接矩阵。 from scipy.cluster.hierarchy import dendrogram, linkage Z = linkage(similarity_matrix, ‘ward’) pd.DataFrame(Z, columns=&#91;’Document\Cluster 1’, ‘Document\Cluster 2’, ‘Distance’, ‘Cluster Size’&#93;, dtype=’object’) 我们语料库的连接矩阵 如果仔细查看连接矩阵，可以看到连接矩阵的每个步骤（行）都告诉了我们哪些数据点（或者 cluster）被合并在一起。如果有 n 个数据点，那么连接矩阵 Z 将是（n-1）*4 的形状，其中 Z&#91;i&#93; 表示在步骤 i 合并了哪些 cluster。每行有四个元素，前两个元素是数据点或 cluster 的名称，第三个元素是前两个元素（数据点或 cluster）之间的距离，最后一个元素是合并完成后 cluster 中元素/数据点的总数。大家可以参考 scipy 文档，其中有详细解释。 下面，把这个矩阵看作一个树状图，以更好地理解元素！ plt.figure(figsize=(8, 3)) plt.title(‘Hierarchical Clustering Dendrogram’) plt.xlabel(‘Data point’) plt.ylabel(‘Distance’) dendrogram(Z) plt.axhline(y=1.0, c=’k’, ls=’–’, lw=0.5) 可以看到每个数据点是如何从一个单独的簇开始，慢慢与其他数据点合并形成集群的。从颜色和树状图的更高层次来看，如果考虑距离度量为 1.0（由虚线表示）或者更小，可以看出模型已经正确识别了三个主要的聚类。利用这个距离，我们可以得到集群的标签。 from scipy.cluster.hierarchy import fcluster max_dist = 1.0 cluster_labels = fcluster(Z, max_dist, criterion=’distance’) cluster_labels = pd.DataFrame(cluster_labels, columns=&#91;’ClusterLabel’&#93;) pd.concat(&#91;corpus_df, cluster_labels&#93;, axis=1) 可以清楚地看到，我们的算法已经根据分配给它们的标签，正确识别了文档中的三个不同类别。这应该能够给大家一个关于如何使用 TF-IDF 特征来建立相似度特征的思路。大家可以用这种处理流程来进行聚类。 主题模型也可以使用一些摘要技术从文本文档中提取主题或者基于概念的特征。主题模型围绕提取关键主题或者概念。每个主题可以表示为文档语料库中的一个词袋或者一组词。总之，这些术语表示特定的话题、主题或概念，凭借这些单词所表达的语义含义，可以轻松将每个主题与其他主题区分开来。这些概念可以从简单的事实、陈述到意见、前景。主题模型在总结大量文本来提取和描绘关键概念时非常有用。它们也可用于从文本数据中捕捉潜在的特征。 主题建模有很多种方法，其中大多涉及到某种形式的矩阵分解。比如隐含语义索引（Latent Semantic Indexing， LSI）就使用了奇异值分解。这里将使用另一种技术：隐含狄利克雷分布（Latent Dirichlet Allocation， LDA），它使用了生成概率模型，其中每个文档由几个主题组合而成，每个术语或单词可以分配给某个主题。这与基于 pLSI（probabilistic LSI）的模型很类似。在 LDA 的情况下，每个隐含主题都包含一个狄利克雷先验。 这项技术背后的数学原理相当复杂，所以我会试着总结一下，而不是罗列很多让人厌倦的细节。我建议读者可以看看 Christine Doig 的一个优秀的演讲，深入了解一下。 上图中的黑色框表示利用前面提到的参数，从 M 个文档中提取 K 个主题的核心算法。下面的步骤是对算法的解释。 初始化必要的参数。1. 随机初始化文档，将每个单词分配到 K 个主题中去。1. 按照如下方法迭代1. 对于每个文档 D：随机初始化文档，将每个单词分配到 K 个主题中去。 对于每个文档 D： a) 对于文档中的单词 W： i.对于主题 T： 计算 P(T|D)， 表示文档 D 中单词分配给 T 主题的比例。 计算 P(W|T)，表示在所有文档中，主题 T 包含单词 W 的比例。 ii. 通过计算概率 P(T|D)*P(W|T) 重新分配单词 W 的主题 T。 运行几个迭代之后，就能获得混合了每个文档的主题，然后就可以根据指向某个主题的单词生成文档的主题。像 gensim 或者 scikit-learn 这样的框架，使得我们能够利用 LDA 模型来生成主题。 大家应该记住，当 LDA 应用于文档-单词矩阵（TF-IDF 或者词袋特征矩阵）时，它会被分解为两个主要部分： 文档-主题矩阵，也就是我们要找的特征矩阵- 主题-单词矩阵，能够帮助我们查看语料库中潜在的主题主题-单词矩阵，能够帮助我们查看语料库中潜在的主题 使用 scikit-learn 可以得到如下的文档-主题矩阵。 from sklearn.decomposition import LatentDirichletAllocation lda = LatentDirichletAllocation(n_topics=3, max_iter=10000, random_state=0) dt_matrix = lda.fit_transform(cv_matrix) features = pd.DataFrame(dt_matrix, columns=&#91;’T1’, ‘T2’, ‘T3’&#93;) features 可以清楚地看到哪些文档对上述输出中的三个主题贡献最大，可以通过如下的方式查看主题及其组成部分。 tt_matrix = lda.components_ for topic_weights in tt_matrix&#58; topic = &#91;(token, weight) for token, weight in zip(vocab, topic_weights)&#93; topic = sorted(topic, key=lambda x&#58; -x&#91;1&#93;) topic = &#91;item for item in topic if item&#91;1&#93; &gt; 0.6&#93; print(topic) print 可以看到，由于组成术语不同，很容易区分这三个主题。第一个在讨论天气，第二个关于食物，最后一个关于动物。主题建模的主题数量选择是一门完整的课题，既是一门艺术，也是一门科学。获得最优主题数量的方法有很多，这些技术既复杂又繁琐，这里就不展开讨论了。 使用主题模型特征的文档聚类这里使用 LDA 法从词袋模型特征构建主题模型特征。现在，我们可以利用获得的文档单词矩阵，使用无监督的聚类算法，对文档进行聚类，这与我们之前使用的相似度特征进行聚类类似。 这次我们使用非常流行的基于分区的聚类方法——K-means 聚类，根据文档主题模型特征表示，进行聚类或分组。在 K-means 聚类法中，有一个输入参数 K，它制定了使用文档特征输出的聚类数量。这种聚类方法是一种基于中心的聚类方法，试图将这些文档聚类为等方差的类。这种方法通过最小化类内平方和来创建聚类。选择出最优的 K 的方法有很多，比如误差平方和度量，轮廓系数（Silhouette Coefficients）和 Elbow method。 from sklearn.cluster import KMeans km = KMeans(n_clusters=3, random_state=0) km.fit_transform(features) cluster_labels = km.labels_ cluster_labels = pd.DataFrame(cluster_labels, columns=&#91;’ClusterLabel’&#93;) pd.concat(&#91;corpus_df, cluster_labels&#93;, axis=1) 从上面的输出中可以看到，文档的聚类分配完全正确。 未来会涉及到的高级策略在这篇文章没有涉及近期出现的一些关于文本数据特征工程的高级方法，包括利用深度学习模型来提取单词特征的方法。我们将在本系列的下一部分中深入探讨这些模型，并详细介绍 Word2Vec和GloVe等流行的单词嵌入模型，敬请期待! 总结 这些例子应该能有助于大家理解文本数据特征工程的一些通用策略。本文中介绍的是基于数学概念、信息检索和自然语言处理的传统策略，这些久经考验的方法在各种数据集和问题上都表现优异。在下一篇文章中，我将详细介绍如何利用深度学习模型进行文本数据特征工程。 对连续数据特征工程感兴趣的读者，请查看本系列第一部分！ 对离散数据特征工程感兴趣的读者，请查看本系列第二部分！ 本文中所使用的所有代码和数据集都可以从 GitHub中访问。代码也可以作为Jupyter笔记本使用。 Via towardsdatascience.com雷锋网 AI 研习社编译整理。 转载来源：如何对非结构化文本数据进行特征工程操作？这里有妙招！]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>英语</tag>
        <tag>HTML</tag>
        <tag>动物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识｜从Github上看深度学习和自然语言处理有趣的项目]]></title>
    <url>%2F2018%2F895b955b%2F</url>
    <content type="text"><![CDATA[知识｜从Github上看深度学习和自然语言处理有趣的项目 转载来源：知识｜从Github上看深度学习和自然语言处理有趣的项目]]></content>
  </entry>
  <entry>
    <title><![CDATA[Error]]></title>
    <url>%2F2018%2F89e2c812%2F</url>
    <content type="text"><![CDATA[Error 转载来源：Error]]></content>
  </entry>
  <entry>
    <title><![CDATA[「IPFS + 区块链 系列」入门篇-IPFS+IPNS+个人博客搭建]]></title>
    <url>%2F2018%2Ff9fbed76%2F</url>
    <content type="text"><![CDATA[孔壹学院：国内区块链职业教育引领品牌。作者：黎跃春，孔壹学院创始人，区块链、高可用架构师区块链博客：http&#58;//liyuechun.org 在阅读这篇文章之前，你需要先学习上一篇【IPFS + 区块链 系列】 入门篇 - IPFS环境配置这篇文章。 目录 如何在IPFS新增一个文件- 1.1 新建file.txt文件- 1.2 查看ipfs相关命令- 1.3 将file.txt添加到ipfs节点1.2 查看ipfs相关命令 通过ipfs创建目录存储文件- 3. 如何在IPFS新增一个目录 如何在IPFS新增一个目录 3.1 使用ipfs add -r可以上传一整个目录- 3.2 通过路径访问contactme.txt文件数据- 3.3 通过Hash查看数据IPFS网络数据3.2 通过路径访问contactme.txt文件数据 创建简易的网页发布到IPFS- 4.1 创建一个index.html文件- 4.2 创建一个style.css文件- 4.3 添加到ipfs- 4.4 网络同步- 4.5 访问网站- 4.6 发布到IPNS4.2 创建一个style.css文件 4.4 网络同步 4.6 发布到IPNS 发布个人博客- 5.1 搭建静态博客- 5.2 节点ID替换- 5.3 浏览博客5.2 节点ID替换 下篇预报- 6.1 ipfs + ethereum`Dapp`开发入门1. 如何在IPFS新增一个文件 1.1 新建file.txt文件 打开终端，切换到桌面，新建一个文件夹1121，切换到1121中，通过vi新建一个文件file.txt，文件里面输入春哥微信号liyc1215保存并且退出。 1.2 查看ipfs相关命令 1.3 将file.txt添加到ipfs节点 当执行完ipfs add file.txt这个命令以后，会将file.txt添加到ipfs当前的节点中，并且会对file.txt文件生成一个唯一的hash QmbrevseVQKf1vsYMsxCscRf6D7S2dftYpHwxkYf94pc7T，如果想查看本地ipfs节点的数据，可以通过ipfs cat QmbrevseVQKf1vsYMsxCscRf6D7S2dftYpHwxkYf94pc7T进行查看。 ⚠️：当我试图通过http&amp;#58;//ipfs.io/ipfs/QmbrevseVQKf1vsYMsxCscRf6D7S2dftYpHwxkYf94pc7T进行数据访问时，无法访问，如下图所示： ⚠️：虽然数据已经添加到当前的你自己的IPFS节点中，但是并没有同步到IPFS网络，所以暂时在网络上无法访问。 ⚠️：重要：接下来执行下面的命令同步节点数据到IPFS网络，再试图在网络上查看数据。 同步节点新建一个终端，执行ipfs daemon。- 从IPFS网络查看数据浏览器访问https&#58;//ipfs.io/ipfs/QmbrevseVQKf1vsYMsxCscRf6D7S2dftYpHwxkYf94pc7T 2. 通过ipfs创建目录存储文件在这上面的步骤走，我们可以通过 ipfs cat QmbrevseVQKf1vsYMsxCscRf6D7S2dftYpHwxkYf94pc7T liyc1215查看添加到ipfs网络的file.txt文件的内容，如下： 当然，我们也可以通过ipfs的相关命令在ipfs的根目录下面创建文件夹，并且将file.txt文件移动或者拷贝到我们创建的文件夹中。 ⚠️：cp不会改变文件hash，mv会改变hash寻址。 3. 如何在IPFS新增一个目录3.1 使用ipfs add -r可以上传一整个目录 3.2 通过路径访问contactme.txt文件数据 如果我们上传的是目录，那么可以通过下面几种方式访问到contactme.txt文件的数据。 3.3 通过Hash查看数据IPFS网络数据 访问目录：https&#58;//ipfs.io/ipfs/QmSsjQDVw1fvmG5RsZMgp2GjihiXn2zDv64mfHZN3AREek 通过目录访问文件：https&#58;//ipfs.io/ipfs/QmSsjQDVw1fvmG5RsZMgp2GjihiXn2zDv64mfHZN3AREek/contactme.txt- 通过文件hash直接访问：https&#58;//ipfs.io/ipfs/QmYx4BnhnLXeMWF5mKu16fJgUBiVP7ECXh7qcsUZnXiRxc 4. 创建简易的网页发布到IPFS在这里我先自己写一个简单的网页给大家演示，先在桌面新建一个site文件夹，然后按照下面的步骤在site文件夹中建立index.html和style.css文件。 4.1 创建一个index.html文件 Hello IPFS!4.2 创建一个style.css文件 4.3 添加到ipfs 最后一行是项目根目录的hash，你先通过ipfs daemon同步网络，然后可以通过https&#58;//ipfs.io/ipfs/&lt;你的项目根目录hash&gt;，即https&amp;#58;//ipfs.io/ipfs/QmdVEGkT5u7LtzzatTrn8JGNEF3fpuMPVs2rPCfvqRykRp访问项目。 4.4 网络同步 4.5 访问网站 浏览器打开https&#58;//ipfs.io/ipfs/QmdVEGkT5u7LtzzatTrn8JGNEF3fpuMPVs2rPCfvqRykRp，效果图如下： 4.6 发布到IPNS 当我们修改网站内容重新添加到ipfs时，hash会发生变化，当我们网站更新时，我们可以将网站发布到IPNS，在IPNS中，允许我们节点的域名空间中引用一个IPFS hash，也就是说我们可以通过节点ID对项目根目录的IPFS HASH进行绑定，以后我们访问网站时直接通过节点·ID 访问即可，当我们更新博客时，重新发布到IPNS`即可。 当我们执行ipfs name publish命令时，会返回我们的节点ID，你可以通过ipfs id进行查看验证是否是你的节点ID。 ⚠️：验证 ⚠️：当然我们现在就可以通过IPNS进行访问了。 ⚠️⚠️⚠️：注意上面是ipns而不是ipfs。 ⚠️：如果你网站数据修改，需要重新发布到IPNS。 5. 发布个人博客你可以通过Hugo按照官方文档创建一个漂亮的静态博客Hugo官方网站，当然你也可以自己编写，或者使用其他开源项目搭建。 5.1 搭建静态博客 大家可以自己搭建，也可以直接下载我的博客源码直接搭建。 源码地址：http&#58;//github.com/liyuechun/ipfs_blogger 5.2 节点ID替换 查看你的节点ID在上面的源码中全局搜索将源码里面的QmdKXkeEWcuRw9oqBwopKUa8CgK1iBktPGYaMoJ4UNt1MP替换成你自己的ID。 接下来重复4. 创建简易的网页发布到IPFS的操作步骤即可。 5.3 浏览博客 浏览器打开https&#58;//ipfs.io/ipns/QmdKXkeEWcuRw9oqBwopKUa8CgK1iBktPGYaMoJ4UNt1MP/查看项目效果。 6. 下篇预报6.1 ipfs + ethereum Dapp开发入门 转载来源：「IPFS + 区块链 系列」入门篇-IPFS+IPNS+个人博客搭建]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>HTML</tag>
        <tag>Links</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链开发（一）搭建基于以太坊go-ethereum的私有链环境 - CSDN博客]]></title>
    <url>%2F2018%2F4210122b%2F</url>
    <content type="text"><![CDATA[通过各方资料了解学习之后，决定自己开始搭建基于以太坊go-ethereum的私有链环境。由于本人的电脑系统为win8，为避免window环境出现过多莫名其妙的问题，特意通过vm搭建了一台ubuntu16.04版本的虚拟系统。以下内容均基于ubuntu16.04系统。 go-ethereum客户端下载地址&amp;参考手册首先，可以查看一下go-ethereum项目在git上的地址： &#91;https&#58;//github.com/ethereum/Go-ethereum&#93;(https&#58;//github.com/ethereum/Go-ethereum) 可以在点击项目上的wiki标签，也可以通过一下地址访问wiki： &#91;https&#58;//github.com/ethereum/Go-ethereum/wiki/Building-Ethereum&#93;(https&#58;//github.com/ethereum/Go-ethereum/wiki/Building-Ethereum) 在wiki页面选择ubuntu系统的安装说明，也可以直接访问下面链接： &#91;https&#58;//github.com/ethereum/go-ethereum/wiki/Installation-Instructions-for-Ubuntu&#93;(https&#58;//github.com/ethereum/go-ethereum/wiki/Installation-Instructions-for-Ubuntu) ubuntu下安装命令打开命令行窗口，或通过快捷键CTL+ALT+T，依次输入以下命令，即可安装成功： 12345sudo apt-get install software-properties-commonsudo add-apt-repository -y ppa&amp;#58;ethereum/ethereumsudo add-apt-repository -y ppa&amp;#58;ethereum/ethereum-devsudo apt-get updatesudo apt-get install ethereum PS：如果安装过程中需要依赖其他组件，则先安装其他组件。另外，在ubuntu16.04版本，sudo apt-get install命令可精简为sudo apt install。 安装测试安装完成之后在命令行输入： 1geth --help 如果现实出命令行各种参数提示信息，则说明安装成功。 创世块在以上安装成功之后，直接启动，即可连接公有链。现在通过配置创世块来创建私有链。同一个网络中，创世块必须是一样的，否则无法联通。 创建一个eth的根目录，在根目录下新建创世块json文件piccgenesis.json。内容如下： 1234567891011&amp;#123 &quot;nonce&quot;&amp;#58;&quot;0x0000000000000042&quot;, &quot;mixhash&quot;&amp;#58;&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;difficulty&quot;&amp;#58; &quot;0x4000&quot;, &quot;alloc&quot;&amp;#58; &amp;#123&amp;#125, &quot;coinbase&quot;&amp;#58;&quot;0x0000000000000000000000000000000000000000&quot;, &quot;timestamp&quot;&amp;#58; &quot;0x00&quot;, &quot;parentHash&quot;&amp;#58;&quot;0x0000000000000000000000000000000000000000000000000000000000000000&quot;, &quot;extraData&quot;&amp;#58; &quot;SecBroBlock&quot;, &quot;gasLimit&quot;&amp;#58;&quot;0x0000ffff&quot;&amp;#125 参数解释： 参数名称 参数描述 mixhash 与nonce配合用于挖矿，由上一个区块的一部分生成的hash。注意他和nonce的设置需要满足以太坊的Yellow paper, 4.3.4. Block Header Validity, (44)章节所描述的条件。 nonce nonce就是一个64位随机数，用于挖矿，注意他和mixhash的设置需要满足以太坊的Yellow paper, 4.3.4. Block Header Validity, (44)章节所描述的条件。 difficulty 设置当前区块的难度，如果难度过大，cpu挖矿就很难，这里设置较小难度 alloc 用来预置账号以及账号的以太币数量，因为私有链挖矿比较容易，所以我们不需要预置有币的账号，需要的时候自己创建即可以。 coinbase 矿工的账号，随便填 timestamp 设置创世块的时间戳 parentHash 上一个区块的hash值，因为是创世块，所以这个值是0 extraData 附加信息，随便填，可以填你的个性信息 gasLimit 该值设置对GAS的消耗总量限制，用来限制区块能包含的交易信息总和，因为我们是私有链，所以填最大。 启动私有链节点启动私有节点所需参数 参数名称 参数描述 identity 区块链的标示，随便填写，用于标示目前网络的名字 init 指定创世块文件的位置，并创建初始块 datadir 设置当前区块链网络数据存放的位置 port 网络监听端口 rpc 启动rpc通信，可以进行智能合约的部署和调试 rpcapi 设置允许连接的rpc的客户端，一般为db,eth,net,web3 networkid 设置当前区块链的网络ID，用于区分不同的网络，是一个数字 console 启动命令行模式，可以在Geth中执行命令 初始化&amp;启动本人启动eth所在目录为： 1/home/zhuzs/eth 此目录下放置刚才配置好的创世块json文件：piccgenesis.json 初始化初始化创世块有两种方法： 方法一：执行命令先进行初始化（注意需要在你准备防止eth的根目录下执行） 1$ geth init /path/to/genesis.json 方法二：在执行启动命令的参数中添加以下参数 1--genesis /path/to/genesis.json 以上两种方案注意path路径进行对应的替换； 启动因此直接执行如下命令： 1geth --identity &quot;secbro etherum&quot; --rpc --rpccorsdomain &quot;*&quot; --datadir &quot;/home/zhuzs/eth/chain&quot; --port &quot;30303&quot; --rpcapi &quot;db,eth,net,web3&quot; -- networkid 95518 console --dev PS：根据自己的环境进行对应的替换。注意，最后添加了–dev，以开发模式启动。 看到一下输出说明启动成功，并且是使用的私有链： 随后就是相关的命令操作，在下一篇博客中进一步说明。 &lt;li class=&quot;prev_article&quot;&gt; 上一篇 &amp;#91;Linux下 $(cd `dirname $0`;pwd)&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/details/53033712) &lt;/li&gt; &lt;li class=&quot;next_article&quot;&gt; 下一篇 &amp;#91;区块链开发（二）以太坊客户端基本操作命令&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/details/53073799) &lt;/li&gt; go-ethereum 部署私有链- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/7/2/A/3_a191030148.jpg&quot; alt=&quot;a191030148&quot; title=&quot;a191030148&quot;&gt; - a191030148 - 2017-10-25 16&amp;#58;27&amp;#58;21 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;2355 以太坊客户端Ethereum Wallet与Geth区别简介- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/2/7/F/3_wo541075754.jpg&quot; alt=&quot;wo541075754&quot; title=&quot;wo541075754&quot;&gt; - wo541075754 - 2017-08-27 12&amp;#58;01&amp;#58;31 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;14818 以太坊官网go-ethereum- 2017年02月09日 13&amp;#58;22 - 50MB - 下载 树莓派raspberry pi安装archlinux，并且在上面搭建以太坊（ethereum）环境- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/0/D/B/3_zhang_yu_joseph.jpg&quot; alt=&quot;Zhang_Yu_Joseph&quot; title=&quot;Zhang_Yu_Joseph&quot;&gt; - Zhang_Yu_Joseph - 2015-10-01 09&amp;#58;45&amp;#58;02 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;2534 以太坊go-ethereum客户端JSON-RPC API调用（一）- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/2/7/F/3_wo541075754.jpg&quot; alt=&quot;wo541075754&quot; title=&quot;wo541075754&quot;&gt; - wo541075754 - 2016-12-31 09&amp;#58;13&amp;#58;02 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;16911 Ethereum钱包区块同步问题- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/9/E/E/3_fengmm521.jpg&quot; alt=&quot;fengmm521&quot; title=&quot;fengmm521&quot;&gt; - fengmm521 - 2017-11-04 22&amp;#58;01&amp;#58;33 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;6988 Ethereum JSON-Api 的使用- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/D/3/D/3_guokaikevin.jpg&quot; alt=&quot;guokaikevin&quot; title=&quot;guokaikevin&quot;&gt; - guokaikevin - 2017-11-19 21&amp;#58;01&amp;#58;11 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;2949 以太坊客户端Geth命令用法-参数详解- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/2/7/F/3_wo541075754.jpg&quot; alt=&quot;wo541075754&quot; title=&quot;wo541075754&quot;&gt; - wo541075754 - 2018-03-18 11&amp;#58;32&amp;#58;30 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;516 安装geth客户端并转账- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/7/B/7/3_ddffr.jpg&quot; alt=&quot;DDFFR&quot; title=&quot;DDFFR&quot;&gt; - DDFFR - 2017-07-04 14&amp;#58;41&amp;#58;24 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;5962 区块链开发（二）以太坊客户端基本操作命令 - &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/2/7/F/3_wo541075754.jpg&quot; alt=&quot;wo541075754&quot; title=&quot;wo541075754&quot;&gt; - wo541075754 - 2016-11-07 22&amp;#58;41&amp;#58;09 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;14094 个人资料 &lt;dl class=&quot;inf_bar clearfix&quot;&gt; &lt;dt class=&quot;csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_381&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/2/7/F/3_wo541075754.jpg&quot; class=&quot;avatar_pic&quot;&gt; &lt;/a&gt; &lt;/dt&gt;&lt;dd&gt; &lt;h3 class=&quot;csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_380&quot;&gt;&amp;#91;wo541075754&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754)&lt;/h3&gt; &lt;svg class=&quot;icon&quot; aria-hidden=&quot;true&quot;&gt; &lt;use xlink&amp;#58;href=&quot;#icon-bokezhuanjia&quot;&gt;&lt;/use&gt; &lt;/svg&gt; 博客专家 &lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;234&quot;&gt; &lt;dt&gt;原创&lt;/dt&gt; &lt;dd&gt;234&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;694&quot;&gt; &lt;dt&gt;粉丝&lt;/dt&gt; &lt;dd id=&apos;fan&apos;&gt;694&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;517&quot;&gt; &lt;dt&gt;喜欢&lt;/dt&gt; &lt;dd&gt;517&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;373&quot;&gt; &lt;dt&gt;评论&lt;/dt&gt; &lt;dd&gt;373&lt;/dd&gt; &lt;/dl&gt; &lt;img src=&apos;https&amp;#58;//csdnimg.cn/jifen/images/xunzhang/xunzhang/zhuanlandaren.png&apos; alt=&apos;专栏达人&apos;&gt; &lt;img src=&apos;https&amp;#58;//csdnimg.cn/jifen/images/xunzhang/xunzhang/chizhiyiheng.png&apos; alt=&apos;持之以恒&apos;&gt; 等级： &lt;a href=&quot;https&amp;#58;//blog.csdn.net/home/help.html#level&quot; title=&quot;7级,点击查看等级说明&quot; target=&quot;_blank&quot;&gt; &lt;img class=&quot;grade-img&quot; src=&quot;https&amp;#58;//csdnimg.cn/jifen/images/xunzhang/jianzhang/blog7.png&quot; alt=&quot;7级,点击查看等级说明&quot;&gt; &lt;/a&gt; 访问量： 127万+ 积分： 1万+ 排名： 1283 // 判断并设置用户名位置，没有博客专家与关注按钮时，用户名居中 $medals_children = $(‘.medals’).children().length; $span_add_follow = $(‘#span_add_follow’).length; if($medals_children === 0 &amp;&amp; $span_add_follow === 0)&amp;#123 $(‘.inf_bar dd’).css(‘vertical-align’,’10px’) &amp;#125 以太坊研发技术交流群 文章搜索 博客专栏 &lt;table cellpadding=&quot;0&quot; cellspacing=&quot;0&quot;&gt; &lt;tr&gt; &lt;td style=&quot;padding&amp;#58;10px 10px 0 0;&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/column/details/13651.html&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//img-blog.csdn.net/20161122200728461&quot; style=&quot;width&amp;#58;75px;height&amp;#58;75px;&quot; /&gt; &lt;/a&gt; &lt;/td&gt; &lt;td style=&quot;padding&amp;#58;10px 0; vertical-align&amp;#58;top;&quot;&gt; &amp;#91;区块链实践&amp;#93;(https&amp;#58;//blog.csdn.net/column/details/13651.html) 文章：67篇 阅读：338731 &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td style=&quot;padding&amp;#58;10px 10px 0 0;&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/column/details/14599.html&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//img-blog.csdn.net/20170227104644223&quot; style=&quot;width&amp;#58;75px;height&amp;#58;75px;&quot; /&gt; &lt;/a&gt; &lt;/td&gt; &lt;td style=&quot;padding&amp;#58;10px 0; vertical-align&amp;#58;top;&quot;&gt; &amp;#91;Zookeeper从入门到专家&amp;#93;(https&amp;#58;//blog.csdn.net/column/details/14599.html) 文章：20篇 阅读：68736 &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td style=&quot;padding&amp;#58;10px 10px 0 0;&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/column/details/15277.html&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//img-blog.csdn.net/20170415200234279&quot; style=&quot;width&amp;#58;75px;height&amp;#58;75px;&quot; /&gt; &lt;/a&gt; &lt;/td&gt; &lt;td style=&quot;padding&amp;#58;10px 0; vertical-align&amp;#58;top;&quot;&gt; &amp;#91;Intellij IDEA日常使用&amp;#93;(https&amp;#58;//blog.csdn.net/column/details/15277.html) 文章：29篇 阅读：348843 &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td style=&quot;padding&amp;#58;10px 10px 0 0;&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/column/details/16183.html&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//img-blog.csdn.net/20170630105130174&quot; style=&quot;width&amp;#58;75px;height&amp;#58;75px;&quot; /&gt; &lt;/a&gt; &lt;/td&gt; &lt;td style=&quot;padding&amp;#58;10px 0; vertical-align&amp;#58;top;&quot;&gt; &amp;#91;Drools规则引擎&amp;#93;(https&amp;#58;//blog.csdn.net/column/details/16183.html) 文章：47篇 阅读：115919 &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;td style=&quot;padding&amp;#58;10px 10px 0 0;&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/column/details/14599.html&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//img-blog.csdn.net/20170227104644223&quot; style=&quot;width&amp;#58;75px;height&amp;#58;75px;&quot; /&gt; &lt;/a&gt; &lt;/td&gt; &lt;td style=&quot;padding&amp;#58;10px 0; vertical-align&amp;#58;top;&quot;&gt; &amp;#91;Zookeeper从入门到专家&amp;#93;(https&amp;#58;//blog.csdn.net/column/details/14599.html) 文章：20篇 阅读：68736 &lt;/td&gt; &lt;td style=&quot;padding&amp;#58;10px 10px 0 0;&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/column/details/16183.html&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//img-blog.csdn.net/20170630105130174&quot; style=&quot;width&amp;#58;75px;height&amp;#58;75px;&quot; /&gt; &lt;/a&gt; &lt;/td&gt; &lt;td style=&quot;padding&amp;#58;10px 0; vertical-align&amp;#58;top;&quot;&gt; &amp;#91;Drools规则引擎&amp;#93;(https&amp;#58;//blog.csdn.net/column/details/16183.html) 文章：47篇 阅读：115919 &lt;/td&gt; 文章分类 区块链 (68) Intellij IDEA (29) Zookeeper (20) Java基础 (18) Drools (47) 程序杂谈 (19) SpringBoot (13) Bootstrap (6) Linux (11) JDBC (1) 单元测试 (1) Dbvisualizer (3) SVN (4) Quartz (2) Spring (4) 日志 (2) ZK (1) Oracle (1) 前端 (5) MySQL (4) Nginx (1) Maven (6) dubbo (1) mybatis (4) SecureCRT (2) 自动化 (3) github (2) mq (1) xstream (1) Solidity (5) 加密算法 (2) 分布式 (4) ssh重启 (1) go语言 (3) 其他 (1) 文章存档 &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2018年4月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2018/04) (4) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2018年3月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2018/03) (15) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2018年2月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2018/02) (3) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2018年1月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2018/01) (9) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年12月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/12) (10) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年11月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/11) (5) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年10月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/10) (3) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年9月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/09) (8) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年8月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/08) (21) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年7月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/07) (25) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年6月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/06) (4) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年5月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/05) (4) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年4月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/04) (10) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年3月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/03) (17) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年2月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/02) (8) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年1月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2017/01) (10) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年12月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/12) (8) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年11月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/11) (21) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年10月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/10) (4) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年9月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/09) (15) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年8月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/08) (8) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年6月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/06) (4) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年5月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/05) (6) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年4月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/04) (5) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年3月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/03) (8) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2016年2月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2016/02) (8) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2015年11月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2015/11) (1) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2015年9月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2015/09) (3) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2015年8月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2015/08) (4) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2015年7月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2015/07) (2) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2015年6月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2015/06) (6) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2015年5月&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/month/2015/05) (10) &lt;/li&gt; 阅读排行 &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/51150035&quot; title=&quot;IntelliJ IDEA 控制台中文乱码解决方案&quot;&gt; IntelliJ IDEA 控制台中文乱码解决方案 &lt;/a&gt; (40713) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/54743138&quot; title=&quot;图解区块链：14张图看懂什么是“区块链技术”？&quot;&gt; 图解区块链：14张图看懂什么是“区块链技术”？ &lt;/a&gt; (37020) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/47829233&quot; title=&quot;IntelliJ IDEA 使用Subversion时忽略文件夹&quot;&gt; IntelliJ IDEA 使用Subversion时忽略文件夹 &lt;/a&gt; (32785) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/50717842&quot; title=&quot;Mysql事物锁等待超时 Lock wait timeout exceeded; try restarting transaction&quot;&gt; Mysql事物锁等待超时 Lock wait timeout exceeded; try restarting transaction &lt;/a&gt; (31522) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/54632929&quot; title=&quot;Merkle Tree（默克尔树）算法解析&quot;&gt; Merkle Tree（默克尔树）算法解析 &lt;/a&gt; (31321) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/46047051&quot; title=&quot;Intellij IDEA 配置Subversion插件&quot;&gt; Intellij IDEA 配置Subversion插件 &lt;/a&gt; (31254) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/50956860&quot; title=&quot;Intellij Idea 使用SVN更新到指定版本&quot;&gt; Intellij Idea 使用SVN更新到指定版本 &lt;/a&gt; (27302) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/51159518&quot; title=&quot;Intellij IDEA 默认打开上次项目设置&quot;&gt; Intellij IDEA 默认打开上次项目设置 &lt;/a&gt; (24458) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/49659597&quot; title=&quot;Intellij 解除（去除）SVN关联&quot;&gt; Intellij 解除（去除）SVN关联 &lt;/a&gt; (21501) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/wo541075754/article/details/53064877&quot; title=&quot;区块链开发（一）搭建基于以太坊go-ethereum的私有链环境&quot;&gt; 区块链开发（一）搭建基于以太坊go-ethereum的私有链环境 &lt;/a&gt; (21328) &lt;/li&gt; 最新评论 &lt;li&gt; &amp;#91;以太坊技术学习及交流相关事宜&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/details/79761870#comments) &lt;p style=&quot;margin&amp;#58;0px;&quot;&gt;&amp;#91;defineconst&amp;#93;(https&amp;#58;//my.csdn.net/defineconst)&amp;#58; 能够微信转账支付不？ &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &amp;#91;Spring boot xstre...&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/details/52841287#comments) &lt;p style=&quot;margin&amp;#58;0px;&quot;&gt;&amp;#91;qq_33749431&amp;#93;(https&amp;#58;//my.csdn.net/qq_33749431)&amp;#58; 我曹，老哥牛逼，这样都被你发现了，必须给个赞，想得我脑壳疼，原来是springboot这b崽子 &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &amp;#91;《Drools7.0.0.Fina...&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/details/74456890#comments) &lt;p style=&quot;margin&amp;#58;0px;&quot;&gt;&amp;#91;weixin_38761382&amp;#93;(https&amp;#58;//my.csdn.net/weixin_38761382)&amp;#58; 博主大神，我刚接触drools，ecplise配置好drools6.5后，新建项目编译报错是什么原... &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &amp;#91;以太坊交易池(txpool)的分析&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/details/79812535#comments) &lt;p style=&quot;margin&amp;#58;0px;&quot;&gt;&amp;#91;Platinum0&amp;#93;(https&amp;#58;//my.csdn.net/Platinum0)&amp;#58; 666 &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &amp;#91;以太坊go-ethereum客户端...&amp;#93;(https&amp;#58;//blog.csdn.net/wo541075754/article/details/53953933#comments) &lt;p style=&quot;margin&amp;#58;0px;&quot;&gt;&amp;#91;qq_26733783&amp;#93;(https&amp;#58;//my.csdn.net/qq_26733783)&amp;#58; &amp;#91;reply&amp;#93;d15269395665&amp;#91;/reply&amp;#93; 请问你现在调好了吗？我遇到跟你一样的情况了。 &#91;以太坊go-ethereum客户端…&#93;(https&#58;//blog.csdn.net/wo541075754/article/details/53953933#comments) &#91;qq_26733783&#93;(https&#58;//my.csdn.net/qq_26733783)&#58; &#91;reply&#93;wo541075754&#91;/reply&#93;参数类型错误？能说具体一点吗？我还是没调出来 &#91;以太坊如何搭建私有连联盟链&#93;(https&#58;//blog.csdn.net/wo541075754/article/details/78926177#comments) &#91;u012862638&#93;(https&#58;//my.csdn.net/u012862638)&#58; 博主您好，现在我这里已经在本地搭建起来一个3个节点的联盟链，我这有个疑问：我在 node2 中 … &#91;Intellij IDEA 201…&#93;(https&#58;//blog.csdn.net/wo541075754/article/details/77504461#comments) &#91;UncleTian&#93;(https&#58;//my.csdn.net/UncleTian)&#58; 好文章！~ &#91;以太坊源码分析-同步之Syncin…&#93;(https&#58;//blog.csdn.net/wo541075754/article/details/79649208#comments) &#91;wo541075754&#93;(https&#58;//my.csdn.net/wo541075754)&#58; &#91;reply&#93;zhugeaming2018&#91;/reply&#93;感谢支持 &#91;以太坊手续费不足异常（insuff…&#93;(https&#58;//blog.csdn.net/wo541075754/article/details/79537043#comments) &#91;zhizouxiao&#93;(https&#58;//my.csdn.net/zhizouxiao)&#58; 初始化私有链的时候，chainId不为0，否则出现insufficient funds for g… &#91;qq_33749431&#93;(https&#58;//my.csdn.net/qq_33749431)&#58; 我曹，老哥牛逼，这样都被你发现了，必须给个赞，想得我脑壳疼，原来是springboot这b崽子 &#91;Platinum0&#93;(https&#58;//my.csdn.net/Platinum0)&#58; 666 &#91;qq_26733783&#93;(https&#58;//my.csdn.net/qq_26733783)&#58; &#91;reply&#93;wo541075754&#91;/reply&#93;参数类型错误？能说具体一点吗？我还是没调出来 &#91;UncleTian&#93;(https&#58;//my.csdn.net/UncleTian)&#58; 好文章！~ &#91;zhizouxiao&#93;(https&#58;//my.csdn.net/zhizouxiao)&#58; 初始化私有链的时候，chainId不为0，否则出现insufficient funds for g… &lt;li&gt; &lt;button class=&quot;left-fixed-btn btn-like csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_373&quot; target=&quot;_self&quot; title=&quot;点赞&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-dianzan&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &amp;#91;1&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn csdn-tracking-statistics tracking-click btn-collect&quot; data-mod=&quot;popu_374&quot; target=&quot;_self&quot; title=&quot;收藏&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-shoucang&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn btn-pinglun csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_544&quot; title=&quot;评论&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-pinglun&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_tsina outside left-fixed-btn&quot; data-cmd=&quot;tsina&quot; title=&quot;分享到新浪微博&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-xinlang&quot;&gt;&lt;/i&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_weixin outside left-fixed-btn&quot; data-cmd=&quot;weixin&quot; title=&quot;分享到微信&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-weixin&quot;&gt;&lt;/i&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_qzone outside left-fixed-btn&quot; data-cmd=&quot;qzone&quot; title=&quot;分享到QQ空间&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-QQ&quot;&gt;&lt;/i&gt; &lt;/li&gt; 转载来源：区块链开发（一）搭建基于以太坊go-ethereum的私有链环境 - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[EOS DAWN-V3.0.0 智能合约开发之Hello World]]></title>
    <url>%2F2018%2F8c8082e7%2F</url>
    <content type="text"><![CDATA[C、C++、Java还是任何其他语言，一般刚开始学习的时候，我们都会从HelloWorld开始，这篇文章主要讲解EOS DAWN-V3.0.0智能合约开发之Hello World。 1. 编写合约代码在桌面创建一个文件夹，比如：0418，用Atom打开0418文件夹。新建文件Hello.cpp文件，并将下面的源码拷贝到Hello.cpp文件中。 1#include &lt;eosiolib/eosio.hpp&gt;#include &lt;eosiolib/print.hpp&gt;// 视频网站：http://kongyixueyuan.com// 个人博客：http://liyuechun.org// 公众号：区块链部落// 进技术群，请加微信（kongyixueyuan）//用eosio命名空间using namespace eosio;//所有的智能合约都继承自contract类class Hello : public eosio::contract &#123; public: using contract::contract; /// @abi action void hi( account_name user ) &#123; print( &quot;Hello, &quot;, name&#123;user&#125; ); &#125;&#125;;EOSIO_ABI( Hello, (hi) ) 2. 生成.wast文件1liyuechun:Project yuechunli$ eosiocpp -o Hello.wast Hello.cppliyuechun:Project yuechunli$ lsHello.cppHello.wastliyuechun:Project yuechunli$ 3. 生成.abi文件1liyuechun:Project yuechunli$ eosiocpp -g Hello.abi Hello.cpp Generated Hello.abi ...liyuechun:Project yuechunli$ lsHello.abiHello.cppHello.wastliyuechun:Project yuechunli$ 1&#123; &quot;____comment&quot;: &quot;This file was generated by eosio-abigen. DO NOT EDIT - 2018-04-18T08:15:50&quot;, &quot;types&quot;: , &quot;structs&quot;: [&#123; &quot;name&quot;: &quot;hi&quot;, &quot;base&quot;: &quot;&quot;, &quot;fields&quot;: [&#123; &quot;name&quot;: &quot;user&quot;, &quot;type&quot;: &quot;account_name&quot; &#125; ] &#125; ], &quot;actions&quot;: [&#123; &quot;name&quot;: &quot;hi&quot;, &quot;type&quot;: &quot;hi&quot;, &quot;ricardian_contract&quot;: &quot;&quot; &#125; ], &quot;tables&quot;: , &quot;clauses&quot;: &#125; 4. 创建钱包账号4.1 创建钱包1liyuechun:Hello yuechunli$ cleos wallet createCreating wallet: defaultSave password to use in the future to unlock this wallet.Without password imported keys will not be retrievable.&quot;PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRL&quot; PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRL必须保存好，解锁钱包时需要使用到这个密码。 4.2 创建两组key1liyuechun:Hello yuechunli$ ./cleos create key-bash: ./cleos: No such file or directoryliyuechun:Hello yuechunli$ cleos create keyPrivate key: 5K7QdknUZsF9apdBhD8TDMZGJjw8zJ8esYwS173YyFRv2453Z9tPublic key: EOS5RU8VsYBLnN5snGeUKmt1sDDzpvQbGyW7LPP6qEryaFctYieCKliyuechun:Hello yuechunli$ cleos create keyPrivate key: 5J8kComGiQHZyNmH6VvkHgtFggeQemazLpihKR4QW75DNkWTVdAPublic key: EOS5fqiC3VFAJ1riMrKf8vzD28nqd4EpXvZGpXt6YewEBnH8DYinG 4.3 向钱包导入私钥1liyuechun:Hello yuechunli$ cleos wallet import 5K7QdknUZsF9apdBhD8TDMZGJjw8zJ8esYwS173YyFRv2453Z9timported private key for: EOS5RU8VsYBLnN5snGeUKmt1sDDzpvQbGyW7LPP6qEryaFctYieCKliyuechun:Hello yuechunli$ cleos wallet import 5J8kComGiQHZyNmH6VvkHgtFggeQemazLpihKR4QW75DNkWTVdAimported private key for: EOS5fqiC3VFAJ1riMrKf8vzD28nqd4EpXvZGpXt6YewEBnH8DYinG 4.4 创建账户1liyuechun:cleos yuechunli$ ./cleos create account eosio liyc111 EOS5RU8VsYBLnN5snGeUKmt1sDDzpvQbGyW7LPP6qEryaFctYieCK EOS5fqiC3VFAJ1riMrKf8vzD28nqd4EpXvZGpXt6YewEBnH8DYinG 5. 部署合约1liyuechun:build yuechunli$ cleos set contract liyc111 ./contracts/HelloReading WAST/WASM from ./contracts/Hello/Hello.wast...Assembling WASM...Publishing contract...executed transaction: 21d891e425f3d65852432e2b6a78146e2e2992a267c9f28c8ce56cd5dbea98f2 1632 bytes 2200576 cycles# eosio &lt;= eosio::setcode &#123;&quot;account&quot;:&quot;liyc111&quot;,&quot;vmtype&quot;:0,&quot;vmversion&quot;:0,&quot;code&quot;:&quot;0061736d0100000001370b60027f7e0060027e7e006001...# eosio &lt;= eosio::setabi &#123;&quot;account&quot;:&quot;liyc111&quot;,&quot;abi&quot;:&#123;&quot;types&quot;:,&quot;structs&quot;:[&#123;&quot;name&quot;:&quot;hi&quot;,&quot;base&quot;:&quot;&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;user&quot;,&quot;t...liyuechun:build yuechunli$ cleos get code liyc111code hash: e387951f9a18870f2c151fbceea5b279a3861bdabab58ea87a67296a8a6583d0liyuechun:build yuechunli$ 6. 执行合约6.1 解锁钱包PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRL是创建钱包是的密码。 1liyuechun:build yuechunli$ cleos wallet unlock --password PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRLUnlocked: default 6.2 执行合约 转载来源：EOS DAWN-V3.0.0 智能合约开发之Hello World]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>Java</tag>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EOS白皮书 - 简书]]></title>
    <url>%2F2018%2F8ea15bc4%2F</url>
    <content type="text"><![CDATA[EOS白皮书 - 简书 转载来源：EOS白皮书 - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[安装hyperledger fabric V1.0.1 - 猫不急 - 博客园]]></title>
    <url>%2F2018%2F37c7029b%2F</url>
    <content type="text"><![CDATA[安装hyperledger fabric V1.0.1 - 猫不急 - 博客园 转载来源：安装hyperledger fabric V1.0.1 - 猫不急 - 博客园]]></content>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu部署基于Fabric的虚拟区块链服务 - CSDN博客]]></title>
    <url>%2F2018%2F61b4068c%2F</url>
    <content type="text"><![CDATA[关于Hyperledger Fabric的部署适合在Ubuntu或其它Linux上进行，本例在Ubuntu16.04LTS上操作。如果是Windows、MacOS系统，建议安装Virtual Box，在虚拟机上部署区块链环境。 准备： 1、源需要换成国内源，这样速度能快很多。 参考：http&#58;//www.linuxidc.com/Linux/2016-06/132518.htm 2、安装好git，ssh服务，配置go语言环境(我的version是1.9.2，官网下载最新版本，注意项目路径名与src包一致！！)，安装docker容器(我的version是1.12.6，建议1.12以上！！)并启动容器服务（配置过程比较简单，自行百度），分别输入需要的环境名字来检查是否正确安装，确认安装正确继续。 参考：http&#58;//www.linuxidc.com/Linux/2017-01/139985.htm 3、修改你的权限 sudo usermod -aG docker USER_NAME 4、注销并重新登录，然后添加阿里云的Docker Hub镜像（一定要注销后再重启docker服务！！） 参考：https&#58;//cr.console.aliyun.com/#/accelerator/ 5、然后重新加载守护进程，输入以下两行命令 sudo systemctl daemon-reloadsudo systemctl restart docker 6、安装python-pip sudo apt-get install python-pip 7、安装docker-compose 直接运行脚本：curl -L https&#58;//get.daocloud.io/docker/compose/releases/download/1.12.0/docker-compose-uname -s-uname -m &gt; ~/docker-composesudo mv ~/docker-compose /usr/local/bin/docker-compose chmod +x /usr/local/bin/docker-compose 部署： 1、建立fabric目录，用Git拉取源码 mkdir -p ~/go/src/github.com/hyperledger cd ~/go/src/github.com/hyperledger git clone https&#58;//github.com/hyperledger/fabric.git 2、切换v1.0.0版本的源码 cd ~/go/src/github.com/hyperledger/fabricgit checkout v1.0.0 3、下载Fabric docker镜像 cd ~/go/src/github.com/hyperledger/fabric/examples/e2e_cli/source download-dockerimages.sh -c x86_64-1.0.0 -f x86_64-1.0.0 若下载成功，输入docker images会看到如下内容 启动： 1、在e2e_cli文件夹内，启动Fabric网络的自动化脚本。 ./network_setup.sh up 2、启动成功，则出现如下： 测试： 1、测试官方example，打开另一个终端： docker exec -it cli bash peer chaincode query -C mychannel -n mycc -c ‘&amp;#123”Args”&#58;&#91;”query”,”a”&#93;&amp;#125’ 余额（Query Result）显示为90。 2、再把a账户的余额全部转给b账户，运行命令： peer chaincode invoke -o orderer.example.com&#58;7050 –tls true –cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C mychannel -n mycc -c ‘&amp;#123”Args”&#58;&#91;”invoke”,”a”,”b”,”90”&#93;&amp;#125’ 运行结果为： 3、再次查询a的余额，结果为： 4、退出cli容器：exit 5、关闭Fabric网络：./network_setup.sh down 另附： docker常用命令： 1）删除一个容器 docker rm 2）强制删除一个容器 docker rm -f 3）强制删除全部容器 docker rm -f $(docker ps -aq) 4）删除一个镜像&#58; docker rmi 5）强制删除一个镜像&#58; docker rmi -f 6）强制删除全部镜像 docker rmi -f $(docker images -q) 结语：虚拟链搭建到此结束，接下来就需要部署合约，部署多机器节点，分析源码！ &lt;li class=&quot;prev_article&quot;&gt; 上一篇 &amp;#91;150个常用Linux命令精简合集&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78518819) &lt;/li&gt; &lt;li class=&quot;next_article&quot;&gt; 下一篇 &amp;#91;从 Kubernetes 谈容器网络&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78535807) &lt;/li&gt; Hyperledger Fabric 区块链多机部署- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/F/5/C/3_songbin830.jpg&quot; alt=&quot;songbin830&quot; title=&quot;songbin830&quot;&gt; - songbin830 - 2017-12-12 09&amp;#58;29&amp;#58;16 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;4045 自己动手部署区块链-hyperledger/fabric-02- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/C/9/B/3_yl_1314.jpg&quot; alt=&quot;YL_1314&quot; title=&quot;YL_1314&quot;&gt; - YL_1314 - 2016-12-28 17&amp;#58;51&amp;#58;34 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;10679 区块链 hyperledger fabric1.0 环境搭建- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/7/E/3/3_ming1215919.jpg&quot; alt=&quot;ming1215919&quot; title=&quot;ming1215919&quot;&gt; - ming1215919 - 2017-07-26 10&amp;#58;52&amp;#58;37 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;2658 区块链之Hyperledger（超级账本）Fabric v1.0 的环境搭建（超详细教程）- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/9/0/A/3_so5418418.jpg&quot; alt=&quot;so5418418&quot; title=&quot;so5418418&quot;&gt; - so5418418 - 2017-10-26 16&amp;#58;53&amp;#58;53 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;5198 超级账本Fabric区块链用弹珠游戏Marbles 部署- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/C/5/0/3_u013938484.jpg&quot; alt=&quot;u013938484&quot; title=&quot;u013938484&quot;&gt; - u013938484 - 2018-03-17 11&amp;#58;01&amp;#58;03 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;341 自己动手部署区块链-hyperledger/fabric-01- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/C/9/B/3_yl_1314.jpg&quot; alt=&quot;YL_1314&quot; title=&quot;YL_1314&quot;&gt; - YL_1314 - 2016-12-28 10&amp;#58;20&amp;#58;17 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;6246 用Kubernetes部署超级账本Fabric的区块链即服务(1)- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/C/9/2/3_q48s71bczbeylou9t0n.jpg&quot; alt=&quot;q48S71bCzBeYLOu9T0n&quot; title=&quot;q48S71bCzBeYLOu9T0n&quot;&gt; - q48S71bCzBeYLOu9T0n - 2017-08-13 00&amp;#58;00&amp;#58;00 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;865 干货 | 超级账本Fabric 1.0 多节点集群的部署(1)- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/C/9/2/3_q48s71bczbeylou9t0n.jpg&quot; alt=&quot;q48S71bCzBeYLOu9T0n&quot; title=&quot;q48S71bCzBeYLOu9T0n&quot;&gt; - q48S71bCzBeYLOu9T0n - 2017-07-02 00&amp;#58;00&amp;#58;00 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;1088 区块链投资现状和区块链应用部署的探讨- &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/3/1/B/3_owndiandian.jpg&quot; alt=&quot;owndiandian&quot; title=&quot;owndiandian&quot;&gt; - owndiandian - 2016-12-20 18&amp;#58;28&amp;#58;23 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;1231 区块链开发（一）搭建基于以太坊go-ethereum的私有链环境 - &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/2/7/F/3_wo541075754.jpg&quot; alt=&quot;wo541075754&quot; title=&quot;wo541075754&quot;&gt; - wo541075754 - 2016-11-07 11&amp;#58;38&amp;#58;18 - &lt;i class=&quot;icon iconfont icon-read&quot;&gt;&lt;/i&gt;21390 个人资料 &lt;dl class=&quot;inf_bar clearfix&quot;&gt; &lt;dt class=&quot;csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_381&quot;&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798&quot; target=&quot;_blank&quot;&gt; &lt;img src=&quot;https&amp;#58;//avatar.csdn.net/9/7/3/3_sinat_35119798.jpg&quot; class=&quot;avatar_pic&quot;&gt; &lt;/a&gt; &lt;/dt&gt;&lt;dd&gt; &lt;h3 class=&quot;csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_380&quot;&gt;&amp;#91;sinat_35119798&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798)&lt;/h3&gt; &lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;9&quot;&gt; &lt;dt&gt;原创&lt;/dt&gt; &lt;dd&gt;9&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;2&quot;&gt; &lt;dt&gt;粉丝&lt;/dt&gt; &lt;dd id=&apos;fan&apos;&gt;2&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;0&quot;&gt; &lt;dt&gt;喜欢&lt;/dt&gt; &lt;dd&gt;0&lt;/dd&gt; &lt;/dl&gt; &lt;dl title=&quot;1&quot;&gt; &lt;dt&gt;评论&lt;/dt&gt; &lt;dd&gt;1&lt;/dd&gt; &lt;/dl&gt; &lt;img src=&apos;https&amp;#58;//csdnimg.cn/jifen/images/xunzhang/xunzhang/chizhiyiheng.png&apos; alt=&apos;持之以恒&apos;&gt; 等级： &lt;a href=&quot;https&amp;#58;//blog.csdn.net/home/help.html#level&quot; title=&quot;2级,点击查看等级说明&quot; target=&quot;_blank&quot;&gt; &lt;img class=&quot;grade-img&quot; src=&quot;https&amp;#58;//csdnimg.cn/jifen/images/xunzhang/jianzhang/blog2.png&quot; alt=&quot;2级,点击查看等级说明&quot;&gt; &lt;/a&gt; 访问量： 5578 积分： 155 排名： 110万+ // 判断并设置用户名位置，没有博客专家与关注按钮时，用户名居中 $medals_children = $(‘.medals’).children().length; $span_add_follow = $(‘#span_add_follow’).length; if($medals_children === 0 &amp;&amp; $span_add_follow === 0)&amp;#123 $(‘.inf_bar dd’).css(‘vertical-align’,’10px’) &amp;#125 文章搜索 文章分类 Go (1) 算法 (4) C++ (4) 区块链 (9) 数据挖掘 (1) 文章存档 &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2018年3月&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/month/2018/03) (2) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2018年1月&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/month/2018/01) (1) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年12月&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/month/2017/12) (5) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年11月&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/month/2017/11) (10) &lt;/li&gt; &lt;!--归档统计--&gt; &lt;li&gt; &amp;#91;2017年8月&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/month/2017/08) (1) &lt;/li&gt; 阅读排行 &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/77662645&quot; title=&quot;CCF —— CSP认证&quot;&gt; CCF —— CSP认证 &lt;/a&gt; (1154) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78774235&quot; title=&quot;数据集整理&quot;&gt; 数据集整理 &lt;/a&gt; (1147) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78547194&quot; title=&quot;用qsort对二维数组进行排序&quot;&gt; 用qsort对二维数组进行排序 &lt;/a&gt; (483) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78836138&quot; title=&quot;以太坊ICO实例（代码片不好用！！）&quot;&gt; 以太坊ICO实例（代码片不好用！！） &lt;/a&gt; (453) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78518919&quot; title=&quot;Ubuntu部署基于Fabric的虚拟区块链服务&quot;&gt; Ubuntu部署基于Fabric的虚拟区块链服务 &lt;/a&gt; (452) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/79411454&quot; title=&quot;Dapp开发（一）&quot;&gt; Dapp开发（一） &lt;/a&gt; (335) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78825076&quot; title=&quot;以太坊私有链简易部署过程&quot;&gt; 以太坊私有链简易部署过程 &lt;/a&gt; (317) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78787761&quot; title=&quot;以太坊资料&quot;&gt; 以太坊资料 &lt;/a&gt; (196) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78551443&quot; title=&quot;Go语言切片的本质&quot;&gt; Go语言切片的本质 &lt;/a&gt; (167) &lt;/li&gt; &lt;li&gt; &lt;a href=&quot;https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/78634067&quot; title=&quot;以太坊和超级账本对比&quot;&gt; 以太坊和超级账本对比 &lt;/a&gt; (111) &lt;/li&gt; 最新评论 &lt;li&gt; &amp;#91;区块链与Git版本工具的比较&amp;#93;(https&amp;#58;//blog.csdn.net/sinat_35119798/article/details/79101986#comments) &lt;p style=&quot;margin&amp;#58;0px;&quot;&gt;&amp;#91;qq_27259753&amp;#93;(https&amp;#58;//my.csdn.net/qq_27259753)&amp;#58; 有没有联系方式？加我V15855526201 ，详聊 &lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn btn-like csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_373&quot; target=&quot;_self&quot; title=&quot;点赞&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-dianzan&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &amp;#91;0&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn csdn-tracking-statistics tracking-click btn-collect&quot; data-mod=&quot;popu_374&quot; target=&quot;_self&quot; title=&quot;收藏&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-shoucang&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li&gt; &lt;button class=&quot;left-fixed-btn btn-pinglun csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_544&quot; title=&quot;评论&quot;&gt; &amp;#91;&lt;i class=&quot;icon iconfont icon-pinglun&quot;&gt;&lt;/i&gt;&amp;#93;(javascript&amp;#58;void(0);) &lt;/button&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_tsina outside left-fixed-btn&quot; data-cmd=&quot;tsina&quot; title=&quot;分享到新浪微博&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-xinlang&quot;&gt;&lt;/i&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_weixin outside left-fixed-btn&quot; data-cmd=&quot;weixin&quot; title=&quot;分享到微信&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-weixin&quot;&gt;&lt;/i&gt; &lt;/li&gt; &lt;li class=&quot;bdsharebuttonbox csdn-tracking-statistics tracking-click&quot; data-mod=&quot;popu_172&quot;&gt; &lt;a class=&quot;bds_qzone outside left-fixed-btn&quot; data-cmd=&quot;qzone&quot; title=&quot;分享到QQ空间&quot;&gt;&lt;/a&gt; &lt;i class=&quot;icon iconfont icon-QQ&quot;&gt;&lt;/i&gt; &lt;/li&gt; 转载来源：Ubuntu部署基于Fabric的虚拟区块链服务 - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[hyperledger fabric本地开发环境mac部署 - 黑神领主]]></title>
    <url>%2F2018%2F83e8ef98%2F</url>
    <content type="text"><![CDATA[hyperledger fabric本地开发环境mac部署 - 黑神领主 转载来源：hyperledger fabric本地开发环境mac部署 - 黑神领主]]></content>
  </entry>
  <entry>
    <title><![CDATA[快速搭建一个Fabric 1.0的环境-博客-云栖社区-阿里云]]></title>
    <url>%2F2018%2F2a3abcbb%2F</url>
    <content type="text"><![CDATA[快速搭建一个Fabric 1.0的环境-博客-云栖社区-阿里云 转载来源：快速搭建一个Fabric 1.0的环境-博客-云栖社区-阿里云]]></content>
  </entry>
  <entry>
    <title><![CDATA[解读R-Net：微软“超越人类”的阅读理解人工智能]]></title>
    <url>%2F2018%2Fd305e55f%2F</url>
    <content type="text"><![CDATA[人工智能的阅读能力在某些方面已经超越了人类，微软的 R-Net 就是达到了这一里程碑的人工智能之一。近日，谷歌工程师 Sachin Joglekar 在 Medium 上发文对 R-Net 进行了直观的介绍。 R-Net 论文：https&#58;//www.microsoft.com/en-us/research/wp-content/uploads/2017/05/r-net.pdf 今年 1 月 13 日，很多媒体的新闻报道称微软和阿里巴巴开发的人工智能在 SQuAD 数据集测试上，阅读能力上超越了人类。尽管这并不完全准确，但这些公司所开发的模型确实能在某些阅读任务的某些指标上超越人类水平。这篇文章为微软实现这一成果背后的人工智能 R-Net 提供了一个直观的介绍。 首先，给出阅读问题…… 给定一个段落 P： 「特斯拉于 1856 年 7 月 10 日（旧历法的 6 月 28 日）出生于奥地利帝国斯米连村（现属克罗地亚）的一个塞族家庭。他的父亲米卢廷·特斯拉是一位塞尔维亚东正教神父。特斯拉的母亲是久卡·特斯拉（娘家姓为 Mandić），她的父亲也是一位东正教神父；&#58;10 她非常擅长制作家庭手工工具、机械器具并且具有记忆塞尔维亚史诗的能力。久卡从没接受过正规教育。尼古拉将自己的记忆和创造能力归功于他母亲的遗传和影响。特斯拉的祖先来自塞尔维亚西部靠近黑山的地方。&#58;12」 然后询问一个问题 Q： 「特斯拉的母亲具有怎样的特殊能力？」 然后提供一部分连续文本作为答案 A： 「擅长制作家庭手工工具、机械器具并且具有记忆塞尔维亚史诗的能力」 斯坦福问答数据集（SQuAD）包含大约 500 篇文章，涉及的问答对数量接近 10 万（上面给出的例子就取自其中）。 在我们介绍微软的用于阅读理解的方法之前，我们先简要介绍一下他们论文中大量使用的两个概念： 1. 循环神经网络（RNN） RNN 是一种特殊的神经网络，可用于分析时间（或序列）数据。标准的前馈神经网络没有记忆的概念，而 RNN 则通过使用「反馈的」语境向量（context vector）而将这一概念整合了进来： 图 1：一种典型的 RNN 从本质上讲，其在任何时间步骤 t 的输出都是过去语境和当前输入的一个函数。 双向 RNN（BiRNN）是一种特殊的 RNN。标准 RNN 是通过「记忆」过去的数据来记忆历史语境，而 BiRNN 还会从反方向进行遍历以理解未来的语境： 图 2：BiRNN 需要指出，尽管 RNN 理论上可以记住任何长度的历史，但通常来说整合短期语境比整合长期信息（相距 20-30 步以上）更好。 注：R-Net 使用 RNN（更具体来说是门控循环单元）的主要目的是模拟「阅读」文本段落的动作。 2. 注意力（attention） 神经网络中的注意力是根据人类重点关注视觉输入中的特定部分并大略查看其余部分的观看方式而建模的。 注意力可以用在这样的应用中：你的数据点集合中并非所有部分都与当前的任务有关。在这样的情况下，注意力是作为该集合中所有点的 softmax 加权平均而计算的。其权重本身则是作为 1）向量集和 2）某个语境的某个非线性函数而计算的。 图 3：在「飞盘」的语境下，网络会重点关注实际的飞盘和与之相关的对象，同时略过其余部分。 注：R-Net 使用了注意力来在另一些文本的语境下突出文本的某些部分。 R-Net 从直观上讲，R-Net 执行阅读理解的方式与你我进行阅读理解的方式相似：通过多次（准确地说是 3 次）「阅读」（应用 RNN）文本以及在每次迭代中越来越好地「微调」（使用注意力）各词的向量表征。 让我们分开解读其中的每一次过程…… 第一次阅读：略览 我们从标准的 token（即词）向量开始，使用了来自 Glove 的词嵌入。但是，人类通常理解一个词在其周围词所构成的语境中的含义。 比如这两个例子：「May happen」和「the fourth of May」，其中「May」的含义取决于周围的词。另外也要注意背景信息可以来自前向，也可以来自反向。因此，我们在标准词嵌入之上使用了 BiRNN，以得到更好的向量。 问题和段落上都会应用这个过程。 第二次阅读：基于问题的分析 在第二次阅读中，该网络会使用文本本身的语境来调节来自段落的词表征。 让我们假设你已经在该段落的重点位置了： 「……她非常擅长制作家庭手工工具、机械器具并且具有记忆塞尔维亚史诗的能力。久卡从没接受过正规教育……」 在有了「制作」的前提下，如果你在问题 token 上应用注意力，你可能会重点关注： 「特斯拉的母亲具有怎样的特殊能力？」 类似地，网络会调整「制作」的向量，使之与「能力」在语义上靠得更近。 该段落中的所有 token 都会完成这样的操作——本质上讲，R-Net 会在问题的需求和文章的相关部分之间形成链接。原论文将这个部分称为门控式基于注意力的 RNN（Gated Attention-based RNN）。 第三次阅读：有自知的完整的段落理解 在第一次阅读过程中，我们在 token 临近周围词的语境中对这些 token 进行了理解。- 在第二次阅读过程中，我们根据当前问题改善了我们的理解。在第二次阅读过程中，我们根据当前问题改善了我们的理解。 现在我们要鸟瞰整个段落，以定位那些对回答问题真正有帮助的部分。要做到这一点，光是有周围词的短期语境视角是不够的。考虑以下部分中突出强调的词： 特斯拉的母亲是久卡·特斯拉（娘家姓为 Mandić），她的父亲也是一位东正教神父；&#58;10 她非常擅长制作家庭手工工具、机械器具并且具有记忆塞尔维亚史诗的能力。久卡从没接受过正规教育。尼古拉将自己的记忆和创造能力归功于他母亲的遗传和影响。 这都是指特斯拉的母亲所具有的能力。但是，尽管前者确实围绕描述该能力的文本（是我们想要的），但后面的能力则是将它们与特斯拉的才能关联了起来（不是我们想要的）。 为了定位答案的正确起始和结束位置（我们会在下一步解决这个问题），我们需要比较段落中具有相似含义的不同词，以便找到它们的差异之处。使用单纯的 RNN 是很难完成这个任务的，因为这些突出强调的词相距较远。 为了解决这个问题，R-Net 使用了所谓「自匹配注意力（Self-Matched Attention）」。 为什么需要自匹配？ 在应用注意力时，我们通常会使用一些数据（比如一个段落词）来衡量一个向量（比如问题词）的集合。但在这个迭代过程中，我们会使用当前的段落词来衡量来自该段落本身的 token。这有助于我们将当前词与段落其余部分中具有相似含义的其它词区分开。为了增强这个过程，这个阅读阶段是使用一个 BiRNN 完成的。 在我看来，使用自匹配注意力这个步骤是 R-Net 最「神奇」的地方：使用注意力来比较同一段落中相距较远的词。 最后一步：标记答案 在最后一步，R-Net 使用了一种指针网络（Pointer Networks）的变体来确定答案所处的起始和结束位置。简单来说： 我们首先根据问题文本计算另一个注意力向量。这被用作这一次迭代的「起始语境（starting context）」。使用这个知识，再为该起始索引计算一组权重（为该段落中的每个词）。得到最高权重的词作为其答案的「起始位置」。 除了权重之外，这个两步 RNN 还会返回一个新的语境——其中编码了有关该答案的起始的信息。 再将上述步骤重复一次——这一次使用新的语境而不是基于问题的语境，用以计算该答案的结束位置。 搞定！我们得到解答了！（实际上，我们上述例子中给出的答案就是 R-Net 实际得出的答案。） 如果你对 R-Net 的详细细节感兴趣，请阅读他们的论文。如果代码能帮助你更好地理解（至少对我而言是如此），请参阅 YerevaNN 试图用 Keras 重建 R-Net 的精彩博文：http&#58;//yerevann.github.io/2017/08/25/challenges-of-reproducing-r-net-neural-network-using-keras/。 转载来源：解读R-Net：微软“超越人类”的阅读理解人工智能]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>微软</tag>
        <tag>塞尔维亚</tag>
        <tag>正教会</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五大常见的MySQL高可用方案]]></title>
    <url>%2F2018%2F9957f042%2F</url>
    <content type="text"><![CDATA[1.概述我们在考虑MySQL数据库的高可用的架构时，主要要考虑如下几方面： 如果数据库发生了宕机或者意外中断等故障，能尽快恢复数据库的可用性，尽可能的减少停机时间，保证业务不会因为数据库的故障而中断。- 用作备份、只读副本等功能的非主节点的数据应该和主节点的数据实时或者最终保持一致。- 当业务发生数据库切换时，切换前后的数据库内容应当一致，不会因为数据缺失或者数据不一致而影响业务。用作备份、只读副本等功能的非主节点的数据应该和主节点的数据实时或者最终保持一致。 关于对高可用的分级在这里我们不做详细的讨论，这里只讨论常用高可用方案的优缺点以及高可用方案的选型。 2.高可用方案2.1.主从或主主半同步复制 使用双节点数据库，搭建单向或者双向的半同步复制。在5.7以后的版本中，由于lossless replication、logical多线程复制等一些列新特性的引入，使得MySQL原生半同步复制更加可靠。 常见架构如下： 通常会和proxy、keepalived等第三方软件同时使用，即可以用来监控数据库的健康，又可以执行一系列管理命令。如果主库发生故障，切换到备库后仍然可以继续使用数据库。 优点： 架构比较简单，使用原生半同步复制作为数据同步的依据；1. 双节点，没有主机宕机后的选主问题，直接切换即可；1. 双节点，需求资源少，部署简单；双节点，没有主机宕机后的选主问题，直接切换即可； 缺点： 完全依赖于半同步复制，如果半同步复制退化为异步复制，数据一致性无法得到保证；1. 需要额外考虑haproxy、keepalived的高可用机制。需要额外考虑haproxy、keepalived的高可用机制。 2.2.半同步复制优化 半同步复制机制是可靠的。如果半同步复制一直是生效的，那么便可以认为数据是一致的。但是由于网络波动等一些客观原因，导致半同步复制发生超时而切换为异步复制，那么这时便不能保证数据的一致性。所以尽可能的保证半同步复制，便可提高数据的一致性。 该方案同样使用双节点架构，但是在原有半同复制的基础上做了功能上的优化，使半同步复制的机制变得更加可靠。 可参考的优化方案如下： 2.2.1.双通道复制 半同步复制由于发生超时后，复制断开，当再次建立起复制时，同时建立两条通道，其中一条半同步复制通道从当前位置开始复制，保证从机知道当前主机执行的进度。另外一条异步复制通道开始追补从机落后的数据。当异步复制通道追赶到半同步复制的起始位置时，恢复半同步复制。 2.2.2.binlog文件服务器 搭建两条半同步复制通道，其中连接文件服务器的半同步通道正常情况下不启用，当主从的半同步复制发生网络问题退化后，启动与文件服务器的半同步复制通道。当主从半同步复制恢复后，关闭与文件服务器的半同步复制通道。 优点： 双节点，需求资源少，部署简单；1. 架构简单，没有选主的问题，直接切换即可;1. 相比于原生复制，优化后的半同步复制更能保证数据的一致性。架构简单，没有选主的问题，直接切换即可; 缺点： 需要修改内核源码或者使用mysql通信协议。需要对源码有一定的了解，并能做一定程度的二次开发。1. 依旧依赖于半同步复制，没有从根本上解决数据一致性问题。依旧依赖于半同步复制，没有从根本上解决数据一致性问题。 2.3.高可用架构优化 将双节点数据库扩展到多节点数据库，或者多节点数据库集群。可以根据自己的需要选择一主两从、一主多从或者多主多从的集群。 由于半同步复制，存在接收到一个从机的成功应答即认为半同步复制成功的特性，所以多从半同步复制的可靠性要优于单从半同步复制的可靠性。并且多节点同时宕机的几率也要小于单节点宕机的几率，所以多节点架构在一定程度上可以认为高可用性是好于双节点架构。 但是由于数据库数量较多，所以需要数据库管理软件来保证数据库的可维护性。可以选择MMM、MHA或者各个版本的proxy等等。常见方案如下： 2.3.1.MHA+多节点集群 MHA Manager会定时探测集群中的master节点，当master出现故障时，它可以自动将最新数据的slave提升为新的master，然后将所有其他的slave重新指向新的master，整个故障转移过程对应用程序完全透明。 MHA Node运行在每台MySQL服务器上，主要作用是切换时处理二进制日志，确保切换尽量少丢数据。 MHA也可以扩展到如下的多节点集群： 优点： 可以进行故障的自动检测和转移;1. 可扩展性较好，可以根据需要扩展MySQL的节点数量和结构;1. 相比于双节点的MySQL复制，三节点/多节点的MySQL发生不可用的概率更低可扩展性较好，可以根据需要扩展MySQL的节点数量和结构; 缺点： 至少需要三节点，相对于双节点需要更多的资源;1. 逻辑较为复杂，发生故障后排查问题，定位问题更加困难;1. 数据一致性仍然靠原生半同步复制保证，仍然存在数据不一致的风险;1. 可能因为网络分区发生脑裂现象;逻辑较为复杂，发生故障后排查问题，定位问题更加困难; 可能因为网络分区发生脑裂现象; 2.3.2.zookeeper+proxy Zookeeper使用分布式算法保证集群数据的一致性，使用zookeeper可以有效的保证proxy的高可用性，可以较好的避免网络分区现象的产生。 优点： 较好的保证了整个系统的高可用性，包括proxy、MySQL;1. 扩展性较好，可以扩展为大规模集群;扩展性较好，可以扩展为大规模集群; 缺点： 数据一致性仍然依赖于原生的mysql半同步复制;1. 引入zk，整个系统的逻辑变得更加复杂;引入zk，整个系统的逻辑变得更加复杂; 2.4.共享存储 共享存储实现了数据库服务器和存储设备的解耦，不同数据库之间的数据同步不再依赖于MySQL的原生复制功能，而是通过磁盘数据同步的手段，来保证数据的一致性。 2.4.1.SAN共享储存 SAN的概念是允许存储设备和处理器（服务器）之间建立直接的高速网络（与LAN相比）连接，通过这种连接实现数据的集中式存储。常用架构如下： 使用共享存储时，MySQL服务器能够正常挂载文件系统并操作，如果主库发生宕机，备库可以挂载相同的文件系统，保证主库和备库使用相同的数据。 优点： 两节点即可，部署简单，切换逻辑简单；1. 很好的保证数据的强一致性；1. 不会因为MySQL的逻辑错误发生数据不一致的情况；很好的保证数据的强一致性； 缺点： 需要考虑共享存储的高可用；1. 价格昂贵；价格昂贵； 2.4.2.DRBD磁盘复制 DRBD是一种基于软件、基于网络的块复制存储解决方案，主要用于对服务器之间的磁盘、分区、逻辑卷等进行数据镜像，当用户将数据写入本地磁盘时，还会将数据发送到网络中另一台主机的磁盘上，这样的本地主机(主节点)与远程主机(备节点)的数据就可以保证实时同步。常用架构如下： 当本地主机出现问题，远程主机上还保留着一份相同的数据，可以继续使用，保证了数据的安全。 DRBD是linux内核模块实现的快级别的同步复制技术，可以与SAN达到相同的共享存储效果。 优点： 两节点即可，部署简单，切换逻辑简单；1. 相比于SAN储存网络，价格低廉；1. 保证数据的强一致性；相比于SAN储存网络，价格低廉； 缺点： 对io性能影响较大；1. 从库不提供读操作；从库不提供读操作； 2.5.分布式协议 分布式协议可以很好解决数据一致性问题。比较常见的方案如下： 2.5.1.MySQL cluster MySQL cluster是官方集群的部署方案，通过使用NDB存储引擎实时备份冗余数据，实现数据库的高可用性和数据一致性。 优点： 全部使用官方组件，不依赖于第三方软件；1. 可以实现数据的强一致性；可以实现数据的强一致性； 缺点： 国内使用的较少；1. 配置较复杂，需要使用NDB储存引擎，与MySQL常规引擎存在一定差异；1. 至少三节点；配置较复杂，需要使用NDB储存引擎，与MySQL常规引擎存在一定差异； 2.5.2.Galera 基于Galera的MySQL高可用集群， 是多主数据同步的MySQL集群解决方案，使用简单，没有单点故障，可用性高。常见架构如下： 优点： 多主写入，无延迟复制，能保证数据强一致性；1. 有成熟的社区，有互联网公司在大规模的使用；1. 自动故障转移，自动添加、剔除节点；有成熟的社区，有互联网公司在大规模的使用； 缺点： 需要为原生MySQL节点打wsrep补丁1. 只支持innodb储存引擎1. 至少三节点；只支持innodb储存引擎 2.5.3.POAXS Paxos 算法解决的问题是一个分布式系统如何就某个值（决议）达成一致。这个算法被认为是同类算法中最有效的。Paxos与MySQL相结合可以实现在分布式的MySQL数据的强一致性。常见架构如下： 优点： 多主写入，无延迟复制，能保证数据强一致性；1. 有成熟理论基础；1. 自动故障转移，自动添加、剔除节点；有成熟理论基础； 缺点： 只支持innodb储存引擎1. 至少三节点；至少三节点； 3.总结随着人们对数据一致性的要求不断的提高，越来越多的方法被尝试用来解决分布式数据一致性的问题，如MySQL自身的优化、MySQL集群架构的优化、Paxos、Raft、2PC算法的引入等等。 而使用分布式算法用来解决MySQL数据库数据一致性的问题的方法，也越来越被人们所接受，一系列成熟的产品如PhxSQL、MariaDB Galera Cluster、Percona XtraDB Cluster等越来越多的被大规模使用。 随着官方MySQL Group Replication的GA，使用分布式协议来解决数据一致性问题已经成为了主流的方向。期望越来越多优秀的解决方案被提出，MySQL高可用问题可以被更好的解决。 参考文献 [2015 OTN]彭立勋-DoubleBinlog方案.pdf —————— 其他阅读推荐： 我如何使用 Django + Vue.js 快速构建项目 一起学 Node.js | 使用 Express + MongoDB 搭建多人博客 本文由『UCloud存储研发团队』提供。 关于作者：王松磊，现任职于UCloud，从事MySQL数据库内核研发工作。主要负责UCloud云数据库udb的内核故障排查工作以及数据库新特性的研发工作。 ———以下是活动的分割线——— 欢迎加入 UCloud开源作者交流群，遇见更多有意思的项目和作者。 添加UCloud运营小妹个人微信号：Surdur，备注：开源作者，我们将拉你进群！ 另，运营小妹也陪聊很专业哦：） 「UCloud机构号」将独家分享云计算领域的技术洞见、行业资讯以及一切你想知道的相关讯息。欢迎提问&amp;求关注 o(////▽////)q~ 以上。 转载来源：五大常见的MySQL高可用方案]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>技术</tag>
        <tag>Linux</tag>
        <tag>MySQL</tag>
        <tag>MariaDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[晚上 11 点肝要排毒？你被这 30 个谣言坑了多少年……]]></title>
    <url>%2F2018%2F9a715849%2F</url>
    <content type="text"><![CDATA[晚上 11 点肝要排毒？你被这 30 个谣言坑了多少年…… 转载来源：晚上 11 点肝要排毒？你被这 30 个谣言坑了多少年……]]></content>
      <tags>
        <tag>华为运动健康</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPFS星际文件系统初识 - 简书]]></title>
    <url>%2F2018%2F9bbe1052%2F</url>
    <content type="text"><![CDATA[IPFS星际文件系统初识 - 简书 转载来源：IPFS星际文件系统初识 - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[四十岁了，你居然还在编程？]]></title>
    <url>%2F2018%2F9dda8f83%2F</url>
    <content type="text"><![CDATA[四十岁了，你居然还在编程？ 转载来源：四十岁了，你居然还在编程？]]></content>
      <tags>
        <tag>MacTalk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Youtube爆火视频 | 用TensorFlow+40行代码识别手写数字图像]]></title>
    <url>%2F2018%2F9e6156c3%2F</url>
    <content type="text"><![CDATA[Youtube爆火视频 | 用TensorFlow+40行代码识别手写数字图像 转载来源：Youtube爆火视频 | 用TensorFlow+40行代码识别手写数字图像]]></content>
      <tags>
        <tag>大数据文摘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[净水器消费者报告：关于净水你需要知道的一切]]></title>
    <url>%2F2018%2Fa1b04fb1%2F</url>
    <content type="text"><![CDATA[净水器消费者报告：关于净水你需要知道的一切 转载来源：净水器消费者报告：关于净水你需要知道的一切]]></content>
      <tags>
        <tag>爱否科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里提出新神经网络算法，压缩掉最后一个比特]]></title>
    <url>%2F2018%2Fd0594453%2F</url>
    <content type="text"><![CDATA[**【新智元导读】**在利用深度网络解决问题的时候人们常常倾向于设计更为复杂的网络收集更多的数据以期获得更高的性能。但是，随之而来的是模型的复杂度急剧提升，参数越来越多，给深度学习在设备上的应用带来挑战。阿里iDST团队最新提出的ADMM神经网络压缩和加速算法，可以无损地压缩掉最后一个比特。论文已经被AAAI 2018录用为oral。 近年来，深度学习在人工智能领域取得了重大的突破。在计算机视觉、语音识别等诸多领域，深度神经网络(DNN, Deep Neural Network)均被证明是一种极具成效的问题解决方式。如卷积神经网络(CNN, Convolutional neural network)在计算机视觉诸多传统问题（分类、检测、分割）都超越了传统方法，循环神经网络(RNN, Recurrent Neural Networks)则在时序信号处理，如机器翻译，语音识别等超过传统方法。 在利用深度网络解决问题的时候人们常常倾向于设计更为复杂的网络收集更多的数据以期获得更高的性能。但是，随之而来的是模型的复杂度急剧提升，直观的表现是模型的层数越来越深，参数越来越多。这会给深度学习带来两个严重的问题： 随着模型参数的增多，模型的大小越来越大，给嵌入式端模型的存储带来了很大的挑战。1. 随着模型的增大，模型inference的时间越来越长，latency越来越大。随着模型的增大，模型inference的时间越来越长，latency越来越大。 以上两个问题给深度学习在终端智能设备上的推广带来了很大的挑战。比如，经典的深度卷积网络VGG-16的模型大小达到528M，用户很难接受下载一个如此大的模型到手机或者其他终端设备上。同时，在一般的智能手机上，VGG-16识别一张图像的时间高达3000+ms，这个latency对于大多数用户来说也是难以接受的。此外，由于深度网络的计算量很大，运行深度网络的能耗很高，这对于手机等终端设备也是一个巨大的挑战。 基于低比特表示技术的神经网络压缩和加速算法 在这个工作中，我们提出一种基于低比特表示技术的神经网络压缩和加速算法。我们将神经网络的权重表示成离散值，并且离散值的形式为2的幂次方的形式，比如&amp;#123-4，-2，-1，0，1，2，4&amp;#125。这样原始32比特的浮点型权重可以被压缩成1-3比特的整形权重，同时，原始的浮点数乘法操作可以被定点数的移位操作所替代。在现代处理器中，定点移位操作的速度和能耗是远远优于浮点数乘法操作的。 首先，我们将离散值权重的神经网络训练定义成一个离散约束优化问题。以三值网络为例，其目标函数可以表示为： 更进一步，我们在约束条件中引入一个scale参数。对于三值网络，我们将约束条件写成&amp;#123-a, 0, a&amp;#125, a&gt;0. 这样做并不会增加计算代价，因为在卷积或者全连接层的计算过程中可以先和三值权重&amp;#123-1, 0, 1&amp;#125进行矩阵操作，然后对结果进行一个标量scale。从优化的角度看，增加这个scale参数可以大大增加约束空间的大小，这有利于算法的收敛。如下图所示， 对于三值网络而言，scale参数可以将约束空间从离散的9个点扩增到4条直线。 为了求解上述约束优化问题，我们引入ADMM算法。在此之前，我们需要对目标函数的形式做一个等价变换。 其中Ic为指示函数，如果G符合约束条件，则Ic(G)=0，否则Ic(G)为无穷大。该目标函数的增广拉格朗日形式为： ADMM算法将上述问题分成三个子问题进行求解，即 与其它算法不同的是，我们在实数空间和离散空间分别求解，然后通过拉格朗日乘子的更新将两组解联系起来。 第一个子问题需要找到一个网络权重最小化： 在实验中我们发现使用常规的梯度下降算法求解这个问题收敛速度很慢。在这里我们使用Extra-gradient算法来对这个问题进行求解。Extra-gradient算法包含两个基本步骤，分别是： 第二个子问题在离散空间中进行优化。通过简单的数学变换第二个子问题可以写成： 该问题可以通过迭代优化的方法进行求解。当a或Q固定时，很容易就可以获得Q和a的解析解。 实验结果 ImageNet图像识别：我们分别在Alexnet、VGG16、Resnet18、Resnet50、GoogleNet等五个主流的CNN框架上验证了所提出的算法。实验中我们分别尝试了Binary网络、Ternary网络、&amp;#123-2, -1, 0, 1, 2&amp;#125、&amp;#123-4, -2, -1, 0, 1, 2, 4&amp;#125四种形式。在Imagenet上Top-1和Top-5准确度结果如下： Alexnet和VGG16： Resnet： GoogleNet： 其中BWN&#91;1&#93;和TWN&#91;2&#93;为我们对比的两种Binary网络和Ternary网络量化方法。从这些结果可以看出，在各个网络框架下，我们的算法都显著超过对比算法。同时，当比特数达到3时，量化之后的网络精度相比于原始网络几乎可以达到无损。在Alexnet和VGG16这两个冗余度比较高的网络上，量化之后的网络甚至可以取得超过原始网络的精度，这是因为量化操作可以起到一个正则的作用，从而提高这类网络的泛化性能。 Pascal VOC目标检测：我们在SSD检测框架下对算法进行验证，分别采用了VGG16+SSD和Darknet+SSD两种网络结构。对于检测任务，尝试了Ternary网络和&amp;#123-4, -2, -1, 0, 1, 2, 4&amp;#125两种量化形式。实验结果如下： 对于Darknet我们使用了两种设置，第一种设置中所有的权重进行相同的量化；第二种设置中，1x1的卷积核使用INT8量化，即括号中的结果。和识别中的结果类似，在VGG+SSD结构中，我们的算法几乎可以做到无损压缩。 参考文献： &#91;1&#93; Rastegari, M.; Ordonez, V.; Redmon, J.; and Farhadi, A. 2016. Xnor-net&#58; Imagenet classification using binary convolutional neural networks. European Conference on Computer Vision. &#91;2&#93; Li, F.; Zhang, B.; and Liu, B. 2016. Ternary weight networks. arXiv preprint arXiv&#58;1605.04711. ※论文题目（中英文）：极限低比特神经网络：通过ADMM算法压缩掉最后一个比特 / Extremely Low Bit Neural Network&#58; Squeeze the Last Bit Out with ADMM ※主要作者（中英文）：冷聪 窦则胜 李昊 朱胜火 金榕 / Cong Leng, Zesheng Dou, Hao Li, Shenghuo Zhu, Rong Jin 加入社群 新智元AI技术+产业社群招募中，欢迎对AI技术+产业落地感兴趣的同学，加小助手微信号&#58; aiera2015_1 入群；通过审核后我们将邀请进群，加入社群后务必修改群备注（姓名-公司-职位；专业群审核较严，敬请谅解）。 此外，新智元AI技术+产业领域社群(智能汽车、机器学习、深度学习、神经网络等)正在面向正在从事相关领域的工程师及研究人员进行招募。 转载来源：阿里提出新神经网络算法，压缩掉最后一个比特]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>比尔·盖茨</tag>
        <tag>固态硬盘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何用Python写一个贪吃蛇AI@慕课网 原创_慕课网_手记]]></title>
    <url>%2F2018%2Fabcdaffa%2F</url>
    <content type="text"><![CDATA[如何用Python写一个贪吃蛇AI@慕课网 原创慕课网手记 转载来源：如何用Python写一个贪吃蛇AI@慕课网 原创慕课网手记]]></content>
  </entry>
  <entry>
    <title><![CDATA[我用Python实现了12500张猫狗图像的精准分类]]></title>
    <url>%2F2018%2Fb95bd127%2F</url>
    <content type="text"><![CDATA[在这篇文章中，我们将展示如何建立一个深度神经网络，能做到以 90% 的精度来对图像进行分类，而在深度神经网络，特别是卷积神经网络兴起之前，这还是一个非常困难的问题。 深度学习是目前人工智能领域里最让人兴奋的话题之一了，它基于生物学领域的概念发展而来，现如今是一系列算法的集合。 事实已经证明深度学习在计算机视觉、自然语言处理、语音识别等很多的领域里都可以起到非常好的效果。 在过去的 6 年里，深度学习已经应用到非常广泛的领域，很多最近的技术突破，都和深度学习相关。 这里仅举几个例子：特斯拉的自动驾驶汽车、Facebook 的照片标注系统、像 Siri 或 Cortana 这样的虚拟助手、聊天机器人、能进行物体识别的相机，这些技术突破都要归功于深度学习。 在这么多的领域里，深度学习在语言理解、图像分析这种认知任务上的表现已经达到了我们人类的水平。 如何构建一个在图像分类任务上能达到 90% 精度的深度神经网络？ 这个问题看似非常简单，但在深度神经网络特别是卷积神经网络（CNN）兴起之前，这是一个被计算机科学家们研究了很多年的棘手问题。 本文分为以下三个部分进行讲解： 展示数据集和用例，并且解释这个图像分类任务的复杂度。- 搭建一个深度学习专用环境，这个环境搭建在 AWS 的基于 GPU 的 EC2 服务上。- 训练两个深度学习模型：第一个模型是使用 Keras 和 TensorFlow 从头开始端到端的流程，另一个模型使用是已经在大型数据集上预训练好的神经网络。搭建一个深度学习专用环境，这个环境搭建在 AWS 的基于 GPU 的 EC2 服务上。 一个有趣的实例：给猫和狗的图像分类 有很多的图像数据集是专门用来给深度学习模型进行基准测试的，我在这篇文章中用到的数据集来自 Cat vs Dogs Kaggle competition，这份数据集包含了大量狗和猫的带有标签的图片。 和每一个 Kaggle 比赛一样，这份数据集也包含两个文件夹： 训练文件夹：它包含了 25000 张猫和狗的图片，每张图片都含有标签，这个标签是作为文件名的一部分。我们将用这个文件夹来训练和评估我们的模型。- 测试文件夹：它包含了 12500 张图片，每张图片都以数字来命名。对于这份数据集中的每幅图片来说，我们的模型都要预测这张图片上是狗还是猫（1= 狗，0= 猫）。事实上，这些数据也被 Kaggle 用来对模型进行打分，然后在排行榜上排名。测试文件夹：它包含了 12500 张图片，每张图片都以数字来命名。对于这份数据集中的每幅图片来说，我们的模型都要预测这张图片上是狗还是猫（1= 狗，0= 猫）。事实上，这些数据也被 Kaggle 用来对模型进行打分，然后在排行榜上排名。 我们观察一下这些图片的特点，这些图片各种各样，分辨率也各不相同。图片中的猫和狗形状、所处位置、体表颜色各不一样。 它们的姿态不同，有的在坐着而有的则不是，它们的情绪可能是开心的也可能是伤心的，猫可能在睡觉，而狗可能在汪汪地叫着。照片可能以任一焦距从任意角度拍下。 这些图片有着无限种可能，对于我们人类来说在一系列不同种类的照片中识别出一个场景中的宠物自然是毫不费力的事情，然而这对于一台机器来说可不是一件小事。 实际上，如果要机器实现自动分类，那么我们需要知道如何强有力地描绘出猫和狗的特征，也就是说为什么我们认为这张图片中的是猫，而那张图片中的却是狗。这个需要描绘每个动物的内在特征。 深度神经网络在图像分类任务上效果很好的原因是，它们有着能够自动学习多重抽象层的能力，这些抽象层在给定一个分类任务后又可以对每个类别给出更简单的特征表示。 深度神经网络可以识别极端变化的模式，在扭曲的图像和经过简单的几何变换的图像上也有着很好的鲁棒性。让我们来看看深度神经网络如何来处理这个问题的。 配置深度学习环境 深度学习的计算量非常大，当你在自己的电脑上跑一个深度学习模型时，你就能深刻地体会到这一点。 但是如果你使用 GPUs，训练速度将会大幅加快，因为 GPUs 在处理像矩阵乘法这样的并行计算任务时非常高效，而神经网络又几乎充斥着矩阵乘法运算，所以计算性能会得到令人难以置信的提升。 我自己的电脑上并没有一个强劲的 GPU，因此我选择使用一个亚马逊云服务 (AWS) 上的虚拟机，这个虚拟机名为 p2.xlarge，它是亚马逊 EC2 的一部分。 这个虚拟机的配置包含一个 12GB 显存的英伟达GPU、一个 61GB 的 RAM、4 个 vCPU 和 2496 个 CUDA 核。 可以看到这是一台性能巨兽，让人高兴的是，我们每小时仅需花费 0.9 美元就可以使用它。当然，你还可以选择其他配置更好的虚拟机，但对于我们现在将要处理的任务来说，一台 p2.xlarge 虚拟机已经绰绰有余了。 我的虚拟机工作在 Deep Learning AMI CUDA 8 Ubuntu Version 系统上，现在让我们对这个系统有一个更清楚的了解吧。 这个系统基于一个 Ubuntu 16.04 服务器，已经包装好了所有的我们需要的深度学习框架（TensorFlow，Theano，Caffe，Keras），并且安装好了 GPU 驱动（听说自己安装驱动是噩梦般的体验）。 如果你对 AWS 不熟悉的话，你可以参考下面的两篇文章： https&#58;//blog.keras.io/running-jupyter-notebooks-on-gpu-on-aws-a-starter-guide.html- https&#58;//hackernoon.com/keras-with-gpu-on-amazon-ec2-a-step-by-step-instruction-4f90364e49achttps&#58;//hackernoon.com/keras-with-gpu-on-amazon-ec2-a-step-by-step-instruction-4f90364e49ac 这两篇文章可以让你知道两点： 建立并连接到一个 EC2 虚拟机。- 配置网络以便远程访问 jupyter notebook。配置网络以便远程访问 jupyter notebook。 用 TensorFlow 和 Keras 建立一个猫/狗图片分类器 环境配置好后，我们开始着手建立一个可以将猫狗图片分类的卷积神经网络，并使用到深度学习框架 TensorFlow 和 Keras。 先介绍下 Keras：Keras 是一个高层神经网络 API，它由纯 Python 编写而成并基于Tensorflow、Theano 以及 CNTK 后端，Keras 为支持快速实验而生，能够把你的 idea 迅速转换为结果。 从头开始搭建一个卷积神经网络 首先，我们设置一个端到端的 pipeline 训练 CNN，将经历如下几步：数据准备和增强、架构设计、训练和评估。 我们将绘制训练集和测试集上的损失和准确度指标图表，这将使我们能够更直观地评估模型在训练中的改进变化。 数据准备 在开始之前要做的第一件事是从 Kaggle 上下载并解压训练数据集。 我们必须重新组织数据以便让 Keras 更容易地处理它们。我们创建一个 data 文件夹，并在其中创建两个子文件夹： train- validationvalidation 在上面的两个文件夹之下，每个文件夹依然包含两个子文件夹： cats- dogsdogs 最后我们得到下面的文件结构： 这个文件结构让我们的模型知道从哪个文件夹中获取到图像和训练或测试用的标签。这里提供了一个函数允许你来重新构建这个文件树，它有 2 个参数：图像的总数目、测试集 r 的比重。 我使用了： n：25000（整个数据集的大小） - r：0.2- ratio = 0.2- n = 25000- organize_datasets(path_to_data=’./train/‘,n=n, ratio=ratio)r：0.2 n = 25000 现在让我们装载 Keras 和它的依赖包吧： 图像生成器和数据增强 在训练模型时，我们不会将整个数据集装载进内存，因为这种做法并不高效，特别是你使用的还是你自己本地的机器。 我们将用到 ImageDataGenerator 类，这个类可以无限制地从训练集和测试集中批量地引入图像流。在ImageDataGenerator 类中，我们将在每个批次引入随机修改。 这个过程我们称之为数据增强（dataaugmentation)。它可以生成更多的图片使得我们的模型不会看见两张完全相同的图片。这种方法可以防止过拟合，也有助于模型保持更好的泛化性。 我们要创建两个 ImageDataGenerator 对象。train_datagen 对应训练集，val_datagen 对应测试集，两者都会对图像进行缩放，train_datagen 还将做一些其他的修改。 基于前面的两个对象，我们接着创建两个文件生成器： train_generator- validation_generatorvalidation_generator 每个生成器在实时数据增强的作用下，在目录处可以生成批量的图像数据。这样，数据将会无限制地循环生成。 模型结构 我将使用拥有 3 个卷积/池化层和 2 个全连接层的 CNN。3 个卷积层将分别使用 32，32，64 的 3 * 3的滤波器（fiter）。在两个全连接层，我使用了 dropout 来避免过拟合。 我使用随机梯度下降法进行优化，参数 learning rate 为 0.01，momentum 为 0.9。 Keras 提供了一个非常方便的方法来展示模型的全貌。对每一层，我们可以看到输出的形状和可训练参数的个数。在开始拟合模型前，检查一下是个明智的选择。 model.summary() 下面让我们看一下网络的结构。 结构可视化 在训练模型前，我定义了两个将在训练时调用的回调函数 (callback function)： 一个用于在损失函数无法改进在测试数据的效果时，提前停止训练。- 一个用于存储每个时期的损失和精确度指标：这可以用来绘制训练错误图表。一个用于存储每个时期的损失和精确度指标：这可以用来绘制训练错误图表。 我还使用了 keras-tqdm，这是一个和 keras 完美整合的非常棒的进度条。它可以让我们非常容易地监视模型的训练过程。 要想使用它，你仅需要从 keras_tqdm 中加载 TQDMNotebookCallback 类，然后将它作为第三个回调函数传递进去。 下面的图在一个简单的样例上展示了 keras-tqdm 的效果。 关于训练过程，还有几点要说的： 我们使用 fit_generator 方法，它是一个将生成器作为输入的变体（标准拟合方法）。- 我们训练模型的时间超过 50 个 epoch。我们训练模型的时间超过 50 个 epoch。 这个模型运行时的计算量非常大： 如果你在自己的电脑上跑，每个 epoch 会花费 15 分钟的时间。- 如果你和我一样在 EC2 上的 p2.xlarge 虚拟机上跑，每个 epoch 需要花费 2 分钟的时间。如果你和我一样在 EC2 上的 p2.xlarge 虚拟机上跑，每个 epoch 需要花费 2 分钟的时间。 分类结果 我们在模型运行 34 个 epoch 后达到了 89.4% 的准确率（下文展示训练/测试错误和准确率），考虑到我没有花费很多时间来设计网络结构，这已经是一个很好的结果了。现在我们可以将模型保存，以备以后使用。 model.save(`./models/model4.h5) 下面我们在同一张图上绘制训练和测试中的损失指标值： 当在两个连续的 epoch 中，测试损失值没有改善时，我们就中止训练过程。 下面绘制训练集和测试集上的准确度。 这两个指标一直是增长的，直到模型即将开始过拟合的平稳期。 装载预训练的模型 我们在自己设计的 CNN 上取得了不错的结果，但还有一种方法能让我们取得更高的分数：直接载入一个在大型数据集上预训练过的卷积神经网络的权重，这个大型数据集包含 1000 个种类的猫和狗的图片。 这样的网络会学习到与我们分类任务相关的特征。 我将加载 VGG16 网络的权重，具体来说，我要将网络权重加载到所有的卷积层。这个网络部分将作为一个特征检测器来检测我们将要添加到全连接层的特征。 与 LeNet5 相比，VGG16 是一个非常大的网络，它有 16 个可以训练权重的层和 1.4 亿个参数。要了解有关 VGG16 的信息，请参阅此篇 pdf 链接&#58;https&#58;//arxiv.org/pdf/1409.1556.pdf 现在我们将图像传进网络来得到特征表示，这些特征表示将会作为神经网络分类器的输入。 图像在传递到网络中时是有序传递的，所以我们可以很容易地为每张图片关联上标签。 现在我们设计了一个小型的全连接神经网络，附加上从 VGG16 中抽取到的特征，我们将它作为 CNN 的分类部分。 在 15 个 epoch 后，模型就达到了 90.7% 的准确度。这个结果已经很好了，注意现在每个 epoch 在我自己的电脑上跑也仅需 1 分钟。 许多深度学习领域的大牛人物都鼓励大家在做分类任务时使用预训练网络，实际上，预训练网络通常使用的是在一个非常大的数据集上生成的非常大的网络。 而 Keras 可以让我们很轻易地下载像 VGG16、GoogleNet、ResNet 这样的预训练网络。想要了解更多关于这方面的信息，请参考这里：https&#58;//keras.io/applications/ 有一句很棒的格言是：不要成为英雄！不要重复发明轮子！使用预训练网络吧！ 接下来还可以做什么？ 如果你对改进一个传统 CNN 感兴趣的话，你可以： 在数据集层面上，引入更多增强数据。- 研究一下网络超参数（network hyperparameter)：卷积层的个数、滤波器的个数和大小，在每种组合后要测试一下效果。- 改变优化方法。- 尝试不同的损失函数。- 使用更多的全连接层。- 引入更多的 aggressive dropout。研究一下网络超参数（network hyperparameter)：卷积层的个数、滤波器的个数和大小，在每种组合后要测试一下效果。 尝试不同的损失函数。 引入更多的 aggressive dropout。 如果你对使用预训练网络获得更好的分类结果感兴趣的话，你可以尝试： 使用不同的网络结构。- 使用更多包含更多隐藏单元的全连接层。使用更多包含更多隐藏单元的全连接层。 如果你想知道 CNN 这个深度学习模型到底学习到了什么东西，你可以： 将 feature maps 可视化。- 可以参考：https&#58;//arxiv.org/pdf/1311.2901.pdf可以参考：https&#58;//arxiv.org/pdf/1311.2901.pdf 如果你想使用训练过的模型： 可以将模型放到 Web APP 上，使用新的猫和狗的图像来进行测试。这也是一个很好地测试模型泛化性的好方法。总结 这是一篇手把手教你在 AWS 上搭建深度学习环境的教程，并且教你怎样从头开始建立一个端到端的模型，另外本文也教了你怎样基于一个预训练的网络来搭建一个 CNN 模型。 用 Python 来做深度学习是让人愉悦的事情，而 Keras 让数据的预处理和网络层的搭建变得更加简单。 如果有一天你需要按自己的想法来搭建一个神经网络，你可能需要用到其他的深度学习框架。 现在在自然语言处理领域，也有很多人开始使用卷积神经网络了，下面是一些基于此的工作： 使用了 CNN 的文本分类：https&#58;//chara.cs.illinois.edu/sites/sp16-cs591txt/files/0226-presentation.pdf- 自动为图像生成标题：https&#58;//cs.stanford.edu/people/karpathy/sfmltalk.pdf- 字级别的文本分类：https&#58;//papers.nips.cc/pahttps&#58;//chara.cs.illinois.edu/sites/sp16-cs591txt/files/0226-presentation.pdf https&#58;//cs.stanford.edu/people/karpathy/sfmltalk.pdf https&#58;//papers.nips.cc/pa 转载来源：我用Python实现了12500张猫狗图像的精准分类]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>深度学习</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>GPU</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以太坊是什么 - 以太坊开发入门指南 - Tiny熊 - 博客园]]></title>
    <url>%2F2018%2F5d0352db%2F</url>
    <content type="text"><![CDATA[以太坊是什么 - 以太坊开发入门指南 - Tiny熊 - 博客园 转载来源：以太坊是什么 - 以太坊开发入门指南 - Tiny熊 - 博客园]]></content>
  </entry>
  <entry>
    <title><![CDATA[收藏｜15000个Python开源项目中精选Top30，Github平均star为3707]]></title>
    <url>%2F2018%2F3adde068%2F</url>
    <content type="text"><![CDATA[翻译 | AI科技大本营（ID：rgznai100） 参与 | SuiSui 继推出2017年机器学习开源项目Top 30榜单后，Mybridge AI又推出了一个Python开源项目Top 30榜单，包括开源Python库、工具等。该榜单基于项目质量、用户参与度以及其他几个方面进行了评估，从大约15000个开源项目中挑选了Top 30，差不多都是在2017年1-12月发布。这些项目在Github上的平均star为3707。 No 1：Home-assistant (v0.6+) 基于Python 3的开源家庭自动化平台&#91;Github 11357 stars，由Paulus Schoutsen提供&#93; https&#58;//github.com/home-assistant/home-assistant No 2：Pytorch PyTorch是使用GPU和CPU优化的深度学习张量库，基于Python语言编写。&#91;Github 11019 stars，由PyTorch团队的Adam Paszke和其他人提供&#93; https&#58;//github.com/pytorch/pytorch No 3：Grumpy Grumpy是一个Python to Go的源代码翻译编译器和运行时，旨在取代CPython 2.7。关键区别在于，Grumpy是将Python源码编译为Go源代码，然后将其编译为native code，而不是bytecode。这也就意味着Grumpy没有虚拟机（VM）。编译好的Go源码是对Grumpy运行时的一系列调用，一个Go库服务于具有相似目的的Python C API。 &#91;Github 8367 stars，由Google的Dylan Trotter及其他工作人员提供&#93;。 https&#58;//github.com/google/grumpy No 4：Sanic 该项目是一个类 Flask 的 Python 3.5+ 网页服务器，专为加速而设计。Sanic支持异步请求处理，意味着你可以使用Python 3.5中一些async/await语法。。&#91;Github 8028 stars，由Channel Cat和Eli Uriegas提供&#93; https&#58;//github.com/channelcat/sanic No 5：Python-fire 一个可以从任何Python对象自动生成命令行界面（CLI）的库。 &#91;Github 7775 stars，来自Google Brain 的 David Bieber&#93; https&#58;//github.com/channelcat/sanic No 6：spaCy（v2.0） 该项目是一个使用Python和Cython的进行高级自然语言处理（NLP）的开源库 &#91;Github 7633 stars，由Matthew Honnibal提供&#93; https&#58;//github.com/explosion/spaCy No 7：Pipenv Python.org官方推荐的Python打包工具。它会自动为项目创建和管理virtualenv，并在安装/卸载软件包时从Pipfile中添加/删除软件包。 &#91;Github 7273 stars，由Kenneth Reitz提供&#93; https&#58;//github.com/pypa/pipenv No 8：MicroPython 一个脱胎于Python且非常高效的Python实现，主要是为了能在嵌入式硬件上（这里特指微控制器级别）更简单地实现对底层的操作。&#91;Github 5728 stars&#93; https&#58;//github.com/micropython/micropython No 9：Prophet 该工具是Facebook开源的一款用于为多周期性的线性或非线性时间序列数据生成高质量预测的工具。&#91;Github 4369 stars，由Facebook提供&#93; https&#58;//github.com/facebook/prophet No 10：Serpent AI 该项目是一个Python写的游戏代理框架，简单而强大，可帮助开发者创建游戏代理。可将任何视频游戏变成一个Python写成的成熟沙箱环境。该框架的目的是为机器学习和AI研究提供一个有价值的工具，不过对于爱好者来说也是非常有趣的。&#91;Github 3411 stars，由Nicholas Brochu提供&#93; https&#58;//github.com/SerpentAI/SerpentAI No 11：Dash Dash是一个纯Python写成的框架，无需JavaScript即可构建交互式的分析类web应用程序。&#91;Github 3281 stars，由Chris P提供&#93; https&#58;//github.com/plotly/dash No 12：InstaPy Instagram机器人，喜欢/评论/Follow 自动化脚本。&#91;Github 3179 stars，由TimG提供&#93;。 https&#58;//github.com/timgrossmann/InstaPy No 13：Apistar 专为Python 3定制的Web API框架&#91;Github 3024 stars，Tom Christie提供&#93;。 https&#58;//github.com/encode/apistar No 14：Faiss 用于密集向量的高效相似性搜索库和聚类的库 &#91;GitHub 2717 stars，贡献者Facebook Research&#93; https&#58;//github.com/facebookresearch/faiss No 15：MechanicalSoup 一个与网站自动交互的Python库，自动存储和发送cookies，支持重定向，并可以跟踪链接和提交表格。&#91;Github 2244 stars&#93; https&#58;//github.com/MechanicalSoup/MechanicalSoup No 16：Better-exceptions 该项目以更友好的形式展示Python中的异常信息。&#91;Github 2121 stars，贡献者Qix&#93; https&#58;//github.com/Qix-/better-exceptions No 17：Flashtext 该项目基于FlashText算法，用以高效搜索句子中的关键词并进行替代。&#91;Github 2019 stars，由Vikash Singh提供&#93;。 https&#58;//github.com/vi3k6i5/flashtext No 18：Maya 在不同系统上的不同语言环境中，Python对日期时间的处理非常不畅，Maya主要就是为了解决解析网站时间数据问题。&#91;Github 1828 stars，Kenneth Reitz提供&#93; https&#58;//github.com/kennethreitz/maya No 19：Mimesis 是一个快速易用的Python库，可以用不同语言为基于不同的目的生成合成数据。这些数据在软件开发和测试阶段非常有用。&#91;Github 1732 stars，由LíkieGeimfari提供&#93; https&#58;//github.com/lk-geimfari/mimesis No 20：Open-paperless 该项目是一个一个文件管理系统，可扫描、索引和归档所有纸张文档。&#91;Github 1717 stars，由Tina Zhou提供&#93; https&#58;//github.com/zhoubear/open-paperless No 21：Fsociety 黑客工具包，渗透测试框架。&#91;Github 1585 stars，Manis Manisso提供&#93; No 22：LivePython Python代码实时可视化跟踪。&#91;Github 1577 stars，由Anastasis Germanidis提供&#93; https&#58;//github.com/agermanidis/livepython No 23：Hatch 一个Python项目、包以及虚拟环境的管理工具。&#91;Github 1537 stars，由Ofek Lev提供&#93; https&#58;//github.com/ofek/hatch No 24：Tangent 该项目是谷歌开源的一个用于自动微分的源到源纯Python库。&#91;Github 1433 stars，来自Google Brain的Alex Wiltschko以及其他人&#93;。 https&#58;//github.com/google/tangent No 25：Clairvoyant 一个Python程序，用于识别和监控短期库存移动的历史线索&#91;Github 1159 stars，由Anthony Federico提供&#93;。 https&#58;//github.com/anfederico/Clairvoyant No 26：MonkeyType 该项目是Instagram开源的一款适用于Python的工具，通过收集运行时类型来生成静态类型注释。&#91;Github 1137 stars，由Instagram工程师Carl Meyer提供&#93;。 https&#58;//github.com/Instagram/MonkeyType No 27：Eel 该项目是一个小型Python库，用于制作简单的类似 Electron的离线HTML/JS GUI应用程序，当前仅支持Python3。 &#91;Github 1137 stars&#93; https&#58;//github.com/ChrisKnott/Eel No 28：Surprise v1.0 用于构建和分析推荐系统的Python scikit &#91;Github 1103 stars&#93; https&#58;//github.com/NicolasHug/Surprise No 29：Gain Web爬虫框架。&#91;Github 1009 stars，由高久力提供&#93; https&#58;//github.com/gaojiuli/gain No 30：PDFTabExtract 一组用于从PDF文件中提取表格的工具，有助于在扫描的文档上进行数据挖掘。 &#91;Github 722 stars&#93; https&#58;//github.com/WZBSocialScienceCenter/pdftabextract 原文地址：https&#58;//medium.mybridge.co/30-amazing-python-projects-for-the-past-year-v-2018-9c310b04cdb3 转载来源：收藏｜15000个Python开源项目中精选Top30，Github平均star为3707]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>GitHub</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EOS DAWN-V3.0.0 智能合约开发之Hello World]]></title>
    <url>%2F2018%2Fb1580910%2F</url>
    <content type="text"><![CDATA[C、C++、Java还是任何其他语言，一般刚开始学习的时候，我们都会从HelloWorld开始，这篇文章主要讲解EOS DAWN-V3.0.0智能合约开发之Hello World。 1. 编写合约代码在桌面创建一个文件夹，比如：0418，用Atom打开0418文件夹。新建文件Hello.cpp文件，并将下面的源码拷贝到Hello.cpp文件中。 1#include &lt;eosiolib/eosio.hpp&gt;#include &lt;eosiolib/print.hpp&gt;// 视频网站：http://kongyixueyuan.com// 个人博客：http://liyuechun.org// 公众号：区块链部落// 进技术群，请加微信（kongyixueyuan）//用eosio命名空间using namespace eosio;//所有的智能合约都继承自contract类class Hello : public eosio::contract &#123; public: using contract::contract; /// @abi action void hi( account_name user ) &#123; print( &quot;Hello, &quot;, name&#123;user&#125; ); &#125;&#125;;EOSIO_ABI( Hello, (hi) ) 2. 生成.wast文件1liyuechun:Project yuechunli$ eosiocpp -o Hello.wast Hello.cppliyuechun:Project yuechunli$ lsHello.cppHello.wastliyuechun:Project yuechunli$ 3. 生成.abi文件1liyuechun:Project yuechunli$ eosiocpp -g Hello.abi Hello.cpp Generated Hello.abi ...liyuechun:Project yuechunli$ lsHello.abiHello.cppHello.wastliyuechun:Project yuechunli$ 1&#123; &quot;____comment&quot;: &quot;This file was generated by eosio-abigen. DO NOT EDIT - 2018-04-18T08:15:50&quot;, &quot;types&quot;: , &quot;structs&quot;: [&#123; &quot;name&quot;: &quot;hi&quot;, &quot;base&quot;: &quot;&quot;, &quot;fields&quot;: [&#123; &quot;name&quot;: &quot;user&quot;, &quot;type&quot;: &quot;account_name&quot; &#125; ] &#125; ], &quot;actions&quot;: [&#123; &quot;name&quot;: &quot;hi&quot;, &quot;type&quot;: &quot;hi&quot;, &quot;ricardian_contract&quot;: &quot;&quot; &#125; ], &quot;tables&quot;: , &quot;clauses&quot;: &#125; 4. 创建钱包账号4.1 创建钱包1liyuechun:Hello yuechunli$ cleos wallet createCreating wallet: defaultSave password to use in the future to unlock this wallet.Without password imported keys will not be retrievable.&quot;PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRL&quot; PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRL必须保存好，解锁钱包时需要使用到这个密码。 4.2 创建两组key1liyuechun:Hello yuechunli$ ./cleos create key-bash: ./cleos: No such file or directoryliyuechun:Hello yuechunli$ cleos create keyPrivate key: 5K7QdknUZsF9apdBhD8TDMZGJjw8zJ8esYwS173YyFRv2453Z9tPublic key: EOS5RU8VsYBLnN5snGeUKmt1sDDzpvQbGyW7LPP6qEryaFctYieCKliyuechun:Hello yuechunli$ cleos create keyPrivate key: 5J8kComGiQHZyNmH6VvkHgtFggeQemazLpihKR4QW75DNkWTVdAPublic key: EOS5fqiC3VFAJ1riMrKf8vzD28nqd4EpXvZGpXt6YewEBnH8DYinG 4.3 向钱包导入私钥1liyuechun:Hello yuechunli$ cleos wallet import 5K7QdknUZsF9apdBhD8TDMZGJjw8zJ8esYwS173YyFRv2453Z9timported private key for: EOS5RU8VsYBLnN5snGeUKmt1sDDzpvQbGyW7LPP6qEryaFctYieCKliyuechun:Hello yuechunli$ cleos wallet import 5J8kComGiQHZyNmH6VvkHgtFggeQemazLpihKR4QW75DNkWTVdAimported private key for: EOS5fqiC3VFAJ1riMrKf8vzD28nqd4EpXvZGpXt6YewEBnH8DYinG 4.4 创建账户1liyuechun:cleos yuechunli$ ./cleos create account eosio liyc111 EOS5RU8VsYBLnN5snGeUKmt1sDDzpvQbGyW7LPP6qEryaFctYieCK EOS5fqiC3VFAJ1riMrKf8vzD28nqd4EpXvZGpXt6YewEBnH8DYinG 5. 部署合约1liyuechun:build yuechunli$ cleos set contract liyc111 ./contracts/HelloReading WAST/WASM from ./contracts/Hello/Hello.wast...Assembling WASM...Publishing contract...executed transaction: 21d891e425f3d65852432e2b6a78146e2e2992a267c9f28c8ce56cd5dbea98f2 1632 bytes 2200576 cycles# eosio &lt;= eosio::setcode &#123;&quot;account&quot;:&quot;liyc111&quot;,&quot;vmtype&quot;:0,&quot;vmversion&quot;:0,&quot;code&quot;:&quot;0061736d0100000001370b60027f7e0060027e7e006001...# eosio &lt;= eosio::setabi &#123;&quot;account&quot;:&quot;liyc111&quot;,&quot;abi&quot;:&#123;&quot;types&quot;:,&quot;structs&quot;:[&#123;&quot;name&quot;:&quot;hi&quot;,&quot;base&quot;:&quot;&quot;,&quot;fields&quot;:[&#123;&quot;name&quot;:&quot;user&quot;,&quot;t...liyuechun:build yuechunli$ cleos get code liyc111code hash: e387951f9a18870f2c151fbceea5b279a3861bdabab58ea87a67296a8a6583d0liyuechun:build yuechunli$ 6. 执行合约6.1 解锁钱包PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRL是创建钱包是的密码。 1liyuechun:build yuechunli$ cleos wallet unlock --password PW5J3rx7Bfg9zb8Kf2owTytccFyJqtDTrqnUX8iBRRUvbwM8RyzRLUnlocked: default 6.2 执行合约1liyuechun:build yuechunli$ cleos push action liyc111 hi &apos;&#123;&quot;user&quot;:&quot;liyc1215&quot;&#125;&apos; -p liyc111executed transaction: 9abcaec2711ce31c693e5124af507f34aa666702bd5bb230ec31ddd6903248a8 232 bytes 102400 cycles# liyc111 &lt;= liyc111::hi &#123;&quot;user&quot;:&quot;liyc1215&quot;&#125;&gt;&gt; Hello, liyc1215liyuechun:build yuechunli$ 转载来源：EOS DAWN-V3.0.0 智能合约开发之Hello World]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>Java</tag>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Page Not Found :( | Hyperledger Composer]]></title>
    <url>%2F2018%2Fb3e9f1cb%2F</url>
    <content type="text"><![CDATA[Page Not Found :( | Hyperledger Composer 转载来源：Page Not Found :( | Hyperledger Composer]]></content>
  </entry>
  <entry>
    <title><![CDATA[张一鸣：为什么BAT挖不走我们的人才？]]></title>
    <url>%2F2018%2Fb961fd4b%2F</url>
    <content type="text"><![CDATA[张一鸣：为什么BAT挖不走我们的人才？ 转载来源：张一鸣：为什么BAT挖不走我们的人才？]]></content>
      <tags>
        <tag>正和岛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未收到世卫大会邀请 台当局心存侥幸：我们可以等_网易新闻]]></title>
    <url>%2F2018%2Fbb009d8c%2F</url>
    <content type="text"><![CDATA[未收到世卫大会邀请 台当局心存侥幸：我们可以等_网易新闻 转载来源：未收到世卫大会邀请 台当局心存侥幸：我们可以等_网易新闻]]></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习实战：用胶囊网络识别交通标志]]></title>
    <url>%2F2018%2Ff4794f7d%2F</url>
    <content type="text"><![CDATA[每个人似乎都对胶囊网络（CapsNet）这种新的神经网络架构的出现很兴奋，我也不例外，忍不住用胶囊网络实现了一个交通标志识别系统，这篇文章就是对这一过程的介绍，当然，也包括胶囊网络的一些基本概念阐述。 项目使用TensorFlow开发，参考的论文是Sara Sabour，Nicholas Frosst和Geoffrey E. Hinton的《 胶囊间动态路由 》，代码保存在github（https&#58;//github.com/thibo73800/capsnet-traffic-sign-classifier）。如果你迫不及待想要试试Tensorflow等机器学习框架，可以访问汇智网的Python机器学习在线环境（http&#58;//www.hubwiz.com/python-ml.html?affid=vat）。 卷积神经网络有什么问题？卷积神经网络（CNN）的问题部分源于其对图像感知的泛化能力，例如一个训练好的图像识别网络可能会对同一图像的旋转版本识别错误，这就是为什么在训练时经常使用数据增强和平均/最大池（Average / Max Pooling）。 池化通过随机选择下一层的神经元子集建立一个新的层。 这可以有效降低上层的计算需求，而且也使得网络减小对特征出现的原始位置的依赖性。 这一简化的依据在于：我们假设特征出现的确切位置对目标识别而言影响不大。 和CNN一样，上层的胶囊可以覆盖更大的图像区域，但是与最大化池不同，我们不会丢弃该区域内目标物体的准确位置信息。 这使得模型对图像中的细微变化可以保持不变的输出。 另一方面，模型有可能忽视图像发生的位移变化。不变意味着无论检测到的字符的顺序和位置是否改变，网络的输出总是相同的。 因此该模型能够理解图像中的特征的旋转和位移，并产生适当的输出。 这对于使用池化来说是不可能的。 这就是启发我们发明这个新架构的原因。 胶囊网络胶囊网络赋予了模型理解图像中所发生变化的能力，从而可以更好地概括所感知的内容。 要了解这个架构如何运作，重要的是掌握胶囊的概念。 胶囊是一组神经元，其激活向量表示某种特定类型的实体（如对象或对象部分）的实例化参数。 我们习惯从深度角度来谈论深度学习，而胶囊网络则引入了嵌套的概念，嵌套为深度引入了一个新的维度。 不是采用添加层的方法来增加网络的深度，相反，胶囊网络是在另一个层中添加（多个）新的图层。 这有点抽象， 但是当你仔细观察时，就会发现情况并不是那么复杂。 在论文中，这一方法的核心分为两部分： 基础胶囊和数字胶囊 。 在我们的案例中，后一部分将被重命名为交通标志胶囊 。 胶囊和基础胶囊 这一层基于经典的卷积计算，创建一个新的由N C滤波器组成的卷积层。 N表示滤波器的数量，C表示每个胶囊的尺寸。 因此会创建出具有（T，T）大小的N C个新图像。 在上图中，每个胶囊的值在新创建的图像中以红色显示。 Tensorflow代码如下： 现在创建好了卷积操作，我们可以重排这些卷积以便创建胶囊操作： 然后我们得到T T N个大小为C的胶囊（在这个项目中是1152个胶囊）。 需要指出的是，卷积的第一个C值（见代码中的注释）等于第一个胶囊的值，正如上面代码所示。 最后，原论文中给出了一个新的非线性函数，可以单独应用于每个胶囊。 这个新函数被称为挤压 （Squashing），看起来像这样： 因此，我们使用非线性Squashing函数来确保将短矢量的长度压缩到接近零，而长矢量的长度压缩到略低于1 交通标志胶囊 在本项目中，这个层由43个胶囊组成，每个胶囊代表一种特定的交通标志。 为了确定模型的预测结果，我们可以选择具有最大长度的胶囊。 但在此之前，需要在前一层的1152个胶囊之间进行转换。 这将通过路由的方法完成。 该方法的作用是选中前一层的哪些胶囊与输出层胶囊进行关联。 换句话说，对于每个胶囊，会有一个新的神经网络进行判断：”嘿，这个胶囊对这个类的判别有价值吗？” 使用迭代的路由处理过程，每个活动胶囊将在上面的层中选择一个胶囊，作为它在树中的父节点。 在路由中，对特征的选择不再是像池化那样随意。 在这篇文章中，我不会详细介绍路由所使用的确切公式，论文中有这些公式的描述。 本项目的实现代码在我的github 。 我还在继续改进以使算法更具可扩展性。 对于交通标志胶囊和路由，我在实现中尽量遵循了论文中的数学公式。 图像重建这种方法有助于引导网络将胶囊向量视为实际的物体，允许在重建之前对每个图像进行编码。 这在正则化方面也得到了很好的结果。 我们使用额外的重建损失来鼓励数字胶囊对输入数字的实例化参数进行编码。 这部分实现代码也包含在项目的github中，代码中的图像重建实现，使用了卷积和最近邻算法来放大图像。 事实上，我不能只是创建一堆简单的层，因为要重建的图像包含3个输出通道。 尽管在MNIST数据中这个实现表现得相当好，但我对其在大规模解决方案中的有效性还存有一些怀疑，不过这只是我的个人观点。 因此，模型最终的损失是基于两种可选的损失： 边际损失：基于模型的实际预测。 这是最高标准的胶囊。- 重建损失：基于图像之间平方差的解码器损失的平均值。重建损失：基于图像之间平方差的解码器损失的平均值。 模型架构由于我处理的数据集与原论文不同，所以模型架构也做了一些调整。 第一个卷积使用256个滤波器、大小为9的核（VALID填充）、RELU激活，dropout取值0.7。 基础胶囊层包含16个滤波器、大小为5的核、16个胶囊。最终获得256个（10,10）大小的滤波器。 即1600个16值胶囊。 最后一层（交通标志胶囊）由大小为32的43个胶囊（43个类）组成。 上述结构的构建代码如下： 训练训练时我使用了Keras的ImageDataGenerator以便进行数据增强。 结果（准确度）： 训练：99％- 验证：98％- 测试：97％验证：98％ 这个结果没能达到经典的卷积神经网络的最佳效果。 但是，考虑到我大部分时间都是在实现胶囊网络，而不是花在超参数调整和图像处理方面，因此对我来说，97％算是初次尝试的好成绩。 我现在还在努力提高这个指标。 分类示例 如果你喜欢这篇文章，请关注我的头条号：新缸中之脑！原文：Understand and apply CapsNet on Traffic sign classification 转载来源：机器学习实战：用胶囊网络识别交通标志]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>GitHub</tag>
        <tag>机器学习</tag>
        <tag>图像处理</tag>
        <tag>新创建集团</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链的那些事，你知道和不知道的都在这里！-云栖社区]]></title>
    <url>%2F2018%2Fbcf5d490%2F</url>
    <content type="text"><![CDATA[区块链的那些事，你知道和不知道的都在这里！-云栖社区 转载来源：区块链的那些事，你知道和不知道的都在这里！-云栖社区]]></content>
  </entry>
  <entry>
    <title><![CDATA[重磅数据揭示中国经济未来，真相无比残酷！]]></title>
    <url>%2F2018%2Fbe1e1600%2F</url>
    <content type="text"><![CDATA[重磅数据揭示中国经济未来，真相无比残酷！ 转载来源：重磅数据揭示中国经济未来，真相无比残酷！]]></content>
      <tags>
        <tag>凤凰财经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[帐号已迁移]]></title>
    <url>%2F2018%2Fbf19b63e%2F</url>
    <content type="text"><![CDATA[帐号已迁移 转载来源：帐号已迁移]]></content>
  </entry>
  <entry>
    <title><![CDATA[床抬高一米，小户型变大户型！]]></title>
    <url>%2F2018%2Fc0527d8f%2F</url>
    <content type="text"><![CDATA[床抬高一米，小户型变大户型！ 转载来源：床抬高一米，小户型变大户型！]]></content>
      <tags>
        <tag>设计吧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[首发：基于 Python3 的开源堡垒机 Jumpserver v1.0正式发布]]></title>
    <url>%2F2018%2Fc0f2fff6%2F</url>
    <content type="text"><![CDATA[Jumpserver是一款开源堡垒机产品(GPLv2 License)，使用 Python3 和 Django1.11 开发。自2014年诞生以来，经历了从 v0.1 到 v0.5， 5个版本迭代，今天我们正式发布一个里程碑版本 v1.0.0。Jumpserver Star数已超过4400个，安装也超过20000人次，感谢朋友们的支持和守候，我们会再接再厉砥砺前行，为中国开源做出一些贡献，改变世界从一点点开始。 1.0.0 **版本新增主要功能:** Windows支持 在既有Linux Web Terminal基础上整合 Apache Guacamole实现了RDP登录- 容器化部署 解决了之前版本持久化内容过多问题，支持容器化部署- 资产树 之前版本使用资产组来组织资产，这次实现了可嵌套的资产组，方便组织资产和以后的授权- 录像/命令存储支持OSS/S3和ES 命令和录像记录通常会限制堡垒机的并发，这里我们实现录像云存储和命令存储到ES集群- 分布式部署 一个中心节点部署Jumpserver API，提供核心API，各云上部署登录组件Coco，无并发限制，无性能瓶颈- 系统用户自动推送 授权后自动将系统用户推送到资产上，当然也支持手动推送- 标签管理 可以给资产打标签，方便过滤- 命令统计增加输出展示 之前版本只统计了输入命令，该版本输出同样进行了收集- Web Terminal改进 类似IDE形式的Web Terminal让你有放弃 xshell, secureCRT的冲动- 系统设置 有些配置直接在页面中设置即可，不用再修改配置文件- LDAP支持 支持了LDAP集中认证，方便企业统一认证容器化部署 解决了之前版本持久化内容过多问题，支持容器化部署 录像/命令存储支持OSS/S3和ES 命令和录像记录通常会限制堡垒机的并发，这里我们实现录像云存储和命令存储到ES集群 系统用户自动推送 授权后自动将系统用户推送到资产上，当然也支持手动推送 命令统计增加输出展示 之前版本只统计了输入命令，该版本输出同样进行了收集 系统设置 有些配置直接在页面中设置即可，不用再修改配置文件 下面秀一波图： Dashboard 用户列表 资产树列表 命令统计 在线会话 Web Terminal Linux Web Teminal Windows SSH登陆 更多图大家自己安装体验吧，感谢你的阅读，Jumpserver致力于打造更好用的混合云堡垒机系统，诚邀你的参与。 官网：http://www.jumpserver.org 文档：http://docs.jumpserver.org 项目：http://github.com/jumpserver/jumpserver 转载来源：首发：基于 Python3 的开源堡垒机 Jumpserver v1.0正式发布]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Apache</tag>
        <tag>Windows</tag>
        <tag>Dashboard</tag>
        <tag>IDE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django+Vue.js 初学入手的一些坑，已填坑 - CSDN博客]]></title>
    <url>%2F2018%2F2cbad18a%2F</url>
    <content type="text"><![CDATA[我用的django是1.11.0 vue是最新的，这是前提，之前因django版本不对导致一系列问题。另外要讲项目部署在Linux上运行，windows下运行也会出现很多坑。 接下来是我参考网上的一片文章开始搭建环境，其中有问题的地方会用红色加粗说明。 1. 创建Django项目命令： 1django-admin startproject ulb_manager 结构： 1234567.├── manage.py└── ulb_manager ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 2. 进入项目根目录，创建一个 app 作为项目后端命令： 12cd ulb_managerpython manage.py startapp backend 即：app 名叫做 backend 结构： 123456789101112131415.├── backend│ ├── __init__.py│ ├── admin.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── manage.py└── ulb_manager ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 3. 使用vue-cli创建一个vuejs项目作为项目前端命令： 1vue-init webpack frontend 即：项目名叫 frontend 结构： 123456789101112131415161718192021222324252627282930313233343536.├── backend│ ├── __init__.py│ ├── admin.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── frontend│ ├── README.md│ ├── build│ │ └── ....│ ├── config│ │ ├── dev.env.js│ │ ├── index.js│ │ ├── prod.env.js│ │ └── test.env.js│ ├── index.html│ ├── package.json│ ├── src│ │ ├── App.vue│ │ ├── assets│ │ │ └── logo.png│ │ ├── components│ │ │ └── Hello.vue│ │ └── main.js│ ├── static│ └── test│ └── ...├── manage.py└── ulb_manager ├── __init__.py ├── settings.py ├── urls.py └── wsgi.py 结构总结： backend Django的一个app- frontend Vuejs项目4. 接下来我们使用 webpack 打包Vusjs项目 命令： 123cd frontendnpm installnpm run build 结构： 123456789101112131415dist├── index.html└── static ├── css │ ├── app.42b821a6fd065652cb86e2af5bf3b5d2.css │ └── app.42b821a6fd065652cb86e2af5bf3b5d2.css.map ├── fonts │ ├── element-icons.a61be9c.eot │ └── element-icons.b02bdc1.ttf ├── img │ └── element-icons.09162bc.svg └── js ├── 0.8750b01fa7ffd70f7ba6.js ├── vendor.804853a3a7c622c4cb5b.js └── vendor.804853a3a7c622c4cb5b.js.map 构建完成会生成一个 文件夹名字叫dist，里面有一个 index.html 和一个 文件夹static ， 5. 使用Django的通用视图 TemplateView找到项目根 urls.py (即ulb_manager/urls.py)，使用通用视图创建最简单的模板控制器，访问 『/』时直接返回 index.html 12345urlpatterns = &amp;#91; url(r&apos;^admin/&apos;, admin.site.urls), **url(r&apos;^$&apos;, TemplateView.as_view(template_name=&quot;index.html&quot;)),** url(r&apos;^api/&apos;, include(&apos;backend.urls&apos;, namespace=&apos;api&apos;))&amp;#93; 6. 配置Django项目的模板搜索路径上一步使用了Django的模板系统，所以需要配置一下模板使Django知道从哪里找到index.html 打开 settings.py (ulb_manager/settings.py)，找到TEMPLATES配置项，修改如下&#58; 12345678910111213141516TEMPLATES = &amp;#91; &amp;#123 &apos;BACKEND&apos;&amp;#58; &apos;django.template.backends.django.DjangoTemplates&apos;, # &apos;DIRS&apos;&amp;#58; &amp;#91;&amp;#93;, **&apos;DIRS&apos;&amp;#58; &amp;#91;&apos;frontend/dist&apos;&amp;#93;**, &apos;APP_DIRS&apos;&amp;#58; True, &apos;OPTIONS&apos;&amp;#58; &amp;#123 &apos;context_processors&apos;&amp;#58; &amp;#91; &apos;django.template.context_processors.debug&apos;, &apos;django.template.context_processors.request&apos;, &apos;django.contrib.auth.context_processors.auth&apos;, &apos;django.contrib.messages.context_processors.messages&apos;, &amp;#93;, &amp;#125, &amp;#125,&amp;#93; 注意这里的 frontend 是VueJS项目目录，dist则是运行 npm run build 构建出的index.html与静态文件夹 static 的父级目录 7. 配置静态文件搜索路径打开 settings.py (ulb_manager/settings.py)，找到 STATICFILES_DIRS 配置项，配置如下&#58; 1234# Add for vuejsSTATICFILES_DIRS = &amp;#91; os.path.join(BASE_DIR, &quot;frontend/dist/static&quot;),&amp;#93; 这样Django不仅可以将/ulb 映射到index.html，而且还可以顺利找到静态文件 此时访问 /ulb 我们可以看到使用Django作为后端的VueJS helloworld 然后运行项目就可以看到所谓的vue界面了。 转载来源：Django+Vue.js 初学入手的一些坑，已填坑 - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[对以太坊公有链上金融项目的开发赞助计划 » 论坛 » EthFans | 以太坊爱好者]]></title>
    <url>%2F2018%2Fc9c4f25a%2F</url>
    <content type="text"><![CDATA[对以太坊公有链上金融项目的开发赞助计划 » 论坛 » EthFans | 以太坊爱好者 转载来源：对以太坊公有链上金融项目的开发赞助计划 » 论坛 » EthFans | 以太坊爱好者]]></content>
  </entry>
  <entry>
    <title><![CDATA[GitHub - ethereum/meteor-dapp-wallet]]></title>
    <url>%2F2018%2F07d3aead%2F</url>
    <content type="text"><![CDATA[GitHub - ethereum/meteor-dapp-wallet 转载来源：GitHub - ethereum/meteor-dapp-wallet]]></content>
  </entry>
  <entry>
    <title><![CDATA[您要找的页面不存在 - 简书]]></title>
    <url>%2F2018%2Fca035c5d%2F</url>
    <content type="text"><![CDATA[您要找的页面不存在 - 简书 转载来源：您要找的页面不存在 - 简书]]></content>
  </entry>
  <entry>
    <title><![CDATA[以太坊代币入门指南 » EthFans | 以太坊爱好者]]></title>
    <url>%2F2018%2F3267cb46%2F</url>
    <content type="text"><![CDATA[以太坊代币入门指南 » EthFans | 以太坊爱好者 转载来源：以太坊代币入门指南 » EthFans | 以太坊爱好者]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hyperledger Fabric概述 - 廉贞 - 博客园]]></title>
    <url>%2F2018%2Fbe58a435%2F</url>
    <content type="text"><![CDATA[Hyperledger Fabric概述 - 廉贞 - 博客园 转载来源：Hyperledger Fabric概述 - 廉贞 - 博客园]]></content>
  </entry>
  <entry>
    <title><![CDATA[第三方登录真的有那么便捷吗？]]></title>
    <url>%2F2017%2Fcb5648e3%2F</url>
    <content type="text"><![CDATA[打开新下载的 APP，小伙伴们会选择手机号码注册登录吗？ 我们越来越习惯不去记密码，而是点击跳转到微信、微博、QQ 等，再点击授权进入到 APP 中。主流 App 为了迎合用户的使用习惯，也会标配第三方登录。 非技术大神的你们难道就不好奇，为什么点击一下授权就完成了登录？如此神奇的功能背后的产品逻辑是什么？ 所谓的第三方登录，就是APP识别到用户将第三方的账号绑定到自己平台的 ID上直接完成登录的过程，简单来说，是指基于用户在第三方平台上已有的账号和密码来快速完成己方应用的登录或者注册的功能。常见的第三方登录平台，一般是已经拥有大量用户的平台，国内的就是各大厂：微信、微博、QQ 等，国外有 Facebook、Twitter。 了解了本质后，我们来看一下第三方登录为何如此受青睐。 APP 接入了第三方登录后，能快速获取到例如头像、昵称、性别、所在城市等用户信息，减少用户填写信息的步骤，简化注册流程，让用户能更快地使用产品，进而提高注册转化率。 而用户选择第三方登录，是为了更方便快捷，此外,和大厂有合作的 APP 也更值得信赖。 举个粟子，微信是最多用户选择的第三方接入应用，通过微信登录来注册一个APP ，只要点击“微信登录-跳转至微信页面-点击确认授权-返回APP ”四个步骤，不用记密码，不用收一大堆短信，在授权期间还不用频繁登录。 然而，第三方登录并不是百利而无一弊。 部分 APP 在用户确认授权后返回界面，仍然需要绑定用户手机号码才能完成账号注册；而且，如果用户用账号密码注册后再用第三方登录进入应用，很可能会发生多于一个账户的情况出现；再者，第三方登录会带来隐藏的个人信息或动态的泄露风险。 APP 商以为第三方登录有效降低用户的使用门槛，减少用户注册登录时长，降低安全风险。但实际上，近些年常用的第三方登录容易造成一人多号，导入的用户鱼龙混杂导致难以转化，用户账号管理上也更加混乱。 哇哩咧？找不到快捷又安全的登录方式提高注册转化率，辛辛苦苦引来的流量不能转化为真正的注册用户，身背几百万拉新任务的渠道宝宝们，KPI的鞭子在后面啪啪响，向 Boss 再借五百年也完不成任务啊！ 经过多方寻找和对比，渠道宝宝们终于找到了一款真正的一键登录，那就是中国移动推出的一键免密登录。为了不再被坑，我们来仔细了解下。 一键免密登录是中国移动旗下的移动认证面向 APP 推出的一项功能，它是基于运营商特有的网关取号、验证能力，能自动通过底层数据网络网关和短信网关直接识别本机号码，在不会泄漏用户信息的前提下，安全、快速地验证用户身份。用户无需经过繁琐的注册登录环节就能一键免密登录 APP，将用户用户体验做到了极致。 APP 接入此能力后，因为降低了用户的注册或登录成本，从而减少由于本地注册的繁琐性而带来的隐形用户流失，最终提高注册转化率；此外，该能力还能返回登录的本机号码，帮助 APP 建立用户与本机号码一对一的账号体系，便于精准营销。 这才是真正意义上的一键登录，APP 如果想一步到位实现注册登录的快捷性，移动认证能力无疑是最好的选择。不行，这么好的产品一定要推荐给Boss，KPI 完成指日可待。 中国移动 移动认证 第三方登录 安全验证 转载来源：第三方登录真的有那么便捷吗？]]></content>
      <categories>
        <category>数码</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>KPI</tag>
        <tag>移动互联网</tag>
        <tag>运营商</tag>
        <tag>中国移动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大神带你分分钟超越最好结果——基于分布式CPU计算的Deeplearning4j迁移学习应用实例]]></title>
    <url>%2F2017%2Fce524a22%2F</url>
    <content type="text"><![CDATA[更多深度文章，请关注：https://yq.aliyun.com/cloud 2016年，欧莱礼媒体公司首席数据科学家罗瑞卡宣称：“2017年将是数据科学和大数据圈参与AI技术合作的一年。”在2017年之前，对基于GPU的深度学习已经渗透到大学和研究机构，但基于CPU分散式深度学习开始在不同的公司和领域得到广泛采用。虽然GPU提供了顶级的数字计算性能，但CPU也在变得更加高效，并且现有的大部分硬件已经有大量可用的CPU计算能力。另外GPU的价格比CPU的价格要相对而言贵好多，相信大家最近一阵也发现显卡的价格暴涨，这源于数字货币比特币的暴涨，而比特币是通过电脑计算得到，计算能力越强，其每天的计算量也就越多，相当于每天“挖矿”的量。涉及深度学习的研究员都应该了解一个事实，基于GPU跑一个网络和基于CPU跑同一个网络，二者的仿真速度可以达到20倍左右的差距。因此，基于CPU的分散式深度学习也会成为后续研究的一个方向。而开源工具Deeplearning4j的出现将快速深度学习扩展到Hadoop堆栈，这将是未来几年影响深度学习的主要催化剂。本文将详细介绍如何使用开源工具——Apache Spark、Apache Hadoop和Deeplearning4j（DL4J），再加上商用硬件（Commodity Hardware，便宜、被广泛使用、容易被买到），能够使用有限的训练集在图像识别任务上获得最先进的结果。 Deeplearning4j：JVM的深度学习工具集 Deeplearning4j是许多开源深度学习工具包之一，创建于2014年。DL4J集成了Hadoop和Spark，设计用于运行在分布式GPU和CPU上的商用环境。它由总部位于旧金山的商用智能和企业软件公司Skymind牵头开发。团队成员包括数据专家、深度学习专家、Java系统工程师和具有一定感知力的机器人。虽然deeplearning4j是为JVM构建的，但它使用高性能原生线性代数库Nd4j，可以对CPU或GPU进行大量优化的计算。另外使用Java编写的DL4J API对于熟悉Java虚拟机（JVM）的Java和Scala开发人员特别有吸引力。此外，Spark模型的并行训练能力使得我们轻松利用现有的群集资源来加快训练时间，而不会牺牲精度。基于Caltech-256图像数据集的对象分类 本文介绍如何使用Apache Spark、Apache Hadoop和deeplearning4j来解决图像分类问题。简单来说，就是通过构建一个卷积神经网络来对Caltech-256数据集中的图像进行分类。在Caltech-256数据集中，实际上有257个对象类别，每类数量大概是80到800个图像，该数据集总共30,607个图像。值得注意的是，该数据集上目前最先进的分类精度在72 - 75％范围内。下面我将带领大家使用DL4J和Spark轻松超越这个结果。 小数据上的有效深度学习 目前，卷积网络可以有几亿个参数，比如在大型视觉识别挑战“ImageNet”中表现最佳的神经网络之一，有1.4亿个参数需要训练！这些网络不仅需要大量的计算和存储资源（即使是使用一组GPU，也可能需要几周时间才能完成计算），而且还需要大量数据。而Caltech-256只有30000多张图像，在这个数据集上训练这样一个复杂的模型是不现实的，因为没有足够的样本来充分学习这么多参数。相反，可以采用一种迁移学习的方法来实现。简单来说，就是将已学到的知识应用到其它领域，使其能够更好地完成新领域的学习。这是因为卷积神经网络在对图像数据集进行训练时往往会学习非常普遍的特征，因此这种类型的特征学习通常对其他图像数据集也是通用的。例如，在ImageNet上训练的网络可能已经学会了如何识别形状、面部特征、图案、文本等，这无疑对于Caltech-256数据集是有用的。 加载预训练的模型 下面讲解如何使用训练好的模型来完成自己的任务，以下示例使用VGG16 模型，该模型夺得了2014 ImageNet竞赛中的亚军（网络结构及训练好的参数已公开）。由于使用了不同的图像数据集，所以需要对VGG16模型进行微小修改以适用于Caltech-256数据集预测任务。该模型具有约1.4亿个参数，大约占用500 MB空间。 首先，获取DL4J可以理解和使用的VGG16型号的版本。事实证明，这种东西是建立在DL4J的API中的，它可以通过几行Scala代码完成。 该模型采用的格式易于DL4J使用，使用内置的模型进行检查。 上面代码显示VGG16网络的结构及参数，ConvolutionLayer表示卷积层、SubsamplingLayer表示采样层、DenseLayer表示全连接层。下图简明扼要的展示了该网络结构： VGG16具有13个卷积层，中间间隔放置最大池化层以收缩图像，降低计算复杂度。卷积层中的权重实际上是过滤器，可以学习从图像中挑选出视觉特征，当使用最大池化层时，它们会“收缩”图像，这意味着后来的卷积层中的滤波器实际上提取更加抽象的特征。这样，卷积层的输出是输入图像的抽象的视觉特征，如“这个图像中有脸吗？”还是“有日落？”卷积层的输出被馈送到连续的三个全连接层，全连接层能够学习这些视觉特征与输出之间的非线性关系。 另外卷积网络的关键性质之一是允许我们进行迁移学习——可以通过已经训练好的VGG16网络传递新的图像数据，并获取每个图像的特征。一旦提取了这些特征，就只需要送人最后的预测网络就可以完成相应的任务，这在计算和复杂度上都是非常容易解决的问题。 使用VGG16进行图像特征化 数据集可以从Caltech-256 网站下载，拆分为三个数据集，分别为训练/验证/测试数据集，并存储在HDFS中。一旦完成该步骤，下一步就是将整个图像数据集传递到网络的所有卷积层和第一个全连接层，并将该输出保存到HDFS。 样做的原因是是因为卷积网络中的大多数内存占用和耗时计算都是发生在卷积层中，VGG16中的大多数参数（权重）调用发生在全连接层。迁移学习利用预先训练的卷积层来获取关于新输入图像的特征，这意味着只有原始模型的一小部分——全连接层被重新训练。其余的参数是静态不变的。通过这种操作，迁移学习可以节省大量的训练时间和计算量。 首先提取用于特征化步骤的网络部分，Deeplearning4j具有内置的迁移学习API可用于此任务。即拆分VGG16模型，在拆分之前和之后获取整个图层列表，代码如下。 现在使用org.deeplearning4j.nn迁移学习包来提取全连接“fc2”层之前（包括“fc2”层）的网络模型，如下图所示：垂线左边部分。 接下来是读取数据库中的图像文件。在这种情况下，这些文件被单独保存到HDFS作为JPEG文件。图像被组织成子目录，其中每个子目录包含属于特定类的一组图像。首先通过使用sc.binaryFiles 加载存储在HDFS中的图像，并使用DataVec库（DL4J的ETL库）中的图像处理工具将它们转换为INDArrays，这是DL4J处理的本机张量表示（此处为完整代码）。最后，使用上图中的冻结网络部分对输入图像进行特征提取，本质上是将它们传递到VGG16模型中的预测层前。 经过上述操作后，得到一个保存到HDFS中新的数据集。接下来可以开始构建使用这种特征化数据的传输学习模型，从而大大减少训练时间和计算复杂度。在上述示例中，得到的新数据集由30607个长度为4096的向量组成（这是由于VGG16模型中的全连接层“f2”维度为4096）。 替换VGG16的预测层 VGG16模型是在ImageNet数据集上进行训练的，而ImageNet数据集具有1000种不同对象类别。在典型的图像分类神经网络中，输出层的最后一层使用其输入来为数据集中的每个对象生成概率（哪一类的概率大就判断为哪一类）。因此，该输入可以被认为是关于图像的抽象视觉特征，提供关于其包含的对象的有用信息。直观地说，上述步骤生成的新数据集于Caltech-256数据集中识别对象应该是有用的。因此，定义一个新的模型，“f2”层前的模型不变，只是替换VGG16模型的最后一层预测层，将维度从原先的1000变成257，正好对应Caltech256数据集的257个类别。 直观图如下，可以看到只是改变了预测层的维度： 该模型现在已准备好使用DL4J进行大量计算，而且还使用Spark进行规模化。简单来说是切分大规模的数据集，然后将分片交给spark群集中的每个工作核心上运行SGD，最后使用Spark RDD聚合操作对每个核心上学习的不同模型进行平均，实现分布式训练。 现在针对具体的迭代次数训练SparkComputationGraph，并监控一些训练统计数据以跟踪进度。 最后，通过spark提交训练工作，然后使用DL4J webui监控进度并诊断问题。下图绘制的是模型得分与迭代次数的关系，注意到分数是minibatch的负对数似然率，分数越小，效果越好。 这次将学习率调低后，该模型似乎能比Imagenet模型能更快地学习，因为这次使用的特征比ImageNet概率更具预测性。 由于训练准确率为88.8％，但验证准确率仅为76.3％，从结果上看该模型似乎已经过拟合了。为了确保模型不会过拟合到验证集，在测试集上评估该模型。 虽然准确率有所降低，但是使用基于现有Hadoop集群和商用CPU的简单深度学习架构仍然打破了该数据集的最好结果！虽然这可能不是一个突破性的成就，但这仍然是一个令人兴奋的结果。 结论 虽然deeplearning4j只是许多深度学习可用的工具之一，但它具有本机ApacheSpark集成，并且采用Java编写，使其特别适合整个Hadoop生态系统。由于现有的企业数据已经通过Hadoop进行了大量访问，而且在Spark上进行处理，所以deeplearning4j的定位是花费更少的时间部署和减少开销，从而企业公司可以立即开始从深度学习中提取数据。它利用ND4J进行大量计算，这是一种高度优化的库，可与商用CPU配合使用，但在需要性能提升时也支持GPU。Deeplearning4j提供了一个全功能的深度学习库，具有从采集到部署的工具，可 用于各种任务，如图像/视频识别，音频处理等。 作者信息 Nisha Muktewar，数据科学家，目前就职于Cloudera的数据科学团队，专注于专业服务、售前工作。 Seth Hendrickson，以前是电气工程师，现在是数据科学家和软件工程师，研究方向是分布式机器学习。 本文由北邮@爱可可-爱生活老师推荐，阿里云云栖社区组织翻译。 文章原标题《Deep learning on Apache Spark and Apache Hadoop withDeeplearning4j | Cloudera Engineering Blog》，作者：Nisha Muktewar、Seth Hendrickson，译者：海棠，审阅： 附件为原文的pdf 文章为简译，更为详细的内容，请查看原文 转载来源：大神带你分分钟超越最好结果——基于分布式CPU计算的Deeplearning4j迁移学习应用实例]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Hadoop</tag>
        <tag>CPU</tag>
        <tag>Spark</tag>
        <tag>加州理工学院</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据：美团酒旅实时数据规则引擎应用实践]]></title>
    <url>%2F2017%2Fcedb0633%2F</url>
    <content type="text"><![CDATA[背景 美团点评酒旅运营需求在离线场景下，已经得到了较为系统化的支持，通过对离线数据收集、挖掘，可对目标用户进行T+1触达，通过向目标用户发送Push等多种方式，在一定程度上提高转化率。但T+1本身的延迟性会导致用户在产生特定行为时不能被实时触达，无法充分发挥数据的价值，取得更优的运营效果。 在此背景下，运营业务需要着手挖掘用户行为实时数据，如实时浏览、下单、退款、搜索等，对满足运营需求用户进行实时触达，最大化运营活动效果。 业务场景 在运营实时触达需求中，存在如下具有代表性的业务场景： 用户在30分钟内发生A行为次数大于等于3次- 用户为美团酒店老客，即用户曾购买过美团酒店产品- 用户在A行为前24小时内未发生B行为- 用户在A行为后30分钟内未发生B行为（排除30分钟内用户自发产生B行为的影响，降低对结果造成的偏差） 本文以该典型实时运营场景为例，围绕如何设计出可支撑业务需求高效、稳定运行的系统进行展开。 早期方案 运营实时触达需求早期活动数量较少，我们通过为每个需求开发一套Storm拓扑相关代码、将运营活动规则硬编码这一“短平快”的方式，对运营实时触达需求进行快速支持，如图1所示： 图1 早期方案示意图 早期方案的问题 早期方案是一种Case By Case的解决方式，不能形成一个完整的系统。随着实时运营业务开展，相关运营活动数量激增，线上维护着多套相似代码，一方面破坏了DRY（Don’t Repeat Yourself）原则，另一方面线上维护成本也呈线性增长，系统逐渐无法支撑当前的需求。 挑战 为解决早期方案中出现的问题，对系统建设提出了以下挑战： 硬编码活动规则的方式产生了大量重复代码，开发成本较高，需求响应时间较长。- 业务规则修改困难，调整运营活动条件需要修改代码并重启线上拓扑。- 线上Storm拓扑较多，资源利用率、系统吞吐量低，统一维护成本较高。- 缺乏完善的监控报警机制，很难早于业务发现系统及数据中存在的稳定性问题。业务规则修改困难，调整运营活动条件需要修改代码并重启线上拓扑。 缺乏完善的监控报警机制，很难早于业务发现系统及数据中存在的稳定性问题。 针对以上挑战，结合业务规则特点，美团点评数据智能团队调研并设计了酒旅运营实时触达系统。 技术调研 规则引擎的必要性 提高灵活度需要从业务规则和系统代码解耦和入手，规则和代码耦合直接导致了重复代码增多、业务规则修改困难等问题。那如何将业务规则和系统代码解耦和呢？我们想到使用规则引擎解决这一问题。 规则引擎是处理复杂规则集合的引擎。通过输入一些基础事件，以推演或者归纳等方式，得到最终的执行结果。规则引擎的核心作用在于将复杂、易变的规则从系统中抽离出来，由灵活可变的规则来描述业务需求。由于很多业务场景，包括酒旅运营实时触达场景，规则处理的输入或触发条件是事件，且事件间有依赖或时序的关系，所以规则引擎经常和CEP（复合事件处理）结合起来使用。 CEP通过对多个简单事件进行组合分析、处理，利用事件的相互关系，找出有意义的事件，从而得出结论。文章最前面背景中提到的业务场景，通过多次规则处理，将单一事件组合成具有业务含义的复合事件，进而提高该类仅浏览未下单的用户的下单概率。可以看出，规则引擎及CEP可以满足业务场景的具体需求，将其引入可以提高系统面对需求变化的灵活度。 规则引擎调研 在设计规则引擎前，我们对业界已有的规则引擎，主要包括Esper和Drools，进行了调研。 Esper Esper设计目标为CEP的轻量级解决方案，可以方便的嵌入服务中，提供CEP功能。 优势 轻量级可嵌入开发，常用的CEP功能简单好用。- EPL语法与SQL类似，学习成本较低。EPL语法与SQL类似，学习成本较低。 劣势 单机全内存方案，需要整合其他分布式和存储。- 以内存实现时间窗功能，无法支持较长跨度的时间窗。- 无法有效支持定时触达（如用户在浏览发生后30分钟触达支付条件判断）。以内存实现时间窗功能，无法支持较长跨度的时间窗。 Drools Drools开始于规则引擎，后引入Drools Fusion模块提供CEP的功能。 优势 功能较为完善，具有如系统监控、操作平台等功能。劣势 学习曲线陡峭，其引入的DRL语言较复杂，独立的系统很难进行二次开发。- 以内存实现时间窗功能，无法支持较长跨度的时间窗。- 无法有效支持定时触达（如用户在浏览发生后30分钟触达支付条件判断）。以内存实现时间窗功能，无法支持较长跨度的时间窗。 由于业务规则对时间窗功能及定时触达功能有较强的依赖，综合以上两种规则引擎的优劣势，我们选用了相对SpEL更为轻量的表达式引擎Aviator，将流式数据处理及规则引擎集成至Storm中，由Storm保证系统在数据处理时的吞吐量，在系统处理资源出现瓶颈时，可在公司托管平台上调整Worker及Executor数量，降低系统水平扩展所需成本。 技术方案 确定引入规则引擎后，围绕规则引擎的设计开发成为了系统建设的主要着力点。通过使用实时数据仓库中的用户实时行为数据，按业务运营活动规则，组合成有意义的复合事件，交由下游运营业务系统对事件的主体，也就是用户进行触达。将系统抽象为以下功能模块，如图2所示： 图2 系统模块图 总体来看，系统组成模块及功能如下： 规则引擎：集成于Storm拓扑中，执行运营活动条件转换成为的具体规则，作出对应响应。- 时间窗模块：具有可选时间跨度的滑动时间窗功能，为规则判定提供时间窗因子。- 定时触达模块：设定规则判定的执行时间，达到设定时间后，执行后续规则。- 自定义函数：在Aviator表达式引擎基础函数之上，扩展规则引擎功能。- 报警模块：定时检查系统处理的消息量，出现异常时为负责人发送报警信息。- 规则配置控制台：提供配置页面，通过控制台新增场景及规则配置。- 配置加载模块：定时加载活动规则等配置信息，供规则引擎使用。时间窗模块：具有可选时间跨度的滑动时间窗功能，为规则判定提供时间窗因子。 自定义函数：在Aviator表达式引擎基础函数之上，扩展规则引擎功能。 规则配置控制台：提供配置页面，通过控制台新增场景及规则配置。 其中，规则引擎由核心组件构成的最小功能集及扩展组件提供的扩展功能组成。由于规则引擎解耦了业务规则和系统代码，使得实时数据在处理时变的抽象，对数据监控、报警提出了更高的要求。下面我们将从规则引擎核心组件、规则引擎扩展组件、监控与报警三个方面分别进行介绍。 规则引擎核心组件 规则引擎核心组件为构成规则引擎的最小集合，用以支持完成基础规则判断。 规则引擎核心流程 引入规则引擎后，业务需求被转换为具体场景和规则进行执行，如图3所示： 图3 规则引擎处理流程图 规则引擎在执行规则过程中，涉及以下数据模型： 场景：业务需求的抽象，一个业务需求对应一个场景，一个场景由若干规则组成。用不同的规则组成时序和依赖关系以实现完整的业务需求。- 规则：规则由规则条件及因子组成，由路由至所属场景的事件触发，规则由规则条件、因子及规则响应组成。- 规则条件：规则条件由因子构成，为一个布尔表达式。规则条件的执行结果直接决定是否执行规则响应。- 因子：因子是规则条件的基础组成部分，按不同来源，划分为基础因子、时间窗因子和第三方因子。基础因子来源于事件，时间窗因子来源于时间窗模块获取的时间窗数据，第三方因子来源于第三方服务，如用户画像服务等。- 规则响应：规则执行成功后的动作，如将复合事件下发给运营业务系统，或发送异步事件进行后续规则判断等。- 事件：事件为系统的基础数据单元，划分为同步事件和异步事件两种类型。同步事件按规则路由后，不调用定时触达模块，顺序执行；异步事件调用定时触达模块，延后执行。规则：规则由规则条件及因子组成，由路由至所属场景的事件触发，规则由规则条件、因子及规则响应组成。 因子：因子是规则条件的基础组成部分，按不同来源，划分为基础因子、时间窗因子和第三方因子。基础因子来源于事件，时间窗因子来源于时间窗模块获取的时间窗数据，第三方因子来源于第三方服务，如用户画像服务等。 事件：事件为系统的基础数据单元，划分为同步事件和异步事件两种类型。同步事件按规则路由后，不调用定时触达模块，顺序执行；异步事件调用定时触达模块，延后执行。 时间窗模块 时间窗模块是酒旅运营实时触达系统规则引擎中的重要构成部分，为规则引擎提供时间窗因子。时间窗因子可用于统计时间窗口内浏览行为发生的次数、查询首次下单时间等，表1中列举了在运营实时触达活动中需要支持的时间窗因子类型： |类型|示例|因子构成|——|count|近X分钟浏览POI大于Y次|count(timeWindow(event.id, event.userId, X 60))|distinct count|近X分钟浏览不同POI大于Y次|count(distinct(timeWindow(event.id, event.userId, X 60)))|first|近X天支付的首单酒店|first(timeWindow(event.id, event.userId, X 60))|last|近X天最后一次搜索的酒店|last(timeWindow(event.id, event.userId, X 60)) 表1 时间窗因子类型 根据时间窗因子类型可以看出，时间窗因子有以下特点： 时间窗存储中需要以List形式保存时间窗详情数据，以分别支持聚合及详情需求。1. 时间窗因子需要天粒度持久化，并支持EXPIRE。1. 时间窗因子应用场景多，是许多规则的重要组成因子，服务承受的压力较大，响应时间需要在ms级别。时间窗因子需要天粒度持久化，并支持EXPIRE。 对于以上特点，在评估使用场景和接入数据量级的基础上，我们选择公司基于Tair研发的KV的存储服务Cellar存储时间窗数据，经测试其在20K QPS请求下，TP99能保证在2ms左右，且存储方面性价比较高，可以满足系统需求。 在实际运营活动中，对时间窗内用户某种行为次数的判断往往在5次以内，结合此业务场景，同时为避免Value过大影响读写响应时间，在更新时间窗数据时设置阈值，对超出阈值部分进行截断。时间窗数据更新及截断流程如图4所示： 图4 时间窗数据更新示意图 文章最前面背景中提到的业务场景，在1. 用户在30分钟内发生A行为次数大于等于3次`3. 用户在A行为前24小时内未发生B行为4. 用户在A行为后30分钟内未发生B行为（排除30分钟内用户自发产生B行为的影响，降低对结果造成的偏差）`中，均使用了时间窗模块对滑动时间窗内的用户行为进行了统计，以时间窗因子作为规则执行判断的依据。 规则引擎扩展组件 规则引擎扩展组件在核心组件的基础上，增强规则引擎功能。 自定义函数 自定义函数可以扩充Aviator功能，规则引擎可通过自定义函数执行因子及规则条件，如调用用户画像等第三方服务。系统内为支持运营需求扩展的部分自定义函数如表2所示： |名称|示例|含义|——|equals|equals(message.orderType, 0)|判断订单类型是否为0|filter|filter(browseList, ‘source’, ‘dp’)|过滤点评侧浏览列表数据|poiPortrait|poiPortrait(message.poiId)|根据poiId获取商户画像数据，如商户星级属性|userPortrait|userPortrait(message.userId)|根据userId获取用户画像数据，如用户常住地城市、用户新老客属性|userBlackList|userBlackList(message.userId)|根据userId判断用户是否为黑名单用户 表2 自定义函数示例 文章最前面背景中提到的业务场景，在2. 用户为美团酒店老客，即用户曾购买过美团酒店产品中，判断用户是否为美团酒店老客，就用到了自定义函数，调用用户画像服务，通过用户画像标签进行判定。 定时触达模块 定时触达模块支持为规则设定定时执行时间，延后某些规则的执行以满足运营活动规则。文章最前面背景中提到的业务场景，在4. 用户在A行为后30分钟内未发生B行为（排除30分钟内用户自发产生B行为的影响，降低对结果造成的偏差）条件中，需要在A行为发生30分钟后，对用户是否发生B行为进行判定，以排除用户自发产生B行为对活动效果造成的影响。 定时触达模块涉及的数据流图如图5所示： 图5 定时触达模块数据流图 早期的业务需求对延迟时间要求较短，且活动总数量较小，通过维护纯内存DelayQueue的方式，支持定时触达需求。随着相关运营活动数量增多及定时触达时间的延长，纯内存方式对内存的占用量越来越大，且在系统重启后定时数据会全部丢失。在对解决方案进行优化时，了解到公司消息中间件组在Mafka消息队列中支持消息粒度延迟，非常贴合我们的使用场景，因此采用此特性，代替纯内存方式，实现定时触达模块。 监控与报警 对比离线数据，实时数据在使用过程中出现问题不易感知。由于系统针对的运营活动直接面向C端，在出现系统异常或数据质量异常时，如果没有及时发现，将会直接造成运营成本浪费，严重影响活动转化率等活动效果评估指标。针对系统稳定性问题，我们从监控与报警两个角度入手解决。 监控 利用公司数据平台现有产品，对系统处理的实时事件按其事件ID上报，以时间粒度聚合，数据上报后可实时查看各类事件量，通过消息量评估活动规则和活动效果是否正常，上报数据展示效果如图6所示： 图6 实时事件监控图 报警 监控只能作为Dashboard供展示及查看，无法实现自动化报警。由于用于监控所上报的聚合数据存储于时序数据库OpenTSDB中，我们基于OpenTSDB开放的HTTP API，定制报警模块，定时调度、拉取数据，对不同事件，按事件量级、活动重要性等指标，应用环比、绝对值等不同报警规则及阈值。超出设定阈值后，通过公司IM及时发送报警信息。如图7所示，该事件环比出现数据量级下降，收到报警后相关负责人可及时跟踪问题： 图7 报警信息示意图 总结与展望 酒旅运营实时触达系统已上线稳定运行一年多时间，是运营业务中十分重要的环节，起到承上启下的作用，在系统处理能力及对业务贡献方面取得了较好的效果： 平均日处理实时消息量近10亿。- 峰值事件QPS 1.4万。- 帮助酒店、旅游、大交通等业务线开展了丰富的运营活动。- 对转化率、GMV、拉新等指标促进显著。峰值事件QPS 1.4万。 对转化率、GMV、拉新等指标促进显著。 当前系统虽然已解决了业务需求，但仍存在一些实际痛点： 实时数据接入非自动化。- 规则引擎能力需要推广、泛化。- 场景及规则注册未对运营PM开放，只能由RD完成。规则引擎能力需要推广、泛化。 展望未来，在解决痛点方面我们还有很多路要走，未来会继续从技术及业务两方面入手，将系统建设的更加易用、高效。 作者简介 晓星，美团平台技术部－数据中心－数据智能组系统工程师，2014年毕业于北京理工大学，从事Java后台系统及数据服务建设。2017年加入美团点评，从事大数据处理相关工作。 伟彬，美团平台技术部－数据中心－数据智能组系统工程师，2015年毕业于大连理工大学，同年加入美团点评，专注于大数据处理技术与高并发服务。 招聘信息 美团平台技术部－数据中心－数据智能组长期招聘数据挖掘算法、大数据系统开发、Java后台开发方面的人才，有兴趣的同学可以发送简历到lishangqiang#meituan.com。 转载来源：大数据：美团酒旅实时数据规则引擎应用实践]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>移动互联网</tag>
        <tag>大数据</tag>
        <tag>美团网</tag>
        <tag>数据挖掘</tag>
        <tag>Storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里等联合论文：基于对抗学习的众包标注用于中文命名实体识别]]></title>
    <url>%2F2017%2F87f01e4a%2F</url>
    <content type="text"><![CDATA[机器之心发布 主要作者：杨耀晟，张梅山，陈文亮，王昊奋，张伟，张民 国际知名的人工智能学术会议 AAAI 2018 即将于 2 月份在美国新奥尔良举办，据机器之心了解，阿里巴巴共有 11 篇论文被接收。机器之心 AAAI 2018 论文专栏，将会对其中的数篇论文进行介绍，同时也欢迎读者推荐更多优质的 AAAI 2018 接收论文。 本文介绍了阿里巴巴业务平台事业部、深圳 Gowild（中文：狗尾草）智能科技有限公司、苏州大学联合发布的论文《Adversarial Learning for Chinese NER from Crowd Annotations》。该论文提出了一种在中文 NER 任务上，利用众包标注结果来训练模型的方法。 1. 文章目的与思想 为了能用较低的成本获取新的标注数据，我们采用众包标注的方法来完成这个任务。众包标注的数据是没有经过专家标注员审核的，所以它会包含一定的噪声。在这篇文章中，我们提出一种在中文 NER 任务上，利用众包标注结果来训练模型的方法。受到对抗学习的启发，我们在模型中使用了两个双向 LSTM 模块，来分别学习众包标注数据中的公有信息和属于不同标注员的私有信息。对抗学习的思想体现在公有块的学习过程中，以不同标注员作为分类目标进行对抗学习，从而优化公有模块的学习质量，使之收敛于真实数据（专家标注数据）。我们认为这两个模块学习到的信息对于任务学习都有积极作用，并在最终使用 CRF 层完成 NER 标注。 模型如下： 数据使用： 我们在对话数据和电商数据上对模型的性能进行验证。 1）对话数据是由 gowild 公司提供的，我们让 43 位标注员在两万句语料上标注「人名」和「歌名」实体。我们认为这份数据非常适合我们的任务。 （1）若让一位专家标注员标注对话数据，由于他的认知是有限的，所以当他出现标注失误时对模型的影响是比较大的。在这种情况下，多位标注员可以在一定程度上弥补单个标注员对于「歌名」和「人名」的认知不足。例如：歌手「周传雄」，但并不是所有人都知道他的另一个称呼「小刚」。多人的知识面肯定要比一个人来的广。 （2）人机对话语料中包含一定比例的语法错误： 你怎么子我都看的手机死机了，在弄自己开门进来干嘛都记得。- 你说谢谢的诗意哥哥吗？你说谢谢的诗意哥哥吗？ 不同的标注员对于上述句子的语义理解可能是不同的，我们也希望模型能学习到这些特征，使模型能更好收敛到最真实的数据分布，提高模型的泛化能力。 最终，我们的模型在对话数据上取得了近一个点的 F1 提升。 2）电商数据是由阿里巴巴提供。首先我们让五位标注员对标题数据和用户请求数据进行标注，目标是标注出已定义好的五类实体：品牌、产品、型号、规格、原料，每句标注任务随机分配给两位标注员。对于标注员的标注结果，我们通过样本抽样，分析得到造成标注噪声（标注不一致）的主要原因是不同标注员对于标注规范和每一句标注样例的认识是不同的。特别是在标题数据集中，产品、型号实体的边界定义非常容易造成标注不一致。 在上述众包标注得到的数据集上训练我们论文中提出的模型，可以得到一个点左右的提升： 文章分块解析： 相关工作： （1）序列标注：早期用来处理序列标注问题的模型都十分依赖人工设计的特征模板，例如：HMM, MEMM 和 CRF 模型，模型的性能很大程度上受限于特征模板的质量。神经网络热潮来临后，一个成熟的新模型被广泛应用：它使用双向 LSTM 来提取序列特征，并用 CRF 解码，在序列任务上取得了显著成果，这也是我们文章中的 baseline 模型。 （2）对抗训练：对抗网络最早被成功的应用在计算机视觉领域。近几年，「对抗」这一概念也被引入到 NLP 任务中，分别在跨语言、跨领域和多任务学习中取得突破。在这些任务中使用「对抗学习」，目的就在于学习到训练语料中的「共有特征」。我们的工作也是以这一目的为出发点，希望通过对抗学习的方式，让模型能分辨出「众包」数据中的「标注噪声」。 （3）众包标注模式：为了能在短时间内以较低成本获取标准语料，我们采用众包标注的模式，具体得到的数据情况见上面的「数据使用」。 Baseline 在文章的所有实验中，我们使用 BIOE 的标签集合。首先，我们训练 CRF 作为传统 baseline 模型。随后，尝试将序列特征映射到更高维度，也就是用 LSTM 模块提取特征。在中文任务中，输入单位为 char（字符），每个字符经过 lookup-table 映射成向量后，经过双向的 LSTM 层提取特征： 最终用 CRF 层进行解码，使模型能更好得学习标签之间的依赖关系： 这一部分的 loss 为： 优化目标为最小化这个 loss 值。 对抗学习部分：Worker Adversarial 我们使用的是众包数据作为训练语料，数据集中存在一定量的标注错误，即「噪声」。这些标注不当或标注错误都是由标注员带来的。不同标注员对于规范的理解和认识面是不同的，我们可以认为一位标注质量高的标注员的标注结果和专家标注员是非常相近的。对抗学习模块如下： 1.baseline 中的 BiLSTM 称为「private」，它的学习目标是拟合多为标注员的独立分布；再加入一个名为「common」的 BiLSTM 模块，common 与 private 的输入相同，它的作用是学习标注结果之间的共有特征： 2.再引入一个新的 BiLSTM 模块，名为「label」，以当前训练样例的标注结果序列为输入。 分别将 common 和 private 模块的输出合并，作为 NER 部分的输入： 最后用 CRF 解码，公式与 baseline 相同，不再贴出。 label 和 common 的输出合并，再输入 CNN 进行特征提取，最终对标注员进行分类： 要注意的是，我们希望标注员分类器最终失去判断能力，所以它在优化时要反向更新： 转载来源：阿里等联合论文：基于对抗学习的众包标注用于中文命名实体识别]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>电子商务</tag>
        <tag>美国</tag>
        <tag>歌手</tag>
        <tag>苏州大学</tag>
        <tag>张伟</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图灵奖得主Sivio Micali的Algorand区块链协议简介]]></title>
    <url>%2F2017%2Fd0773b71%2F</url>
    <content type="text"><![CDATA[图灵奖得主Sivio Micali的Algorand区块链协议简介 转载来源：图灵奖得主Sivio Micali的Algorand区块链协议简介]]></content>
      <tags>
        <tag>南湖互联网金融评论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[头条 | 万亿汽车后服务，你关注的创业经、血泪史和商业逻辑都在这里了]]></title>
    <url>%2F2017%2Fd11319ad%2F</url>
    <content type="text"><![CDATA[头条 | 万亿汽车后服务，你关注的创业经、血泪史和商业逻辑都在这里了 转载来源：头条 | 万亿汽车后服务，你关注的创业经、血泪史和商业逻辑都在这里了]]></content>
      <tags>
        <tag>虎嗅网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【应用】利用IPFS构建自己的去中心化分布式Wiki系统 – ipfs]]></title>
    <url>%2F2017%2Fd8daf94a%2F</url>
    <content type="text"><![CDATA[【应用】利用IPFS构建自己的去中心化分布式Wiki系统 – ipfs 转载来源：【应用】利用IPFS构建自己的去中心化分布式Wiki系统 – ipfs]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于Sup-Separable Convolution的Seq2Seq模型 SliceNet原理解析]]></title>
    <url>%2F2017%2Fda2030de%2F</url>
    <content type="text"><![CDATA[基于Sup-Separable Convolution的Seq2Seq模型 SliceNet原理解析 转载来源：基于Sup-Separable Convolution的Seq2Seq模型 SliceNet原理解析]]></content>
  </entry>
  <entry>
    <title><![CDATA[解析Google最新“移动实时视频分割”技术]]></title>
    <url>%2F2017%2Fdc3b54ed%2F</url>
    <content type="text"><![CDATA[视频分割是一种广泛使用的技术，电影导演和视频内容创作者可以使用这种技术将场景的前景与背景分离，然后将它们作为两个不同的视觉层处理。 通过修改或替换背景，创作者可以表达特定的情绪，将他们自己放在有趣的位置或强化消息的冲击力。不过，这个操作一直以来都是一个相当耗时的手动过程（例如，艺术家需要对每一帧进行转描），或者需要利用带绿幕的摄影棚环境来实时移除背景（这种技术称为色差抠像）。为了让用户能够在取景器中创造这种效果，我们设计了一种适合手机的新技术。 我们高兴地为 YouTube 应用带来精确、实时的设备上移动视频分割，将这项技术集成到”短片故事中”。”短片故事”目前仍处于有限测试阶段，它是 YouTube 推出的一种新型轻量化视频格式，专门为 YouTube 创作者设计。我们的新分割技术让创作者可以替换和修改背景，无需专业设备即可轻松地提高视频的制作价值。 YouTube 短片故事中的神经网络视频分割 为此，我们通过机器学习利用卷积神经网络来完成语义分割任务。特别是，在考虑以下要求和约束的基础上，我们设计了一个适合手机的网络架构和训练过程： 移动解决方案应当轻量化，并且运行速度至少要比现有的最先进照片分割模型快 10-30 倍。对于实时推理，此类模型需要达到每秒 30 帧的速度。- 视频模型应利用时间冗余度（相邻的帧看起来相似）并具备时间一致性（相邻的帧得到相似的结果）。- 优质的分割结果需要优质的标注。视频模型应利用时间冗余度（相邻的帧看起来相似）并具备时间一致性（相邻的帧得到相似的结果）。 数据集我们标注了数以万计捕捉各种前景姿态和背景环境的图像，以便为我们的机器学习管道提供优质数据。标注包括头发、眼镜、脖子、皮肤和嘴唇等前景元素的准确像素位置，一般背景标签的交叉验证结果可以达到人类标注质量 98% 的交集并集比例 (IOU or Jaccard index)。 我们的数据集中一个使用九个标签仔细标注的示例图像 - 前景元素叠加到图像上 网络输入我们具体的分割任务是计算一个二进制蒙版，将视频每个输入帧（三个通道，RGB）的前景与背景分离。在所有帧中实现计算蒙版的时间一致性非常关键。目前的方法使用 LSTM 或 GRU 来实现一致性，但是对于手机上的实时应用来说，这些方法的计算开销过高。因此，我们首先将前一帧的计算蒙版作为先验知识，将它用作第四个通道与当前的 RGB 输入帧串联，以实现时间一致性，如下图所示： 原始帧（左侧）分成三个颜色通道，并与上一个蒙版（中间）串联。这将用作我们神经网络的输入来预测当前帧（右侧）的蒙版 训练过程在视频分割中，我们既需要实现帧间的时间连续性，同时还应考虑时间不连续性，例如其他人突然闯入相机视野。为了训练我们的模型可靠地处理这些用例，我们以多种方式转换每个照片的标注真实值并将它作为前一帧的蒙版： 清空前一个蒙版 - 训练神经网络正确处理场景中的第一帧和新对象。这将模拟有人出现在相机帧中的情况。- 仿射转换的真实蒙版 - 小型转换可以训练网络传播到前一帧的蒙版并进行调整。大型转换则训练网络理解不合适的蒙版并舍弃它们。- 转换后的图像 - 我们对原始图像进行薄板样条平滑，以便仿真快速的相机移动和旋转。仿射转换的真实蒙版 - 小型转换可以训练网络传播到前一帧的蒙版并进行调整。大型转换则训练网络理解不合适的蒙版并舍弃它们。 网络架构利用修正的输入/输出，我们构建了一个标准的沙漏型分割网络架构，并进行了以下改进： 1. 我们使用具有步幅为4 或更多的大卷积内核来检测高分辨率 RGB 输入帧上的对象特征。具有少量通道的层（如 RGB 输入）的卷积开销相对较低，因此，使用大内核几乎不会影响计算开销。 2. 为了提高速度，我们使用较大步幅激进地进行下采样，并结合短路连接（skip connections，例如 U-Net）在上采样期间恢复低级别特征。对于我们的分割模型，与使用无短路连接相比，这种技术将 IOU 大幅提升了 5%。 带跳过连接的沙漏型分割网络 3. 为了进一步提高速度，我们优化了默认的 ResNet 瓶颈。在这篇论文中，作者将网络中间的通道压缩了四倍（例如，使用 64 个不同的卷积内核将 256 个通道缩减为 64 个）。不过，我们注意到可以更激进地压缩 16 倍或 32 倍，并且质量没有明显下降。 ResNet 瓶颈与较大的压缩系数 4. 为了优化和提高边缘的准确性，我们在网络顶层添加了多个 DenseNet 层，其全分辨率与神经抠图相似。这种技术将整体模型质量稍微提高了 0.5% IOU，但是分割的感知质量显著提升。 以上这些修改的最终结果是，我们的网络可以在移动设备上以相当快的速度运行。在保证高准确率（在验证数据集上实现 94.8% 的 IOU）的基础上，它在 iPhone 7 上可以达到 100+ FPS 的速度，而在 Pixel 2 上则可以达到 40+ FPS 的速度，从而为 YouTube 短片故事带来各种平滑的运行和自适应效果。 我们的近期目标是通过在 YouTube “短片故事”中进行有限的分阶段发布，在第一组效果中测试我们的技术。随着我们不断改进分割技术并扩展到更多标签，我们计划将它与 Google 更广泛的增强现实服务集成。 转载来源：解析Google最新“移动实时视频分割”技术]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>YouTube</tag>
        <tag>iPhone</tag>
        <tag>相机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯入局在线文档领域，初创公司还有机会逆袭吗？]]></title>
    <url>%2F2017%2Fdcf1147a%2F</url>
    <content type="text"><![CDATA[摘要：4 月 18 日，腾讯正式发布在线文档工具「腾讯文档」，马化腾在朋友圈表示：这是一个意外惊喜，没有一丝丝的防备。 上周 4 月 12 日的媒体沟通会上，石墨文档正式对外公布，已于 2017 年完成近亿元的 B 轮融资，投资方为今日头条。4 月 18 日，腾讯也正式发布在线文档工具「腾讯文档」，马化腾在朋友圈表示：这是一个意外惊喜，没有一丝丝的防备。 腾讯文档入局，更「意外」的应该是刚刚站稳脚跟的同类产品。此前国内并没有成熟的在线文档产品，初创公司最大的优势之一就是出发早，而腾讯入局无疑会加速这一领域的竞争。 腾讯是带着资源、野心来的，在线协作工具需要的社交场景腾讯已经具备，各种资源、能力的接入也比创业团队更有优势。当然，有优势并不代表一定会成功。总体来看，在线文档在国内还处于起步阶段，腾讯这样的大玩家加入，更大的意义在于普及作用。 我们为什么要用在线文档？ 在线文档并不是一个新概念。国外的典型产品是 Google Docs，2007 年发布，至今已经有十年。2016 年，Google Docs 的活跃用户就超过了 3 亿，企业用户达 500 万，年收入超过 10 亿美元。在传统办公领域占据领导地位的微软，也在 2011 年推出了云端的 Office 365。从理论上讲，微软 Office 在全球的十几亿用户都是在线文档的潜在用户，市场潜力十分巨大。 在腾讯文档发布之前，国内并没有互联网巨头直接参与到在线文档的竞争，不过大家对这一市场已经早有关注。今日头条投资了石墨文档、金山 WPS 投资了一起写，就连微软也针对微信平台推出了 Office 365 微助理。 大家已经都意识到这是一片巨大的蓝海，但参与方式有所不同，这跟各家的基因有关。金山 WPS、微软 Office 本来就在做传统办公软件，Google 一直在布局自己的软件生态，腾讯则是以社交为切入点。 先不谈各自的目的，在线文档本身就是一种产品进化的产物。首先它是在线的，不需要额外下载软件，在浏览器就能使用，抛弃了本地文件，文件的管理更方便。第二，在线文档让协作和分享变得更自由，实时编辑、实时修改，减少了本地文件繁多造成的失误。第三，很重要的一点，在线文档比本地文件更安全，设备损坏、被偷，文件都不会丢失。尤其是涉及多人协作的时候，文档的查看、编辑权限都由用户自己控制。 石墨文档的创始人吴洁举过这样一个例子，现在任何一家企业员工离职 5 分钟之内就可以把文件资料全都拷走，而云端的文件批量下载时，是可以通过技术手段切断的，拷走的内容也可以打上水印。所以当企业员工统一用在线文档工具时，内部资料很安全，离职时也能回收，并且不会影响自己的个人资料。 腾讯做在线文档的优势 其实从目前的产品来看，腾讯文档和同类软件并没有太大区别，上面说的功能大家也几乎都有，那么腾讯做这件事的优势在哪里呢？ 石墨文档的吴洁曾提到，中国的创业公司做在线文档，是有一定技术壁垒的。国外把 Office 三件套做全的公司只有微软和谷歌，不算 PPT 的话还有 Quip，而 Quip 的创始人是 Facebook 的前 CTO，团队是硅谷最厉害的一批工程师。抛去这样的背景不讲，想做 Office 是很难的。在中国做在线文档，需要坚定的决心、长时间的投入，和关键的人才。 这些挑战对创业公司来说比较困难，而由腾讯来做，起步的优势、运营能力、未来的发展都有了很多的可能性。 腾讯文档的发布并不是临时起意，其实最早用户用 QQ 传文件，这就是一种办公的雏形。直到现在，QQ 上还有将近两亿的文档活跃用户，日均文件传输量超过 1.8 亿次。2017 年 4 月，腾讯推出主打办公的 TIM 客户端，进一步解决用户的办公问题，目前月活用户也已经突破两千万，内置的在线文档规模超过 1300 万。这次推出腾讯文档，腾讯有更大的野心，就是通过文档这样一个支点，去撬动办公背后一个足够支撑千亿市值的巨大市场。 腾讯的基因是社交，而在线文档又需要多人协同，所以微信、QQ 的关系链就成了腾讯文档最大的优势。腾讯文档的服务除了支持网页端、移动端两大平台，还和微信、QQ 全面打通。QQ 传输的文档可以一键转为在线文档进行编辑以及预览，微信上则有小程序的版本支持。比起其他同类产品的分享，腾讯文档不管是在查看、编辑体验，还是账号登录、分享上，都要便捷许多。 作为国内互联网的巨头，腾讯产品间的资源互补形成了一个庞大的生态，拿已经加入的翻译功能来说，接入的是「翻译君」的能力，类似的天气、地理等数据，都可以在闭环系统中提供。在线文档是核心，关系链是纽带。未来腾讯的 QQ 邮箱、多人语音都可以与在线文档产生融合，如果能达到这样的预期，腾讯完全可以自己搞出一套办公领域的产品矩阵。 对初创公司是好事还是坏事？ 对这个领域的初创公司来说，腾讯的入局是好事还是坏事？这很难说。正如前面提到的，两者目前在功能上并看不出太大区别，甚至石墨的某些细节功能、设计要做得更好。所以前期腾讯文档能带来的，一定是把整个在线文档的市场扩大，将更多潜在用户带入这个全新的领域。至于以后，与在线文档相近的笔记、协作类领域都诞生过独角兽，机会还是有的。只是腾讯文档一出现，初创公司的节奏就不得不加快了，整个产业会进入快速竞争的时期，玩家也会越来越多。 从目前国内的在线文档市场来看，现在各家抢的不是对方的市场，而是未开垦的潜在用户，腾讯十亿的用户无疑是个巨大的压力。据石墨文档的吴洁说，目前他们的盈利还主要靠在个人收费版和企业版上，内部也在推出 SDK 等一些商业化的产品。盈利对初创公司来说永远是个紧箍咒，相比之下腾讯文档少了很多束缚。 现在去谈谁是最后的赢家还很远，可以预见的是在线文档领域会涌入更多的玩家。好在在线文档还是个重体验的产品，所以虽然腾讯入局，机会也还是有的，未来这个领域会有更多的可能。 编辑：Rubberso ■ 转载来源：腾讯入局在线文档领域，初创公司还有机会逆袭吗？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>创业</tag>
        <tag>Google</tag>
        <tag>云计算</tag>
        <tag>移动互联网</tag>
        <tag>微软</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习精要之CapsuleNets理论与实践（附Python代码）]]></title>
    <url>%2F2017%2Fe0aa8c36%2F</url>
    <content type="text"><![CDATA[摘要： 本文对胶囊网络进行了非技术性的简要概括，分析了其两个重要属性，之后针对MNIST手写体数据集上验证多层感知机、卷积神经网络以及胶囊网络的性能。 神经网络于上世纪50年代提出，直到最近十年里才得以发展迅速，正改变着我们世界的方方面面。从图像分类到自然语言处理，研究人员正在对不同领域建立深层神经网络模型并取得相关的突破性成果。但是随着深度学习的进一步发展，又面临着新的瓶颈——只对成熟网络模型进行加深加宽操作。直到最近，Hinton老爷子提出了新的概念——胶囊网络（Capsule Networks），它提高了传统方法的有效性和可理解性。 本文将讲解胶囊网络受欢迎的原因以及通过实际代码来加强和巩固对该概念的理解。 为什么胶囊网络受到这么多的关注？对于每种网络结构而言，一般用MINST手写体数据集验证其性能。对于识别数字手写体问题，即给定一个简单的灰度图，用户需要预测它所显示的数字。这是一个非结构化的数字图像识别问题，使用深度学习算法能够获得最佳性能。本文将以这个数据集测试三个深度学习模型，即：多层感知机（MLP）、卷积神经网络（CNN）以及胶囊网络（Capsule Networks）。 多层感知机（MLP） 使用Keras建立多层感知机模型，代码如下： 在经过15次迭代训练后，结果如下： 可以看到，该模型实在是简单！ 卷积神经网络（CNN） 卷积神经网络在深度学习领域应用十分广泛，表现优异。下面构建卷积神经网络模型，代码如下： 打印模型参数概要： 从上图可以发现，CNN比MLP模型更加复杂，下面看看其性能： 可以发现，CNN训练耗费的时间比较长，但其性能优异。 胶囊网络（Capsule Network） 胶囊网络的结构比CNN网络更加复杂，下面构建胶囊网络模型，代码如下： 打印模型参数概要： 该模型耗费时间比较长，训练一段时间后，得到如下结果： 可以发现，该网络比之前传统的网络模型效果更好，下图总结了三个实验结果： 这个实验也证明了胶囊网络值得我们深入的研究和讨论。 胶囊网络背后的概念为了理解胶囊网络的概念，本文将以猫的图片为例来说明胶囊网络的潜力，首先从一个问题开始——下图中的动物是什么？ 它是一只猫，你肯定猜对了吧！但是你是如何知道它是一只猫的呢？现在将这张图片进行分解： 情况1——简单图像 你是如何知道它是一只猫的呢？可能的方法是将其分解为单独的特征，如眼睛、鼻子、耳朵等。如下图所示： 因此，本质上是把高层次的特征分解为低层次的特征。比如定义为： P(脸) = P(鼻子) &amp; ( 2 x P(胡须) ) &amp; P(嘴巴) &amp; ( 2 x P(眼睛) ) &amp; ( 2 x P(耳朵) ) 其中，P(脸) 定义为图像中猫脸的存在。通过迭代，可以定义更多的低级别特性，如形状和边缘，以简化过程。 情况2——旋转图像 将图像旋转30度，如下图所示： 如果还是按照之前定义的相同特征，那么将无法识别出它是猫。这是因为底层特征的方向发生了改变，导致先前定义的特征也将发生变化。 综上，猫识别器可能看起来像这样： 更具体一点，表示为： P(脸) = ( P(鼻子) &amp; ( 2 x P(胡须) ) &amp; P(嘴巴) &amp; ( 2 x P(眼睛) ) &amp; ( 2 x P(耳朵) ) ) OR ( P(rotated_鼻子) &amp; ( 2 x P(rotated_胡须) ) &amp; P(rotated_嘴巴) &amp; ( 2 x P(rotated_眼睛) ) &amp; ( 2 x P(rotated_耳朵) ) ) 情况3——翻转图像 为了增加复杂性，下面是一个完全翻转的图像： 可能想到的方法是靠蛮力搜索低级别特征所有可能的旋转，但这种方法耗时耗力。因此，研究人员提出，包含低级别特征本身的附加属性，比如旋转角度。这样不仅可以检测特征是否存在，还可以检测其旋转是否存在，如下图所示： 更具体一点，表示为： P(脸) = [ P(鼻子), R(鼻子) ] &amp; [ P(胡须_1), R(胡须_1) ] &amp; [ P(胡须_2), R(胡须_2) ] &amp; [ P(嘴巴), R(嘴巴) ] &amp; … 其中，旋转特征用R()表示，这一特性也被称作旋转等价性。 从上述情况中可以看到，扩大想法之后能够捕捉更多低层次的特征，如尺度、厚度等，这将有助于我们更清楚地理解一个物体的形象。这就是胶囊网络在设计时设想的工作方式。 胶囊网络另外一个特点是动态路由，下面以猫狗分类问题讲解这个特点。 上面两只动物看起来非常相似，但存在一些差异。你可以从中发现哪只是狗吗？ 正如之前所做的那样，将定义图像中的特征以找出其中的差异。 如图所示，定义非常低级的面部特征，比如眼睛、耳朵等，并将其结合以找到一个脸。之后，将面部和身体特征结合来完成相应的任务——判断它是一只猫或狗。 现在假设有一个新的图像，以及提取的低层特征，需要根据以上信息判断出其类别。我们从中随机选取一个特征，比如眼睛，可以只根据它来判断其类别吗？ 答案是否定的，因为眼睛并不是一个区分因素。下一步是分析更多的特征，比如随机挑选的下一个特征是鼻子。 只有眼睛和鼻子特征并不能够完成分类任务，下一步获取所有特征，并将其结合以判断所属类别。如下图所示，通过组合眼睛、鼻子、耳朵和胡须这四个特征就能够判断其所属类别。基于以上过程，将在每个特征级别迭代地执行这一步骤，就可以将正确的信息路由到需要分类信息的特征检测器。 在胶囊构件中，当更高级的胶囊同意较低级的胶囊输入时，较低级的胶囊将其输入到更高级胶囊中，这就是动态路由算法的精髓。 胶囊网络相对于传统深度学习架构而言，在对数据方向和角度方面更鲁棒，甚至可以在相对较少的数据点上进行训练。胶囊网络存在的缺点是需要更多的训练时间和资源。 胶囊网络在MNIST数据集上的代码详解首先从识别数字手写体项目下载数据集，数字手写体识别问题主要是将给定的28x28大小的图片识别出其显示的数字。在开始运行代码之前，确保安装好Keras。 下面打开Jupyter Notebook软件，输入以下代码。首先导入所需的模块： 然后进行随机初始化： 下一步设置目录路径： 下面加载数据集，数据集是“.CSV”格式。 展示数据表示的数字： 现在将所有图像保存为Numpy数组： 这是一个典型的机器学习问题，将数据集分成7:3。其中70%作为训练集，30%作为验证集。 下面将分析三个不同深度学习模型对该数据的性能，分别是多层感知机、卷积神经网络以及胶囊网络。 1.多层感知机 定义一个三层神经网络，一个输入层、一个隐藏层以及一个输出层。输入和输出神经元的数目是固定的，输入为28x28图像，输出是代表类的10x1向量，隐层设置为50个神经元，并使用梯度下降算法训练。 打印模型参数概要： 在迭代15次之后，结果如下： Epoch 14/1534300/34300 [==============================] - 1s 41us/step - loss: 0.0597 - acc: 0.9834 - val_loss: 0.1227 - val_acc: 0.9635Epoch 15/1534300/34300 [==============================] - 1s 41us/step - loss: 0.0553 - acc: 0.9842 - val_loss: 0.1245 - val_acc: 0.9637 结果不错，但可以继续改进。 2.卷积神经网络 把图像转换成灰度图（2D），然后将其输入到CNN模型中： 下面定义CNN模型： 打印模型参数概要： 通过增加数据来调整进程： CNN模型的结果： 3.胶囊网络 建立胶囊网络模型，结构如图所示： 下面建立该模型，代码如下： 打印模型参数概要： 胶囊模型的结果： 为了便于总结分析，将以上三个实验的结构绘制出测试精度图： 从结果中可以看出，胶囊网络的精度优于CNN和MLP。 总结本文对胶囊网络进行了非技术性的简要概括，分析了其两个重要属性，之后针对MNIST手写体数据集上验证多层感知机、卷积神经网络以及胶囊网络的性能。 作者信息 Faizan Shaikh，数据科学，深度学习初学者。 本文由阿里云云栖社区组织翻译，文章原标题《Essentials of Deep Learning: Getting to know CapsuleNets (with Python codes)》，作者：Faizan Shaikh，译者：海棠，审阅：Uncle_LLD。 转载来源：深度学习精要之CapsuleNets理论与实践（附Python代码）]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>深度学习</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>编译器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Python进行深度学习的完整入门指南(附资源)]]></title>
    <url>%2F2017%2Fe10cc535%2F</url>
    <content type="text"><![CDATA[利用Python进行深度学习的完整入门指南(附资源) 转载来源：利用Python进行深度学习的完整入门指南(附资源)]]></content>
      <tags>
        <tag>大数据文摘</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[收割者已从房市股市退出，正在寻找下一片韭菜地]]></title>
    <url>%2F2017%2Fe1d370a5%2F</url>
    <content type="text"><![CDATA[收割者已从房市股市退出，正在寻找下一片韭菜地 转载来源：收割者已从房市股市退出，正在寻找下一片韭菜地]]></content>
      <tags>
        <tag>凤凰财经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里巴巴参谋长曾鸣全面深入阐释：何谓互联网的本质？]]></title>
    <url>%2F2017%2Fe56af9ec%2F</url>
    <content type="text"><![CDATA[阿里巴巴参谋长曾鸣全面深入阐释：何谓互联网的本质？ 转载来源：阿里巴巴参谋长曾鸣全面深入阐释：何谓互联网的本质？]]></content>
      <tags>
        <tag>小象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[6个最好的HTML框架，用于开发一个伟大的移动UI]]></title>
    <url>%2F2017%2Fe80b4f02%2F</url>
    <content type="text"><![CDATA[6个最好的HTML框架，用于开发一个伟大的移动UI 转载来源：6个最好的HTML框架，用于开发一个伟大的移动UI]]></content>
  </entry>
  <entry>
    <title><![CDATA[【值得收藏的深度学习思维导图】全面梳理基本概念与11大模型关系]]></title>
    <url>%2F2017%2Fe80f32a8%2F</url>
    <content type="text"><![CDATA[【值得收藏的深度学习思维导图】全面梳理基本概念与11大模型关系 转载来源：【值得收藏的深度学习思维导图】全面梳理基本概念与11大模型关系]]></content>
      <tags>
        <tag>新智元</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这十部美剧，代表了美剧在2016年的最高水准]]></title>
    <url>%2F2017%2Fe9c0a8b2%2F</url>
    <content type="text"><![CDATA[这十部美剧，代表了美剧在2016年的最高水准 转载来源：这十部美剧，代表了美剧在2016年的最高水准]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫框架Scrapy：爬取校花网]]></title>
    <url>%2F2017%2Fea9d394a%2F</url>
    <content type="text"><![CDATA[以校花网为例进行爬取，校花网：http://www.xiaohuar.com/，让你体验爬取校花的成就感。 想爬哪就爬哪 Scrapy，Python开发的一个快速,高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据 Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等 整体架构大致 Scrapy运行 基本使用 1、创建项目 运行命令: 1 scrapy startproject p1（your_project_name） 2.自动创建目录的结果： 文件说明：- scrapy.cfg 项目的配置信息，主要为Scrapy命令行工具提供一个基础的配置信息。（真正爬虫相关的配置信息在settings.py文件中）- items.py 设置数据存储模板，用于结构化数据，如：Django的Model- pipelines 数据处理行为，如：一般结构化的数据持久化- settings.py 配置文件，如：递归的层数、并发数，延迟下载等- spiders 爬虫目录，如：创建文件，编写爬虫规则注意：一般创建爬虫文件时，以网站域名命名 编写爬虫 备注：- 1.爬虫文件需要定义一个类，并继承scrapy.spiders.Spider- 2.必须定义name，即爬虫名，如果没有name，会报错。因为源码中是这样定义的： 3.编写函数parse，这里需要注意的是，该函数名不能改变，因为Scrapy源码中默认callback函数的函数名就是parse；- 4.定义需要爬取的url，放在列表中，因为可以爬取多个url，Scrapy源码是一个For循环，从上到下爬取这些url，使用生成器迭代将url发送给下载器下载url的html。源码截图： 4、运行 5.scrapy查询语法： 6.scrapy查询语法中的正则： 7、格式化处理 各位同学注意啦！！ 想获取更多视频或者有任何学习问题 欢迎加入Python交流群 626062078 转载来源：Python爬虫框架Scrapy：爬取校花网]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>Python</tag>
        <tag>HTML</tag>
        <tag>Scrapy</tag>
        <tag>网络爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动驾驶安全员究竟都干什么？我今天去百度Apollo体验了一天]]></title>
    <url>%2F2017%2Feae7da24%2F</url>
    <content type="text"><![CDATA[自动驾驶安全如今又一次引发了社会关注，随着自动驾驶技术的发展，越来越多的公司将自家的自动驾驶汽车从实验室搬到了公共道路上。 （今天我到百度公司当一天“自动驾驶汽车安全员”） 自动驾驶安全员作为自动驾驶汽车上最关键的监察角色，有着十分重要的地位。可真正的自动驾驶安全员的日常生活究竟是什么样的？我们在中国最成体系和规模的自动驾驶研发团队百度 Apollo 待了一天。 这是一份具有“人道主义”的高尚工作 “我之前是个军人，曾经获得汽车大比武三等功，与自动驾驶汽车相处我认为是一个逐渐相互信任的过程。”——百度自动驾驶汽车安全员靳师傅。 （靳师傅参与 Apollo 自动驾驶汽车项目已经500多天了） “刚开始那会儿甭提多晕了，研发上车没20分钟就得吐。”靳师傅打趣到，百度算是最早开始研发自动驾驶并准备上路测试的公司。 在项目开始测试时，自动驾驶汽车就像一个孩子，在街上慢慢地走着，看到路口小心翼翼地打转向。而安全员就像个大家长，关键时刻拉一把。随着技术的进步，百度自动驾驶汽车需要的介入越来越少，如今安全员与自动驾驶汽车实现了某种默契， 作为自动驾驶汽车第一个乘客，汽车安全员的“车品”很重要。 百度自动驾驶汽车能做到如此自然的体感也是拜他们所赐。“佛系”的驾驶习惯更容易让自动驾驶汽车体验像有司机驾驶的。在自动驾驶汽车上路前，安全员却又是自动驾驶汽车研发时的最后屏障，“责任感”是安全员一直强调的理念。 既是自动驾驶汽车第一名乘客， 又是最后一道屏障 在百度自动驾驶部门中有一个不成文的守则，不管人还是机器，在职业上做必须做到100%尽责，百度作为站在世界头部的自动驾驶研发公司，从规范、布局和远景上都有相当全面的考虑，安全员除了驾驶水平过硬外，还要从技术上尽可能杜绝安全漏洞，把问题反馈给研发测试团队。 这时，安全员将不再是汽车的家长，而是最大的产品经理和“产品体验官”，所以你会经常看到汽车安全员指责研发慢，或用小白板给产品经理上课的一幕。 （北京共发布了五张自动驾驶测试实验用临时牌照，百度 Apollo 有五张） 前不久，北京市发布了首批自动驾驶测试实验用临时牌照，该临时牌照公分为T1-T5五个级别，百度拿到的五张T3牌照是国内目前最高级别。 安全员将自动驾驶汽车人为介入的原因划分为四大模块，即策略缺陷、系统故障、规则政策、人为原因。任何人为的记录都会按照动机、路面状况等原因进行归纳总结，再反馈给研发和产品。他既为自己的生命负责也为汽车负责，更为整个公共道路的行人、车辆负责。 成为一名汽车安全员需要经历非常严格的考验，根据百度相关人员的介绍，大概要分为五个阶段： 1、司机考察期； 2、开环数据采集司机； 3、开环研发车司机； 4、闭环研发车司机； 5、自动驾驶汽车安全员。 司机入职，除了法律法规测试之外还要经过一定公里数的上路测试。司机行车时不仅要严格遵守法律法规不能出错，还要具备紧急停车、紧急避让等高难度车技。我们采访到一位曾担任某世界顶尖车企的测试师，在他看来，百度自动驾驶安全员的考核相当全面且职业。 当司机通过初轮考察后便成为开环数据采集车或者开环研发车的实习司机，这些测试司机们要学习自动驾驶相关知识，协助研发、产品进行相关数据的收集和测试。 当成为闭环研发司机阶段时，证明司机已经具备了稳定的驾驶技术和相当的自动驾驶业务能力，可进一步深入接触自动驾驶汽车的测试，在这个阶段司机逐渐会将控制方向盘的权限交给车辆本身，成为一名观察者。这一阶段的司机要适应既控制车还要需要时刻关注周边的道路情况这一全新的状态。 最后成为一名合格的、了解相关自动驾驶参数且能独立上路的百度自动驾驶安全员。 说安全员不累，那是假的 “你觉得做自动驾驶安全员，累么？” “说不累那是假的，这行业跟普通司机很不一样，你需要时刻注意车辆周边的路况，尤其是过路口或者车多的时候。” 百度自动驾驶安全员李师傅说到。 自动驾驶安全员按照当日任务和路况一天要跑60-200公里不等，在一天的采访中发现他们基本上大部分的时间都在车上工作。在工作时，安全员一方面需要集中精神观察测试车辆附近的交通路况，还要将脚放在刹车上，提防车辆自己的“小脾气”。每次出现人工介入时，安全员都要按照严格的流程记录介入的细节和时间。 在体验时，我发现这辆自动驾驶汽车行车体验已经无限接近人类驾驶的车辆，而在此之前，这些安全员可有点受罪。 项目起步时，自动驾驶汽车行车体验很不稳定，经常会出现突然刹车，打转向等危险操作。一旦车辆出现失控情况，安全员必须时刻准备着握紧方向盘、及时将方向调正。随着研发越发深入，行车体验逐渐变好，安全员又将车辆关注的焦点由车转移到周边的人和车上。 虽然自动驾驶汽车已经发展许久，但是公共道路上的“围观群众”都对这个顶着奇怪东西的改装车有着强烈的好奇心和“误解”。在公共道路上测试自动驾驶汽车时，经常会受到其他“不明真相”群众的误解和调戏。这些司机发现这是一辆自动驾驶汽车时，总想试试这辆车的“真功夫”。 “要么离得特别近想看看里面什么样，要么就想别咱们。虽然挺无奈的，但毕竟咱们这行太前沿了，可以理解。” 李师傅说。 我不禁想起上个月 Uber 自动驾驶汽车的事故，根据录像显示，车辆在自动驾驶模式中直接撞向了横穿马路的行人，车里的安全员看起来注意力并不是那么集中。我向百度的安全员求证后得知，长时间的工作很容易进入一种疲劳的状态，注意力及体力都有所下降。 对此，百度会给安全员充足的空间去自我调整和休息，不允许安全员在行驶时双手离开方向盘。随着设备集成度越来越高，安全员的辅助监测设备也减少到一个屏幕。百度自动驾驶官方人员表示，将会进一步优化自动驾驶安全员的行车体验，同时也为安全员上了高额保险。 （百度 Apollo 自动驾驶测试车） 这是一个全新的新旧观念碰撞的职业 虽然自动驾驶安全员目前只出现于自动驾驶行业的特殊工种，但它一定会在不远的未来高度爆发。随着自动驾驶行业的稳步推进，关于“自动驾驶技术的量产”议题也提上了日程。 在可预见的两年内，封闭道路的自动驾驶汽车一定会实现普及，此时安全员将成为一个关乎乘客性命、车辆安全的重要角色。职业的标准化也将随着行业的普及形成一个具象形态。安全员具体的职能一方面离不开百度、谷歌这些头部队伍对自动驾驶上路的思考，另一方面还需要安全员从事人员自身的责任感和热情。 从我这一天与安全员的体验与沟通中，我发现安全员本身都很积极拥抱自动驾驶技术，对工作有着极大热情。自动驾驶汽车就像他们的孩子一样，一点点的成长和优化都能传达到安全员的体验中。也正是这些前线的安全员不断付出和努力，才让自动驾驶汽车愈发有人性。 转载来源：自动驾驶安全员究竟都干什么？我今天去百度Apollo体验了一天]]></content>
      <categories>
        <category>汽车</category>
      </categories>
      <tags>
        <tag>Google</tag>
        <tag>汽车产业</tag>
        <tag>Uber</tag>
        <tag>汽车用品</tag>
        <tag>交通</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一段关于国产芯片和操作系统的往事]]></title>
    <url>%2F2017%2Fedd542d4%2F</url>
    <content type="text"><![CDATA[一段关于国产芯片和操作系统的往事 转载来源：一段关于国产芯片和操作系统的往事]]></content>
      <tags>
        <tag>梁宁-闲花照水录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国人未来怎么租房子？]]></title>
    <url>%2F2017%2F8a03af59%2F</url>
    <content type="text"><![CDATA[中国人未来怎么租房子？ 转载来源：中国人未来怎么租房子？]]></content>
      <tags>
        <tag>凤凰财经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Êý¾Ý½»»»¸ñÊ½FlatBuffers½éÉÜ - ÅÝÔÚÍøÉÏµÄÈÕ×Ó]]></title>
    <url>%2F2017%2F2751070a%2F</url>
    <content type="text"><![CDATA[Êý¾Ý½»»»¸ñÊ½FlatBuffers½éÉÜ - ÅÝÔÚÍøÉÏµÄÈÕ×Ó 转载来源：Êý¾Ý½»»»¸ñÊ½FlatBuffers½éÉÜ - ÅÝÔÚÍøÉÏµÄÈÕ×Ó]]></content>
  </entry>
  <entry>
    <title><![CDATA[OAuth 2.0 认证的原理与实践]]></title>
    <url>%2F2017%2Ff3555418%2F</url>
    <content type="text"><![CDATA[更多深度文章，请关注云计算频道：https://yq.aliyun.com/cloud 原文链接：https://yq.aliyun.com/articles/72652 使用 OAuth 2.0 认证的的好处是显然易见的。你只需要用同一个账号密码，就能在各个网站进行访问，而免去了在每个网站都进行注册的繁琐过程。 本文将介绍 OAuth 2.0 的原理，并基于 Spring Security 和 GitHub 账号，来演示 OAuth 2.0 的认证的过程。 什么是 OAuth 2.0 OAuth 2.0 的规范可以参考 ： RFC 6749 OAuth 是一个开放标准，允许用户让第三方应用访问该用户在某一网站上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。目前，OAuth 的最新版本为 2.0 OAuth 允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的网站（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth 允许用户授权第三方网站访问他们存储在另外的服务提供者上的信息，而不需要分享他们的访问许可或他们数据的所有内容。 OAuth 2.0 的核心概念 OAuth 2.0 主要有4类角色： resource owner：资源所有者，指终端的“用户”（user）- resource server：资源服务器，即服务提供商存放受保护资源。访问这些资源，需要获得访问令牌（access token）。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。如果，我们访问新浪博客网站，那么如果使用新浪博客的账号来登录新浪博客网站，那么新浪博客的资源和新浪博客的认证都是同一家，可以认为是同一个服务器。如果，我们是新浪博客账号去登录了知乎，那么显然知乎的资源和新浪的认证不是一个服务器。- client：客户端，代表向受保护资源进行资源请求的第三方应用程序。- authorization server： 授权服务器， 在验证资源所有者并获得授权成功后，将发放访问令牌给客户端。 ## OAuth 2.0 的认证流程resource server：资源服务器，即服务提供商存放受保护资源。访问这些资源，需要获得访问令牌（access token）。它与认证服务器，可以是同一台服务器，也可以是不同的服务器。如果，我们访问新浪博客网站，那么如果使用新浪博客的账号来登录新浪博客网站，那么新浪博客的资源和新浪博客的认证都是同一家，可以认为是同一个服务器。如果，我们是新浪博客账号去登录了知乎，那么显然知乎的资源和新浪的认证不是一个服务器。 authorization server： 授权服务器， 在验证资源所有者并获得授权成功后，将发放访问令牌给客户端。 ## OAuth 2.0 的认证流程 认证流程如下： （A）用户打开客户端以后，客户端请求资源所有者（用户）的授权。- （B）用户同意给予客户端授权。- （C）客户端使用上一步获得的授权，向认证服务器申请访问令牌。- （D）认证服务器对客户端进行认证以后，确认无误，同意发放访问令牌。- （E）客户端使用访问令牌，向资源服务器申请获取资源。- （F）资源服务器确认令牌无误，同意向客户端开放资源。（B）用户同意给予客户端授权。 （D）认证服务器对客户端进行认证以后，确认无误，同意发放访问令牌。 （F）资源服务器确认令牌无误，同意向客户端开放资源。 其中，用户授权有四种模式： 授权码模式（authorization code）- 简化模式（implicit）- 密码模式（resource owner password credentials）- 客户端模式（client credentials）简化模式（implicit） 客户端模式（client credentials） 实践 OAuth 2.0 Talk is cheap！下面将演示代码。 本例子将通过 Gradle、Spring Boot、Spring Security、 Thymeleaf、等技术来实现一个client 以及 resource server，并 通过 GitHub来给我们的应用授权。 依赖 本项目基于Gralde 来管理依赖，读者可以自行改成 Maven 的方式： 配置 项目的核心配置如下： 包括了作为一个client 所需要大部分参数。其中 clientId 、 clientSecret 是在 GitHub 注册一个应用时生成的。如果读者不想注册应用，则可以直接用上面的配置即可。 如果要注册，则文章最后有注册流程。 项目安全的配置 安全配置上需要加上@EnableWebSecurity 、 @EnableOAuth2Client注解，来启用Web 安全认证记忆，表明这是一个OAuth 2.0 客户端 ： 使用 Spring Security，我们需要继承 org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter并重写以下 configure 方法： 上面的配置是设置了一些过过滤策略，除了静态资源以及不需要授权的页面，我们允许访问，其他的资源，都是需要授权访问。 其中，我们也设置了一个过滤器 ssoFilter，用于在 BasicAuthenticationFilter 之前进行拦截。如果拦截道的是/login，就是访问认证服务器。 资源服务器 我们写了两个控制器来提供相应的资源。 MainController.java 在index 页面，将如认证成功，将会显示一些认证信息。 UserController.java 是用来模拟用户管理的相关资源。 前端页面 页面，我主要是采用 Thymeleaf 以及Bootstrap 来编写的。 首页用于现实用户的基本信息。 用户管理界面显示用户的列表： 运行效果 这个是没有授权访问首页： 当我们点击登录，会重定向到 GitHub，登录界面并进行授权： 这个是授权后的首页： 授权后就能够进入用户管理界面： 注册GitHub 应用 如果需要注册，请看下面的流程，来生成 Client ID 和 Client Secret 访问https://github.com/settings/applications/new 注册应用，生成 客户端 id 和 密码。比如： 客户端 id 和 密码写入程序配置即可。 源码 《Spring Security 教程》：https://github.com/waylau/spring-security-tutorial 转载来源：OAuth 2.0 认证的原理与实践]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>科技</tag>
        <tag>文章</tag>
        <tag>Gradle</tag>
        <tag>新浪</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[被点赞就能挣钱？基于区块链的社交媒体平台 Steemit - CSDN博客]]></title>
    <url>%2F2017%2Ff48380b8%2F</url>
    <content type="text"><![CDATA[从PC时代到移动互联网时代，社群媒体平台的需求一直都存在，从QQ到微信，我们在这些平台上撰写了多少文章、挥洒了多少青春岁月，同时也被把隐私卖给了平台、注意力也被广告所攫获？ 不知你是否曾经想过，自己在社群媒体平台上发布的内容（文章、相片、影片）能值多少钱呢？ 80.22*7.42 = 595.2324, 也就是这篇文章价值将近600块钱 Steemit背后到底运作原理到底是什么呢？下面让我们来为你揭开他的神秘面纱 发表优质文章：文章质量越高、收到的赞数越高，作者得到的奖励就越高1. 挖掘优质文章：越早在优质文章刚发表的时候透过点赞、留言来支持，也能获得奖励1. 持有Steem Power：类似股权分红（下面详解）1. 透过外部交易所购买Steam代币 直接奖励内容生成者，省去平台中介费1. 无广告，把使用者的注意力留给优质内容1. 没人能透过算法操纵、屏蔽平台上的文章 可转换成SP或者SMD (立即生效) 还本：不论Steem市场价格如何波动，1SMD永远等价于1美金的Steem假设今天1 Steem = 0.5美金1 SMD 可跟平台兑换 2 Steem- 1 SMD 可跟平台兑换 100 Steem 可以用赞同/反对来决定每个文章的收益 可转换成Steem (需等13周，每周等额到帐) 把Steem转为SP的过程称为Power Up- 把SP转为Steam的过程称为Power Down 以Steem为核心，这三种代币的转换关系图如下 90% 依比例分配给SP持有者- 10% 进入贡献奖金池，再分成三份75% 发帖/回覆/评论创作者- 15% 投票者(根据SP计算)- 10% 证人(记帐/打包区块者) 在撰写文章介面的右下角有个Rewards，有三种不同的奖励方式可以选择，默认是Default (50%/50%) Power UP 100% - 将文章奖励 100% 存成 SP1. Default (50%/50%) - 将文章奖励的50%存成 SP，另外 50% 透过 STEEM &amp; SBD 组合形式发放（根据市场行情，可能是一种或者两种组合）1. Decline Payout： 文章不要奖励，对应文章的所有奖励会回归奖池 SP多的人点赞影响力更大，所有文章根据点赞者的SP加总计算后得出分数，共同瓜分奖金池1. 你可以获得别人给你帖子回覆、评论时获得的奖励的 50% 否决票：如果被网友发现恶意刷赞行为，可以给予否决票。但为了避免否决票被滥用，每个人都有个信誉值，这个分数必须透过发帖、评论、日积月累才能逐步提升的，信誉值低对信誉值高的人的否决票是不起作用的1. 投票力：每个人的投票力是有限的，每次投票都会消耗，随著投票力下降，点赞者带来的影响力也会下降，每天恢复20%的投票力1. 延迟奖励：所有投票会被延迟24小时后才会计算奖励，如果有人在短时间内投票作弊，仍然会发现并予以否决 共识机制：DPOS (委托权益证明) 买卖平台：Bittrex, Poloniex, Livecoin 竞争对手：YOYOW, Yours, Facebook, YouTube, Instagram, Twitter Steemit新人直通车 https://steemit.com/cn/@tumutanzi/5ndvpm-steemit 30分钟全面搞懂Steem https://steemit.com/steem/@gaoduzhu/steem STEEM的基本介紹及資料整理 https://steemit.com/cn/@htliao/steem 艾伯特 http://www.aibbt.com/a/14027.html 转载来源：被点赞就能挣钱？基于区块链的社交媒体平台 Steemit - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[Cocos引擎创始人王哲：区块链游戏，其实也没什么神秘的]]></title>
    <url>%2F2017%2Ff5e68156%2F</url>
    <content type="text"><![CDATA[文：王哲 在周六的 Cocos 区块链游戏开发者大会上，我和 INB 资本的合伙人尹健辉一起演讲和演示了基于 Cocos 引擎开发的区块链游戏的编译、发布、运行在 Cocos 公链上的整个过程，以及游戏道具脱离游戏后在链上存储、交易、然后从链上回到游戏里，把武器挂件装备上去、以及把炸弹消耗掉的整个过程。 由于这部分演讲是用对话形式开展的，速记稿也比较凌乱毕竟太多技术干货了，所以我打算直接用这篇长文，完整阐释我们做了什么、计划做什么、以及为什么要做这些事情的整个思路逻辑。这篇文章真的很长，请耐心看完。 一、为什么我们要着手区块链游戏的研究 在和健辉一起演示区块链之前，我的个人演讲的部分，解释了为什么 Cocos 要在今天开始着手研究区块链游戏的方向。我自己讲了大概 30~40 分钟，其实核心是围绕这张图来展开的： 目前手机原生游戏领域的多数从业者，都是 2012~2014 年才进入这个领域的。但是我们 2010 年就开始做 Cocos2d-x 了，在 2010 年 12 月 1 日发布了第一个版本 Cocos2d-x 0.7.0。当时我周围的人都很不理解，为什么不做端游呢？为什么不做页游呢？当时国内的市场环境，手游上就 iOS AppStore 可以达到每月 50 万的最高月流水，还不够端游月流水的一个零头；安卓上则完全没有任何游戏变现模式，没有内购计费没有广告变现，那么你们在瞎折腾啥呢？ 后来的历史，大家也都一起经历过了。这是 3 月 12 日上周一我做区块链游戏大会的 PPT 时，截取的几个国家游戏畅销榜排名，Cocos 游戏仍然占据了大多数。Cocos 引擎被喷了这么多年，事实证明，在中国市场上，仍然是市场占有率最高的手游引擎。网易的几款 3D 游戏，我们内部称为「Cocos+」，就是在 Cocos 的基础上，网易自研构造了整个 3D 引擎叠加上去。我半开玩笑地和网易的朋友说，你们大概用了 20% 的 Cocos 吧，那么就调成 20% 透明度？于是就有了下面这张图。网易的技术路线，也说明了 Cocos 在 3D 的潜力，只要我们假以时日和研发投入，希望 Cocos 引擎也能做到像《楚留香》那样级别的 3D 能力，而且不是属于某家游戏公司的，而是属于全行业的。 但是原生手游领域，在 2017 年开始就已经进入我称为「生态稳定」的状态了。「生态稳定」是中性词，说难听点是「生态凋零」，大厂占据了绝对优势地位，这个领域即使越来越赚钱，也和大多数中小 CP 和创业者没有任何关系，基金和风险投资也不再愿意投资 CP 了。在 2017 年大家看不到太多机会之后，很多人离开了游戏行业，改行去做 O2O、直播、大数据、人工智能等新兴领域了。但还是有很多和我一样，就是热爱游戏行业，一辈子只认做游戏的朋友仍在坚守。直到 2017 年 12 月 28 日微信发布小游戏，2018 年 3 月 15 日 Facebook 宣布开放 Instant Games 平台，都把 HTML5 小游戏推向了风口浪尖，大家才看到新的机会。之前有提前做 HTML5 技术布局的游戏公司，都从中获得了很大的增益。Cocos 引擎也在微信和 Facebook 首发小游戏里得到了新一轮的爆发，占据了绝对优势的市场份额。 微信小游戏在上周已经可以注册和调试了，并要求大家准备各种资质材料，相信距离完全开放、可自由发布已经不远了。Facebook Instant Games 则在发布的当天就立刻完全开放，而在平台开放后仅仅过了 7 小时，就有一家国内游戏公司用 Cocos 引擎发布上去 8 款游戏。 所以，现在回头来看，我们在 2012 年开始布局和探索 HTML5 游戏开发技术，和大家介绍用 JavaScript 语言开发游戏，是完全正确的。 今天对于 Cocos 开始探索区块链游戏的各种技术，社区论坛里有不少质疑和嘲笑的声音。但是回顾前面几年的历史，我在 2012 年开始介绍用 JavaScript 来开发原生游戏，用 JSB （JavaScript Bindings）技术打包到原生平台、而且还可以发布到 HTML5 环境的时候，当时有多少人反对、嘲笑、觉得我们不务正业呢？甚至到我们在 2016 年 3 月推出 Cocos Creator，以 JavaScript 为第一优先的开发语言时，仍然有至少 50%~60% 的开发者跳出来骂。当时很多人喷的是，Cocos 团队不务正业，我只关心我的 C++ 和 Lua，我不需要 JavaScript。今天小游戏的机会来了，你还能那么确信 Cocos 团队在几年前投入 HTML5 技术研发是不务正业吗？ 我们每次在一个技术爆发、未到成熟的时候，就立刻提前布局一些新技术的研发投入，其实就是为了在老技术老平台「生态稳定」的时候，可以给诸位开发者提供「多一些选择」。回到第一张图，原生手游领域我们 2010 年开始研究，2012 年爆发；这时候我们不等原生手游发展到生态稳定的阶段，就立刻投入 HTML5 技术的研发，即使被人喷、被人认为不务正业；6 年后 HTML5 小游戏爆发证明了我们的技术前瞻性，但同时也我们不会等到 HTML5 进入生态稳定，就需要立刻布局新的技术平台了。从目前的情况来看，区块链游戏的确是一种很有潜力的新技术，值得我们去研究。 很多开发者看到这里就会问了，OK，你说服我了，我也支持 Cocos 研究新技术，但是已有的原生和 H5 引擎是否会受影响？我在这里统一答复：不受影响。因为我甚至不太想把区块链研发团队建在厦门，和引擎团队放在一起。主要原因是厦门基本就没有区块链技术高手。目前可演示的 Cocos 区块链项目几个研发人员在成都，我最终会在北京和成都中间做出一个选择，毕竟这两个城市人才比较多，目前暂时倾向于成都。但同时，厦门的 Cocos Creator / Cocos2d-x 引擎团队在春节后也大举招人。这里顺便打个广告，对自己的引擎开发技术有自信，希望一起做一个全球一流引擎、一起做一家伟大公司的朋友，可以在微信上、或者通过微信公众号联系我，我们招2D/3D/编辑器技术高手，工作地点厦门。 在周六的会上，我也展示了 Cocos Creator 2.0 的性能飙升，我们只是用了在 3D 研发上得到的部分成果，一个 2D/3D 通用的渲染器，把 Cocos 原来的底层换掉，然后就得到了这样的性能提高。Creator 2.0 目前已经出到 Alpha-5 版本了，而且这次拉了腾讯互娱的大神们进来趟坑。填完坑之后，应该在 4~5 月份，就可以发至少 beta 甚至 RC 版给大家用了。 会上我也演示了 Cocos 3D 目前的工作流，以及一款可以部分客户端 2D、部分客户端 3D 的麻将游戏。我们希望通过这种技术方案，让开发者们可以平滑过渡到 3D 方案上，甚至因为是 H5/热更新的缘故，可以做灰度发布和 A/B test。具体演示过程大家可以去看这周稍后放出的会议录像。 好了，讲完了我们为什么要进入区块链游戏领域的逻辑，以及让大家放心我们对原生/H5的投入，和 Creator 2.0 版本即将带给大家性能上质的飞跃。 下面进入区块链的内容了。 二、区块链黑话翻译 几个月前，我刚开始看区块链相关资料的时候，也是极度懵逼的。后来发现，链圈自己发明了很多行业术语，或者说「黑话」，其实和手游圈一样的。外行人看手游圈，我们也是一堆黑话比如：SDK、API、次留、七留、人均阿普（ARPU）、付费阿普（ARPPU）、LTV、CPA、CPI、CPC、填充率、CPM 和 eCPM 还讲的是完全不同的东西……。类似地，搞清楚链圈的这些术语之后就容易理解多了。 所以在我和健辉一起完成演讲之前，我坚持要求把很多链圈的行业术语「翻译」成了游戏圈的术语，当然还有一些无法翻译的，我只能在这里简单科普一下，链圈的极客们就不用看了，主要给游戏圈的 Cocos 开发者们看的： 游戏运行在区块链环境上 —— 目前阶段，一般指的是游戏接入了区块链 SDK，在金币内购和道具生成/交易/兑换的时候通过区块链 SDK 调用任一区块链节点提供的API。最理想状态是游戏绝大多数逻辑、甚至全部逻辑都由智能合约构成，完全在智能合约虚拟机中执行。- 区块链虚拟机、智能合约虚拟机 —— 区块链 SDK 上绑了 JavaScript 、 Lua 脚本或 Solidity 脚本的执行环境。JSVM、Lua VM 的确是翻译成虚拟机没错。比较有意思的是，现在的区块链系统中，通常是数个节点共同执行并见证一份智能合约。区块链虚拟机、智能合约虚拟机 —— 区块链 SDK 上绑了 JavaScript 、 Lua 脚本或 Solidity 脚本的执行环境。JSVM、Lua VM 的确是翻译成虚拟机没错。比较有意思的是，现在的区块链系统中，通常是数个节点共同执行并见证一份智能合约。 区块链浏览器 —— 这个模糊的命名是被我吐槽最久的。其实它不是一个架设在区块链上的网页浏览器，而只是网站上登录后，类似「我的账户」里面可以看到「我的交易记录」以及每次交易记录区块描述的这么一堆网页。这应该是直译 Block Chain Expoloer 的锅。区块链浏览器通常还带有合约浏览、共识过程监督、出块记录、理事会等功能，这就看具体的设计了。- Token —— Token 是一种权益证明，并不是区块链特有，例如Q币也算是一种 token，在中心化系统中也可以发行和流通。从技术上来说，区块链和 token 是可以完全分开的。区块链系统中的权益证明，能通过加密算法和分布式账本标明资产的唯一性、确定真伪、并通过共识算法进行流通。一般 token 会被通俗理解为数字币。比特币、以太币、以及在以太坊上用各种智能合约生成的数字币都叫 TToken。实际上 token 也可以用来证明你拥有某种游戏道具，比如屠龙刀、裁决的拥有权，这就是虚拟资产的持有证明了，而不是纯粹的币。- TPS —— Trade Per Second，每秒能交易多少次，这是区块链主要性能指标。比特币大概 7 TPS，以太坊 25 TPS，而石墨烯技术的链理论上可以达到 10 万~100 万 TPS 的峰值吞吐性能。- 石墨烯技术和 DPOS 共识方案 —— 咱们行业多数游戏都是专制独裁式的。我游戏厂商今天要做个运营活动、发个道具，直接由游戏厂商说了算；比特币则类似全员民主投票制，稳，但是效率真是太低了；而所谓的石墨烯技术和 DPOS 共识就是类似咱们国家的民主集中制，大家先投票选出几个代表，然后由这些代表负责后续的日常投票就行了。这种方法在民主的低效和专制独裁的风险之间，取得了一个很好的平衡。Cocos 链就是采用这种技术的，否则每秒不到 30 次交易的那些公链，怎么可能支撑商业化游戏的运营呢。更多的链圈黑话，大家自己去网上搜索学习吧。我就不多写了。 正式开始之前，我得强调一下，我们是链圈的，不是币圈的。区块链底层技术可以拿来讨论，发币炒币这种事情就不用讨论了。我本人连股票都不炒的，比特币和以太坊钱包都还没开。花那个时间不如撸代码和打游戏有意思。 有媒体或开发者用「区块链引擎」来描述发布会后的 Cocos。这样的解读是不对的，游戏引擎就是游戏引擎，我们只是可以让开发者能更方便地接入区块链 SDK 而已。这和引擎提供广告、提供统计等服务的本质是一样的，甚至和引擎支持微信小游戏平台、支持 Facebook Instant Games 平台都是类似的。Unity 的 70% 收入来自于他们自家广告平台，人家也不会称自己是「广告引擎」嘛。正确表述是，「今天 Cocos 让游戏可以通过引擎快速接入我们的区块链 SDK 了」。 Cocos 区块链项目的名字叫 Project BCX，BCX 的全称是 Block Chain Expedition。BCX 在我们内部一般读为 /biks/。Expedition —— 让我们去远征吧，很可能是像 HTML5 技术一样，三到五年的一趟远征，最后带回来给开发者多一种新平台的选择。 三、区块链游戏的四阶段发展路线设想，以及我们的对应实现方案 首先，我们认为区块链游戏的发展，会分为四个阶段： 第一阶段：使用 token 作为游戏金币的结算 这一阶段的区块链游戏使用 token 作为游戏金币产出的结算。 一些项目的数字币基于以太坊的 ERC20 标准进行制作，基于 ERC20 协议发行的 token 很容易交换和兼容可用于不同的项目和平台， Token 的持有人可以完全控制资产并且跟踪到任何地址任何数量，其流通路径可在区块链浏览器中查询。 Candy.one 的游戏平台是这一阶段的代表。会前宣传说我们会演示 Cocos 游戏接入 Candy.one 平台，其实我们在现场根本就没有演示，因为这一阶段是在是太容易了。对于引擎而言，就和接入一个微信支付宝 SDK 一样简单。 真的是很简单。我们一款已经开发好的 H5 游戏，加入 Libs 里面两个混淆过的 JS 文件，调用这个区块链 SDK 的 API，构建，搞定。什么区块链容器、区块链虚拟机，我们游戏圈的人不用理会这些概念，就是接入一个 SDK，2 天时间搞定。 这个阶段会遇到的局限是：token 是同质化的，只能用来表达积分、金币这样的纯粹一些数字，无法表达不同的道具。比如说，你在游戏里打出了第一个钻石、然后第二个钻石，就可以记录为你有 2 个钻石，这个叫「同质化」；但是如果你有了第一只以太猫、第二只以太猫，两只猫的毛色、眼睛、形态都不一样，这样你就无法在链上记录说你有「以太猫x2」了，第一只和第二只以太猫需要分开记录，这叫「非同质化」。所以我们需要立刻进入第二阶段。 第二阶段：游戏金币和道具的去中介化、去代理交易 以太坊的 ERC721 Token，就是一种「非同质」 token 的标准范例。而之前大火的「以太猫」，就是非同质 token 的代表性应用。所以，不论是游戏中的道具、装备、玩家账号，你手里有把风之力、有把蛋刀、或者裁决、，都可以用非同质 token 来表达。这个 token 代表了你对这件道具的所有权，可以脱离游戏去买卖交易。 该阶段解决了玩家之间道具脱离游戏在链上交易、甚至是不同游戏里交易的问题。由于这个过程是去中介的，理论上到达该阶段之后，玩家就不需要像 5173、交易猫这样的道具交易平台了。你不再需要把账号密码给到一个交易平台上的代理人，那个代理人起到平台信誉担保的作用，一边收了买家的钱，把钱给到你，然后再一边把装备和账号给到买家，中间赚取差价。 我们的 Project BCX 正处于这个阶段，会稍微往前一点儿有个第三阶段的雏形。周六我和 INB 资本合伙人尹健辉在演示中，重点演示了我们已实现该阶段的功能。 健辉在这个地方有个很特别的设计是，交易的「原子化」实现。虽然「付钱」和「得到道具」是两件事情、属于两笔不同的记账，但是 Project BCX 里面的规则是把这两笔记账绑定绑定到一起，成为一个「原子」，如果你付了钱没有得到道具，或者得到了道具但是付款失败，这次交易的「原子」就会整体失败、整个回撤。而区块链的去中介去代理化，就是说只有你自己能对自己的道具和金币进行操作，在原子化交易规则之下和去中心挂化挂单、撮合系统的帮助之下，你在链上的交易里，再也不需要有道具交易平台那些代理人的帮助了。 但第二阶段的缺点是，游戏运行规则仍然是在链之外的。虽然道具的产量、流通是透明的，但产出规则仍然是可以被游戏厂商暗箱操作的。今天做个运营活动，明天出个新boss，结果玩家花了大量时间、或投入大量充值购买的装备道具被快速贬值。玩家和游戏厂商的价值严重背离了。我们不少游戏人，天天想着怎么洗用户，用户又不傻，很快就跑到王者荣耀、吃鸡游戏、TapTap 等「不会被洗」的地方去了。 第三阶段：关键规则上链运行 如何才能保证我作为玩家不会被反复洗呢？不会说得到一件橙装之后，下个月的运营活动里就被快速贬值呢？我们设想了第三阶段应该实现的功能，就是比如高级道具的掉落、金币产出规则等上链运行，游戏运营方将这些关键规则在区块链上以智能合约的形式实现，在区块链浏览器的支持下，规则对玩家是公开、透明的。 之前有提到，Project BCX 稍微有了第三阶段的雏形。我们设想并实现了一个很有趣的功能，称之为「铁匠铺」。铁匠铺应该是一个由游戏运营方、游戏玩家代表共同成立的治理委员会，关键规则在治理委员会讨论投票通过后，所有关键道具都只能通过铁匠铺来生成。未经过委员会讨论通过的情况下，游戏运营方是无法单方面生成各种道具装备的。 所以： 铁匠铺是具有道具、装备制作权限的账号和一组合约- 铁匠铺是独立于游戏的道具产出点- 铁匠铺的道具，具有限量性或唯一性- 铁匠铺由游戏厂商、玩家、玩家公会等构成的治理委员会管理铁匠铺是独立于游戏的道具产出点 铁匠铺由游戏厂商、玩家、玩家公会等构成的治理委员会管理 其实进一步想，这么设计之下，游戏的运营和收入方式会有很大的改动，游戏本身也会变得有趣：比如说在同样的三国世界观下，我们可以在《三国志》里面获得一把青龙偃月刀，记录到链上，然后到《真三国无双》里面割草，接着到《街机三国》里面把曹操砍了。这些游戏一开始可能是同家游戏厂商做的不同游戏，但最后有可能演变成不同游戏厂商做的不同游戏，但都接入同样的链、同样的世界观、同样的道具产出和交易规则、被一个世界观治理委员会管理。多家不同游戏厂商和玩家一起讨论、制定、公开青龙偃月刀的产出规则，而游戏运营的收入，就不能通过「洗用户」来维系了，而可能是通过提供区块链记账的算力来收取交易手续费。表面上看因为不能洗大R而短期收入降低了，但是游戏的生命周期则可能拉得很长，游戏厂商的关注点不应该是付费点设计和运营活动了，而是专注于有趣好玩的游戏内容生产，回归游戏的本质。 其实这一点我们还没完全思考得特别清晰，但直觉上这是一个正确的方向，让玩家和游戏运营方的利益一致化，实现游戏的长期运营和收入。如果我们今天不想做出一些改变，只是靠不停滚服洗玩家的话，最后玩家即使不玩你区块链游戏和铁匠铺规则，也会跑去玩那些大厂的公平竞技游戏了。 我和健辉在周六的演示里，演示了「只有铁匠铺账号才能创建道具」的功能，但对于游戏运营方和玩家、和玩家公会如何成立一个治理委员会来决定这些道具产出规则，则没有想得太明白，毕竟这已经不是技术的范畴了。 第四阶段：游戏整体上链运行 这个阶段的脑洞就比较大了。我们设想，行业的最终形态可能是游戏整体上链运行，游戏的全部逻辑代码都在链环境中执行，并由去中心化的区块链网络承载和存储数据，在这个场景下需要可信、高效、无延迟的运行容器与轻量级的节点，用于游戏的运行。但是，哈哈，目前业界尚无决定性的技术方案，大家各种链的性能和算力显然都扛不住啊。也许某天会有哪个顶尖聪明的程序员提出解决方案，这只能等了。 四、Project BCX 希望解决的问题，和技术特点 总体来讲，我们在区块链游戏方向的探索，希望能解决以下技术问题： 1、合适的区块容量和出块时间。容量太大么出块时间慢，容量太小么，怎么记录各种道具的一大堆数据。石墨烯方案的最大区块大小为 2M /块，对于记录游戏道具，这显然不够用。我们具体定多少呢，还在测，反正中间找到个平衡点。另外，我们也已经做了一些改进； 2、提供自定义数据结构存储。你这游戏是把风之力，那个游戏是把屠龙刀，每个游戏记录自家道具的数据结构肯定是不一样的，我们也不应该强求大家一样。所以块里面应该能支持自定义数据结构的存储； 3、提供带有区块链操作接口的多平台游戏运行环境。这句话翻译过来就是，区块链 SDK 应该能跨 iOS, Android, H5…… 这句基本是废话，本来就应该如此； 4、提供用户道具交易的 token 交换原子操作。这点上面已经讲解过了，因为没有中间代理商了，必须一手交钱一手交货，两个行为合并为一个原子。我们已经实现该功能； 5、去中介交易的实现和一个道具交易市场的范例。恩，这点我们也已经做完了； 6、提供完整的钱包和区块链浏览器。同上，开发完了，会上有演示； 7、支持同质和非同质 token 的跨链承兑网关。同质和非同质，前面已经讲解过了。什么叫「跨链承兑网关」呢？你看，Cocos 最早就是靠跨手机平台起家的，然后有 AnySDK 和 SDKBOX 帮助大家快速跨各种支付 SDK 广告 SDK。到了区块链游戏的时代，必然是各种公链各种币满天飞，这时候就需要引擎能帮助开发者能把游戏快速接入各种链各种币，反正多一种币的支付，就多一群玩家，玩家可不能因为他只有 a 币没有 b 币而流失； 8、二级资产的发行和交易能力。Project BCX 的设计是，CP 可以在 Cocos 公链上发行自己的二级数字币，游戏厂商或者我们前面提到的铁匠铺管委会，可以自由交易这些数字资产； 9、高速合约虚拟机。这个是和快速共识设计配套的，我们需要能快速地执行合约代码，不然玩家多了肯定扛不住。速度越快，可以上链的游戏内容就越多，对玩家利益就越有保障。 五、篇末 谢谢各位有耐心看到这里。我很久没有写过这么长的文章了，还得尽量通俗不晦涩。整体而言，Cocos 在区块链上的研究，是直奔「让玩家和游戏厂商利益一致化」「游戏厂商能专注生产好玩有趣的内容，而不是天天盘算怎么设计付费坑怎么洗用户」而去的。我前面也说过，大家天天洗用户洗大 R 的结果，就是玩家干脆跑到腾讯网易做的 MOBA、吃鸡等公平竞技游戏里去了，而这种公平竞技游戏，都需要高 DAU 堆起来的。在手机游戏流量红利结束之后，想要有 DAU 支撑，你要么得有超级流量平台、最好还是超级社交平台，要么得有大笔市场费用做投放买流量，这两件事情和大多数游戏公司已经没什么关系了。今天的 H5 小游戏，或者叫「手机页游」固然开放了新的流量获取方式，但可能两三年之后又会进入「生态稳定」的阶段，大家又必须去找新的突破口和新流量来源。今天 Cocos 投入区块链技术的研究，和我们早在 2010 年开始手游原生平台，2012 年开始 HTML5 技术一样，未雨绸缪，希望在手机页游/小游戏的流量红利结束之后，能给各位开发者提供多一种可选的方案。 最后我再强调一下，我们对区块链领域的投入研究，是和早几年的 Cocos VR 一样放在体外，并不影响 Cocos 作为游戏引擎本身的研发投入。引擎团队今年仍然在融资和扩张。应用了我们部分 3D 研发成果的 Cocos2d-x 4.0 将在 Q3 发布，将实现渲染多通道支持、2D 材质系统和 2D 光照，而且实现了下一步可适配 iOS Metal 的渲染架构；而性能大幅提升的 Cocos Creator v2.0 目前已经进展到 alpha-5 版本，计划在 Q2 发布，敬请期待。 不论是在手机原生，还是 H5 小游戏，或者在未来可能存在机会的区块链游戏上，『让游戏开发更简单』，既是对各位开发者的承诺，也是我们始终不变的愿景。 转载来源：Cocos引擎创始人王哲：区块链游戏，其实也没什么神秘的]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>JavaScript</tag>
        <tag>小游戏</tag>
        <tag>HTML5</tag>
        <tag>TPS游戏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从鸿茅药酒违法广告数2000+依然热销，谈消费者为什么对保健品痴迷？]]></title>
    <url>%2F2017%2Ff623961a%2F</url>
    <content type="text"><![CDATA[从鸿茅药酒违法广告数2000+依然热销，谈消费者为什么对保健品痴迷？ 转载来源：从鸿茅药酒违法广告数2000+依然热销，谈消费者为什么对保健品痴迷？]]></content>
      <tags>
        <tag>冀连梅药师</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK 为什么这么流行？｜GIAC 访谈]]></title>
    <url>%2F2017%2F635fc0ef%2F</url>
    <content type="text"><![CDATA[在大会前夕，高可用架构采访了本届大会讲师曾勇，就目前业界非常流行的 ELK 框架等问题进行了访谈。 曾勇（Medcl），Elastic 开发工程师与布道师，在分布式搜索、高性能、高可用架构、自动化运维等方面积累了超过七年的经验。Elastic 开源社区负责人。 1、曾勇，您好，很荣幸能采访到您。您作为 Elastic Stack 中国布道师，能否简单分享一下您在 ELK 布道过程中的收获和感受？ 这个问题很好，首先作为布道师，首要任务就是让更多的人了解我们的产品，链接社区和我们的开源产品，那自然而然就要接触到更多的人，这个是我之前工作经验中所不同的地方，收获就是能够听到更多用户的声音，然后再反馈到我们的产品改进中。Elastic 的产品一直在改进，我们一直在倾听社区和客户的声音，用户其实有很多诉求，功能，性能，可用性各方面，作为开源软件厂商，这些也都必须要考虑到，Elastic Stack 最近刚发布了全新的 6.0 版本，比如就有新增了用户经常反馈需要将搜索结果导出到 CSV 的功能，还有对视觉障碍更加友好的颜色和对比度，完善的键盘导航支持，屏幕读取文字转语音等这些人性化功能。 2、Elastic Stack 总部在美国，很多读者朋友很好奇您的工作方式是怎样的？是远程办公吗？两地的时间差会不会导致沟通效率下降？ 我们的工作方式确切的说是分布式办公，elastic 现在全球员工超过 600 人，分布于 30 多个国家和地区，大家可以选择自己最舒适的地方进行办公，时间差肯定有，所以我们的工作内容大部分都以异步方式进行处理，也用了很多的工具来进行协同，平时线上视频会议比较多，每年也有多次的线下面对面交流，从我们软件发版的速度大家应该可以看到，我们的效率是非常高的。 3、在大数据场景下，ELK 一经推出就变得非常流行。ELK 在大数据场景下有怎样的定位？解决了用户什么样的痛点？ ELK 一推出，最开始是在运维圈子里面火了起来，因为大家之前都没有很好的工具来进行运维的日志分析，ELK 由三个产品组成，Elasticsearch 负责海量数据的存储和搜索，Logstash 负责各种来自各种数据源的日志采集，而 Kibana 则很方便让你快速进行分析，三个组合在一起，一个完整的日志分析的解决方案就有了，不用编写一行代码。随着用户的众多，各种场景也被进一步挖掘出来，刚好最近几年也是大数据比较火热的时候，大家都在使用各种大数据的产品，然后发现 Elasticsearch 就有处理海量数据的能力，几十百 TB 也处理起来也很正常，并且比 Hadoop 要更方便，速度更快。 4、提到大数据，就不得说 Hadoop 生态圈。对比 Hadoop 生态圈和 ELK，您觉得它们各自有什么样的优势和缺点？ Elasticsearch 和 Hadoop 不一样，他不是一个编程框架，也不是一个需要你编写大量代码才能开始用的计算引擎，Elasticsearch 也是分布式架构，它提供了开箱即用的各种功能，比如搜索，你只需要构建 QueryDSL 查询就能拿到你想要的结果，再比如聚合，我们提供了常见的聚合操作，和搜索一样简单，所以，作为用户你可以花更多时间在业务上，而不用在具体的底层实现上花费大量的时间。另外 Elastic Stack 其他产品组合在一起，能够更好的在一起工作，从接入到最终分析展现都是现成的。这个是两相比较，Elastic 产品易用性上的优势。 还有一个就是，Elasticsearch 的速度 要快的多。Elasticsearch 天然的索引支持，能够在秒级甚至毫秒级别对海量的数据进行探索，这个是 Hadoop 及之上的系统所远远达不到的。Elasticsearch 同样也支持海量的数据，目前上 PB 规模的用户已有很多了，对于大部分的用户，数据规模其实达不到真正意义的海量，所以使用 Elasticsearch 完全就可以轻松解决大部分的场景需求，并且更加简单。 Elasticsearch 没有提供 Map Reduce 这种可以进行更加灵活的数据操作，不能作为一个任意的分布式计算平台，虽然也提供 script 支持，但是还是有一些局限，这个是 Elastic 设计的一个权衡，支持的特性，必须速度第一。 其实还有很多区别，比如同样都是分布式，Elasticsearch 部署和运维要更加简单等等。当然作为用户来说，我觉得要看其具体需求，了解各自的适用场景然后再进行选择。 5、作为 ELK 的核心组件，Elasticsearch 的最新版本已经是6.x，可谓发展迅猛。我很想知道，ES 在快速发展的背后，有没有踩过坑？或者有没有让您觉得有纪念意义的故事？ Elasticsearch 发展很快，甚至大家都觉得有点太快而不适应，软件公司发版都快赶上互联网公司产品的发版了。 作为产品，这个好事，有很多都是需求推动，恰恰说明我们产品的接受度非常高，很受大家的欢迎。 踩坑那是必然的，Elastic 一路走来踩了不少坑，一开始引入了 type 这概念，产生了很多误用引起的问题。对用户造成的困扰和产品的使用影响都是巨大的，所以在 6.0 我们已经不支持多个 Type 了，7.0 会完全移除。当然有很多值得纪念的里程碑的事件，第一个要数废弃 facts 和 aggregation 聚合的引入， 从此 Elasticsearch 不单是一个搜索引擎，更是分析引擎，第二个，要算 doc values 的引入，更快、更少占内存、同时更加稳定。在这次大会上也会介绍我们这一路走来的林林总总，欢迎关注。 6、从企业级分布式搜索，到大数据应用场景，ELK 有没有在其他的热门场景做一些探索？或者说它的下一步规划是什么？ Elastic Stack 除了分布式搜索和大数据应用场景，在很多领域都有广泛应用，比如 SIEM 领域，有很多公司用来进行安全方面的数据分析，做企业防入侵检测、异常流量分析、用户行为分析等。比如现在流行的 AIOPS，也有很多底层就是基于 Elasticsearch的。 除此之外，还有很多拿来替换 Zabbix、Nagios 来做基础设施监控，有一些公司是用来做业务指标分析。最近我们推出了 APM 的开源组件，未来应该会有很多公司用来进行应用性能分析。除了这几个主要的热门场景，其他的应用场景也真是五花八门。有用来做物联网数据分析的，什么电网使用量分析预测。还有做基因数据分析的。有用来实时监测伊波拉疫情，疾控预防。舆情监控等等。太多了就不一一列举了。 7、作为 GIAC 大数据平台专题的讲师，能否简单透露一下您将要给听众带来哪些值得期待的内容？ 这次分享主要会介绍 Elastic Stack 各产品一路走来的架构演进和主要的变化。曾经遇到的问题和如何解决的。也会介绍一些典型的使用场景，方便大家发散思维。另外会对未来的产品的演进方向做一个展望，总结过去、现在和未来，对我们产品感兴趣、想知道拿来都能干什么以及以后将会怎么样，都可以过来了解一下。 8、最后，您对 GIAC 有什么寄语或者期望？ 这是我第一次参加 GIAC，希望能够跟大家多多交流，也希望 GIAC 作为一个平台，能够起到传播技术、引领潮流，能够带来更多的思想碰撞。 本期 GIAC 大会上，大数据平台部分精彩的议题如下： 注：出品人及演讲议题以最新官网为准，全部最新演讲议题请点击“阅读原文”至官网查看。 参加 GIAC，盘点年底最新技术，目前单人购买优惠 600 元，多人购买有更多优惠。点击“阅读原文”了解大会更多详情。 转载来源：ELK 为什么这么流行？｜GIAC 访谈]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>ElasticSearch</tag>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乐视是庞氏骗局？贾跃亭说：说这话的人不是黑手就是SB；孙宏斌说：老贾都用自己的钱，哪有这种骗局？]]></title>
    <url>%2F2017%2Ff89931ec%2F</url>
    <content type="text"><![CDATA[乐视是庞氏骗局？贾跃亭说：说这话的人不是黑手就是SB；孙宏斌说：老贾都用自己的钱，哪有这种骗局？ 转载来源：乐视是庞氏骗局？贾跃亭说：说这话的人不是黑手就是SB；孙宏斌说：老贾都用自己的钱，哪有这种骗局？]]></content>
      <tags>
        <tag>虎嗅网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【服务器】Docker 核心技术与实现原理]]></title>
    <url>%2F2017%2Fd378dd82%2F</url>
    <content type="text"><![CDATA[提到虚拟化技术，我们首先想到的一定是 Docker，经过四年的快速发展 Docker 已经成为了很多公司的生产环境中大规模使用，也不再是一个只能在开发阶段使用的玩具了。作为在生产环境中广泛应用的产品，Docker 有着非常成熟的社区以及大量的使用者，代码库中的内容也变得非常庞大。 同样，由于项目的发展、功能的拆分以及各种奇怪的改名 PR，让我们再次理解 Docker 的的整体架构变得更加困难。 虽然 Docker 目前的组件较多，并且实现也非常复杂，但是本文不想过多的介绍 Docker 具体的实现细节，我们更想谈一谈 Docker 这种虚拟化技术的出现有哪些核心技术的支撑。 首先，Docker 的出现一定是因为目前的后端在开发和运维阶段确实需要一种虚拟化技术解决开发环境和生产环境环境一致的问题，通过 Docker 我们可以将程序运行的环境也纳入到版本控制中，排除因为环境造成不同运行结果的可能。但是上述需求虽然推动了虚拟化技术的产生，但是如果没有合适的底层技术支撑，那么我们仍然得不到一个完美的产品。本文剩下的内容会介绍几种 Docker 使用的核心技术，如果我们了解它们的使用方法和原理，就能清楚 Docker 的实现原理。 Namespaces命名空间 (namespaces) 是 Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。 在这种情况下，一旦服务器上的某一个服务被入侵，那么入侵者就能够访问当前机器上的所有服务和文件，这也是我们不想看到的，而 Docker 其实就通过 Linux 的 Namespaces 对不同的容器实现了隔离。 Linux 的命名空间机制提供了以下七种不同的命名空间，包括CLONE_NEWCGROUP、CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER和CLONE_NEWUTS，通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。 进程进程是 Linux 以及现在操作系统中非常重要的概念，它表示一个正在执行的程序，也是在现代分时系统中的一个任务单元。在每一个 *nix 的操作系统上，我们都能够通过ps命令打印出当前操作系统中正在执行的进程，比如在 Ubuntu 上，使用该命令就能得到以下的结果： 当前机器上有很多的进程正在执行，在上述进程中有两个非常特殊，一个是pid为 1 的 /sbin/init 进程，另一个是pid为 2 的 kthreadd 进程，这两个进程都是被 Linux 中的上帝进程 idle 创建出来的，其中前者负责执行内核的一部分初始化工作和系统配置，也会创建一些类似getty的注册进程，而后者负责管理和调度其他的内核进程。 如果我们在当前的 Linux 操作系统下运行一个新的 Docker 容器，并通过exec进入其内部的bash并打印其中的全部进程，我们会得到以下的结果： 在新的容器内部执行ps命令打印出了非常干净的进程列表，只有包含当前ps -ef在内的三个进程，在宿主机器上的几十个进程都已经消失不见了。 当前的 Docker 容器成功将容器内的进程与宿主机器中的进程隔离，如果我们在宿主机器上打印当前的全部进程时，会得到下面三条与 Docker 相关的结果： 在当前的宿主机器上，可能就存在由上述的不同进程构成的进程树： 这就是在使用clone(2)创建新进程时传入CLONE_NEWPID实现的，也就是使用 Linux 的命名空间实现进程的隔离，Docker 容器内部的任意进程都对宿主机器的进程一无所知。 Docker 的容器就是使用上述技术实现与宿主机器的进程隔离，当我们每次运行docker run或者docker start时，都会在下面的方法中创建一个用于设置进程间隔离的 Spec： 在setNamespaces方法中不仅会设置进程相关的命名空间，还会设置与用户、网络、IPC 以及 UTS 相关的命名空间： 所有命名空间相关的设置Spec最后都会作为Create函数的入参在创建新的容器时进行设置： 所有与命名空间的相关的设置都是在上述的两个函数中完成的，Docker 通过命名空间成功完成了与宿主机进程和网络的隔离。 网络如果 Docker 的容器通过 Linux 的命名空间完成了与宿主机进程的网络隔离，但是却有没有办法通过宿主机的网络与整个互联网相连，就会产生很多限制，所以 Docker 虽然可以通过命名空间创建一个隔离的网络环境，但是 Docker 中的服务仍然需要与外界相连才能发挥作用。 每一个使用docker run启动的容器其实都具有单独的网络命名空间，Docker 为我们提供了四种不同的网络模式，Host、Container、None 和 Bridge 模式。 在这一部分，我们将介绍 Docker 默认的网络设置模式：网桥模式。在这种模式下，除了分配隔离的网络命名空间之外，Docker 还会为所有的容器设置 IP 地址。当 Docker 服务器在主机上其中之后会创建新的虚拟网桥 docker0，随后在该主机上启动的全部服务在某人情况下都与该网桥相连。 在默认情况下，每一个容器在创建时都会创建一对虚拟网卡，两个虚拟网卡组成了数据的通道，其中一个会放在创建的容器中，会加入到名为 docker0 网桥中。我们可以使用如下的命令来查看当前网桥的接口： docker0 会为每一个容器分配一个新的 IP 地址并将 docker0 的 IP 地址设置为默认的网关。网桥 docker0 通过 iptables 中的配置与宿主机器上的网卡相连，所有符合条件的请求都会通过 iptables 转发到 docker0 并由网桥分发给对应的机器。 我们在当前的机器上使用docker run -d -p 6379&#58;6379 redis命令启动了一个新的 Redis 容器，在这之后我们再查看当前iptables的 NAT 配置就会看到在DOCKER的链中出现了一条新的规则： 上述规则会将从任意源发送到当前机器 6379 端口的 TCP 包转发到 192.168.0.4&#58;6379 所在的地址上。 这个地址其实也是 Docker 为 Redis 服务分配的 IP 地址，如果我们在当前机器上直接 ping 这个 IP 地址就会发现它是可以访问到的： 从上述的一系列现象，我们就可以推测出 Docker 是如何将容器的内部的端口暴露出来并对数据包进行转发的了；当有 Docker 的容器需要将服务暴露给宿主机器，就会为容器分配一个 IP 地址，同时向 iptables 中追加一条新的规则。 当我们使用redis-cli在宿主机器的命令行中访问 127.0.0.1&#58;6379 的地址时，经过 iptables 的 NAT PREROUTING 将 ip 地址定向到了 192.168.0.4，重定向过的数据包就可以通过 iptables 中的 FILTER 配置，最终在 NAT POSTROUTING 阶段将 ip 地址伪装成 127.0.0.1，到这里虽然从外面看起来我们请求的是 127.0.0.1&#58;6379，但是实际上请求的已经是 Docker 容器暴露出的端口了。 Docker 通过 Linux 的命名空间实现了网络的隔离，又通过 iptables 进行数据包转发，让 Docker 容器能够优雅地为宿主机器或者其他容器提供服务。 libnetwork整个网络部分的功能都是通过 Docker 拆分出来的 libnetwork 实现的，它提供了一个连接不同容器的实现，同时也能够为应用给出一个能够提供一致的编程接口和网络层抽象的容器网络模型。 The goal of libnetwork is to deliver a robust Container Network Model that provides a consistent programming interface and the required network abstractions for applications. libnetwork 中最重要的概念，容器网络模型由以下的几个主要组件组成，分别是 Sandbox、Endpoint 和 Network： 在容器网络模型中，每一个容器内部都包含一个 Sandbox，其中存储着当前容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个 Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡 veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux 网桥或者 VLAN。 想要获得更多与 libnetwork 或者容器网络模型相关的信息，可以阅读 Design · libnetwork 了解更多信息，当然也可以阅读源代码了解不同 OS 对容器网络模型的不同实现。 挂载点虽然我们已经通过 Linux 的命名空间解决了进程和网络隔离的问题，在 Docker 进程中我们已经没有办法访问宿主机器上的其他进程并且限制了网络的访问，但是 Docker 容器中的进程仍然能够访问或者修改宿主机器上的其他目录，这是我们不希望看到的。 在新的进程中创建隔离的挂载点命名空间需要在clone函数中传入CLONE_NEWNS，这样子进程就能得到父进程挂载点的拷贝，如果不传入这个参数子进程对文件系统的读写都会同步回父进程以及整个主机的文件系统。 如果一个容器需要启动，那么它一定需要提供一个根文件系统（rootfs），容器需要使用这个文件系统来创建一个新的进程，所有二进制的执行都必须在这个根文件系统中。 想要正常启动一个容器就需要在 rootfs 中挂载以上的几个特定的目录，除了上述的几个目录需要挂载之外我们还需要建立一些符号链接保证系统 IO 不会出现问题。 为了保证当前的容器进程没有办法访问宿主机器上其他目录，我们在这里还需要通过 libcotainer 提供的pivor_root或者chroot函数改变进程能够访问个文件目录的根节点。 到这里我们就将容器需要的目录挂载到了容器中，同时也禁止当前的容器进程访问宿主机器上的其他目录，保证了不同文件系统的隔离。 这一部分的内容是作者在 libcontainer 中的 SPEC.md 文件中找到的，其中包含了 Docker 使用的文件系统的说明，对于 Docker 是否真的使用chroot来确保当前的进程无法访问宿主机器的目录，作者其实也没有确切的答案，一是 Docker 项目的代码太多庞大，不知道该从何入手，作者尝试通过 Google 查找相关的结果，但是既找到了无人回答的 问题，也得到了与 SPEC 中的描述有冲突的 答案 ，如果各位读者有明确的答案可以在博客下面留言，非常感谢。 chroot在这里不得不简单介绍一下：chroot（change root），在 Linux 系统中，系统默认的目录就都是以/也就是根目录开头的，chroot的使用能够改变当前的系统根目录结构，通过改变当前系统的根目录，我们能够限制用户的权利，在新的根目录下并不能够访问旧系统根目录的结构个文件，也就建立了一个与原系统完全隔离的目录结构。 与 chroot 的相关内容部分来自 理解 chroot 一文，各位读者可以阅读这篇文章获得更详细的信息。 CGroups我们通过 Linux 的命名空间为新创建的进程隔离了文件系统、网络并与宿主机器之间的进程相互隔离，但是命名空间并不能够为我们提供物理资源上的隔离，比如 CPU 或者内存，如果在同一台机器上运行了多个对彼此以及宿主机器一无所知的『容器』，这些容器却共同占用了宿主机器的物理资源。 如果其中的某一个容器正在执行 CPU 密集型的任务，那么就会影响其他容器中任务的性能与执行效率，导致多个容器相互影响并且抢占资源。如何对多个容器的资源使用进行限制就成了解决进程虚拟资源隔离之后的主要问题，而 Control Groups（简称 CGroups）就是能够隔离宿主机器上的物理资源，例如 CPU、内存、磁盘 I/O 和网络带宽。 每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的 CGroup 之间是有层级关系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。 Linux 的 CGroup 能够为一组进程分配资源，也就是我们在上面提到的 CPU、内存、网络带宽等资源，通过对资源的分配，CGroup 能够提供以下的几种功能： 在 CGroup 中，所有的任务就是一个系统的一个进程，而 CGroup 就是一组按照某种标准划分的进程，在 CGroup 这种机制中，所有的资源控制都是以 CGroup 作为单位实现的，每一个进程都可以随时加入一个 CGroup 也可以随时退出一个 CGroup。– CGroup 介绍、应用实例及原理描述 Linux 使用文件系统来实现 CGroup，我们可以直接使用下面的命令查看当前的 CGroup 中有哪些子系统： 大多数 Linux 的发行版都有着非常相似的子系统，而之所以将上面的 cpuset、cpu 等东西称作子系统，是因为它们能够为对应的控制组分配资源并限制资源的使用。 如果我们想要创建一个新的 cgroup 只需要在想要分配或者限制资源的子系统下面创建一个新的文件夹，然后这个文件夹下就会自动出现很多的内容，如果你在 Linux 上安装了 Docker，你就会发现所有子系统的目录下都有一个名为 docker 的文件夹： 9c3057xxx其实就是我们运行的一个 Docker 容器，启动这个容器时，Docker 会为这个容器创建一个与容器标识符相同的 CGroup，在当前的主机上 CGroup 就会有以下的层级关系：每一个 CGroup 下面都有一个tasks文件，其中存储着属于当前控制组的所有进程的 pid，作为负责 cpu 的子系统，cpu.cfs_quota_us文件中的内容能够对 CPU 的使用作出限制，如果当前文件的内容为 50000，那么当前控制组中的全部进程的 CPU 占用率不能超过 50%。如果系统管理员想要控制 Docker 某个容器的资源使用率就可以在docker这个父控制组下面找到对应的子控制组并且改变它们对应文件的内容，当然我们也可以直接在程序运行时就使用参数，让 Docker 进程去改变相应文件中的内容。 当我们使用 Docker 关闭掉正在运行的容器时，Docker 的子控制组对应的文件夹也会被 Docker 进程移除，Docker 在使用 CGroup 时其实也只是做了一些创建文件夹改变文件内容的文件操作，不过 CGroup 的使用也确实解决了我们限制子容器资源占用的问题，系统管理员能够为多个容器合理的分配资源并且不会出现多个容器互相抢占资源的问题。 UnionFSLinux 的命名空间和控制组分别解决了不同资源隔离的问题，前者解决了进程、网络以及文件系统的隔离，后者实现了 CPU、内存等资源的隔离，但是在 Docker 中还有另一个非常重要的问题需要解决 - 也就是镜像。镜像到底是什么，它又是如何组成和组织的是作者使用 Docker 以来的一段时间内一直比较让作者感到困惑的问题，我们可以使用docker run非常轻松地从远程下载 Docker 的镜像并在本地运行。Docker 镜像其实本质就是一个压缩包，我们可以使用下面的命令将一个 Docker 镜像中的文件导出： 你可以看到这个 busybox 镜像中的目录结构与 Linux 操作系统的根目录中的内容并没有太多的区别，可以说 Docker 镜像就是一个文件。 存储驱动Docker 使用了一系列不同的存储驱动管理镜像内的文件系统并运行容器，这些存储驱动与 Docker 卷（volume）有些不同，存储引擎管理着能够在多个容器之间共享的存储。 想要理解 Docker 使用的存储驱动，我们首先需要理解 Docker 是如何构建并且存储镜像的，也需要明白 Docker 的镜像是如何被每一个容器所使用的；Docker 中的每一个镜像都是由一系列只读的层组成的，Dockerfile 中的每一个命令都会在已有的只读层上创建一个新的层： 容器中的每一层都只对当前容器进行了非常小的修改，上述的 Dockerfile 文件会构建一个拥有四层 layer 的镜像：当镜像被docker run命令创建时就会在镜像的最上层添加一个可写的层，也就是容器层，所有对于运行时容器的修改其实都是对这个容器读写层的修改。 容器和镜像的区别就在于，所有的镜像都是只读的，而每一个容器其实等于镜像加上一个可读写的层，也就是同一个镜像可以对应多个容器。 AUFSUnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文件系统服务。而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀的性能和效率。 AUFS 作为联合文件系统，它能够将不同文件夹中的层联合（Union）到了同一个文件夹中，这些文件夹在 AUFS 中称作分支，整个『联合』的过程被称为联合挂载（Union Mount）： 每一个镜像层或者容器层都是/var/lib/docker/目录下的一个子文件夹；在 Docker 中，所有镜像层和容器层的内容都存储在/var/lib/docker/aufs/diff/目录中： 而/var/lib/docker/aufs/layers/中存储着镜像层的元数据，每一个文件都保存着镜像层的元数据，最后的/var/lib/docker/aufs/mnt/包含镜像或者容器层的挂载点，最终会被 Docker 通过联合的方式进行组装。 上面的这张图片非常好的展示了组装的过程，每一个镜像层都是建立在另一个镜像层之上的，同时所有的镜像层都是只读的，只有每个容器最顶层的容器层才可以被用户直接读写，所有的容器都建立在一些底层服务（Kernel）上，包括命名空间、控制组、rootfs 等等，这种容器的组装方式提供了非常大的灵活性，只读的镜像层通过共享也能够减少磁盘的占用。 其他存储驱动AUFS 只是 Docker 使用的存储驱动的一种，除了 AUFS 之外，Docker 还支持了不同的存储驱动，包括aufs、devicemapper、overlay2、zfs和vfs等等，在最新的 Docker 中，overlay2取代了aufs成为了推荐的存储驱动，但是没有overlay2驱动的机器上仍然会使用aufs作为 Docker 的默认驱动。 不同的存储驱动在存储镜像和容器文件时也有着完全不同的实现，有兴趣的读者可以在 Docker 的官方文档 Select a storage driver 中找到相应的内容。 想要查看当前系统的 Docker 上使用了哪种存储驱动只需要使用以下的命令就能得到相对应的信息： 作者的这台 Ubuntu 上由于没有overlay2存储驱动，所以使用aufs作为 Docker 的默认存储驱动。 总结Docker 目前已经成为了非常主流的技术，已经在很多成熟公司的生产环境中使用，但是 Docker 的核心技术其实已经有很多年的历史了，Linux 命名空间、控制组和 UnionFS 三大技术支撑了目前 Docker 的实现，也是 Docker 能够出现的最重要原因。 作者在学习 Docker 实现原理的过程中查阅了非常多的资料，从中也学习到了很多与 Linux 操作系统相关的知识，不过由于 Docker 目前的代码库实在是太过庞大，想要从源代码的角度完全理解 Docker 实现的细节已经是非常困难的了，但是如果各位读者真的对其实现细节感兴趣，可以从 Docker CE 的源代码开始了解 Docker 的原理。 Reference Chapter 4. Docker Fundamentals · Using Docker by Adrian Mount- TECHNIQUES BEHIND DOCKER- Docker overview- Unifying filesystems with union mounts- DOCKER 基础技术：AUFS- RESOURCE MANAGEMENT GUIDE- Kernel Korner - Unionfs&#58; Bringing Filesystems Together- Union file systems&#58; Implementations, part I- IMPROVING DOCKER WITH UNIKERNELS&#58; INTRODUCING HYPERKIT, VPNKIT AND DATAKIT- Separation Anxiety&#58; A Tutorial for Isolating Your System with Linux Namespaces- 理解 chroot- Linux Init Process / PC Boot Procedure- Docker 网络详解及 pipework 源码解读与实践- Understand container communication- Docker Bridge Network Driver Architecture- Linux Firewall Tutorial&#58; IPTables Tables, Chains, Rules Fundamentals- Traversing of tables and chains- Docker 网络部分执行流分析（Libnetwork 源码解读）- Libnetwork Design- 剖析 Docker 文件系统：Aufs与Devicemapper- Linux - understanding the mount namespace &amp; clone CLONE_NEWNS flag- Docker 背后的内核知识 —— Namespace 资源隔离- Infrastructure for container projects- Spec · libcontainer- DOCKER 基础技术：LINUX NAMESPACE（上）- DOCKER 基础技术：LINUX CGROUP- 《自己动手写Docker》书摘之三： Linux UnionFS- Introduction to Docker- Understand images, containers, and storage drivers- Use the AUFS storage driverTECHNIQUES BEHIND DOCKER Unifying filesystems with union mounts RESOURCE MANAGEMENT GUIDE Union file systems&#58; Implementations, part I Separation Anxiety&#58; A Tutorial for Isolating Your System with Linux Namespaces Linux Init Process / PC Boot Procedure Understand container communication Linux Firewall Tutorial&#58; IPTables Tables, Chains, Rules Fundamentals Docker 网络部分执行流分析（Libnetwork 源码解读） 剖析 Docker 文件系统：Aufs与Devicemapper Docker 背后的内核知识 —— Namespace 资源隔离 Spec · libcontainer DOCKER 基础技术：LINUX CGROUP Introduction to Docker Use the AUFS storage driver 关于图片和转载本作品采用知识共享署名 4.0 国际许可协议进行许可。 转载时请注明原文链接，图片在使用时请保留图片中的全部内容，可适当缩放并在引用处附上图片所在的文章链接，图片使用 Sketch 进行绘制。 原文链接：Docker 核心技术与实现原理 · 面向信仰编程网址：https&#58;//draveness.me/docker 转载来源：【服务器】Docker 核心技术与实现原理]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
        <tag>CPU</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[“每天AI资讯这么多！该看哪些？”推荐一份优质资料清单]]></title>
    <url>%2F2017%2Feb6a4100%2F</url>
    <content type="text"><![CDATA[原作 BAILOOL &amp; meetshah1995 Root 编译自 GitHub 量子位 出品 | 公众号 QbitAI 人工智能最近火到炸裂，不看吧担心和时代脱节，看吧每天资讯多到想哭，信息过载心好累肿么办？ 来&lt;(￣︶￣)↗跟着GitHub上的资深用户BAILOOL走，看看他们每日追踪的信息源，拿到第一手的学术进展和行业动态，不用再追着不同的网站看啦。 以下是原文 怎么避免“从入门到放弃”不少童鞋发现人工智能很火，产生墙裂的学习兴趣（主要是工资高dei不dei），所以现在想上车学习，于是开始到处看“一文看懂”系列，或者开始修AI领域大牛的课程。 结果却发现，看完之后什么也没看懂。或者课程听起来很吃力，慢慢觉得自己智商跟不上，不像是这块料，就放弃了。 上车姿势不对啊童鞋们！知道大家刚开始控制不住寄几，疲于奔命地到处搜罗入门资料和课程，GitHub上的好心人就整理一份机器学习上车指南，包含精挑细选的一手资讯、经无数人验证的教程和高质量的信息源。 Step 1：刚迈脚上车，然后要干嘛下了决心要转行AI，就等于一只脚上了车，不过一上来也别给自己整太大压力，上来就看大砖头的书或者报一门课程。 先来点简单的，好培养自己的兴趣和耐力，比如说，泡泡论坛。特别是如果你现在啥也不太懂，建议你每天打开电脑之后，别和妹纸聊微信了，别看农药解说的直播了。克制一下自己内心的及时行乐 好好在Reddit这几个论坛上泡一会，泡它一个早上： machine_learning（https&#58;//www.reddit.com/user/techrat_reddit/m/machine_learning/）- MachineLearning（https&#58;//www.reddit.com/r/MachineLearning/）- computervision（https&#58;//www.reddit.com/r/computervision/）- learnmachinelearning（https&#58;//www.reddit.com/r/learnmachinelearning/）（https&#58;//www.reddit.com/user/techrat_reddit/m/machine_learning/） （https&#58;//www.reddit.com/r/MachineLearning/） （https&#58;//www.reddit.com/r/computervision/） （https&#58;//www.reddit.com/r/learnmachinelearning/） 还有，Quora上的这几个板块也有很多料，： Machine Learning（https&#58;//www.quora.com/pinned/Machine-Learning）- Computer Vision（https&#58;//www.quora.com/pinned/Computer-Vision）- Deep Learning（https&#58;//www.quora.com/pinned/Deep-Learning）- Reinforcement Learning（https&#58;//www.quora.com/pinned/Reinforcement-Learning）（https&#58;//www.quora.com/pinned/Machine-Learning） （https&#58;//www.quora.com/pinned/Computer-Vision） （https&#58;//www.quora.com/pinned/Deep-Learning） （https&#58;//www.quora.com/pinned/Reinforcement-Learning） Step 2：站久了该找个座啦等到什么时候，你看论坛的内容吃不饱，觉得自己需要更高阶的知识充电，就可以转战去arXiv读论文了。 简单介绍一下（以下信息来自Wiki），arXiv呢，是个收集物理学、数学、计算机科学与生物学的论文预印本的网站。将预稿上传到arvix作为预收录，可以防止自己的idea在论文被收录前被别人剽窃。 因此arXiv是个可以证明论文原创性（上传时间戳）的文档收录网站。现今的很多科学家习惯先将其论文上传至arXiv.org，再提交予专业的学术期刊。 Computer Vision and Pattern Recognition（https&#58;//arxiv.org/list/cs.CV/recent）- Artificial Intelligence（https&#58;//arxiv.org/list/cs.AI/recent- Learning（https&#58;//arxiv.org/list/cs.LG/recent）- Neural and Evolutionary Computing（https&#58;//arxiv.org/list/cs.NE/recent）（https&#58;//arxiv.org/list/cs.CV/recent） （https&#58;//arxiv.org/list/cs.AI/recent （https&#58;//arxiv.org/list/cs.LG/recent） 不过arXiv有个缺点，就是自己搜索相应的论文很麻烦。 所以有个大神，Andrej，建立了一个论文自动推送网站arxiv-sanity.com，用户在上面建立一个自己的账号之后，往上丢几篇感兴趣的文章，这个网站就可以自动推送从arXiv上搜来且符合用户兴趣方向的相关论文。 Step 3：听听懂路的老司机报下站如果读完论文之后，感觉一脸大写的懵✘，辣可以上ShortScience.org那转转。 这个网站是专门的论文讨论网站，上面有很多大牛点评同行的工作，或者读paper时做的笔记。大家看paper时也喜欢扎堆在ShortScience上发表自己的观点和看法。 特别适合刚上车的新手，如果自己读paper功力不太够，get不到重点，需要有人导读啥的，那么可以上这个网站去看看其他大牛对这篇论文的评论（有点儿像看完电影，总是习惯性上豆瓣看影评的赶脚） Step 4：看看别人怎么开车另外，还有个把paper和code整理到了一起的网站GitXiv.com，看名字就知道相当于GitHub和arXiv的合体。 在这个圈子里，已经形成了一股趋势，学术上一有最新进展，科学家都会把paper往arXiv上扔，然后没几天开发者们就把完成需求的开源代码抢发在GitHub上，大家执行力都超强的说。 不过，两个出处的链接没有个统一的地方可以关联在一起，不方便大家检索，也不方便大家横向比较和讨论，所以产生了这么个根据地GitXiv，供大家扎堆，还可以同行打分评论。 至于怎么上手自己开车，第5步之后就要靠大家去摸索啦，最后分享几个高质的信息源给大家。 最后：一手+高质+深度的信息feed到现在这个阶段，可能一般的信息流已经满足不了你了。扔几个我们圈内人都会锁定的频道： HackerNews（https&#58;//news.ycombinator.com/news）硅谷技术圈和投资圈都会关注的新闻网站，资讯不仅和AI有关，还会涉及到创业和信息安全，需要自己筛选。- DataTau（datatau.com）专门给数据科学家看的HackerNews。- AITopics(https&#58;//aitopics.org/search)可以自己设置订阅规则或者订阅源的资讯阅读器。（https&#58;//news.ycombinator.com/news） DataTau（datatau.com） AITopics 可以自己设置订阅规则或者订阅源的资讯阅读器。 油管上有几个频道做得也不错，可以挑一个跟就好： 3Blue1Brown(https&#58;//www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw)- Two Minute Papers（https&#58;//www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg）- Robert Miles（https&#58;//www.youtube.com/channel/UCLB7AzTwc6VFZrBsO2ucBMg）- S**iraj Raval**（https&#58;//www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A）(https&#58;//www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw) （https&#58;//www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg） （https&#58;//www.youtube.com/channel/UCLB7AzTwc6VFZrBsO2ucBMg） （https&#58;//www.youtube.com/channel/UCWN3xxRkmTPmbKwht9FuE5A） 几家AI巨头的官方博客也挺值得跟，可以扔进订阅源里： Google（https&#58;//research.googleblog.com/）- Facebook（https&#58;//research.fb.com/blog/）- Nvidia（https&#58;//blogs.nvidia.com/blog/category/deep-learning/）- Apple（https&#58;//machinelearning.apple.com/）（https&#58;//research.googleblog.com/） （https&#58;//research.fb.com/blog/） （https&#58;//blogs.nvidia.com/blog/category/deep-learning/） （https&#58;//machinelearning.apple.com/） 更新频率有点儿低，不过每次更新都是猛料的： Google Scholar（https&#58;//scholar.google.com/）- ResearchGate（https&#58;//www.researchgate.net/）- Distill（https&#58;//distill.pub/）（https&#58;//scholar.google.com/） （https&#58;//www.researchgate.net/） （https&#58;//distill.pub/） 推特上活跃的领域大牛必须关注一波（什么？你还没有推特？那你怎么活在AI圈子里！快，别墨迹，现在就去搞一个账号）：Deep Learning Hub；Marshall Kirkpatrick；Lynn Cherny；Top-N；Top 10 AI；Text Data, Vis &amp; Art。 这里就提这么几个人，等你到推特上之后关注完，推特会自己再给你推相关的大神的。 最后，有几个私人博客我觉得信息筛选的质量都符合我平时阅读的标准，大家挑一个喜欢的就好： The Wild Week in AI（https&#58;//www.getrevue.co/profile/wildml）周更，上面时不时还会有初创团队招人信息放出来，比较适合找工作的孩纸。- inFERENCe（inference.vc）不定期更，博主是隔了三年没碰机器学习，然后重新捡回来相关的研究进展。这个博是他个人的一个学习机器学习的成长记录地。- The Morning Paper（https&#58;//blog.acolyer.org/）日更，这个博客是一个原本什么都不懂的VC开的，初心是想开始积累自己在ML领域的认知，资讯的选取更多是从投资者的角度出发。- I**nside AI**（https&#58;//inside.com/ai）Inside网站旗下的AI话题板块，专注于资讯的深度。现在大多数新闻都是为了流量，吸引读者的眼球，而很少考虑读者的收获，导致优质新闻的产出和占道越来越少，很难到达渴望深度内容的读者。所以，Inside AI希望经过他们的筛选，订阅用户能重新获取有价值的新闻资讯。（https&#58;//www.getrevue.co/profile/wildml） inFERENCe（inference.vc） The Morning Paper 日更，这个博客是一个原本什么都不懂的VC开的，初心是想开始积累自己在ML领域的认知，资讯的选取更多是从投资者的角度出发。 （https&#58;//inside.com/ai） 最后，附上原文链接： https&#58;//github.com/BAILOOL/DoYouEvenLearn/blob/master/README.md — 完 — 诚挚招聘 量子位正在招募编辑/记者，工作地点在北京中关村。期待有才气、有热情的同学加入我们！相关细节，请在量子位公众号(QbitAI)对话界面，回复“招聘”两个字。 量子位 QbitAI · 头条号签约作者 վ’ᴗ’ ի 追踪AI技术和产品新动态 转载来源：“每天AI资讯这么多！该看哪些？”推荐一份优质资料清单]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>人工智能</tag>
        <tag>Quora</tag>
        <tag>Reddit</tag>
        <tag>信息安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[当美团滴滴激战正酣，他却和VIPKID深谈了一次，未来百亿美元教育公司长啥样？]]></title>
    <url>%2F2017%2Ffa8a7c50%2F</url>
    <content type="text"><![CDATA[2018年4月，零界·新经济100人2018年CEO峰会在北京举行，讨论关于中国的创业者和投资者们都面临时代的变革，技术、资本、用户的变化将加速各领域的融合和统一，文本为VIPKID创始人及CEO米雯娟，新经济100人创始人兼CEO李志刚一场有关新教育改变未来的对话。 李志刚：这次跟我聊的嘉宾，热爱教育，年龄比我小10岁，做教育已经二十年了。2014年春节后，我第一次遇到她，她刚刚创办她的公司，才两个员工。从2013年到2015年，我大概看了一百家在线教育公司，认识她1年8个月后，2015年10月，我选择第一家在线教育公司做，就是VIPKID创始人米雯娟。 米雯娟：我先问你两个问题，第一个是过去你采访了两百多家公司，教育类占5%，为什么？ 李志刚：首先从个人角度来说，我是自学成才的，对教育充满渴望，我父亲也是一位中学语文老师，从小受教育的熏陶。 第二个原因是在商言商，中国有13亿人口，中国传统文化注重教育，注重出人头地、望子成龙。教育是很大的行业，现金流非常好，所以我一直关注这个领域。 李志刚米雯娟：的确，教育在全球是6万亿美元的行业。2014年，这么多互联网教育创业的公司，你为什么选择了VIPKID？当时我们的团队非常惊讶和惊喜。 李志刚：2014年，很多在线教育公司融了1亿美元，比VIPKID高的有一二十家，为什么选择你？我觉得核心原因有两个，第一是赛道的选择。教育行业我认为只有在大的IP里才会出现百亿美金公司的机会，第一是K12，第二是英语。同时后者还伴随着全球化的激励。第二是对人的选择。刚才我说过了，我认识你1年8个月才做，之前也见面过几次。其实，2015年10月我做VIPKID的文章，我对小米的评价是：专注、执行力强、自带鸡血。 米雯娟：您还预测了我们会做中文项目，我们真做了Lingo Bus。 李志刚：是的，当时我们边走路边去中关村地铁，我觉得为什么会做中文，因为中国经济在2028年左右会超过美国，成为全球第一大经济实体，一定会伴随着一个重要的历史机遇，是什么呢？像两三百年前伴随的是英文的全球化，未来世界各地和中国做生意，首先要了解中国，了解中文。这对教育公司来讲是一个机会，让全球少年学中文，这是我三年前建立的逻辑。 最终，这件事是你干起来的。短短三年时间，你为什么做成了这么一家公司？你经历了哪些重要时刻？ 米雯娟：过去三年是VIPKID推向市场做产品增长、国际化发展的三年。在这之前我们花了一年半时间来打磨产品。 我坚信小朋友在线上学习没问题的，孩子们享受探索的天性和在线教育的特点可以很好地结合在一起。三年前我们推向市场的时候，少儿英语在线的比例基本等于0%，到现在所有人想做在线少儿英语的时候，比例已经超过10%。未来三五年线上比例会达到百分之三五十。 当时和你聊的时候，你还觉得我们是第一个吃螃蟹的人：8岁以下的孩子怎么在线学习？所以在找老师的时候，我们确保找到全球最好的老师。当时还有一个更便捷的方式是在国内找外教。但对VIPKID来说，我们选择在国外寻找外教，而且坚持只找最优质的北美老师。 米雯娟李志刚：4万名北美老师，老师是很个性化的，从公司角度来看，希望变成标准化的，你怎么做？ 米雯娟：个性化和标准化是完全协同的。我们的标准化体现在知识体系上，教学要求上。我们要求老师一定要采取10种方式来鼓励孩子学习；缺席七堂课，账号就被关掉了。 李志刚：未来是五万，甚至5年后是十万老师，人很难管理，更何况是中外文化差异，如何来管理10万名老师？ 米雯娟：特别简单，以学生为中心，以拼搏者为本。拼搏者包括老师。我们所有问题是以学生为中心，然后我们去服务好我们的老师。举个例子，有一次，我们告诉老师，希望他们圣诞节也来上课，我们会安排一些激励。但是激励规则没有讲清楚，当时老师们认为我应该有这个激励。当时，我们面临的损失是100万美金。 公司很小，这笔钱很多。当时团队讨论完之后，决定这笔损失我们认，因为是我们没讲清楚。 有的老师就留言说，没想VIPKID能够这样做，我要在你们这里教学一辈子。这种信任感，是共享经济中非常重要的要点。 李志刚：昨天谈到重公司，第一是供应链，在你这里就是老师。第二是劳动密集型，正好你也有。第三点，技术驱动。你在现在、未来，有没有在这方面做一些工作？ 米雯娟：VIPKID每个月积攒压缩后有超过100TB的数据，利用大数据、人工智能等技术，我们已经初步建立起了个性化学习路径，在教、学、评、练、测环节形成了“数据+算法+场景”的闭环。一方面我们持续赋能教师，从教师管理、教学辅助、教学内容三方面，帮助老师提升教学效能。另一方面，为孩子提供个性化的学习路径，学习系统可以利用人脸识别技术实时反馈学生的上课数据，如孩子发音、孩子情绪等，量化孩子的上课表现，从而及时给予老师教学指导意见，为学生打造真正个性化的、高效的学习课堂。在“测”和“评”上，我们同样做了很多工作帮助小朋友提升学习效果。 我们每个月新增数据非常大，这是新教育的特点，传统教育是出版社出版教材，一年培训一次老师，搜集意见再改进。我们可以做到以周来迭代内容，随时有几万个老师给予反馈。 米雯娟：你对教育未来发展趋势怎么看？ 李志刚：在中国首先还是K12，另外一块是素质教育。未来中产家庭越来越多，除了成绩以外，会关注未来孩子探索更多的世界。另外就是技术驱动教育，通过技术给学生提供更好的学习教育。 米雯娟：构建全球云端的K12大课堂，让最合适的老师帮助到地球每个角落的小朋友学习成长。未来我们最大的梦想不是做一个成功的线上儿童教育机构，更重要的是站在这样一个历史时间点，一个是互联网教育被初步认证，孩子们特别喜欢，另一个是中国发展走向全球，是不是有一个国际化的中国教育品牌去帮助孩子们去学习？我觉得对于教育来讲，在技术非常多的介入之前，始终没有解决的问题是教育的均衡和普惠。 均衡讲的是资源的连接，一个在北京非常优秀的语文老师，有没有可能帮助在伦敦定居的小朋友学中文。那同样为什么不能够让我们在山区的小朋友们，都能够接受非常高质量的英文教育。 所以在均衡这件事情来讲，我们其实做了一些事情，做乡村英语教育，我们在2017年就做了100家学校，2018年我们要做1000家学校，进入到学校里面，给孩子们开设免费的在线外教课。将来我们做1万家。 李志刚：以五年时间为基础，VIPKID有五万的老师群体，未来可能是10万。我认为，肯定需要技术驱动，老师的业务模式标准化。同时，通过技术捕捉学生信息，他的表情、他的态度、他的效果，给予更好的学习效率。这应该是VIPKID五年内应该干的。 五到十年后，如果说我对VIPKID有什么期望的话，它没有国界，不仅是教育，还包括文化、语言、人文的交流，是一个用科技支撑起来的教育、人文、科技类的公司。 本文转自新经济100人。文章为作者独立观点，不代表芥末堆立场。 转载来源：当美团滴滴激战正酣，他却和VIPKID深谈了一次，未来百亿美元教育公司长啥样？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>经济</tag>
        <tag>在线教育</tag>
        <tag>移动互联网</tag>
        <tag>美团网</tag>
        <tag>滴滴打车</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随机森林的直观理解]]></title>
    <url>%2F2017%2F669275ab%2F</url>
    <content type="text"><![CDATA[对于那些认为随机森林是黑匣子算法的人来说，这篇帖子会提供一个不同的观点。接下来，我将从4个方面去理解随机森林模型。 1.我们的特征有多重要？在sklearn随机森林中使用model.feature_importance来研究其重要特征是很常见的。重要特征是指与因变量密切相关的特征，并且对因变量的变化影响较大。我们通常将尽可能多的特征提供给随机森林模型，并让算法反馈对预测最有用的特征列表。但仔细选择正确的特征可以使我们的目标预测更加准确。 计算feature_importances的想法很简单，但却很有效。 把想法分解成简单的几步： 训练随机森林模型（假定有正确的超参数）1. 找到模型的预测分数（称之为基准分数）1. 多次（p次，p为特征个数）计算预测分数，每次打乱某个特征的顺序，可见下图1. 将每次预测分数与基准分数进行比较。如果随机调整特征顺序后预测分数小于基准分数，这意味着我们的模型如果没有这个特征会变得很糟糕。1. 删除那些不会降低基准分数的特征，并用减少后的特征子集重新训练模型。找到模型的预测分数（称之为基准分数） 将每次预测分数与基准分数进行比较。如果随机调整特征顺序后预测分数小于基准分数，这意味着我们的模型如果没有这个特征会变得很糟糕。 图1：计算特征重要性 注：将F4列打乱重新进行预测来判断特征F4的重要性 计算特征重要性的代码： 下面的代码将为所有特征提供一个结构为&amp;#123特征，重要性&amp;#125的字典。 图2：随机森林中的重要特征 输出： 2.我们对我们的预测有多大信心？一般来说，当企业想要有所预测时，他们的最终目的不是降低成本就是提高利润。在做出重大商业决策之前，企业十分热衷于去评估做出这个决定的风险的大小。但是，当预测结果并没有被展现在置信区间时，我们可能会无意中将企业至于更多的风险中，而不是降低风险。 当我们使用线性模型（基于分布假设的一般模型）时，比较容易找到我们预测的置信水平。但是当谈到随机森林的置信区间时，找起来并不是那么容易。 图3：偏差与方差的说明图 我想，任何上过线性回归课程的人都肯定看过这张图3。为了找到一个最佳线性模型，我们要去寻找偏差—方差最为折衷的模型。这张图片很好地说明了预测中偏差和方差的定义。（我们理解为这4张图分别是由四个不同的人掷飞镖所得）。 如果我们有高偏差和低方差值时（第三个人），我们投掷的飞镖会固定的远离红心。相反，如果我们有高的方差和低的偏差（第二个人），那么他投掷飞镖的结果就很不一样。如果有人去猜测他下一个飞镖击中的位置，那么它既有可能打到靶心也有可能远离靶心。现在我们来假设在现实生活中识别一起信用欺诈等同于上面例子击中靶心。如果信用公司拥有的的预测模型与上面第二人的掷飞镖行为很相似，那么该公司在大多数时候都不会抓住这个诈骗犯，尽管模型预测的是正确的。 因此，不仅仅是意味着预测的准确程度，我们还应该检查我们的预测的置信水平。 在随机森林中如何做到这一点？ 随机森林是由许多决策树组成。每棵树分别预测新的数据，随机森林从这些树中提取出平均预测值。预测置信水平的想法只是为了去看来自不同树木的预测有多少因为新的观测而产生变化，然后进一步分析。 基于方差树预测置信度的源代码： 注：偏差 = (up-down)/Yhat 以上代码的输出如下所示： 图4：基于方差树的置信树 从这个输出数据可以读出，我们可以说我们对于验证集上索引为14的观测的预测最没有信心。 3.什么是预测路径？如果我们想要分析哪些特征对于整体随机森林模型是重要的，则 特征重要性（如在第一部分中）是有用的。但是如果我们对某个特定的观察感兴趣，那么 Tree interpreter的角色就会发挥作用。 举个例子，现在有一个RF模型，这种模型会预测—一位来医院的患者X是否具有很高的概率再入院?，为了简单起见，我们考虑只有3个特征—患者的血压值，患者的年龄以及患者的性别。现在，如果我们的模型认为患者A有80％的可能会再次入院，我们怎么能知道这个被模型预测为他（她）将重新入院的患者A有什么特殊之处?在这种情况下，Tree interpreter会指示预测路径紧随那个特殊的患者。就像是，因为患者A是65岁的男性，这就是为什么我们的模型会预测他将再次入院。另一个被模型预测将再次入院的患者B ，可能时因为他有高血压（而不是因为年龄或性别）。 基本上，Tree interpreter给出了偏差的排序列表（在起始节点的平均值）以及单个节点对给定预测的贡献。 图5&#58;决策树路径（来源：http&#58;//blog.datadive.net/interpreting&amp; 图5的这棵决策树（深度：3层）基于波士顿房价数据集。根据中间节点的预测值以及导致数值发生变化的特征，它显示了决策路径的分解。单节点的贡献是该节点的值与前一个节点值的差值。 图6&#58;Tree interpreter（最终再次入院的概率=0.6) 图6 给出了对于患者A使用Tree interpreter的输出示例。图片显示年龄为65岁是模型预测再入院概率高于均值的最高贡献者。 图7&#58;将特征贡献通过瀑布图可视化展示图 图6同样也可以使用瀑布图7来表示。我从“ 瀑布图包 ”中选材做的这个快速简单的瀑布图。 上面的瀑布图可视化代码： 相关变量的阐释： • 值（图片B)是指通过节点预测目标值。（就是在该节点中落下的观测目标的平均值）。 • 贡献是当前节点的值减去上一节点的值（这是为一个路径提供的贡献特征）。 • 路径是为了到达叶节点而通过某些观察所获得的所有特征分割的组合。 tree interpreter包直接用来计算每个节点的贡献，链接：treeinterpreter 4.目标变量如何与重要特征相关？ Partial Dependence Plots找到最重要的特征后，下一步我们可能会感兴趣的是研究目标变量与兴趣特征之间的直接关系。从线性回归中得到的与其相类似的是模型系数。对于线性回归，系数以这种方式被计算，即我们可以通过说：“在XjXj中有1个单位变化，保持所有其他XiXi不变，YY会发生什么变化？”这样的方式来解释。 虽然我们有来自随机森林的特征重要性，但是它们只是给出YY的变化是由于XiXi的改变之间的相关性。我们不能直接地解释他们就像保持所有其他特征不变，YY该变量取决于XjXj中的单位的变化。 幸运的是，我们有看一被看作线性模型系数图表的局部依赖图，但同样也可被扩展为看起来像黑箱模型。这个想法是将预测中所做的改变孤立于一个特定的功能。它不同于XX对YY的散点图，因为散点图不能隔离XX对YY的直接关系，并且可能受XX和YY所依赖的其他变量的间接关系所影响。 PDP分析步骤如下： 训练一个随机森林模型（假设F1 … F4是我们的特征，Y是目标变量，假设F1是最重要的特征）。1. 我们有兴趣探索Y和F1的直接关系。1. 用F1（A）代替F1列，并为所有的观察找到新的预测值。采取预测的平均值。（称之为基准值）1. 对F1（B）… F1（E）重复步骤3，即针对特征F1的所有不同值。1. PDP的X轴具有不同的F1值，而Y轴是虽该基准值F1值的平均预测而变化。我们有兴趣探索Y和F1的直接关系。 对F1（B）… F1（E）重复步骤3，即针对特征F1的所有不同值。 图8&#58;PDP分析逻辑图8&#58;PDP分析逻辑 图 9 是partial dependence plot的一个例子。数据来自 kaggle bulldozer competition data，它显示了生产年份（YearMade）和（销售价格）SalesPrice的关系 图9&#58;partial dependence plot（YearMade与SalePrice的变化) 而图10是SalePrice与YearMade的线状图。我们可以看到，散点图/折线图可能无法像PDP那样捕获YearMade对SalesPrice的直接影响。 图10&#58;上述两个图片均来自(来源https&#58;//github.com/fastai/fastai/t 写在最后： 在大多数情况下，随机森林在预测中可以击败线性模型预测。针对随机森林经常提出的反对意见是：对它的理解没有线性模型那样直观，但是本文的讨论希望帮助你回答这样的反对意见。 作者个人简历：目前在旧金山大学学习数据科学（分析），在Manifold.ai做实习生。此前，曾在凯捷咨询公司担任数据科学家，在Altisource担任高级业务分析师。 更多精彩文章您可前往BigQuant社区查看并参与讨论：BigQuant社区 转载来源：随机森林的直观理解]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>随机森林</tag>
        <tag>F1赛车</tag>
        <tag>飞镖</tag>
        <tag>欢聚时代</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云Redis读写分离典型场景：如何轻松搭建电商秒杀系统]]></title>
    <url>%2F2017%2Fc2560231%2F</url>
    <content type="text"><![CDATA[秒杀活动是绝大部分电商选择的低价促销，推广品牌的方式。不仅可以给平台带来用户量，还可以提高平台知名度。一个好的秒杀系统，可以提高平台系统的稳定性和公平性，获得更好的用户体验，提升平台的口碑，从而提升秒杀活动的最大价值。 本次主要讨论阿里云云数据库Redis缓存设计高并发的秒杀系统。 秒杀的特征秒杀活动对稀缺或者特价的商品进行定时，定量售卖，吸引成大量的消费者进行抢购，但又只有少部分消费者可以下单成功。因此，秒杀活动将在较短时间内产生比平时大数十倍，上百倍的页面访问流量和下单请求流量。 秒杀活动可以分为3个阶段： 秒杀前：用户不断刷新商品详情页，页面请求达到瞬时峰值。- 秒杀开始：用户点击秒杀按钮，下单请求达到瞬时峰值。- 秒杀后：一部分成功下单的用户不断刷新订单或者产生退单操作，大部分用户继续刷新商品详情页等待退单机会。秒杀开始：用户点击秒杀按钮，下单请求达到瞬时峰值。 消费者提交订单，一般做法是利用数据库的行级锁。只有抢到锁的请求可以进行库存查询和下单操作。但是在高并发的情况下，数据库无法承担如此大的请求，往往会使整个服务blocked，在消费者看来就是服务器宕机。 秒杀系统系统架构图 秒杀系统的流量虽然很高，但是实际有效流量是十分有限的。利用系统的层次结构，在每个阶段提前校验，拦截无效流量，可以减少大量无效的流量涌入数据库。 利用浏览器缓存和CDN抗压静态页面流量 秒杀前，用户不断刷新商品详情页，造成大量的页面请求。所以，我们需要把秒杀商品详情页与普通的商品详情页分开。对于秒杀商品详情页尽量将能静态化的元素尽量静态化处理，除了秒杀按钮需要服务端进行动态判断，其他的静态数据可以缓存在浏览器和CDN上。这样，秒杀前刷新页面导致的流量进入服务段的流量只有很小的一部分 利用阿里云读写分离Redis缓存拦截流量 CDN是第一级流量拦截，第二级流量拦截我们使用支持读写分离的阿里云Redis。在这一阶段我们主要读取数据，读写分离Redis能支持高大60万以上qps的，完全可以支持需求。 首先通过数据控制模块，提前将秒杀商品的缓存到阿里云读写分离Redis，并设置秒杀开始标记： 秒杀开始前，服务集群读取goodsId_Start为0，直接返回未开始。 数据控制模块将goodsId_start改为1，标志秒杀开始。 服务集群缓存开始标记位并开始接受请求，并记录到redis中goodsId_access，商品剩余数量为(goodsId_count - goodsId_access)。 当接受下单数达到goodsId_count后，继续拦截所有请求，商品剩余数量为0 可以看出，最后成功参与下单的请求只有少部分可以被接受。在高并发的情况下，允许稍微多的流量进入。因此可以控制接受下单数的比例。 利用阿里云主从版Redis缓存加速库存扣量 成功参与下单，进入下层服务，开始进行订单信息校验，库存扣量。为了避免直接访问数据库，我们使用阿里云主从版Redis来进行库存扣量，阿里云主从版Redis提供10万级别的QPS。我们使用Redis来优化库存查询，提前拦截秒杀失败的请求，将大大提高系统的整体吞吐量。我们也是通过数据控制模块提前将库存存入Redis&#58; //我们将每个秒杀商品在redis中用一个hash结构表示 扣量时，服务器通过请求Redis获取下单资格，我们通过lua脚本实现，由于Redis时单线程模型，lua可以保证多个命令的原子性： lua脚本： 先使用SCRIPT LOAD将lua脚本提前缓存在Redis，然后调用EVALSHA调用脚本，比直接调用EVAL节省网络带宽： 秒杀服务通过判断Redis是否返回抢购个数n，即可知道此次请求是否扣量成功。 使用阿里云主从版Redis实现简单的消息队列异步下单入库 扣量完成后，需要进行订单入库。如果商品数量较少的时候，直接操作数据库即可。如果秒杀的商品是1万，甚至10万级别，那数据库锁冲突将带来很大的性能瓶颈。因此，利用消息队列组件，当秒杀服务将订单信息写入消息队列后，即可认为下单完成，避免直接操作数据库。 消息队列组件依然可以使用Redis实现，在R2中用list数据结构表示： 将订单内容写入Redis&#58; 异步下单模块从Redis中顺序获取订单信息，并将订单写入数据库： 我们通过使用Redis作为消息队列，异步处理订单入库，有效的提高了用户的下单完成速度。 数据控制模块，管理秒杀数据同步 最开始，我们利用阿里云读写分离Redis进行流量限制，只让部分流量进入下单。对于下单检验失败和退单等情况，我们需要让更多的流量进来。因此，数据控制模块需要定时将数据库中的数据进行一定的计算，同步到主从版Redis，同时再同步到读写分离的Redis，让更多的流量进来。 转载来源：阿里云Redis读写分离典型场景：如何轻松搭建电商秒杀系统]]></content>
      <categories>
        <category>设计</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>电子商务</tag>
        <tag>脚本语言</tag>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LSTM、GRU与神经图灵机：详解深度学习最热门的循环神经网络]]></title>
    <url>%2F2017%2Ffb1efad0%2F</url>
    <content type="text"><![CDATA[循环神经网络是当前深度学习热潮中最重要和最核心的技术之一。近日，Jason Brownlee 通过一篇长文对循环神经网络进行了系统的介绍。 循环神经网络（RNN/recurrent neural network）是一类人工神经网络，其可以通过为网络添加额外的权重来在网络图（network graph）中创建循环，以便维持一个内部状态。 为神经网络添加状态的好处是它们将能在序列预测问题中明确地学习和利用背景信息（context），这类问题包括带有顺序或时间组件的问题。 在这篇文章中，你将踏上了解用于深度学习的循环神经网络的旅程。 在读完这篇文章后，你将了解： 用于深度学习的顶级循环神经网络的工作方式，其中包括 LSTM、GRU 和 NTM。- 顶级 RNN 与人工神经网络中更广泛的循环（recurrence）研究的相关性。- RNN 研究如何在一系列高难度问题上实现了当前最佳的表现。顶级 RNN 与人工神经网络中更广泛的循环（recurrence）研究的相关性。 注意，我们并不会覆盖每一种可能的循环神经网络，而是会重点关注几种用于深度学习的循环神经网络（LSTM、GRU 和 NTM）以及用于理解它们的背景。 那就让我们开始吧！ 概述 我们首先会设置循环神经网络领域的场景；然后，我们将深入了解用于深度学习的 LSTM、GRU 和 NTM；之后我们会花点时间介绍一些与用于深度学习的 RNN 相关的高级主题。 循环神经网络- 完全循环网络（Fully Recurrent Networks）- 递归神经网络（Recursive Neural Networks）- 神经历史压缩器（Neural History Compressor）递归神经网络（Recursive Neural Networks） 长短期记忆网络（LSTM）- 门控循环单元（GRU）神经网络- 神经图灵机（NTM）门控循环单元（GRU）神经网络 循环神经网络 首先让我们设置场景。 人们普遍认为循环（recurrence）是给网络拓扑结构提供一个记忆（memory）。 一种更好的看法是训练集包含一种样本——其带有一组用于循环训练样本的输入。这是「传统的惯例」，比如传统的多层感知器 X(i) -&gt; y(i) 但是该训练样本得到了来自之前的样本的一组输入的补充。这是「非传统的」，比如循环神经网络 [X(i-1), X(i)] -&gt; y(i) 和所有的前馈网络范式一样，问题的关键是如何将输入层连接到输出层（包括反馈激活），然后训练该结构使其收敛。 现在，让我们来看看几种不同的循环神经网络，首先从非常简单的概念开始 完全循环网络 多层感知器的分类结构得到了保留，但该架构中的每个元素与其它每个元素之间都有一个加权的连接，并且还有一个与其自身的反馈连接。 并不是所有这些连接都会被训练，而且其误差导数的极端非线性意味着传统的反向传播无法起效，因此只能使用通过时间的反向传播（Backpropagation Through Time）方法或随机梯度下降（SGD）。 另外，可参阅 Bill Willson 的张量积网络（Tensor Product Networks）：http://www.cse.unsw.edu.au/~billw/cs9444/tensor-stuff/tensor-intro-04.html递归神经网络 循环神经网络是递归网络的线性架构变体。 递归（recursion）可以促进分层特征空间中的分支，而且其所得到的网络架构可以在训练进行中模拟它。 其训练是通过子梯度方法（sub-gradient methods）使用随机梯度实现的。 R. Socher 等人 2011 年的论文《Parsing Natural Scenes and Natural Language with Recursive Neural Networks》中使用 R 语言对其进行了详细的描述，参阅：http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Socher_125.pdf 神经历史压缩器 在 1991 年，Schmidhuber 首先报告了一种非常深度的学习器，其可以通过一种 RNN 层次的无监督预训练来在数百个神经层上执行功劳分配（credit assignment）。 每个 RNN 都是无监督训练的，可以预测下一个输入。然后只有产生错误的输入会被前馈，将新信息传送到该层次结构中的下一个 RNN，然后以更慢的、自组织的时间尺度进行处理。 事实表明不会有信息丢失，只是会有压缩。该 RNN stack 是数据的一个「深度生成模型（deep generative model）。这些数据可以根据其压缩形式重建。 参阅 J. Schmidhuber 等人 2014 年的论文《Deep Learning in Neural Networks: An Overview》：http://www2.econ.iastate.edu/tesfatsi/DeepLearningInNeuralNetworksOverview.JSchmidhuber2015.pdf当误差被反向传播通过大型结构时，非线性导数的极限（extremity）的计算会增长，会使功劳分配（credit assignment）困难甚至是不可能，使得反向传播失败。 长短期记忆网络 使用传统的通过时间的反向传播（BPTT）或实时循环学习（RTTL/Real Time Recurrent Learning），在时间中反向流动的误差信号往往会爆炸（explode）或消失（vanish） 反向传播误差的时间演化指数式地依赖于权重的大小。权重爆炸可能会导致权重振荡，而权重消失则可能导致学习弥合时间滞后并耗费过多时间或根本不工作。 LSTM 是一种全新的循环网络架构，可用一种合适的基于梯度的学习算法进行训练。- LSTM 是为克服误差反向流动问题（error back-flow problem）而设计的。它可以学习桥接超过 1000 步的时间间隔。- 在有噪声的、不可压缩的输入序列存在，而没有短时间滞后能力的损失时，这是真实的。LSTM 是为克服误差反向流动问题（error back-flow problem）而设计的。它可以学习桥接超过 1000 步的时间间隔。 通过一种有效的基于梯度的算法，误差反向流动问题可以克服，因为该算法让网络架构可以强迫常量（因此不会有爆炸或消失）误差流过特殊单元的内部状态。这些单元可以减少「输入权重冲突（Input Weight Conflict）」和「输出权重冲突（Output Weight Conflict）」的影响。 输入权重冲突：如果输入是非零的，则同样的输入权重必须被同时用于存储特定的输入并忽略其它输入，那么这就将会经常收到有冲突的权重更新信号。 这些信号将会试图使该权重参与存储输入并保护该输入。这种冲突会使学习变得困难，并且需要一个对背景更敏感的机制来通过输入权重控制「写入操作（write operations）」。 输出权重冲突：只要一个单元的输出是非零的，那么这个单元的输出连接的权重就将吸引在序列处理过程中生成的有冲突的权重更新信号。 这些信号将试图使正在输出的权重参与进来，获取存在在处理单元中信息，并且在不同的时间保护后续的单元免受正被馈送的单元的输出的干扰。 这些冲突并不特定于长期滞后（long-term lags），并且也可以同样影响到短期滞后（short-term lags）。值得注意的是，随着滞后的增长，存储的信息必须被保护起来免受干扰，尤其是在学习的高级阶段。 网络架构：不同类型的单元都可能传递关于网络当前状态的有用信息。比如说，一个输入门（输出门）可能会使用来自其它记忆单元（memory cell）的输入来决定是否存储（读取）其记忆单元中的特定信息。 记忆单元包含门（gate）。门特定于它们调解的连接。输入门是为了纠正输入权重冲突，而输出门是为了消除输出权重冲突。 门：具体来说，为了缓解输入和输出权重冲突以及干扰，我们引入了一个乘法输入门单元来保护存储的记忆内容免受不相关输入的干扰，还引入了一个乘法输出门单元来保护其它单元免受存储中当前不相关记忆内容的干扰。 LSTM 架构示例。这个 LSTM 网络带有 8 个输入单元、4 个输出单元和 2 个大小为 2 的记忆单元模块。in1 是指输入门，out1 是指输出门，cell1 = block1 是指 block 1 的第一个记忆单元。来自 1997 年的《Long Short-Term Memory》 因为处理元素的多样性和反馈连接的，LSTM 中的连接比多层感知器的连接复杂。 记忆单元模块：记忆单元共享同一个输入门和同一个输出门，构成一种名叫记忆单元模块（memory cell block）的结构。 记忆单元模块有利于信息存储；就像传统的神经网络一样，在单个单元内编码一个分布式输入可不是一件容易的事情。一个大小为 1 的记忆单元模块就是一个简单的记忆单元。 学习（Learning）：一种考虑了由输入和输出门导致的修改过的、乘法动态的实时循环学习（RTRL/Real Time Recurrent Learning）的变体被用于确保通过记忆单元误差的内部状态反向传播到达「记忆单元网络输入（memory cell net inputs）」的非衰减误差（non-decaying error）不会在时间中被进一步反向传播。 猜测（Guessing）：这种随机方法可以超越许多时间滞后算法。事实已经说明，之前的工作中所使用的许多长时间滞后任务可以通过简单的随机权重猜测得到比提出的算法更快的解决。 参见 S. Hochreiter 和 J. Schmidhuber《Long-Short Term Memory》：http://dl.acm.org/citation.cfm?id=1246450LSTM 循环神经网络最有意思的应用出现在语言处理领域。更全面的描述可参阅 Gers 的论文 ： F. Gers 和 J. Schmidhuber 2001 年的论文《LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages》：ftp://ftp.idsia.ch/pub/juergen/L-IEEE.pdf- F. Gers 2001 年的博士论文《Long Short-Term Memory in Recurrent Neural Networks》：http://www.felixgers.de/papers/phd.pdfF. Gers 2001 年的博士论文《Long Short-Term Memory in Recurrent Neural Networks》：http://www.felixgers.de/papers/phd.pdf LSTM 的局限性 LSTM 有效的截断版本无法轻松解决类似于「强延迟的异或（strongly delayed XOR）」这样的问题。 每个记忆单元模块都需要一个输入门和一个输出门。并不一定需要其它循环方法。 在记忆单元内穿过「常量误差传送带（Constant Error Carrousels）」的常量误差流可以得到与传统的前馈架构（会一次性获得整个输入串）一样的效果。 和其它前馈方法一样，LSTM 也有「regency」概念上的缺陷。如果需要精密的计数时间步骤，那么可能就需要额外的计数机制。 LSTM 的优点 该算法桥接长时间滞后的能力来自其架构的记忆单元中的常量误差反向传播。 LSTM 可以近似有噪声的问题域、分布式表征和连续值。 LSTM 可以很好地泛化其所考虑的问题域。这是很重要的，因为有的任务无法用已有的循环网络解决。 在问题域上对网络参数进行微调看起来是不必要的。 在每个权重和时间步的更新复杂度方面，LSTM 基本上就等于 BPTT。 LSTM 很强大，在机器翻译等领域实现了当前最佳的结果。 门控循环单元神经网络 门控循环单元神经网络已经在序列和时间数据上得到了成功的应用。 最适合语音识别、自然语言处理和机器翻译。与 LSTM 一起，它们在长序列问题领域表现优良。 门控（gating）被认为是在 LSTM 主题中，涉及到一个门控网络生成信号来控制当前输入和之前记忆发生作用的方式，以更新当前的激活，从而更新当前的网络状态。 门本身是自我加权的，会在整个学习阶段中根据一个算法有选择性地更新。 门网络会增加计算复杂度，从而会增加参数化（parameterization），进而引入额外的计算成本。 LSTM RNN 架构将简单 RNN 的计算用作内部记忆单元（状态）的中间候选项。门控循环单元（GRU）RNN 将 LSTM RNN 模型的门控信号减少到了 2 个。这两个门分别被称为更新门（update gate）和重置门（reset gate）。 GRU（和 LSTM）RNN 的门控机制和在参数化方面的简单 RNN 一样。对应这些门的权重也使用 BPTT 随机梯度下降来更新，因为其要试图最小化成本函数。 每个参数更新都将涉及到与整体网络的状态相关的信息。这可能会有不利影响。 门控的概念可使用三种新变体的门控机制来探索和扩展。 这三种门控变体为：GRU1（其中仅使用之前的隐藏状态和偏置来计算每个门——、GRU2（其中仅使用之前的隐藏状态来计算每个门—）和 GRU3（其中仅使用偏置来计算每个门）。我们可以观察到参数显著减少，其中 GRU3 的参数数量最小。 这三种变体和 GRU RNN 在手写数字的 MNIST 数据库和 IMDB 电影评论数据集上进行了基准测试。 从 MNIST 数据集生成了 2 个序列长度，而从 IMDB 数据集生成了 1 个序列长度。 这些门的主要驱动信号似乎是（循环）状态，因为其包含关于其它信号的基本信息。 随机梯度下降的使用隐含地携带了有关网络状态的信息。这可以解释仅在门信号中使用偏置的相对成功，因为其自适应更新携带了有关网络状态的信息。 门控变体可使用有限的拓扑结构评估来探索门控机制。 更多信息请参阅： R. Dey 和 F. M. Salem 2017 年的论文《Gate-Variants of Gated Recurrent Unit (GRU) Neural Networks》：https://arxiv.org/ftp/arxiv/papers/1701/1701.05923.pdf- J. Chung 等人 2014 年的论文《Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling》：https://pdfs.semanticscholar.org/2d9e/3f53fcdb548b0b3c4d4efb197f164fe0c381.pdfJ. Chung 等人 2014 年的论文《Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling》：https://pdfs.semanticscholar.org/2d9e/3f53fcdb548b0b3c4d4efb197f164fe0c381.pdf 神经图灵机 神经图灵机通过将神经网络与外部记忆资源耦合而对该神经网络的能力进行了延展——它们可以通过注意（attention）过程与外部记忆资源交互。参阅机器之心文章《神经图灵机深度讲解：从图灵机基本概念到可微分神经计算机》。 这种组合的系统类似于图灵机或冯·诺依曼结构，但它是端到端可微分的，使得其可以有效地使用梯度下降进行训练。 初步的结果表明神经图灵机可以根据输入和输出样本推理得到基本的算法，比如复制、排序和联想回忆（associative recall）。 RNN 相比于其它机器学习方法的突出之处在于其在长时间范围内学习和执行数据的复杂转换的能力。此外，我们都知道 RNN 是图灵完备的，因此其有能力模拟任意程序，只要连接方式合适即可。 标准 RNN 的能力被扩展以简化算法任务的解决方案。这种丰富性主要是通过一个巨大的可寻址的记忆实现的，所以通过类比于图灵的通过有线存储磁带实现的有限状态机（finite-state machine）的丰富性，其被命名为神经图灵机（NTM）。 和图灵机不同，神经图灵机是一种可微分的计算机，可以通过梯度下降训练，从而为学习程序提供了一种实用的机制。 神经图灵机架构。NTM 架构大体上如上所示。在每一个更新循环中，控制器网络接收一个来自外部环境的输入并给出一个输出作为响应。它也会通过一系列并行的读写头来读写一个记忆矩阵（memory matrix）。虚线是 NTM 回路与外部世界的分界线。来自 2014 年的《Neural Turing Machines》 关键在于，该架构的每个组件都是可微分的，使其可以直接使用梯度下降进行训练。这可以通过定义「模糊（blurry）」的读写操作来实现，其可以或多或少地与记忆中的所有元素进行交互（而非像普通的图灵机或数字计算机那样处理单个元素）。 更多信息请参阅： A. Graves 等人 2014 年的《Neural Turing Machines》：https://arxiv.org/pdf/1410.5401.pdf- R. Greve 等人 2016 年的《Evolving Neural Turing Machines for Reward-based Learning》：http://sebastianrisi.com/wp-content/uploads/greve_gecco16.pdfR. Greve 等人 2016 年的《Evolving Neural Turing Machines for Reward-based Learning》：http://sebastianrisi.com/wp-content/uploads/greve_gecco16.pdf NTM 实验 复制（copy）任务可以测试 NTM 是否可以存储和回调长序列的任意信息。向该网络提供一个随机二进制向量的输入序列，后面跟着一个分隔符。 该网络被训练用来复制 8 位的随机向量序列，其中序列长度是在 1 到 20 之间随机的。目标序列就仅仅是输入序列的副本而已（没有分隔符）。 重复复制任务是复制任务的扩展，即要求该网络输出被复制的序列给定的次数，然后给出一个序列终止标志。这个任务的主要目的是看 NTM 是否可以学习简单的嵌套函数。 该网络的输入是随机长度的随机二进制向量序列，后面跟着一个标量值，表示我们想要的副本的数量，其出现在一个单独的输入信道上。 联想记忆任务（associative recall tasks）涉及到组织间接产生的数据，即当一个数据项指向另一个项的时候。要创建一个项列表，使得查询其中一个项时需要该网络返回后续的项。 我们定义了一个二进制向量序列，通过分隔符对其左右进行了限制。在几个项被传播到该网络中后，通过展示随机项对该网络进行查询，看该网络是否可以产生下一个项。 动态 N-gram 任务测试的是 NTM 是否可以通过使用记忆作为可覆写的表格来快速适应新的预测分布；该网络可以使用这个表格来持续对转换统计保持计数，从而模拟传统的 N-gram 模型。 考虑在二进制序列上的所有可能的 6-gram 分布的集合。每个 6-gram 分布都可以被表达成一个有 32 个数字的表格，其基于所有可能长度的 5 个二进制历史指定了下一位（bit）为 1 的概率。通过使用当前的查找表绘制 200 个连续的位，会生成一个特定的训练序列。该网络对该序列进行观察，一次一位，然后被要求预测出下一位。 优先级排序任务测试的是 NTM 的排序能力。该网络的输入是一个随机二进制向量的序列，以及每个向量的一个标量优先级评分。该优先级是在 [-1, 1] 范围内均匀分布的。目标序列是根据它们的优先级排序后的二进制向量序列。 NTM 有 LSTM 的前馈结构作为它们的组件之一。 总结 你通过这篇文章了解了用于深度学习的循环神经网络。具体来说，你了解了： 用于深度学习的顶级循环神经网络的工作方式，其中包括 LSTM、GRU 和 NTM。- 顶级 RNN 与人工神经网络中更广泛的循环（recurrence）研究的相关性。- RNN 研究如何在一系列高难度问题上实现了当前最佳的表现。顶级 RNN 与人工神经网络中更广泛的循环（recurrence）研究的相关性。 转载来源：LSTM、GRU与神经图灵机：详解深度学习最热门的循环神经网络]]></content>
      <categories>
        <category>其它</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>文章</tag>
        <tag>R语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中科院计算所开源深度文本匹配开源工具 MatchZoo]]></title>
    <url>%2F2017%2F079a1dbc%2F</url>
    <content type="text"><![CDATA[via GitHub 雷锋网 AI 科技评论消息，中国科学院计算技术研究所网络数据科学与技术重点实验室近日发布了深度文本匹配开源项目 MatchZoo。MatchZoo 是一个 Python 环境下基于 TensorFlow 开发的开源文本匹配工具，可以应用于文本检索、自动问答、复述问题、对话系统等多种应用任务场景。 GitHub&#58; https&#58;//github.com/faneshion/MatchZoo 在 arxiv 上，MatchZoo&#58; A Toolkit for Deep Text Matching 介绍了开源项目的主要结构： 据雷锋网了解，这一开源工具能够让大家更加直观地了解深度文本匹配模型的设计、更加便利地比较不同模型的性能差异、更加快捷地开发新型的深度匹配模型。 MatchZoo主要特点MatchZoo 基于 Keras 开发，支持 TensorFlow、CNTK 及 Theano，并能在 CPU 与 GPU 上无缝运行。MatchZoo 包括数据预处理，模型构建，训练与评测三大模块： 数据预处理模块（data preparation） 该模块能将不同类型文本匹配任务的数据处理成统一的格式，具体包含如下的几个文件： word dictionary：每个单词的映射符，通过预设的规则进行过滤常用词，筛选少见词、噪声词。- corpus file：问题及回答内容文件，每行以（id, length, word_id）格式书写，分别表示问题或者回答的 id，文本长度，以及词 id；- relation file：包括训练、验证、测试文件，每行以（rel,query_id, doc_id）格式书写，分别表示问题与回答的相关度（数据中１为相关，０为不相关），问题的 id，以及答案的 id；corpus file：问题及回答内容文件，每行以（id, length, word_id）格式书写，分别表示问题或者回答的 id，文本长度，以及词 id； 同时，该模块针对不同的任务需求提供了不同的数据生成器，包括有基于单文档的数据生成器、基于文档对的数据生成器、以及基于文档列表的数据生成器。不同的数据生成器可适用于不同的文本匹配任务，如文本问答、文本对话、以及文本排序等。 模型构建模块（model construction） 该模块基于 Keras 以帮助我们快速开发。Keras 中包含了深度学习模型中广泛使用的普通层，如卷积层、池化层、全连接层等，除此之外，在 matchzoo/layers/中，研究人员还针对文本匹配定制了特定的层，如动态池化层、张量匹配层等。这些操作能够快速高效地实现复杂的深度文本匹配的模型，在 matchzoo/models/中，研究人员实现了目前主流的深度文本匹配模型（如 DRMM, MatchPyramid, DUET, MVLSTM, aNMM, ARC-I, ARC-II, DSSM, CDSSM 等）。 训练与评测模块（training and evaluation） 该模块提供了针对回归、分类、排序等问题的目标函数和评价指标函数。例如，在文本排序中常用的基于单文档的目标、基于文档对的目标、以及基于文档序列的目标。用户可以根据任务的需要选择合适的目标函数。在模型评估时，MatchZoo 也提供了多个广为使用的评价指标函数，如 MAP、NDCG、Precision，Recall 等。同时，在文本排序任务中，MatchZoo 还能生成兼容 TREC 的数据格式，可以方便地使用 trec_eval来进行模型评估。 运行 git clone https&#58;//github.com/faneshion/MatchZoo.gitcd MatchZoopython setup.py installpython main.py –phase train –model_file ./models/arci_ranking.configpython main.py –phase predict –model_file ./models/arci_ranking.config 基准测试在 Github 上，作者们以 WikiQA 数据为例来介绍 MatchZoo 的使用。 以 DRMM 为例，在 MatchZoo/matchzoo 中运行： python main.py –phase train –model_file models/wikiqa_config/drmm_wikiqa.config 在测试时可运行： python main.py –phase predict –model_file models/wikiqa_config/drmm_wikiqa.config 运行十个模型的结果如下： 训练 loss 曲线图如下： 测试 MAP 性能曲线图如下： 论文地址：https&#58;//arxiv.org/pdf/1707.07270.pdf，雷锋网整理 转载来源：中科院计算所开源深度文本匹配开源工具 MatchZoo]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>深度学习</tag>
        <tag>GitHub</tag>
        <tag>Python</tag>
        <tag>Word</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[优质博文集锦-云栖社区-阿里云]]></title>
    <url>%2F2017%2Ffbafdf9e%2F</url>
    <content type="text"><![CDATA[优质博文集锦-云栖社区-阿里云 转载来源：优质博文集锦-云栖社区-阿里云]]></content>
  </entry>
  <entry>
    <title><![CDATA[CNode：Node.js专业中文社区]]></title>
    <url>%2F2017%2Fff373b3b%2F</url>
    <content type="text"><![CDATA[CNode：Node.js专业中文社区 转载来源：CNode：Node.js专业中文社区]]></content>
  </entry>
  <entry>
    <title><![CDATA[vue.js应用从创建到运行，从入门到精通]]></title>
    <url>%2F2017%2F76e21f30%2F</url>
    <content type="text"><![CDATA[目录一个简单vue应用的创建 选择什么方式创建vue应用- 创建- 项目结构分析- 运行创建 运行 vue.js知识点的学习 vue.js是怎么构成一个spa应用- 组件- vue实例- 响应式- 模板语法组件 响应式 vue.js细化学习 过滤器——后台得到的数据格式不是你想要的？过滤器帮你！- 指令——还想用DOM操作节点？指令帮你实现！- 混合——个个组件重复写方法很麻烦？混合帮你解决！- 组件——如何开发出灵活的组件- 过渡——页面没动画？过渡可以做的很完美!指令——还想用DOM操作节点？指令帮你实现！ 组件——如何开发出灵活的组件 正篇 昨天写了一篇webpack+vue.js+element打造大型项目，看到网友们反应不错，于是小编一大早编起来编写接下来未完成的章节，今天完成的是Vue.js知识点的学习，它涵盖了开发中需要的知识，也涉及了一些大家开发中没主要的知识点和细节，希望的、能够帮助到广大网友们，如果大家有什么疑问和要求，大家可以在下方留言或者加我的微信&#58;Neho_Developer 一个简单vue应用的创建 选择什么方式创建vue应用写完了上一篇文章，我一直考虑有什么方式创建一个vue应用而纠结，用CDN引入的方式，从传统开发转过来的人很好理解，但事实上我们用vue.js开发都是比较大型的应用，这种方式学到最后是不需要的，最后还是选择了webpack开发vue应用，在创建之前，我们要确认电脑上安装了运行环境node.js和npm管理包。 创建一个vue应用在这里我们使用vue.js官方提供的vue脚手架vue-cli创建一个应用，所谓的脚手架，通俗来讲，就是通过人家定义好的一个应用文件模板，通过脚手架，我们可以下载下来供开发者自己使用。我们先安装vue-cli npm install -g vue-cli 使用vue-cli初始化项目,这个过程中，大家可以选择一直enter就好了，当要选择y/n时，选择n 进到目录 cd my-project-name 安装依赖 cnpm install 运行vue应用 以上步骤都必须正确执行，我们在浏览器上输入localhost&#58;8080便可以看到运行的结果。 项目文件分析安装好了之后我们打开项目的文件 创建好的项目文件 node_modules这个文件夹是在npm install后，将npm包放在此文件夹内，我们不需要修改 src我们开发修改的目录 babelrc使用bable转化文件，一般我们不需要修改 gitignore当我们协同开发项目时，我们往往需要通过版本控制工具协同开发，比如git，关于git后续会讲解git的使用技巧教程，这个文件就是配置git版本时，忽略不需要上传文件的目录清单 indexvue应用为spa（单页面应用），这个为打包之后在浏览器运行的html文件，一般不需要修改 package.jsonnpm包安装的目录清单，一般不需要修改 README.MDmarkdown格式的文件，可以在里面写一些这个项目的操作记录和介绍，一般不需要修改 webpack.config.jswebpack模块开发工具的配置文件，我们在这里主要修改加载器的配置信息 vue.js知识点的学习vue.js是怎么样构建一个spa应用的 理解学过html的人都知道，一个html文件是如何将超文本信息展示给用户的，是通过一个个元素，更加普遍的是通过DIV元素，像建屋子一样叠一个美丽的网页。类似的，vue也是通过一个个类似DIV一样的东西，我们称其为组件，他也想DIV一样，可以嵌套，叠加，还有DIV不能实现的其他功能，通过vnode渲染在index这个文件上，从而得到了我们常见的div组成的html文件。而我们开发的经理，则是去实现一个个组件的功能。 一个页面可以看作由组件树组成的 组件 webpack中vue组件的文件体现形式及实现页面的现实在webpack中组件以文件.vue格式体现。一个vue文件则为一个组件，我们来看看一个vue文件包含什么。 根组件app.vue文件 我们可以看到，一个vue文件包含三部分,这三个部分正好是网页的上个基本元素HTML CSS JAVASCRIPT,一个spa页面，通过一个或多个以vue文件格式体现的组件便可以构成一个页面，我们看看他是怎么实现通过组件展示一个网页 vue文件的实现方式 组件的作用域在组件中，变量是独立的，也就是说在中定义的变量，在其他的vue文件中是不可以访问的，当组件间需要交互数据，怎么办呢，下面就全面的介绍了 父子组件的通信子组件获取负组件的变量：在子组件中this.$parent,返回父组件的实例，便可以访问父组件的变量，也可以通过props向子组件注入变量。 子组件获取父组件的html：可以通过slot分发父组件的html。 当组件之间的关系并不是父子关系，那怎么办呢，这时我推荐大家使用vue的插件vuex，接下来的文章会专门介绍vuex vue实例 理解如果一个应用只有一个vue组件构成的话，从MVC框架来看的话，template标签定义的就是应用的视图层VIEW，script标签中的定义的就是model层了，这样说其实不是很准确，更加确切的说应该的实例中的data对象 data对象：model层 export default &amp;#123data()&amp;#123return&amp;#123//这里是一个应用的model层text&#58;’你好，Neho’&amp;#125&amp;#125&amp;#125 视图层 &amp;#123&amp;#123text&amp;#125&amp;#125 页面 你好，Neho vue实例一个vue组件对应一个vue实例，在script标签中，我们通过new Vue()方式创建一个vue实例，通常来说，不通过的组件vue实例是不一样的，我们可以通过向这个方法传入一个对象来实例化不同的vue实例。对象中常用的属性有data属性——定义数据，methods属性——定义操作data数据的函数，created属性——实力在一个vue实例中，不同的生命周期会调用不同的函数钩子，我们来看看一个简单的代码 根组件 效果 页面效果 响应式vue的一个很出色的特点是视图层view（template标签）和数据层model（data中定义的数据）是时时同步的，我们来看看简单的例子 写好代码我们看看效果代码 代码 页面 页面 这是一个很简单的页面，但我们试图去修改input标签的内容时，发现页面显示的内容也跟着改了 页面 修改后页面 敢于v-model的使用，下面会介绍到，这里我们只需要知道它可以同步input的内容到它绑定的data属性edit上。 模板语法 理解，写过后台的人对模板这个概念估计不会陌生，通常来说，在一个html文件中，我们不能直接将js代码写在html标签中，这样是会报错了，为了解决这个问题，模板诞生了，使用模板，通常来说，不同模板有不同后缀名，比如ejs模板，他的后缀名为ejs。在vue文件中，模板的文件后缀名就是vue，使用vue的模板，我们可以直接在temlate标签中使用js代码如上面的&amp;#123&amp;#123&amp;#125&amp;#125，他可以是我们在里面写js表达式。我们来看看vue模板有什么语法- &amp;#123&amp;#123&amp;#125&amp;#125——将里面的变量（script标签中data定义的变量）输出在页面上&amp;#123&amp;#123&amp;#125&amp;#125——将里面的变量（script标签中data定义的变量）输出在页面上 通过&amp;#123&amp;#123&amp;#125&amp;#125，我们可以在里面写入data定义好的变量，从而显示在页面上。 v-html——将传入的变量（script标签中data定义的变量）输出在页面上（不包括节点）使用&amp;#123&amp;#123&amp;#125&amp;#125很方便，但有时我们需要拼接节点的时候，他会把div这类节点字符串也输出出来，这是我们不愿看到的，我们可以使用v-html来解决这个问题，我们来看下代码 代码 代码 页面效果 页面 v-if——控制节点元素的显示，传入的变量为false时，该指令绑定的元素不显示代码 代码 页面——我们可以看到，页面并没有出现我们在div中写的文本 v-for——循环输出文本，这对于我们创建一些重复的节点非常有用代码，我们需要输出5行li列表，以前我们需要重复写5个li，现在只要写一个就好了 代码 页面效果 页面 v-bind——每种标签都有自己的属性，当我们需要将实例定义好的变量传入属性中，怎么办呢，v-bind可以帮我们解决这个问题，这个例子中，input有一个value属性，我们需要要将data中定义好的变量输出到页面上代码 代码 页面 页面 v-on——我们知道，web是事件驱动的应用，当我们需要在模板中添加事件监听怎么办呢，这里我们使用v-on，在这里我们在节点中添加点击事件，事件会调用实例中定义的函数clickMe,然后弹出警告框代码 代码 页面点击前 页面 页面点击按钮后 页面 v-model——在处理表单的时候，开发者最感到头疼的是如何获取表单的信息，在vue.js中，我们可以通过v-model时时将绑定的input元素内的文本同步到传入v-model的值，而且这个过程是双向的，用户修改input内的文本，data中的变量会跟随改变，通过方法改变data中的变量，页面input的文本也会随着改变。- 结语结语 vue.js知识点就将这么多了，这已经可以满足打开日常开发的需求，如果有什么不足或者不明白之处，大家可以下方留言或者加我的微信^_^,接下来讲讲大家不怎么注意，但在开发中合理运用会大大简化我们的开发 vue.js细化学习过滤器——后台得到的数据格式不是你想要的？过滤器帮你！ 为什么使用过滤器在开发当中，常常遇到一些后台返回的数据并不是我们想展示在页面上的，比如后台对于时间的处理，往往返回给前段的是时间戳，然而我们不可以能将时间戳展示在页面上，这样的话过滤器就排上用场了 怎么使用过滤器vue2.0后，过滤器只在模板语法&amp;#123&amp;#123&amp;#125&amp;#125中使用，对于时间戳处理我们可以这样 &amp;#123&amp;#123时间戳|时间戳过滤器&amp;#125&amp;#125 过滤器实战——金额过滤器 解决问题后台返回的金额往往只是一个number数据类型，但我们在页面显示时候，往往需要在金额前面加上金额符号￥，之时候我们可以使用过滤器解决这个问题 首先创建一个全局的过滤器priceFormat代码 代码 将过滤器引入入口文件main.js- 在组件中使用 页面 指令——还想用DOM操作节点？指令帮你实现！ 指令的定义 指令（Directives）是带有 v- 前缀的特殊属性。指令属性的值预期是单一 JavaScript 表达式（除了 v-for，之后再讨论）。指令的职责就是当其表达式的值改变时相应地将某些行为应用到 DOM 上 有哪些指令上面我们学到了模板语法，其中v-if,v-model等等都是官方封装好的指令，但有时候我们需要自己定义属于自己的指令 指令解决的问题vue.js开发应用的时候，大多时候，vue是不支持我们用DOM去看开发的，但有时候我们必须使用DOM的方式去解决一些问题，比如在用户点击购买按钮的时候会弹出一个信息输入组件，我们往往需要弹出的信息输入框会自动聚焦，方便用户的输入。这时候我们就需要写一个自动对焦的指令 首先我们先创建一个指令代码 将指令引入入口文件main.js- 在需要绑定的元素上绑定自定义指令v-focus代码 代码 页面——我们在页面添加一个购买按钮，当用户点击按钮，会弹出一个蒙版输入框，这时候输入框会自动获得焦点。 点击前 点击前的页面 点击购买后——可以看到，这时候输入框已经自动获得焦点了 点击后的页面 混合——个个组件重复写方法很麻烦？混合帮你解决！ 解决的问题在开发的过程中，有些方法似乎并不是单独一个组件使用，很多的组件都会使用到这种方法，比较典型的就是在大型的单页面开发中，往往会涉及到路由的转跳，在使用编程路由的时候，由于组件的作用域是独立的，methods中定义的方法并不能在所有组件中使用，为此我们必须在每个组件中重复的编写this.$router.push()这一简单方法，这时候我们可以通过定义一个全局的混合methods，便可以在所有的组件中使用路由转跳的方法 在这里，由于没有涉及路由的概念，我们通过一个简单的全局methods方法，来演示一下怎么使用混合- 定义一个全局混合定义一个全局混合 代码 在webpack入口文件main.js引入mixin- 在组件中使用全局混合方法 代码 点击前 页面 点击后 页面 结语Vue的知识点介绍就在这里了，在开发过程中常用的的知识都有所讲解，如果大家有什么不懂得，意见或者想重点介绍的，可以留言下方或者加我们QQ564648147,我们一起探讨进步吧^^,新手期，觉得小编写的不错的点个赞或者转发分享给周围的朋友吧(ง •̀•́)ง 下期vue-router从入门到精通——开发一个CMS登陆界面,有兴趣的关注我吧，定期更新 转载来源：vue.js应用从创建到运行，从入门到精通]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>HTML</tag>
        <tag>JavaScript</tag>
        <tag>Git</tag>
        <tag>科技</tag>
        <tag>文章</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于snowflake算法实现发号器 - CSDN博客]]></title>
    <url>%2F2017%2F1b323c24%2F</url>
    <content type="text"><![CDATA[#一、背景： 清分系统需要一套id生成器服务，保证分布式情况下全局唯一。 #二、算法描述： ##1、原始算法： （1）snowflake是twitter开源的分布式ID生成算法，其核心思想是：一个long型的ID，使用其中43bit作为毫秒数，3bit作为机房编号，5bit作为机器编码，12bit作为毫秒内序列号。这个算法单机每毫秒内理论上最多可以生成2^12，也就是4096个ID，完全能满足业务的需求。 （2）snowflake的结构如下(每部分用-分开)&#58; 0 - `0000000000000000000000000000000000000000000 - 000 -00000 - 000000000000` 一共加起来刚好64位，为一个Long型。(转换成字符串长度为18) snowflake生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和workerId作区分），并且效率较高。 ##2、算法变形： （1）long类型最大值是9,223,372,036,854,775,807（2^63 -1），即19位十进制数。取前13位作为毫秒数，1位作为毫秒内序列号，2位作为机器编号，3位作为数据库表尾号。这个算法单机每毫秒内理论最多可以生产10个id(每秒内理论最多可以生产1w个id)，完全满足业务需求。 （2）结构如下(每部分用 - 分开)： 0000000000`000 - 0 - 00 -000` 加起来正好19位。生成的ID整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞。 ##3、清分系统中的id样例： （1）服务器分配机器编码 （2）现清分系统中，tradeFlowId和summaryTradeFlowId前4位为YYMM，即1611开头的19位数。 新的snowflake id生成器生成的id是1613开头的19位数。如1613024787541981316，1613024787541为当前时间 (毫秒+偏移量1345400000000)，9为序列号，81为机器编码，316为数据库尾号。 （3）现清分系统中，batchid为26开头的10位数。 batchid不涉及数据库尾号，所以可以减少id的位数，保证batchid大于26开头的10位数就可以。生成id如1478484776931281，1478484776931为当前时间，2为序列号，81为机器编码。 #三、代码描述： ##1、加锁实现： ##2、无锁实现： #四、结果分析 ##1、对比与选择 通过对比加锁和无锁两种算法，发现并发数为100-10000的区间中，两者差别甚微。由于twitter选取的是加锁算法，我们也选择经过考证的加锁算法。 ##2、算法特点分析 算法支持单机qps为10000(自己mac上跑的结果)，目前业务情况是单台机器qps为50左右。- 单台机器生成的id为单调递增。- 算法支持的时间截止日期为2262年(取long型最高13位9223372036850作为时间戳)。- 算法支持99台机器。- 针对业务需求，机器号需要额外获取。##3、异常情况 （1）获取机器号出错。 服务启动时获取机器编号，获取失败则服务启动失败。 （2）在获取当前 Timestamp 时, 如果获取到的时间戳比前一个已生成 ID 的 Timestamp 还要小怎么办? 继续获取当前机器的时间, 直到获取到更大的 Timestamp 才能继续工作；- 把 NTP 配置成不会向后调整的模式，也就是说, NTP 纠正时间时, 不会向后回拨机器时钟。 转载来源：基于snowflake算法实现发号器 - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[你的选择是？盘点50多种有用的机器学习和预测API]]></title>
    <url>%2F2017%2Ffdf582dd%2F</url>
    <content type="text"><![CDATA[导读：本文为大家介绍了在机器学习、预测、文本分析和分类、人脸识别、语言翻译等方面，非常有用的50多个API的更新列表。 随着基于人工智能和机器学习的应用程序的发展，我们看到大量应用程序接口（API）的混搭应用。 API是一套用于构建软件应用程序的例程、协议和工具。在这篇文章中，我们删除了列表中从2015年就停止使用的API，还添加了新的API，比如最近来自IBM、谷歌和微软等巨型提供商。 所有的API被分类到新兴的应用程序组中： 人脸和图像识别- 文本分析、NLP、情感分析- 语言翻译- 预测和其他机器学习文本分析、NLP、情感分析 预测和其他机器学习 在每组申请中，我们按字母顺序列出。 API概述基于截至2017年2月3日在其网址上显示的信息。看看这些API投入使用，如果我们错过了一些流行的API，请在下面的评论中提出。 人脸和图像识别 1.Animetrics人脸识别：这个API可以用来检测图片中的人脸，并将其与一组已知的人脸进行匹配。 API还可以添加或删除可搜索的图库中的主题，并添加或删除主题中的一个面部。 2.Betaface：是一个面部识别和检测Web服务。其特点包括多个人脸检测、人脸裁剪、123个面部点检测（22个基本，101个高级），面临非常大的数据库中的验证、识别、相似性搜索。 3.视觉识别：专注于高端计算机视觉解决方案，主要针对物体检测和物体识别软件。一个识别服务，提供眼睛、脸部、车辆、版权和车牌检测的识别服务。 API的主要价值在于可以即时了解对象、用户和行为。 4.Face ++：面部识别和检测服务，提供应用程序中的检测、识别和分析功能。用户可以打电话来训练程序、检测面孔、识别面孔、分组面孔、操作人员、创建人脸集合、创建组和获取信息。 5.FaceMark：是一种能够检测正面照片上68个点的API，以及35个用于配置文件脸部照片的API。 6.FaceRect：是一个功能强大且完全免费的面部检测API。该API在单张照片上查找人脸（正面和侧面）或多张人脸，为找到的每张人脸生成JSON输出。另外，FaceRect可以为每个检测到的脸部（眼睛，鼻子和嘴巴）找到脸部特征。 7.谷歌云视觉API：由像TensorFlow这样的平台提供支持，已经启用了可以学习和预测图像内容的模型。它可以帮助你找到自己喜欢的图像，并快速大规模地获取丰富的注释。它将图像分成数千个类别（例如，“船”，“狮子”，“艾菲尔铁塔”），以相关的情绪检测脸部，并识别出多种语言印刷的文字。 8.新的IBM Watson视觉识别：了解图像的内容 - 视觉概念标记图像，查找人脸，估计年龄和性别，并在集合中查找类似的图像。您也可以通过创建自己的自定义概念来训练服务。 9.Kairos：是一个平台，可让你快速将情绪分析和人脸识别添加到你的应用程序和服务中。 10.微软认知服务 - 计算机视觉：基于云的API可以基于输入和用户选择以不同方式分析视觉内容。例如，基于内容的标签图像、图像分类、检测人脸并返回其坐标、识别特定域的内容、生成内容的描述、识别图像中的文字、标志成人内容。 11.Rekognition：为社交照片应用程序提供面部和场景图像识别优化。 API利用眼睛、嘴巴、脸部和鼻子以及情绪识别和性依赖特征，可以预测性别，年龄和情绪。 12.Skybiometry人脸检测和识别：提供人脸检测和识别服务。新版本的API包括将黑眼镜与清晰镜片区分开来。 文本分析、NLP、情感分析 1．Bitext提供市场上最准确的多语言话题。目前提供了四种语义服务：实体和概念提取、情感分析和文本分类。该API可以使用8种语言。 2.Diffbot分析：为开发人员提供可以识别、分析和提取任何网页上的主要内容和部分的工具。 3.免费自然语言处理服务：是一种免费服务，包括情绪分析、内容提取和语言检测。这是一个流行的API市场。 4.新的谷歌云自然语言API：分析文本的结构和含义，包括情感分析、实体识别和文本注释。 5.IBM Watson Alchemy语言：教导计算机学习如何阅读和进行文本分析（例如，用于将非结构化数据转化为结构化，特别是在社交媒体监控、商业智能、内容推荐、金融交易和有针对性的广告中）。 6.云文本分类：API执行预分类任务，如提取文本，标记化，停止删除和引理。 7.新的微软 Azure文本分析API是一套使用Azure机器学习构建的文本分析Web服务。该API可用于分析非结构化文本，如情感分析，关键短语提取、语言检测和主题检测。不需要训练数据。 8.微软认知服务 - 文本分析：从文本中检测情感、关键短语、主题和语言。与此API相同的其他API（语言的认知服务）包括必应拼写检查、语言理解、语言分析、网络语言模型。 9.nlpTools：是一个简单的JSON over HTTP RESTful Web服务，用于自然语言处理。它对在线新闻媒体的情绪分析和文本分类进行了解码。 10.新的Geneea：可以对所提供的原始文本，从给定的URL中提取的文本或直接提供的文档执行分析（自然语言处理）。 11.来自谷歌 Research的新成员使用机器学习模型来评估评论对于对话可能产生的影响，并标出令人反感的评论。 12.语义生物医学标记：具有内置的能力，使用文本分析识别133种生物医学实体类型，并将其语义链接到知识库系统中。 13．汤森路透Open Calais：使用自然语言处理、机器学习和其他方法，分类与链接文档与实体（人员，地点，组织等）、实体（人“x”为公司“y”工作）和事件（“z”人在x日被任命为公司董事长）。 14.Yactraq Speech2Topics是一项云端服务，通过语音识别和自然语言处理，将音频视频内容转换为主题元数据。 语言翻译 1.谷歌云翻译：可以动态翻译成千上万的语言对之间的文本。 API让网站和程序以编程方式与翻译服务集成。 2.新的IBM Watson语言翻译器：将文本从一种语言翻译成另一种语言。该服务提供了多个领域特定的模型，你可以根据你独特的术语和语言进行自定义。例如，客户可以用他们自己的语言进行沟通。 3.LangId：一种快速检索任何语言信息的方法，不需要指定语言（即可以识别需要分析的文本以哪种语言编写）。 4.新的微软认知服务 - 翻译：自动检测在翻译之前发送的文本的语言。它为所支持的9种语言中的任何一种语言进行语音翻译，并对60种支持的语言中的任何一种进行文本翻译。 MotaWord：是一个快速的人工翻译平台。它提供超过70种语言的翻译。 API还可以让开发人员获得每个翻译的引用，提交翻译项目以及文档和样式的指南，跟踪翻译项目的进度并实时获取活动提要。 WritePath翻译：API允许开发人员访问和集成WritePath与其他应用程序的功能。操作可以通过这个API来完成：检索单词数量，发布翻译文档以及检索已翻译的文档和文本。 预测和其他机器学习 1.亚马逊机器学习：查找数据模式。此API的示例用途是用于欺诈检测、预测需求、定向营销和点击预测。 2.BigML：为云托管的机器学习和数据分析提供服务。用户可以建立一个数据源，并创建一个模型，通过标准的HTTP来预测使用基本的监督和无监督的机器学习任务进行预测。 3.Ersatz：一个使用GPU支持的深度神经网络即服务的基于网络的预测程序。在Ersatz中，训练了一组不同的神经网络模型（集成方法），有时多达20种。 4.谷歌云预测：提供了一个RESTful API来构建机器学习模型。这些工具可以帮助分析数据，为你的应用程序添加各种功能，如客户情绪分析、垃圾邮件检测、推荐系统等。 5.全新的Google云语音API：使用快速而准确的语音识别功能，将音频从麦克风或文件转换为超过80种语言和变体的文本 6.Guesswork.co：为电子商务网站提供产品推荐引擎。猜测使用在谷歌预测 API之上运行的语义规则引擎准确地预测客户意图。 Hu&#58;toma：帮助世界各地的开发人员构建并通过提供免费访问专有平台提供工具和渠道来创建和分享会话AI的深度学习。 8.新的IBM Watson对话：构建了解自然语言的聊天机器人，并将其部署在任何设备上的消息传递平台和网站上。与此API相同的其他API（语言的认知服务）包括对话框、自然语言分类器、个性的见解和音调分析仪。 9.新的IBM Watson演讲：将语音转换为文本和文本转换为语音（例如，在联络中心转录通话或创建语音控制应用程序）。 10.新的IBM Watson 数据透视：这个集合包括三个API：AlchemyData新闻、发现和权衡分析。 AlchemyData提供充满自然语言处理的新闻和博客内容，以便进行高度针对性的搜索和趋势分析。权衡分析有助于人们在平衡多个目标时作出决定。 11.IBM Watson检索和排名：开发人员可以将其数据加载到服务中，使用已知的相关结果来训练机器学习模型（Rank）。服务输出包括相关文档和元数据的列表。例如，联络中心代理也可以快速找到答案，以改善平均呼叫处理时间。 12.Imagga：提供API自动分配标签到你的图像使你的图像可发现。它基于图像识别平台即服务。 13.indico：提供文本分析（例如，情绪分析、推特参与、情绪）和图像分析（例如，面部情绪、面部定位）。指示API可以自由使用，不需要训练数据。 14．Microsoft Azure认知服务API：正在取代Azure机器学习推荐服务，该服务基于预测分析提供解决方案。它为客户提供个性化的产品推荐，并改善销售。新版本具有新的功能，如批处理支持、更好的API浏览器、更清洁的API表面、更一致的注册/计费体验等。 15.新的微软Azure异常检测API：使用数值检测时间序列数据中的异常。 16.新的微软认知服务 - QnA Maker：将信息提炼成对话，易于浏览的答案。同一组中的其他API（知识认知服务）包括学术知识、实体链接、知识探索、建议。 17.新的微软认知服务 - 说话人识别：让你的应用程序能够知道谁在说话。与此API相同的其他API（语音认知服务）包括Bing Speech（将语音转换为文本并再次转换并理解其意图）和Custom Recognition（自定义识别）。 18.新的MLJAR提供原型、开发和部署模式识别算法的服务。 19.NuPIC：是一个用Python / C ++编写的开源项目，实现Numenta的皮质学习算法，由NuPIC社区维护。 API允许开发人员使用原始算法，将多个区域（包括层次结构）串联起来，并利用其他平台功能。 20.PredicSis：为大数据提供强大的洞察力，并通过预测分析提高营销绩效。 21.PredictionIO：是一个基于Apache 2.0许可证发布的Apache Spark，HBase和Spray上构建的开源的机器学习服务器。示例API方法包括创建和管理用户和用户记录、检索项目和内容以及基于用户创建和管理建议。 22.RxNLP - 集群句子和简短文本：文本挖掘和自然语言处理服务。其中一个API，群集句子API可以将句子（例如来自多个新闻文章的句子）或短文本（例如来自Twitter或Facebook状态更新的文章）分组为逻辑组。 23.新的Recombee：通过RESTful API提供使用数据挖掘、查询语言和机器学习算法（例如协同过滤和基于内容的推荐）的服务。 24.Sightcorp F.A.C.E .&#58;一个web服务，允许第三方应用程序更好地了解用户的行为，并检索相关的面部分析，如年龄、性别、面部表情、头部姿势或种族。 其他API集合：Mashape Blog＆Programmable Web 错过了你最喜欢的API吗？可以在评论中留下你喜欢的一种分享给更多的人！ 转载来源：你的选择是？盘点50多种有用的机器学习和预测API]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>云计算</tag>
        <tag>Azure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最全深度学习资源集合（Github：Awesome Deep Learning）]]></title>
    <url>%2F2017%2F932c2179%2F</url>
    <content type="text"><![CDATA[偶然在github上看到Awesome Deep Learning项目，故分享一下。其中涉及深度学习的免费在线书籍、课程、视频及讲义、论文、教程、网站、数据集、框架和其他资源，包罗万象，非常值得学习。 其中研究人员部分篇幅所限本文未整理进来。另外上面的GIF录制于MIT自动驾驶课程（MIT 6.S094&#58; Deep Learning for Self-Driving Cars） PS：github上取名“awesome”的一般都非常牛逼，此项目亦然！ 以下整理至： Awesome Deep Learninghttps&#58;//github.com/ChristosChristofidis/awesome-deep-learning 由于无法限制站外链接，且排版等原因，可以在上述原网址里查看。 免费在线数据、课程 视频和讲义 论文 教程 网站 数据集 框架 其他资源 转载来源：最全深度学习资源集合（Github：Awesome Deep Learning）]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>GitHub</tag>
        <tag>机器学习</tag>
        <tag>技术</tag>
        <tag>麻省理工学院</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[站酷 (ZCOOL) - 设计师互动平台 - 打开站酷，发现更好的设计！]]></title>
    <url>%2F2017%2F6826055b%2F</url>
    <content type="text"><![CDATA[站酷 (ZCOOL) - 设计师互动平台 - 打开站酷，发现更好的设计！ 转载来源：站酷 (ZCOOL) - 设计师互动平台 - 打开站酷，发现更好的设计！]]></content>
  </entry>
  <entry>
    <title><![CDATA[Google发布自然语言处理解析器SLING，免除模块化分析级联效应产生的缺陷]]></title>
    <url>%2F2017%2F9b60799c%2F</url>
    <content type="text"><![CDATA[雷锋网 AI科技评论消息，日前，Google发布自然语言框架语义解析器SLING，它能以语义框架图（semantic frame graph）的形式，将自然语言文本直接解析为文本语义表示。这一系统避免了级联效应，另外还减少了不必要的计算开销。 详细消息雷锋网 AI科技评论编译整理如下： 直到最近，大多数实际的自然语言理解(NLU)系统都采用的是从词性标签和依存句法分析（dependency parsing）到计算输入文本的语义表示的分析。虽然这使得不同分析阶段易于模块化，但前期的错误会在后期和最终表示上产生层叠效应，中间阶段的输出也可能会与这一阶段本身并不相关。 例如，一个典型的NLP系统可能在早期执行依存句法分析的任务，在结束阶段时执行共指解析（coreference resolution）任务，早期依存句法分析阶段出现的任何错误都会产生级联效应，影响共指解析的输出。 今天我们发布SLING实验系统，它能以语义框架图（semantic frame graph）的形式，将自然语言文本直接解析为文本语义表示。 输出框架图能直接捕获用户感兴趣的语义标注（semantic annotation），因为没有运行任何中间阶段，所以避免了上述那种管道系统的缺陷，另外还减少了不必要的计算开销。 SLING使用具有特殊用途的循环神经网络模型，通过框架图上的增量编辑操作（incremental editing operation）来计算输入文本的输出表示。框架图足够灵活，可以捕获大家感兴趣的许多语义任务(下面有更多介绍)。SLING中的分析器（parser）只使用输入词来进行训练，不需要额外再生成标注(例如依存句法分析)。 SLING通过提供高效的、可扩展的框架存储实现（frame store implementation）和JIT编译器来生成高效的代码来执行循环神经网络，从而在推理（inference）时能快速进行句法分析。 尽管SLING还处于实验阶段，但得益于高效的框架存储和神经网络编译器，它在台式机CPU上能实现超过2500符号/秒的解析速度。 SLING使用C++，目前可以在GitHub上下载。这个系统在技术报告中有详细描述。 框架语义句法分析（Frame Semantic Parsing） 框架语义表示文本的含义（例如一句话），是一套正规表述。每个正规表述都被称为一个框架，可以被看作是知识或语义的一个单元，还包含与与它相关的概念或其他框架的相互作用。 SLING将框架组织成属性槽（slot）列表，其中每个属性槽都有对应的名称(角色)和值（可能是literal或是到另一个框架的链接）。 下面是一个例句&#58; “很多人都宣称自己预测到了黑色星期一。”（Many people now claim to have predicted Black Monday） 下图是SLING识别提到的实体(例如人物、地点或事件)、度量(例如日期或距离)和其他概念(例如动词)，并将它们放置在正确的语义角色中的说明。 上面的例子相当简单，框架图的功能强大到可以模拟各种复杂的语义标注任务。对于初学者来说，这种框架可以非常方便地将语言的内外部信息类型(例如知识库)结合起来。这可以用于处理复杂的语言理解问题，例如引用、隐喻、转喻等。这些任务的框架图只在框架类型、角色和链接约束条件上有所不同。 SLING SLING通过优化语义框架来训练循环神经网络。网络隐藏层中学到的内部表示取代了在前面那种管道系统中的手工特性组合和中间表示。 解码器使用伴随反复出现的特征一起的表示，来计算用于框架图更新的一系列过渡，以获得输入语句的预期框架语义表示。在SLING中用TensorFlow和DRAGNN来训练模型。 下面的动图展示了使用过滤操作将框架和角色逐渐添加到框架图中的构建过程。 正如一开始讨论的那个简单例句，SLING使用ARG1角色将动词和事件框架连接起来，表示事件框架是被预测的概念。 这个过渡系统的一个关键层面是，有一个很小的固定大小的框架缓冲区，它代表了最近被唤起或修改的框架，用橙色方框标记。这个缓冲区会捕捉到我们倾向于记住的最近被唤起、提及或强化的知识的直觉。如果一个框架不再使用，那么当新的框架出现时，它最终会从这个缓冲区中被清除掉。我们发现这种简单的机制在捕捉大量框架间链接的片段时非常有效。 下一步 上面所描述的实验仅仅是对诸如知识提取、解析复杂引用和对话理解等语义句法分析研究任务的启动研究。 在Github上发布的SLING中有上述任务的预训练模型，还有一些示例和方法，大家可以在提供的综合数据或自己的数据上来训练解析器。希望SLING能对大家有所帮助有用，我们期待着在其他语义句法分析任务上应用和扩展SLING。 Github地址：https&#58;//github.com/google/sling Via：Google Research Blog 雷锋网 AI科技评论编译整理。 转载来源：Google发布自然语言处理解析器SLING，免除模块化分析级联效应产生的缺陷]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>人工智能</tag>
        <tag>编译器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设计一款多场景分布式发号器（Vesta）-极客]]></title>
    <url>%2F2017%2F1fc4384e%2F</url>
    <content type="text"><![CDATA[如何设计一款多场景分布式发号器（Vesta）-极客 转载来源：如何设计一款多场景分布式发号器（Vesta）-极客]]></content>
  </entry>
  <entry>
    <title><![CDATA[CNN在NLP领域的实践（1） 文本分类 - CSDN博客]]></title>
    <url>%2F2017%2F128c950f%2F</url>
    <content type="text"><![CDATA[众所周知，卷积神经网络（CNN）在计算机视觉领域取得了极大的进展，但是除此之外CNN也逐渐在自然语言处理（NLP）领域攻城略地。本文主要以文本分类为例，介绍卷积神经网络在NLP领域的一个基本使用方法，由于本人是初学者，而且为了避免东施效颦，所以下面的理论介绍更多采用非数学化且较为通俗的方式解释。 0.文本分类 所谓文本分类，就是使用计算机将一篇文本分为a类或者b类，属于分类问题的一种，同时也是NLP中较为常见的任务。 一.词向量 提到深度学习在NLP中的应用就不得不提到词向量，词向量（Distributed Representation）在国内也经常被翻译为词嵌入等等，关于词向量的介绍的文章已经有很多，比如这位大神的博客：http&amp;#58;//blog.csdn.net/zhoubl668/article/details/23271225 本文则用较为通俗的语言帮助大家了解词向量。 所谓词向量就是通过神经网络来训练语言模型，并在训练过程钟生成一组向量，这组向量将每个词表示为一个n维向量。举个例子，假如我们要将&quot;北京&quot;表示为一个2维向量，可能的一种结果如 北京=（1.1,2.2）,在这里北京这个词就被表示为一个2维的向量。但是除了将词表示为向量以外，词向量还要保证语义相近的词在词向量表示方法中的空间距离应当是相近的。比如 &apos;中国&apos; - &apos;北京&apos; ≈ &apos;英国&apos; - &apos;伦敦&apos; 。上述条件可在下列词向量分布时满足，&apos;北京&apos;=（1.1,2.2），&apos;中国&apos;=（1.2,2.3） ，’伦敦’=（1.5,2.4），’英国’=(1.6,2.5)。 一般训练词向量可以使用google开源word2vec程序。 二.**卷积神经网络与词向量的结合** 有关CNN的博客非常之多，如果不了解CNN的基本概念可以参见这位大神的博客如下：http&#58;//blog.csdn.net/zhoubl668/article/details/23271225 这里就不在赘述。 通常卷积神经网络都是用来处理类似于图像这样的二维（不考虑rgb）矩阵，比如一张图片通常都可以表示为一个2维数组比如255*255，这就表示该图片是一张255像素宽，255像素高的图片。那么如何将CNN应用到文本中呢，答案就是词向量。 我们刚刚介绍了词向量的概念，下面介绍下如何将文本通过词向量的方式转换成一个类图像类型的格式。一般来说一篇文本可以被视为一个词汇序列的组合，比如有篇文本内容是 ‘书写代码，改变世界’。可以将其转换为（’书写’，’代码’，’改变’，’世界’）这样一个文本序列，显然这个序列是一个一维的向量，不能直接使用cnn进行处理。 但是如果使用词向量的方式将其展开，假设在某词向量钟 ‘书写’ =（1.1,2.1），’代码’ = （1.5,2.9），’改变’ = （2.7,3.1） ，’世界’ = （2.9,3.5）,那么（’书写’，’代码’，’改变’，’世界’）这个序列就可以改写成（（1.1,2.1），（1.5,2.9），（2.7,3.1），（2.9,3.5）），显然原先的文本序列是41的向量，改写之后的文本可以表示为一个42的矩阵。 推而广之任何以文本序列都可以表示为m*d的数组，m维文本序列的词数，d维词向量的维数。 三.**用于文本分类的神经网络结构设计** **本文前面介绍了词向量、卷积神经网络等概念，并提出可以将文本转换成一个由词序列和词向量嵌套而成的二维矩阵，并通过CNN对其进行处理，下面以文本分类任务为例，举例说明如何设计该神经网络的样式。 3.1 文本预处理部分的流程 这部分主要是分3步，共4种状态。1.将原始文本分词并转换成以词的序列 2.将词序列转换成以词编号（每个词表中的词都有唯一编号）为元素的序列 3.将词的编号序列中的每个元素（某个词）展开为词向量的形式。下面通过一张图（本人手画简图。。。。囧）来表示这个过程，如下图所示： 3.2 神经网络模块的设计 本文关于神经网络设计的思想来自于以下博文： http&#58;//www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/ 由于该文章是纯英文的，某些读者可能还不习惯阅读这类文献，我下面结合一张神经网络设计图，来说明本文中所使用的神经网络，具体设计图（又是手画图，囧）如下： 简要介绍下上面的图，第一层数据输入层，将文本序列展开成词向量的序列，之后连接 卷积层、激活层、池化层 ，这里的卷积层因为卷积窗口大小不同，平行放置了三个卷积层，垂直方向则放置了三重（卷积层、激活层、池化层的组合）。之后连接全脸阶层和激活层，激活层采用softmax并输出 该文本属于某类的概率。 3.3 编程实现所需要的框架和数据集等 3.3.1 框架：本文采用keras框架来编写神经网络，关于keras的介绍请参见莫言大神翻译的keras中文文档：http&amp;#58;//keras-cn.readthedocs.io/en/latest/ 。 3.3.2 数据集：文本训练集来自20_newsgroup,该数据集包括20种新闻文本，下载地址如下：http&amp;#58;//www.qwone.com/~jason/20Newsgroups/ 3.3.3 词向量：虽然keras框架已经有embedding层，但是本文采用glove词向量作为预训练的词向量，glove的介绍和下载地址如下（打开会比较慢）： http&#58;//nlp.stanford.edu/projects/glove/ 3.4 代码和相应的注释 在3.2部分已经通过一张图介绍了神经网络的设计部分，但是考虑到不够直观，这里还是把所使用的代码，罗列如下，采用keras编程，关键部分都已经罗列注释，代码有部分是来源自keras文档 中的example目录下的：pretrained_word_embeddings.py,但是该程序我实际运行时出现了无法训练的bug，所以做了诸多改变，最主要的是我把原文中的激活层从relu改成了tanh，整体的设计结构也有了根本性的改变。对keras原始demo有兴趣的可以参见： http&#58;//keras-cn.readthedocs.io/en/latest/blog/word_embedding/ 下面就是本文中所使用的文本分类代码： 四.**总结** 本文描述了如何使用深度学习和keras框架构建一个文本分类器的全过程，并给出了相应的代码实现，为了方便大家使用，下面给出本文代码的下载地址一（简单版）： https&#58;//github.com/894939677/deeplearning_by_diye/blob/master/pretrain_text_class_by_diye.py 下面给出本文代码的下载地址二（完整版）： https&#58;//github.com/894939677/deeplearning_by_diye/blob/master/pre_merge_3.py 五.后记 本文描述的是使用类似于googlenet的网络结构，实际上也可以使用类似与resnet的网络结构来做这个事情 转载来源：CNN在NLP领域的实践（1） 文本分类 - CSDN博客]]></content>
  </entry>
  <entry>
    <title><![CDATA[谷歌开源「Tangent」：一个用于自动微分的源到源Python库]]></title>
    <url>%2F2017%2F8fb17f0e%2F</url>
    <content type="text"><![CDATA[选自Google Research Blog 机器之心编译 参与：黄小天、刘晓坤 近日，谷歌在其官方博客上开源了「Tangent」，一个用于自动微分的源到源 Python 库；它通过 Python 函数 f 生成新函数，来计算 f 的梯度，从而实现更好的梯度计算可视化，帮助用户更容易地编辑和调试梯度；本文还扼要概述了 Tangent API，包括如何使用 Tangent 在 Python 中生成易于理解、调试和修改的梯度代码。 Tangent 是一个免费、开源的新 Python 库，用于自动微分。和目前已有的机器学习库不同，Tangent 是一个源到源（source-to-source）的系统，利用 Python 函数 f 生成一个新的 Python 函数，来计算 f 的梯度。这为用户提供了更好的梯度计算可视化，使用户可以容易地对梯度进行编辑和调试。Tangent 在调试和设计机器学习模型上有如下特征： 易于调试反向传播过程- 快速编辑和调试梯度- 正向模式（Forward mode）自动微分- 高效的 Hessian 向量内积（Hessian-vector products）- 代码优化快速编辑和调试梯度 高效的 Hessian 向量内积（Hessian-vector products） 本文对 Tangent API 进行了概述，包括如何使用 Tangent 在 Python 中生成易于理解、调试和修改的梯度代码。 神经网络（NN）使机器学习模型处理图像、视频、音频和文本的能力出现巨大进步。训练神经网络在这些任务上获得高性能的基本抽象概念是一个有着 30 年历史的思想——「反向模式自动微分」（也叫做反向传播），它由神经网络中的两个传播过程组成：首先运行「前向传播」计算每一个节点的输出，然后运行「反向传播」计算一系列导数以决定权重的更新率，从而提高模型的准确性。 训练神经网络和在新型架构上做研究需要准确、高效和简易地计算这些导数。当模型训练结果不好时，或者尝试建立一些尚未理解的东西时，调试这些导数的能力非常必要。自动微分，或简称为「autodiff」，是一种计算表征一些数学函数的计算机程序的导数的技术，并可以在几乎所有的机器学习库中实现。 目前已有的库通过追踪程序的执行（在运行时，比如 TF Eager、PyTorch 和 Autograd）或建立动态数据流图然后对图微分（预编，比如 TensorFlow），实现自动微分。与之相反，Tangent 能自主在 Python 源代码上进行预编的自动微分，并生成 Python 源代码作为其输出。 因此，你可以把自动微分代码当做程序的余下部分进行阅读。对于那些不仅想在 Python 编写模型，还希望在不牺牲速度和灵活性的前提下阅读和调试自动生成导数的代码的研究者和学生，Tangent 是很有用的。 用 Tangent 编写的模型易于检查和调试，而不需要特殊的工具或间接的方式。Tangent 能提供其它 Python 机器学习库没有的额外自动微分的特征，具有强大的性能，并和 TensorFlow 以及 Numpy 兼容。 Python 代码的自动微分 我们如何自动生成纯 Python 代码的导数？数学函数比如 tf.exp 或 tf.log 含有可以用来构建反向传播的导数。相似地，句法片段（比如子程序、条件和循环）也有反向传播版本。Tangent 有办法为每个 Python 句法片段生成生成导数代码，同时调用很多的 NumPy 和 TensorFlow 函数。 Tangent 有一个单一函数 API： 下面的动图展示了如何一个 Python 函数上调用 tangent.grad： 如果你想要打印出导数，你可以运行： 在 hood 之下，tangent.grad 首先抓取你传递给它的 Python 函数源代码。Tangent 有一个 Python 句法导数和 TensorFlow Eager 函数的大型方法库。tangent.grad 函数逆序运行你的代码，查找匹配的反向传播方法，并将其添加到导数函数的尾部。这一逆序处理技术被称之为反向模式自动微分（reverse-mode automatic differentiation）。 df 函数只适用于标量（非数组）输入。Tangent 同样支持 使用 TensorFlow Eager 函数处理数字数组- 子程序- 控制流子程序 尽管我们从 TensorFlow Eager 支持开始，Tangent 并没有受限于任何数字库，我们非常欢迎添加 PyTorch 或 MXNet 导数方法的请求。 下一步 Tangent 现在是开源的（github.com/google/tangent），但仍处于试验阶段，难免存在一些 bug，如果你能在 GitHub 上指出，我们将很快修复。 我们正致力于在 Tangent 支持 Python 语言的更多属性（比如闭包、内嵌函数定义、类、更多的 Numpy 和 TensorFlow 函数），同样计划在未来添加更多高级的自动微分和编译功能，比如内存与计算之间的自动博弈，更主动的优化以及λ升降。最后，我们非常期望能与社区一起开发 Tangent。 转载来源：谷歌开源「Tangent」：一个用于自动微分的源到源Python库]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>GitHub</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么XGBoost在机器学习竞赛中表现如此卓越？]]></title>
    <url>%2F2017%2Fe18ce50b%2F</url>
    <content type="text"><![CDATA[挪威科技大学 Didrik Nielsen 的硕士论文《使用 XGBoost 的树提升：为什么 XGBoost 能赢得「每一场」机器学习竞赛？（Tree Boosting With XGBoost - Why Does XGBoost Win “Every” Machine Learning Competition?）》研究分析了 XGBoost 与传统 MART 的不同之处以及在机器学习竞赛上的优势。机器之心技术分析师对这篇长达 110 页的论文进行了解读，提炼出了其中的要点和核心思想，汇成此篇。本文原文发表在机器之心英文官网上。 论文原文：https&#58;//brage.bibsys.no/xmlui/bitstream/handle/11250/2433761/16128_FULLTEXT.pdf- 解读文章英文原文：https&#58;//syncedreview.com/2017/10/22/tree-boosting-with-xgboost-why-does-xgboost-win-every-machine-learning-competition/解读文章英文原文：https&#58;//syncedreview.com/2017/10/22/tree-boosting-with-xgboost-why-does-xgboost-win-every-machine-learning-competition/ 引言 tree boosting（树提升）已经在实践中证明可以有效地用于分类和回归任务的预测挖掘。 之前很多年来，人们所选择的树提升算法一直都是 MART（multiple additive regression tree/多重累加回归树）。但从 2015 年开始，一种新的且总是获胜的算法浮出了水面：XGBoost。这种算法重新实现了树提升，并在 Kaggle 和其它数据科学竞赛中屡获佳绩，因此受到了人们的欢迎。 在《Tree Boosting With XGBoost - Why Does XGBoost Win “Every” Machine Learning Competition?》这篇论文中，来自挪威科技大学的 Didrik Nielsen 研究调查了： XGBoost 与传统 MART 的不同之处1. XGBoost 能赢得「每一场」机器学习竞赛的原因XGBoost 能赢得「每一场」机器学习竞赛的原因 这篇论文分成三大部分： 回顾统计学习的一些核心概念1. 介绍 boosting 并以函数空间中数值优化的方式对其进行解释；进一步讨论更多树方法以及树提升方法的核心元素1. 比较 MART 和 XGBoost 所实现的树提升算法的性质；解释 XGBoost 受欢迎的原因介绍 boosting 并以函数空间中数值优化的方式对其进行解释；进一步讨论更多树方法以及树提升方法的核心元素 统计学习的基本概念 这篇论文首先介绍了监督学习任务并讨论了模型选择技术。 机器学习算法的目标是减少预期的泛化误差，这也被称为风险（risk）。如果我们知道真实的分布 P(x,y)，那么风险的最小化就是一个可以通过优化算法解决的最优化任务。但是，我们并不知道真实分布，只是有一个用于训练的样本集而已。我们需要将其转换成一个优化问题，即最小化在训练集上的预期误差。因此，由训练集所定义的经验分布会替代真实分布。上述观点可以表示成下面的统计学公式： 其中 是模型的真实风险 R(f) 的经验估计。L(.) 是一个损失函数，比如平方误差损失函数（这是回归任务常用的损失函数），其它损失函数可以在这里找到：http&#58;//www.cs.cornell.edu/courses/cs4780/2017sp/lectures/lecturenote10.html。n 是样本的数量。 当 n 足够大时，我们有： ERM（经验风险最小化）是一种依赖于经验风险的最小化的归纳原理（Vapnik, 1999）。经验风险最小化运算 f hat 是目标函数的经验近似，定义为： 其中 F 属于某个函数类，并被称为某个模型类（model class），比如常数、线性方法、局部回归方法（k-最近邻、核回归）、样条函数等。ERM 是从函数集 F 中选择最优函数 f hat 的标准。 这个模型类和 ERM 原理可以将学习问题转变成优化问题。模型类可以被看作是候选的解决方案函数，而 ERM 则为我们提供了选择最小化函数的标准。 针对优化问题的方法有很多，其中两种主要方法是梯度下降法和牛顿法；MART 和 XGBoost 分别使用了这两种方法。 这篇论文也总结了常见的学习方法： 常数 线性方法 局部最优方法 基函数扩展：显式非线性项、样条、核方法等 自适应基函数模型：GAM（广义相加模型）、神经网络、树模型、boosting 另一个机器学习概念是模型选择（model selection），这要考虑不同的学习方法和它们的超参数。首要的问题一直都是：增加模型的复杂度是否更好？而答案也总是与模型自身的泛化性能有关。如下图 1 所示，我们也许可以在模型更加复杂的同时得到更好的表现（避免欠拟合），但我们也会失去泛化性能（过拟合）： 图 1：泛化性能 vs 训练误差 为平方损失使用预期条件风险的经典的偏置-方差分解（bias-variance decomposition），我们可以观察风险相对于复杂度的变化： 图 2：预期风险 vs 方差 vs 偏置 为此通常使用的一种技术是正则化（regularization）。通过隐式和显式地考虑数据的拟合性和不完善性，正则化这种技术可以控制拟合的方差。它也有助于模型具备更好的泛化性能。 不同的模型类测量复杂度的方法也不一样。LASSO 和 Ridge（Tikhonov regularization）是两种常用于线性回归的测量方法。我们可以将约束（子集化、步进）或惩罚（LASSO、Ridge）直接应用于复杂度测量。 理解 Boosting、树方法和树提升 Boosting boosting 是一种使用多个更简单的模型来拟合数据的学习算法，它所用的这些更简单的模型也被称为基本学习器（base learner）或弱学习器（weak learner）。其学习的方法是使用参数设置一样或稍有不同的基本学习器来自适应地拟合数据。 Freund 和 Schapire (1996) 带来了第一个发展：AdaBoost。实际上 AdaBoost 是最小化指数损失函数，并迭代式地在加权的数据上训练弱学习器。研究者也提出过最小化对数损失的二阶近似的新型 boosting 算法：LogitBoost。 Breiman (1997a,b 1998) 最早提出可以将 boosting 算法用作函数空间中的数值优化技术。这个想法使得 boosting 技术也可被用于回归问题。这篇论文讨论了两种主要的数值优化方法：梯度提升和牛顿提升（也被称为二阶梯度提升或 Hessian boosting，因为其中应用了 Hessian 矩阵）。下面，让我们一步一步了解 boosting 算法。 boosting 拟合同一类的集成模型（ensemble model）： 其可以被写成自适应基函数模型： 其中 f_0(x)=θ_0 且 f_m(x)=θ_m*Φ_m(x)，m=1,…,M，Φm 是按顺序累加的基本函数，可用于提升当前模型的拟合度。 因此，大多数 boosting 算法都可以看作是在每次迭代时或准确或近似地求解 所以，AdaBoost 就是为指数损失函数求解上述等式，其约束条件为：Φm 是 A=&amp;#123-1,1&amp;#125 的分类器。而梯度提升或牛顿提升则是为任意合适的损失函数近似求解上述等式。 梯度提升和牛顿提升的算法如下： 是梯度 是使用数据学习到的弱学习器 是经验 Hessian- 梯度提升：梯度提升： 是由线搜索（line search）确定的步长- 牛顿提升：牛顿提升： 最常用的基本学习器是回归树（比如 CART），以及分量形式的线性模型（component-wise linear model）或分量形式的平滑样条（component-wise smoothing spline）。基本学习器的原则是要简单，即有很高的偏置，但方差很低。 boosting 方法中的超参数有： 迭代次数 M：M 越大，过拟合的可能性就越大，因此需要验证集或交叉验证集。1. 学习率 η ：降低学习率往往会改善泛化性能，但同时也会让 M 增大，如下图所示。学习率 η ：降低学习率往往会改善泛化性能，但同时也会让 M 增大，如下图所示。 在 Boston Housing 数据集上的不同学习率的样本外（out-of-sample）RMSE 树方法 树模型是简单和可解释的模型。它们的预测能力确实有限，但将多个树模型组合到一起（比如 bagged trees、随机森林或在 boosting 中），它们就可以变成一种强大的预测模型。 我们可以将树模型看作是将特征空间分割成几个不同的矩形和非重叠区域集合，然后它可以拟合一些简单的模型。下图给出了使用 Boston Housing 数据得到的可视化结果： 终端节点的数量和树的深度可以看作是树模型的复杂度度量。为了泛化这种模型，我们可以在复杂度度量上轻松地应用一个复杂度限制，或在终端节点的数量或叶权重的惩罚项上应用一个惩罚（XGBoost 使用的这种方法）。 因为学习这种树的结构是 NP 不完全的，所以学习算法往往会计算出一个近似的解。这方面有很多不同的学习算法，比如 CART（分类和回归树）、C4.5 和 CHAID。这篇论文描述了 CART，因为 MART 使用的 CART，XGBoost 也实现了一种与 CART 相关的树模型。 CART 以一种自上而下的方式生长树。通过考虑平行于坐标轴的每次分割，CART 可以选择最小化目标的分割。在第二步中，CART 会考虑每个区域内每次平行的分割。在这次迭代结束时，最好的分割会选出。CART 会重复所有这些步骤，直到达到停止标准。 给定一个区域 Rj，学习其权重 wj 通常很简单。令 Ij 表示属于区域 Rj 的索引的集合，即 xi∈Rj，其中 i∈Ij。 其权重是这样估计的： 对于一个树模型 f_hat，经验风险为： 其中我们令 L_j hat 表示节点 j 处的累积损失。在学习过程中，当前树模型用 f_before hat 和 f_after hat 表示。 我们可以计算所考虑的分割所带来的增益： 对于每一次分割，每个可能节点的每个可能分割都会计算这种增益，再取其中最大的增益。 现在让我们看看缺失值。CART 会使用替代变量（surrogate variable）来处理缺失值，即对于每个预测器，我们仅使用非缺失数据来寻找分割，然后再基于主分割寻找替代预测因子，从而模拟该分割。比如，假设在给定的模型中，CART 根据家庭收入分割数据。如果一个收入值不可用，那么 CART 可能会选择教育水平作为很好的替代。 但 XGBoost 是通过学习默认方向来处理缺失值。XGBoost 会在内部自动学习当某个值缺失时，最好的方向是什么。这可以被等价地看作是根据训练损失的减少量而自动「学习」缺失值的最佳插补值。 根据类别预测器，我们可以以两种方式处理它们：分组类别或独立类别。CART 处理的是分组类别，而 XGBoost 需要独立类别（one-hot 编码）。 这篇论文以列表的形式总结了树模型的优缺点： 优点（Hastie et al., 2009; Murphy, 2012）： •容易解释 •可以相对快地构建 •可以自然地处理连续和分类数据 •可以自然地处理缺失数据 •对输入中的异常值是稳健的 •在输入单调变换时是不变的 •会执行隐式的变量选择 •可以得到数据中的非线性关系 •可以得到输入之间的高阶交互 •能很好地扩展到大型数据集 缺点（Hastie et al., 2009; Kuhn and Johnson, 2013; Wei-Yin Loh, 1997; Strobl et al., 2006）： •往往会选择具有更高数量的不同值的预测器 •当预测器具有很多类别时，可能会过拟合 •不稳定，有很好的方差 •缺乏平滑 •难以获取叠加结构 •预测性能往往有限 树提升 在上述发展的基础上，现在我们将 boosting 算法与基本学习器树方法结合起来。 提升后的树模型可以看作是自适应基函数模型，其中的基函数是回归树： 提升树模型（boosting tree model）是多个树 fm 的和，所以也被称为树集成（tree ensemble）或叠加树模型（additive tree model）。因此它比单个树模型更加平滑，如下图所示： 拟合 Boston Housing 数据的叠加树模型的可视化 在提升树模型上实现正则化的方法有很多： 在基函数扩展上进行正则化 在各个树模型上进行正则化 随机化 一般来说，提升树往往使用很浅的回归树，即仅有少数终端节点的回归树。相对于更深度的树，这样的方差较低，但偏置更高。这可以通过应用复杂度约束来完成。 XGBoost 相对于 MART 的优势之一是复杂度的惩罚，这对叠加树模型而言并不常见。目标函数的惩罚项可以写成： 其中第一项是每个单个树的终端节点的数量，第二项是在该项权重上的 L2 正则化，最后一项是在该项权重上的 L1 正则化。 Friedman(2002) 最早引入了随机化，这是通过随机梯度下降实现的，其中包括在每次迭代时进行行子采样（row subsampling）。随机化有助于提升泛化性能。子采样的方法有两种：行子采样与列子采样（column subsampling）。MART 仅包含行子采样（没有替代），而 XGBoost 包含了行子采样和列子采样两种。 正如前面讨论的那样，MART 和 XGBoost 使用了两种不同的 boosting 算法来拟合叠加树模型，分别被称为 GTB（梯度树提升）和 NTB（牛顿树提升）。这两种算法都是要在每一次迭代 m 最小化： 其基函数是树： 其一般步骤包含 3 个阶段： 确定一个固定的候选树结构的叶权重 ； 使用前一阶段确定的权重，提出不同的树结构，由此确定树结构和区域； 一旦树结构确定，每个终端节点中的最终叶权重（其中 j=1,..,T）也就确定了。 算法 3 和 4 使用树作为基函数，对算法 1 和 2 进行了扩展： XGBoost 和 MART 的差异 最后，论文对两种树提升算法的细节进行了比较，并试图给出 XGBoost 更好的原因。 算法层面的比较 正如之前的章节所讨论的那样，XGBoost 和 MART 都是要通过简化的 FSAM（Forward Stage Additive Modelling/前向阶段叠加建模）求解同样的经验风险最小化问题： 即不使用贪婪搜索，而是每次添加一个树。在第 m 次迭代时，使用下式学习新的树： XGBoost 使用了上面的算法 3，即用牛顿树提升来近似这个优化问题。而 MART 使用了上面的算法 4，即用梯度树提升来做这件事。这两种方法的不同之处首先在于它们学习树结构的方式，然后还有它们学习分配给所学习的树结构的终端节点的叶权重的方式。 再看看这些算法，我们可以发现牛顿树提升有 Hessian 矩阵，其在确定树结构方面发挥了关键性的作用，XGBoost： 而使用了梯度树提升的 MART 则是： 然后，XGBoost 可以直接这样定义牛顿树提升的叶权重： 使用梯度树提升的 MART 则这样定义： 总结一下，XGBoost 使用的 Hessian 是一种更高阶的近似，可以学习到更好的树结构。但是，MART 在确定叶权重上表现更好，但却是对准确度更低的树结构而言。 在损失函数的应用性方面，牛顿树提升因为要使用 Hessian 矩阵，所以要求损失函数是二次可微的。所以它在选择损失函数上要求更加严格，必须要是凸的。 当 Hessian 每一处都等于 1 时，这两种方法就是等价的，这就是平方误差损失函数的情况。因此，如果我们使用平方误差损失函数之外的任何损失函数，在牛顿树提升的帮助下，XGBoost 应该能更好地学习树结构。只是梯度树提升在后续的叶权重上更加准确。因此无法在数学上对它们进行比较。 尽管如此，该论文的作者在两个标准数据集上对它们进行了测试：Sonar 和 Ionosphere（Lichman, 2013）。这个实证比较使用了带有 2 个终端节点的树，没有使用其它正则化，而且这些数据也没有分类特征和缺失值。梯度树提升还加入了一个线搜索（line search），如图中红色线所示。 这个比较图说明这两种方法都能无缝地执行。而且线搜索确实能提升梯度提升树的收敛速度。 正则化比较 正则化参数实际上有 3 类： 1.boosting 参数：树的数量 M 和学习率η 树参数：在单个树的复杂度上的约束和惩罚 随机化参数：行子采样和列子采样 两种 boosting 方法的主要差别集中在树参数以及随机化参数上。 对于树参数，MART 中的每个树都有同样数量的终端节点，但 XGBoost 可能还会包含终端节点惩罚 γ，因此其终端节点的数量可能会不一样并且在最大终端节点数量的范围内。XGBoost 也在叶权重上实现了 L2 正则化，并且还将在叶权重上实现 L1 正则化。 在随机化参数方面，XGBoost 提供了列子采样和行子采样；而 MART 只提供了行子采样。 为什么 XGBoost 能赢得「每一场」竞赛？ 通过使用模拟数据，论文作者首次表明树提升可以被看作是自适应地确定局部邻域。 使用 生成 然后使用局部线性回归（使用了两种不同灵活度的拟合）来拟合它： 然后使用平滑样条函数（使用了两种不同灵活度的拟合）来拟合它： 现在我们尝试提升的树桩（boosted tree stump）（两个终端节点）拟合： 本论文详细说明了权重函数影响拟合的确定的方式，并且表明树提升可以被看作是直接在拟合阶段考虑偏置-方差权衡。这有助于邻域保持尽可能大，以避免方差不必要地增大，而且只有在复杂结构很显然的时候才会变小。 尽管当涉及到高维问题时，树提升「打败了」维度的诅咒（curse of dimensionality），而没有依赖任何距离指标。另外，数据点之间的相似性也可以通过邻域的自适应调整而从数据中学习到。这能使模型免疫维度的诅咒。 另外更深度的树也有助于获取特征的交互。因此无需搜索合适的变换。 因此，是提升树模型（即自适应的确定邻域）的帮助下，MART 和 XGBoost 一般可以比其它方法实现更好的拟合。它们可以执行自动特征选择并且获取高阶交互，而不会出现崩溃。 通过比较 MART 和 XGBoost，尽管 MART 确实为所有树都设置了相同数量的终端节点，但 XGBoost 设置了 Tmax 和一个正则化参数使树更深了，同时仍然让方差保持很低。相比于 MART 的梯度提升，XGBoost 所使用的牛顿提升很有可能能够学习到更好的结构。XGBoost 还包含一个额外的随机化参数，即列子采样，这有助于进一步降低每个树的相关性。 机器之心分析师的看法 这篇论文从基础开始，后面又进行了详细的解读，可以帮助读者理解提升树方法背后的算法。通过实证和模拟的比较，我们可以更好地理解提升树相比于其它模型的关键优势以及 XGBoost 优于一般 MART 的原因。因此，我们可以说 XGBoost 带来了改善提升树的新方法。 本分析师已经参与过几次 Kaggle 竞赛了，深知大家对 XGBoost 的兴趣以及对于如何调整 XGBoost 的超参数的广泛深度的讨论。相信这篇文章能够启迪和帮助初学者以及中等水平的参赛者更好地详细理解 XGBoost。 参考文献 Chen, T. and Guestrin, C. (2016). Xgboost&#58; A scalable tree boosting system. In Proceedings of the 22Nd ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining, KDD 』16, pages 785–794, New York, NY, USA. ACM.- Freund, Y. and Schapire, R. E. (1996). Experiments with a new boosting algorithm. In Saitta, L., editor, Proceedings of the Thirteenth International Conference on Machine Learning (ICML 1996), pages 148–156. Morgan Kaufmann.- Friedman, J. H. (2002). Stochastic gradient boosting. Comput. Stat. Data Anal., 38(4)&#58;367–378.- Hastie, T., Tibshirani, R., and Friedman, J. (2009). The Elements of Statistical Learning&#58; Data Mining, Inference, and Prediction, Second Edition. Springer Series in Statistics. Springer.- Kuhn, M. and Johnson, K. (2013). Applied Predictive Modeling. SpringerLink &#58; Bu ̈cher. Springer New York.- Lichman, M. (2013). UCI machine learning repository.- Murphy, K. P. (2012). Machine Learning&#58; A Probabilistic Perspective. The MIT Press.- Strobl, C., laure Boulesteix, A., and Augustin, T. (2006). Unbiased split selection for classification trees based on the gini index. Technical report.- Vapnik, V. N. (1999). An overview of statistical learning theory. Trans. Neur. Netw., 10(5)&#58;988–999.- Wei-Yin Loh, Y.-S. S. (1997). Split selection methods for classification trees. Statistica Sinica, 7(4)&#58;815–840.- Wikipedia&#58;&#58;Lasso. https&#58;//en.wikipedia.org/wiki/Lasso_(statistics)- Wikipedia&#58;&#58;Tikhonov regularization. https&#58;//en.wikipedia.org/wiki/Tikhonov_regularizationFreund, Y. and Schapire, R. E. (1996). Experiments with a new boosting algorithm. In Saitta, L., editor, Proceedings of the Thirteenth International Conference on Machine Learning (ICML 1996), pages 148–156. Morgan Kaufmann. Hastie, T., Tibshirani, R., and Friedman, J. (2009). The Elements of Statistical Learning&#58; Data Mining, Inference, and Prediction, Second Edition. Springer Series in Statistics. Springer. Lichman, M. (2013). UCI machine learning repository. Strobl, C., laure Boulesteix, A., and Augustin, T. (2006). Unbiased split selection for classification trees based on the gini index. Technical report. Wei-Yin Loh, Y.-S. S. (1997). Split selection methods for classification trees. Statistica Sinica, 7(4)&#58;815–840. Wikipedia&#58;&#58;Tikhonov regularization. https&#58;//en.wikipedia.org/wiki/Tikhonov_regularization 转载来源：为什么XGBoost在机器学习竞赛中表现如此卓越？]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>数学</tag>
        <tag>机器学习</tag>
        <tag>Kaggle</tag>
        <tag>麻省理工学院</tag>
        <tag>维基百科</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hinton的Capsule论文全公开！首发《胶囊间的动态路由》原文精译]]></title>
    <url>%2F2017%2F35ef43a6%2F</url>
    <content type="text"><![CDATA[雷锋网AI研习社按：日前，深度学习教父Geoffrey Hinton关于Capsule（胶囊）的新论文一发出，马上引起了热烈讨论。雷锋字幕组趁热对论文做了全文翻译，想了解具体细节的读者欢迎仔细阅读。有翻译不当的地方欢迎指出，更期待您可以加入我们（申请加入，联系微信 julylihuaijiang）。 胶囊间的动态路由 摘要 本论文所研究的胶囊意为一组神经元，其激活向量反映了某类特定实体（可能是整体也可能是部分）的表征。本论文使用激活向量的模长来描述实体存在的概率，用激活向量的方向表征对应实例的参数。某一层级的活跃胶囊通过矩阵变换做出预测，预测结果会用来给更高层级的胶囊提供实例参数。当多个预测值达成一致时，一个高层级的胶囊就会被激活。论文中展示了差异化训练的多层胶囊系统可以在MNIST上达到当前最高水平的表现，在识别高度重叠的数字上也要比卷积网络要好得多。网络的实现中运用迭代的一致性路由机制：当低层级的胶囊的预测向量和高层级胶囊的激活向量有较大的标量积时，这个低层级胶囊就会倾向于向高层级胶囊输出。 一、简介 人类视觉通过使用仔细确定的固定点序列来忽略不相关的细节，以确保只有极小部分的光学阵列以最高的分辨率被处理。要理解我们对场景的多少知识来自固定序列，以及我们从单个固定点中能收集到多少知识，内省不是一个好的指导，但是在本文中，我们假设单个固定点给我们提供的不仅仅是一个单一的识别对象及其属性。我们假设多层视觉系统在每个固定点上都会创建一个类似解析树这样的东西，并且单一固定解析树在多个固定点中如何协调的问题会被我们忽略掉。 解析树通常通过动态分配内存来快速构建，但根据Hinton等人的论文「Learning to parse images，2000」，我们假设，对于单个固定点，从固定的多层神经网络中构建出一个解析树，就像从一块岩石雕刻出一个雕塑一样（雷锋网 AI 科技评论注： 意为只保留了部分树枝）。每个层被分成许多神经元组，这些组被称为“胶囊”（Hinton等人「Transforming auto-encoders，2011」），解析树中的每个节点就对应着一个活动的胶囊。通过一个迭代路由过程，每个活动胶囊将在更高的层中选择一个胶囊作为其在树中的父结点。对于更高层次的视觉系统，这样的迭代过程就很有潜力解决一个物体的部分如何层层组合成整体的问题。 一个活动的胶囊内的神经元活动表示了图像中出现的特定实体的各种属性。这些属性可以包括许多不同类型的实例化参数，例如姿态（位置，大小，方向），变形，速度，反照率，色相，纹理等。一个非常特殊的属性是图像中某个类别的实例的存在。表示存在的一个简明的方法是使用一个单独的逻辑回归单元，它的输出数值大小就是实体存在的概率（雷锋网 AI 科技评论注： 输出范围在0到1之间，0就是没出现，1就是出现了）。在本文中，作者们探索了一个有趣的替代方法，用实例的参数向量的模长来表示实体存在的概率，同时要求网络用向量的方向表示实体的属性。为了确保胶囊的向量输出的模长不超过1，通过应用一个非线性的方式使矢量的方向保持不变，同时缩小其模长。 胶囊的输出是一个向量，这一设定使得用强大的动态路由机制来确保胶囊的输出被发送到上述层中的适当的父节点成为可能。最初，输出经过耦合总和为1的系数缩小后，路由到所有可能的父节点。对于每个可能的父结点，胶囊通过将其自身的输出乘以权重矩阵来计算“预测向量”。如果这一预测向量和一个可能的父节点的输出的标量积很大，则存在自上而下的反馈，其具有加大该父节点的耦合系数并减小其他父结点耦合系数的效果。这就加大了胶囊对那一个父节点的贡献，并进一步增加了胶囊预测向量和该父节点输出的标量积。这种类型的“按协议路由”应该比通过最大池化实现的非常原始的路由形式更有效，其中除了保留本地池中最活跃的特征检测器外，忽略了下一层中所有的特征检测器。作者们论证了，对于实现分割高度重叠对象所需的“解释”，动态路由机制是一个有效的方式。 卷积神经网络（CNN）使用学习得到的特征检测器的转移副本，这使得他们能够将图片中一个位置获得的有关好的权重值的知识，迁移到其他位置。这对图像解释的极大帮助已经得到证明。尽管作者们此次用矢量输出胶囊和按协议路由的最大池化替代CNN的标量输出特征检测器，他们仍然希望能够在整个空间中复制已习得的知识，所以文中构建的模型除了最后一层胶囊之外，其余的胶囊层都是卷积。与CNN一样，更高级别的胶囊得以覆盖较大的图像区域，但与最大池化不同，胶囊中不会丢弃该区域内实体精确位置的信息。对于低层级的胶囊，位置信息通过活跃的胶囊来进行“地点编码”。当来到越高的层级，越多的位置信息在胶囊输出向量的实值分量中被“速率编码”。这种从位置编码到速率编码的转变，加上高级别胶囊能够用更多自由度、表征更复杂实体的特性，表明更高层级的胶囊也相应地需要更高的维度。 二、如何计算一个胶囊的向量输入和输出 已经有很多方法可以实现胶囊的大致思路。这篇文章的目的，不是去探究所有可能的方法，而只是表明非常简单直接的方式就可以取得很好的效果，而且动态路由也可以起到帮助。 作者们用胶囊输出向量的模长来表示一个胶囊所表征的实体在输入中出现的概率。因此作者们采用一个非线性函数对向量进行“压缩”，短向量被压缩到几乎为零，长向量也被压缩到1以下长度。判别学习中充分利用这个非线性函数。 （式1） 其中vj是胶囊j的输出向量，sj是它的全部输入。 除了第一层胶囊，胶囊sj的全部输入是对预测向量uj|i的加权求和。这些预测向量都是由低一层的胶囊产生，通过胶囊的输出ui 和一个权重矩阵Wij相乘得来。 （式2） 其中cij是由迭代的动态路径过程决定的耦合系数。 胶囊i和其上一层中所有胶囊的耦合系数的和为1，并由“routing softmax”决定。这个“routing softmax”的初始逻辑值bij 是胶囊i耦合于胶囊j的对数先验概率。 （式3） 这个对数先验可以和其他权重一起被判别学习。他们由两个胶囊的位置和类型决定，而不是当前的输入图像决定。耦合系数会从初始值开始迭代，通过测量每个高一层胶囊j的当前输出vi和低一层胶囊i的预测值ui|j之间的一致性。 所述一致性是简单的点积aij=vj . ui|j。这个一致性可被看做最大似然值，并在计算出所有将胶囊i连接到更高层胶囊得到的新耦合值前，加到初始逻辑值bi,j上。 在卷积胶囊层中，胶囊内每一个单元都是一个卷积单元。因此每一个胶囊都会输出一个向量网格而不是一个简单的向量。 路由计算的伪码如下图 三、某类数字是否存在的边缘损失 作者们用实例化向量的模长来表示胶囊要表征的实体是否存在。所以当且仅当图片里出现属于类别k的数字时，作者们希望类别k的最高层胶囊的实例化向量模长很大。为了允许一张图里有多个数字，作者们对每一个表征数字k的胶囊分别给出单独的边缘损失函数(margin loss)&#58; （式4） 其中Tc=1当且仅当图片中有属于类别C的数字，m+=0.9，m-=0.1。是为了减小某类的数字没有出现时的损失，防止刚开始学习就把所有数字胶囊的激活向量模长都压缩了。作者们推荐选用 λ = 0.5。总损失就是简单地把每个数字胶囊的损失加起来的总和。 四、CapsNet 结构 图1：一个简单的3层CapsNet。这个模型的结果能和深层卷积网络（比如. Batch-normalized maxout network in network，2015）的结果媲美。DigitCaps层每个胶囊的激活向量模长给出了每个类的实例是否存在，并且用来计算分类损失。 是PrimaryCapsules中连接每个 ui, i ∈ (1, 32 × 6 × 6) 和每个vj , j ∈ (1, 10)的权重矩阵。 图2：从DigitCaps层来重构数字的解码结构。训练过程中极小化图像和Sigmoid层的输出之间的欧氏距离。训练中作者们用真实的标签作为重构的目标。 图1展示的是一个简单的CapsNet结构。 这是一个很浅的网络，只有2个卷积层和1个全连接层。Conv1有256个9*9的卷积核，步长取1，激活函数为ReLU。这层把像素亮度转化成局部特征检测器的激活，接下去这个值会被用来作为原始胶囊(primary capsules)的输入。 原始胶囊是多维实体的最底层。这个过程和图形生成的视角相反，激活了一个原始胶囊就和刚好是图形渲染的逆过程。与先分别计算实例的不同部分再拼在一起形成熟悉的总体理解（图像中的每个区域都会首先激活整个网络而后再进行组合）不同，这是一种非常不同的计算方式。而胶囊的设计就很适合这样的计算。 第二层PrimaryCapsules是一个卷积胶囊层，有32个通道，每个通道有一个8维卷积胶囊（也就是说原始胶囊有8个卷积单元，99的卷积核，步长为2）。这一层中的胶囊能看到感受野和这个胶囊的中心重合的所有25681 Conv1单元的输出。PrimaryCapsules一共有&#91;32,6,6&#93;个输出（每个输出是一个8维向量），&#91;6,6&#93;网格中的每个胶囊彼此共享权重。由于具有区块非线性，可以把PrimaryCapsules视作一个符合式1的卷积层。最后一层（DigitCaps）有对每个数字类有一个16维的胶囊，所有低一层的胶囊都可以是这一层胶囊的输入。 作者们只在两个连续的胶囊层（比如PrimaryCapsules和DigitCaps）之间做路由。因为Conv1的输出是1维的，它所在的空间中不存在方向可以和高层的向量方向达成一致性。所以在Conv1和PrimaryCapsules之间没有路由。所有的路由逻辑值(bij)被初始化为0。因此，一开始一个胶囊的输出（ui）会以相同的概率（cij）传入到所有的母胶囊（v0，v1，…，v10）。作者们用TensorFlow实现了这个网络，选择了Adam优化器和TensorFlow的默认参数，包括指数衰减的学习率用来优化式4的边缘损失的总和。 4.1 为了正则化效果而做的重构工作 作者们使用了一个额外的重构损失，希望数字胶囊能对输入数字的实例化参数做编码。在训练过程中，作者们用掩蔽的方法只把正确的数字胶囊的激活向量保留下来。然后用这个激活向量来做重构。数字胶囊的输出会传入一个由3个全连接层组成的解码器，它的结构如图2，用来建模像素密度。 作者们极小化回归单元的输出和原来图片的像素亮度之间的平方误差，并把重构误差收缩到原来的0.0005倍，这样才不会在训练过程中盖过边缘误差的作用。如图3所示，CapsNet的16维输出的重构是鲁棒的，同时也只保留了重要的细节。 五、把 Capsule 用在MNIST上 使用 28×28 MNIST的图片集进行训练，训练前这些图片在每个方向不留白地平移了2个像素。除此之外，没有进行其他的数据增改或者转换。在MNIST数据库中，6万张图片用于训练，另外1万张用于测试。 图3： 利用3次路由迭代学习的CapsNet对MNIST中的测试照片进行重构。(l, p, r)分别代表真实标签、模型预测和重建结果。最右两列展示的是重建失败的例子，解释了模型是如何混淆了图片中的“5”和“3”。其他列属于被正确分类了的，展示了模型可以识别图像中的细节，同时降低噪声。 表1：CapsNet 分类MNIST数字测试准确度。结果包含了三次测试得到的平均数和标准差。 测试中作者使用的是单一模型，没有进行“综合”或者明显的数据扩增方法。（Wan等人在「Regularization of neural networks using dropconnect」中通过“综合”及数据扩增实现了0.21%的错误率，而未使用这两种方法时的错误率是0.57%）作者们通过3层神经网络实现了较低的错误率（0.25%），这一错误率以往只有更深的网络才能达到。表1展现的是不同设置的CasNet在NMIST数据库上的测试错误率，表明了路由以及正则器重构的重要性。其基线是一个标准的三层神经网络（CNN），分别具有256、256及128个通道。每个通道具有5×5的卷积核，卷积步长为1。接着有两个全连接层，大小分别为328、192。最后的全连接层通过dropout连接到带有交叉熵损失的10个分类输出的softmax层。 5.1 capsule的单个维度表示什么 由于模型中只向DigitCaps层的胶囊传递一个数字的编码并置零其他数字，所以这些胶囊应该学会了在这个类别已经具有一个实例的基础上拓展了变化空间。这些变化包括笔画粗细、倾斜和宽度。还包括不同数字中特定的变化，如数字2尾部的长度。通过使用解码器网络可以看到单个维度表示什么。在计算正确的数字胶囊的激活向量之后，可以将这个激活向量的扰动反馈给解码器网络，并观察扰动如何影响重建。这些扰动的例子如图4所示。可以看到，胶囊的一个维度（总数为16）几乎总是代表数字的宽度。有些维度表示了全局变化的组合，而有些维度表示数字的局部变化。例如，字母6上部分的长度和下部分圈的大小使用了不同的维度。 图4：维度扰动。每一行表示DigitCaps16个维度表示中的一个维度在&#91;-0.25, 0.25&#93;范围，步长0.05时的重构结果 5.2 仿射变换的鲁棒性 实验表明，每个DigitCaps层的胶囊都比传统卷积网络学到了每个类的更鲁棒的表示。由于手写数字的倾斜、旋转、风格等方面存在自然差异，训练好的CapsNet对训练数据小范围的仿射变换具有一定的鲁棒性。 为了测试CapsNet对仿真变换的鲁棒性，作者们首先基于MNIST训练集创造了一个新的训练集，其中每个样本都是随机放在40× 40像素的黑色背景上的MNIST数字。然后用这样的训练集训练了一个CapsNet和一个传统的卷积网络（包含MaxPooling和DropOut）。 然后，作者们在affNIST数据集上测试了这个网络，其中，每个样本都是一个具有随机小范围仿射变换的MNIST数字。模型并没有在任何放射变换，甚至标准MNIST自然变换的训练集合上训练过，但一个训练好的带有早期停止机制（early stop）的CapsNet，在拓展的MNIST测试集上实现了99.23％的准确度，在仿射测试集上实现了79％的准确性。具有类似参数数量的传统卷积模型在扩展的MNIST测试集上实现了类似的准确度（99.22％），在仿射测试集上却只达到了66％。 六、高度重叠数字的分割 动态路由可以视为平行的注意力机制，允许同层级的胶囊参与处理低层级的活动胶囊，并忽略其他胶囊。理论上允许模型识别图像中的多个对象，即使对象重叠。Hinton等人的目的是分割并识别高度重合数字对象（「 Learning to parse images，2000」中提出，其它人也在类似的领域实验过他们的网络，Goodfellow等人在「Multi-digit number recognition from street view imagery using deep convolutional neural networks，2013」中，Ba等人在「Multiple object recognition with visual attention，2014」中，Greff等人在「Tagger&#58; Deep unsupervised perceptual grouping，2016」中）。一致性路由使利用对象的形状的先验知识帮助进行分割成为了可能，并避免在像素领域进行更高级别的细分。 6.1 MultiMNIST数据集 作者们通过在数字上覆盖另一个来自相同集合（训练或测试）但不同类别的数字来生成MultiMNIST训练测试数据集。每个数字在每个方向上最多移动4个像素，产生3636像素的图像。考虑到2828像素图像中的数字是以20*20像素的范围作为边框，两个数字的边框内范围平均有80%的重合部分。MNIST数据集中的每个数字都会生成1K MultiMNIST示例。训练集的大小为60M，测试集的大小为10M。 6.2 MultiMNIST数据集上的结果 作者用MultiMNIST的训练数据中重新训练得到的3层CapsNet模型，比基线卷积模型获得了更高的分类测试准确率。相较于Ba等人在「Multiple object recognition with visual attention，2014」的序列注意力模型，他们执行的是更简单的、数字交叠远远更小的任务（本文的测试数据中，两个数字的外框交叠率达到80%，而Ba等人的只有4%），而本文的模型在高度交叠的数字对中获得了与他们同样的5%的错误率。测试图片由测试集中的成对的图片构成。作者们把两个最活跃的数字胶囊看作胶囊网络产生的分类结果。在重建过程中，作者们每次选择一个数字，用它对应的数字胶囊的激活向量来重建这个数字的图像（已经知道这个图像是什么，因为作者们预先用它来生成合成的图像）。与上文MNIST测试中模型的唯一不同在于，现在把将学习率的衰减步数提高到了原来的10倍，这是因为训练数据集更大。 图5：一个经3次路由迭代的CapsNet在MultiMNIST测试数据集上的样本重建结果 如图中靠下的图像所示，两个重建出的互相交叠的数字分别显示为绿色和红色的。靠上的图显示的是输入的图像。表示图像中两个数字的标签；表示用于重建的两个数字。最右边的两列显示了从标签和从预测重建的两个错误分类样例。在例子中，模型将8错判成7；在的例子中，模型将9错判成0。其他的列都分类正确并且显示了模型不仅仅考虑了所有的像素同时能够在非常困难的场景下将一个像素分配给两个数字（1-4列）。值得说明的是，在数据集产生的过程中，像素的值都会被剪裁到1以内。两个含“*”的列显示了重建的数字既不是标签值也不是预测值。这些列显示模型不仅仅找到了所有存在的数字的最佳匹配，甚至还考虑了图像中不存在的数字。所以在的例子中，模型并不能重建数字7，是因为模型知道数字对5和0是最佳匹配，而且也已经用到了所有的像素。的例子也是类似的，数字8的环并没有触发为0的判断，因为该数字已经被当做8了。因此，如果两个数字都没有其他额外的支持的话，模型并不会将一个像素分配给这两个数字。 图5中的重构表明，CapsNet 能够把图片分割成两个原来的数字。因为这一分割并非是直接的像素分割，所以可以观察到，模型可以准确处理重叠的部分(即一个像素同时出现在多个数字上)，同时也利用到所有像素。每个数字的位置和风格在DigitCaps中都得到了编码。给定一个被编码数字，解码器也学会了去重构这一数字。解码器能够无视重叠进行重构的特性表明，每个数字胶囊都能从PrimaryCapsules层接收到的不同激活向量来获取位置和风格。 表1 也着重表现了这一任务中胶囊之间路由的重要性。作为CapsNet分类器准确率的对比基线，作者们一开始先训练了带有两层卷积层和两层全连接层的卷积神经网络。 第一层有512个大小为99的卷积核，步长为1；第二层有256个大小为55的卷积核，步长为1。在每个卷积层后，模型都连接了一个2*2大小，步长2的池化层。 第三层是一个1024维的全连接层。 所有的这三层都有ReLU非线性处理。 最后10个单元的层也是全连接。 我们用TF默认的Adam优化器来训练最后输出层的Sigmoid交叉熵损失。 这一模型有24.56M参数，是CapsNet的11.36M参数的两倍多。作者们从一个小点的CNN(32和64个大小为5*5的卷积核，步幅为1，以及一个512维的全连接层)开始，然后逐渐增大网络的宽度，直到他们在MultiMNIST的10K子集上达到最好的测试精度。他们也在10K的验证集上搜索了正确的学习率衰减步数。 作者们一次解码了两个最活跃的DigitCaps胶囊，得到了两张图片。然后把所有非零的像素分配给不同的数字，就得到了每个数字的分割结果。 七、其它数据集 作者们在 CIFAR10 的数据及上测试了胶囊模型，在用了不同的超参和7个模型集成（其中每个模型都通过图像中24x24的小块进行三次路由迭代）后得到10.6%的错误率。这里的图片都是三个颜色通道的，作者们一共用了64种不同的 primary capsule，除此之外每个模型都和在 MNIST 数据集中用的一模一样。作者们还发现胶囊能够帮助路由softmax增加一个“以上皆非”的分类种类，因为不能指望10个 capsules 的最后一层就能够解释图片里的一切信息。在测试集上有 10.6% 的错误率差不多也是标准的卷积网络初次应用到 CIFAR10 上能达到的效果。 和生成模型一个一样的缺点是，Capsules 倾向于解释图片中的一切。所以当能够对杂乱的背景建模时，它比在动态路由中只用一个额外的类别来的效果好。在 CIFAR-10 中，背景对大小固定的模型来说变化太大，因此模型表现也不好。 作者们还用了和 MNIST 中一样的模型测试了 smallNORB 数据集，可以得到目前最好的 的 2.7% 的错误率。smallNORB 数据集由 96×96的双通道灰度图组成。作者们把图片缩放到 48×48 像素，并且在训练时从中随机裁剪 32×32 的大小。而在测试时，直接取中间 32×32 的部分。 作者们还在 SVHN 的 73257 张图片的小训练集上训练了一个小型网络。我们把第一个卷积层的通道数减少到 64个，primary capsule 层为 16 个 6维胶囊，最后一个胶囊层为8维的。最后测试集错误率为 4.3%. 八、讨论以及以往工作 30年来， 语音识别的最新进展使用了以高斯混合作为输出分布的隐马尔可夫模型。这些模型虽然易于在一些计算机上学习，但是存在一个致命的缺陷：他们使用的“n种中的某一种”的表示方法的效率是呈指数下降的，分布式递归神经网络的效率就比这种方法高得多。为了使隐马尔可夫模型能够记住的迄今它所生成字符的信息倍增，需要使用的隐藏节点数目需要增加到原来的平方。而对于循环神经网络来说，只需要两倍的隐藏神经元的数量即可。 现在卷积神经网络已经成为物体识别的主流方法，理所当然要问是其中是否也会有效率的指数下降，从而引发这种方法的式微。一个可能性是卷积网络在新类别上泛化能力的困难度。卷积网络中处理平移变换的能力是内置的，但对于仿射变换的其他维度就必须进行选择，要么在网格中复制特征检测器，网格的大小随着维度数目指数增长，要么同样以指数方式增加的标注训练集的大小。胶囊通过将像素强度转换为识别到的片段中的实例化参数向量，然后将变换矩阵应用于片段，以预测更大的片段的实例化参数，从而避免了效率的指数下降。学到了部分和整体之间固有的空间关系的转换矩阵构成了具有视角不变性的知识，从而可以自动泛化到的视角中。 胶囊使得我们可以做出一个非常具有表征意义的假设：在图像的每一个位置，至多只有一个胶囊所表征的实体的实例。这种假设是由一种称为“crowding”(Pelli等人「Crowding is unlike ordinary masking&#58; Distinguishing feature integration from detection，2004」) 的感知现象驱动的，它消除了绑定问题，并允许一个胶囊使用分布式表示(它的激活向量)来对给定位置的该类型实体的实例化参数进行编码。这种分布式表示比通过在高维网格上激活一个点来编码实例化参数的效率要高得多，并且通过正确的分布式表示，胶囊可以充分利用空间关系可以由矩阵乘法来建模的特点。 胶囊中采用的神经活动会随着视角的变化而变化，而不是试图消除神经活动中视角变化带来的影响。这使它们比“归一化”法(如Jaderberg等「Spatial transformer networks，2015」)更具有优势&#58;它们可以同时处理多个不同仿射变换或不同对象的不同部件。 胶囊同时也非常擅长处理图像分割这样的另一种视觉上最困难的问题之一，因为实例化参数的矢量允许它们使用在本文中演示的那样的一致性路由。对胶囊的研究目前正处于一个与本世纪初研究用于语音识别的递归神经网络类似的阶段。根据基础表征性的特点，已经有理由相信这是一种更好的方法，但它可能需要一些更多的在细节上的洞察力才能把它变成一种可以投入应用的高度发达的技术。一个简单的胶囊系统已经在分割数字图像上提供了无与伦比的表现，这表明了胶囊是一个值得探索的方向。 （完） 关注AI研习社，回复【论文】即可获取论文原文及翻译。 欢迎各界朋友加入字幕组，让雷锋字幕组翻译水平更上一层楼。组长微信：julylihuaijiang。 雷锋字幕组翻译 / 熊浪涛、小颖同学、sophie、Clay、李振、孟庆淳、Jackie、小耗子在南京、张小彬、Moonsea、陈智敏 审校 / 晓凡 统筹 / 囧囧、凡江 转载来源：Hinton的Capsule论文全公开！首发《胶囊间的动态路由》原文精译]]></content>
      <categories>
        <category>科学</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>CNN</tag>
        <tag>科学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【重磅】Hinton大神Capsule论文首次公布，深度学习基石CNN或被取代]]></title>
    <url>%2F2017%2F2f547fb7%2F</url>
    <content type="text"><![CDATA[【重磅】Hinton大神Capsule论文首次公布，深度学习基石CNN或被取代 转载来源：【重磅】Hinton大神Capsule论文首次公布，深度学习基石CNN或被取代]]></content>
      <tags>
        <tag>新智元</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[吴恩达Deeplearning.ai 全部课程学习心得分享]]></title>
    <url>%2F2017%2F35812f7d%2F</url>
    <content type="text"><![CDATA[选自Medium 作者：Ryan Shrott 机器之心编辑部 本文作者，加拿大国家银行首席分析师 Ryan Shrott 完成了迄今为止（2017 年 10 月 25 日）吴恩达在 Coursera 上发布的所有深度学习课程，并为我们提供了课程解读。 目前 Coursera 上可用的课程中，有三门课非常值得关注： 神经网络与深度学习（Neural Networks and Deep Learning） 改进深度神经网络：调整超参数、正则化与优化（Improving Deep Neural Networks&#58; Hyperparamater tuning, Regularization and Optimization） 结构化机器学习项目（Structuring Machine Learning Projects） 我发现这三门课非常重要，在其中，我们可以从吴恩达教授那里获得很多有用的知识。吴恩达在教学语言上做得很好，解释概念清晰明了。例如，吴恩达明确指出监督学习并没有超出多维曲线拟合过程的范畴，而对于这种方法的其他理解方式，如对人类神经系统的模拟，实际上并不严谨。 学习这些课程的基础知识要求不多，只要求你事先掌握一些线性代数，以及 Python 基础编程知识。在我看来，你也需要了解向量计算来理解优化过程的内在知识。但如果你不关心内部运作方式，并只希望了解高级层面上的内容，尽管跳过微积分的部分。 第 1 课：为什么深度学习如此热门？ 现在人类产生的 90% 数据是在最近 2 年内被收集的。深度神经网络（DNN）能够利用体量巨大的数据。因此，DNN 超越了较小的网络和传统学习算法。 规模是如何推动 DNN 性能的 此外，算法上的创新也使得 DNN 的训练速度变得更快。例如，从 Sigmoid 激活函数改为 RELU 激活函数对梯度下降等任务的优化过程产生了巨大影响。这些算法的改进使得研究人员可以更快地遍历灵感→ 代码→ 经验的开发循环，从而带来更多的创新。 深度学习开发循环 第 2 课：深度学习中的向量化 在开始这门课之前，我并不知道神经网络可以在没有任何明确循环语句的情况下被实现（除了层之间的）。吴恩达点明了 Python 中向量化编程设计的重要性。课程附带的作业引导你进行向量化的编程，同时这些方法也可以很快迁移到你自己的项目中。 第 3 课：深入了解 DNN 前几门课实际上在引导你使用 NumPy 从头开始实现前向和反向传播。通过这种方法，我更加深入了解了高级深度学习框架（如 TensorFlow 和 Keras）的工作原理。吴恩达解释了计算图背后的想法，从而让我们了解了 TensorFlow 如何实现「神奇优化」的。 第 4 课：为什么需要深度？ 在这一节中，吴恩达深入解释了 DNN 的层概念。例如，对于面部识别系统，他向我们解释了先处理的层是用于处理面部边界的，其后的层用于将这些边界识别为面部组件（如鼻子、眼睛、嘴等），再其后的层会将这些组件整合到一起识别人的身份。他还解释了电路理论（circuit theory）的思想——存在一个函数，需要来自隐藏单元指数式的数字来适应浅网络的数据。可以通过添加有限数量的附加层来简化指数问题。 第 5 课：处理偏差和方差的工具 吴恩达解释了研究者识别和处理偏差方差相关问题的步骤。下图诠释了一种解决这些问题的系统性方法。 解决偏差和方差问题的方法 他还解决了偏差和方差之间的「权衡」（tradeoff）。他认为在现在这个深度学习的时代，我们拥有独立解决每个问题的工具，使权衡不再存在。 第 6 课：正则化 为什么向成本函数添加惩罚项会降低方差？在上这门课之前我的理解是它使权重矩阵接近于零，从而产生一个更「线性」的函数。吴恩达给出了另外一种和 tanh 激活函数相关的解释，即较小的权重矩阵生成较小的输出，使得输出围绕在 tanh 函数线性区域的中心。 tanh 激活函数 他还给出了 dropout 的有趣解释。之前我认为 dropout 在每次迭代中消灭随机神经元，就像越小的网络线性程度就越强一样。但是吴恩达的解释是从单个神经元的角度来看待生命（life）。 单个神经元的角度 由于 dropout 随机消灭连接，这促使神经元向父系神经元中更加均匀地扩展权重。通过扩展权重，它可以减少权重的 L2 范数（squared norm）。他还解释了 dropout 是 L2 正则化的自适应形式，两种方法效果相近。 第 7 课：归一化为何有效？ 吴恩达展示了为什么归一化可以通过绘制等高线图的方式加速优化步骤。他详细讲解了在归一化和非归一化等高线图上进行梯度下降所需要的迭代次数变化，即相同优化算法没经过归一化操作会需要更多的迭代数。 第 8 课：初始化的重要性 吴恩达表示不使用参数初始化可能导致梯度消失或爆炸。他展示了多个步骤来解决这些问题。基本原则是确保每一层的权重矩阵的方差都近似为 1。他还讨论了 tanh 激活函数的 Xavier 初始化。 第 9 课：为什么使用小批量梯度下降？ 吴恩达使用等高线图解释了使用小批量和大批量训练之间的权衡。基本原则是较大的批量每次迭代会变慢，较小的批量可以加快迭代过程，但是无法保证同样的收敛效果。最佳方法就是在二者之间进行权衡，使得训练过程比一次性处理整个数据集要快，又能利用向量化技术的优势。 第 10 课：高级优化技术的直观理解 吴恩达解释了合适使用动量（momentum）和 RMSprop 等技术限制梯度下降逼近极小值的路径。他还用球滚下山的例子生动地解释了这一过程。他把这些方法结合起来来解释著名的 Adam 优化。 第 11 课：基本的 TensorFlow 后端理解 吴恩达不仅解释了如何使用 TensorFlow 实现神经网络，同时还讲解了在优化过程中出现的后端进程。有一个家庭作业就是鼓励我们使用 TensorFlow 实现 dropout 和 L2 正则化，这加强了我对后端过程的理解。 第 12 课：正交化 吴恩达还讨论了机器学习策略中正则化的重要性。其基本思想是，我们希望实现并控制影响算法性能的因素，即一次只控制一个影响性能的因素。例如为了解决偏差问题，我们可以使用更大的网络或更鲁棒的优化技术，我们希望这些控制只影响偏差而不会影响其它如泛化等问题。缺少正交化控制的案例是过早停止了算法的最优化过程，因为这样会同时影响模型的偏差和方差。 第 13 课：单数值评估度量的重要性 吴恩达强调了选择单数值评估度量（single number evaluation metric）的重要性，它可以允许我们评估算法。如果目标改变，我们应该在模型开发过程中仅更改评估度量。吴恩达给我们讲解了一个使用猫分类应用识别色情图片的案例。 第 14 课：测试和开发集的分布 通常我们会假设测试集与开发集（dev sets）的分布相同，这就确保了我们在迭代过程中朝向正确的目标优化。这同样意味着如果你决定纠正测试集中错误的标注数据，那么你需要在开发集中纠正错误标注的数据。 第 15 课：处理不同的训练和测试/开发分布 吴恩达介绍了为什么我们对训练和测试/开发集没有相同的分布这一问题感兴趣。因为我们希望根据实际关心的样本来计算评估度量。例如我们可能希望使用和训练问题无关的的样本进行训练，但我们并不希望算法使用这些样本进行评估，这就令我们的算法可以在更多的数据上进行训练。经验上，这种方法可以在许多案例上产生非常好的效果。缺点是可能我们的训练和测试/开发集有不同的分布，这个问题的通常解决办法是，可以留出一小部分训练集，并确定训练集的泛化性能。然后我们可以比较这些误差率与实际的开发误差，并计算一个「数据误匹配」的度量标准。吴恩达还解释了解决这些数据误匹配问题的方法，例如人工数据合成。 第 16 课：训练集/开发集/测试集大小 在深度学习时代，训练集/开发集/测试集的分隔方法也发生了巨大的改变。之前，我只知道较普遍的 60/20/20 分隔。吴恩达强调，对于一个非常大的数据集，应该使用 98/1/1 甚至 99/0.5/0.5 的分隔。这是因为开发集合测试集只要足够大能保证模型处于团队设定的置信区间即可。如果你使用 1 千万个训练样本，那么 10 万样本（即数据集的 1%）就足够保证开发集和/或测试集的置信区间了。 第 17 课：近似贝叶斯最优误差 吴恩达解释了在某些应用中人类级别的性能如何作为贝叶斯误差的替代。例如，在视觉和听觉识别任务中，人类级别的误差通常很接近贝叶斯误差，可以用于量化模型中可避免的偏差。如果没有诸如贝叶斯误差这样的基准测试，理解网络中的方差和可避免的偏差问题是很困难的。 第 18 课：误差分析 吴恩达介绍了一种能显著提高算法性能的有效性的误差分析技术。基本想法是手工标注错误分类的样本，集中精力处理对错误分类数据影响最大的误差。 猫识别 App 误差分析 例如，在猫识别中吴恩达认为模糊的图像最容易导致误差。这种敏感性分析可以令人看到在降低总体误差的过程中，你花费的精力到底有多值得。还有一种可能是，修复模糊图像是很费力的任务，而其它的误差更容易理解和修复。敏感性分析和近似操作都将作为决策过程的因素。 第 19 课：什么时候使用迁移学习？ 迁移学习允许将一个模型的知识迁移到另一个。例如，你可以将一个猫识别 app 中的图像识别知识迁移到放射诊断中去。实现迁移学习需要用更多的数据重训练网络的最后几个层，以用于相似的应用领域。其思想基础是网络的低层的隐藏单元拥有更加广阔的应用范围，即对具体的任务类型不敏感。总之，当任务之间拥有相同的输入特征，并且需要学习的任务拥有比需要训练的任务多得多的数据的时候，迁移学习是可行的。 第 20 课：什么时候使用多任务学习？ 多任务学习迫使单个神经网络同时学习多个任务（和每一个任务都配置单独的神经网络相反）。吴恩达解释道，当任务集合通过共享低级特征获得学习增益，以及每一个任务的数据量规模相似的时候，这种方法能工作得很好。 第 21 课：什么时候用端到端的深度学习？ 端到端的深度学习需要多层处理并将它们组合到单个神经网络中，这使得数据能在没有人工设计步骤引进偏差的前提下自主进行优化过程。另一方面，这个方法需要非常多的数据，有可能排除潜在的手工设计成分。 结论 吴恩达的深度学习课程使我对深度学习模型的开发过程有了基本的直观理解，以上我解释过的课程只不过是这个课程中展示资料的一部分。即使完成了课程你也还不能称为深度学习专家，而我唯一的不满是课程的作业布置太简单了。顺便提一句，写这篇文章并没有得到 deeplearning.ai 的批准。 转载来源：吴恩达Deeplearning.ai 全部课程学习心得分享]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>在线教育</tag>
        <tag>吴恩达</tag>
        <tag>加拿大</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学界 | 词嵌入2017年进展全面梳理：趋势和未来方向]]></title>
    <url>%2F2017%2F33fb6aa3%2F</url>
    <content type="text"><![CDATA[学界 | 词嵌入2017年进展全面梳理：趋势和未来方向 转载来源：学界 | 词嵌入2017年进展全面梳理：趋势和未来方向]]></content>
      <tags>
        <tag>机器之心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[月入五千的国贸人，教你如何活的像年薪百万]]></title>
    <url>%2F2017%2F6f1463fd%2F</url>
    <content type="text"><![CDATA[月入五千的国贸人，教你如何活的像年薪百万 转载来源：月入五千的国贸人，教你如何活的像年薪百万]]></content>
      <tags>
        <tag>脉脉编辑部</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[「TensorFlow 谷歌神经机器翻译」从零开始打造属于你的翻译系统]]></title>
    <url>%2F2017%2F1bee3236%2F</url>
    <content type="text"><![CDATA[1 新智元编译 机器翻译——自动在两种语言之间进行翻译的任务——是机器学习中最活跃的研究领域之一。在多种机器翻译方法中，序列到序列（“seq2seq”）模型最近取得了巨大的成功，并已经成为大多数商业翻译系统的事实上的标准，例如谷歌翻译。这是由于 seq2seq 模型能够利用深度神经网络捕捉句子意义。但是，虽然 seq2seq 模型（例如 OpenNMT 或 tf-seq2seq）有大量的资料，但是缺少可以同时教知识和构建高质量翻译系统的技能的教程。 谷歌今天公布了一个用 TensorFlow 构建神经机器翻译（NMT）系统的教程，全面解释 seq2seq 模型，并演示如何从零开始构建 NMT 翻译模型。这个教程从 NMT 的背景知识讲起，并提供构建一个 NMT 系统的代码细节。接着，教程讲解注意力机制（attention mechanism），这是让 NMT 能够处理长句子的关键。最后，教程提供如何复制谷歌的 NMT 系统（GNMT）中的关键功能，在多个 GPU 上进行训练的详细信息。 这一教程还包括详细的基准测试结果，使用者可以自行复制。谷歌的模型提供了强大的开源基准，性能与 GNMT 的结果相当，在流行的 WMT’14 英语 - 德语翻译任务上实现了 BLEU 得分 24.4 的性能。 教程还包括其他基准测试结果（英语 - 越南语，德语 - 英语）。 此外，这个教程还提供了完全动态的 seq2seq API（与 TensorFlow 1.2 一起发布），旨在使构建 seq2seq 模型更加简洁： 使用tf.contrib.data中新的输入管道轻松读取和预处理动态大小的输入序列。- 使用padded batching和sequence length bucketing来提高训练和推理速度。- 使用流行的架构和训练schedule训练seq2seq模型，包括几种类型的attention和scheduled sampling。- 使用in-graph beam search在seq2seq模型中执行推理。- 为多GPU设置优化seq2seq模型。使用padded batching和sequence length bucketing来提高训练和推理速度。 使用in-graph beam search在seq2seq模型中执行推理。 希望这一教程有助于研究界创造更多新的NMT模型并进行实验。完整教程的GitHub地址：https&#58;//github.com/tensorflow/nmt，本文提供主要内容的翻译介绍。 神经机器翻译（seq2seq）教程 作者：Thang Luong, Eugene Brevdo, Rui Zhao 目录 导言- 基础神经机器翻译背景知识基础 安装教程 训练——如何构建你的第一个NMT系统 嵌入 编码器 解码器 损失 梯度计算和优化 实践——让我们开始训练一个NMT模型 推理——如何生成翻译 中级教程注意力机制的背景知识 Attention Wrapper API 实践——构建一个以注意力为基础的NMT模型 提示与技巧构建训练，评估和推理图 数据输入管道 更好的NMT模型的其他细节 双向RNN 束搜索（Beam Search） 超参数 多GPU训练 基准IWSLT英语 - 越南语 WMT德语 - 英语 WMT英语 - 德语（完全比较） 其他资源- 致谢- 参考文献致谢 导言 序列到序列（seq2seq）模型（Sutskever et al.，2014，Cho et al.，2014）在机器翻译、语音识别、文本概况等各种任务中取得了巨大的成功。本教程提供了对 seq2seq 模型的全面解释，并演示了如何从头开始构建一个具有竞争力的 seq2seq 模型。我们专注于神经机器翻译（NMT）任务，这是第一个大获成功的 seq2seq 模型的测试平台。教程中包含的代码是轻便，高质量，生产就绪，并结合了最新的研究观点的。我们通过以下方式实现这一目标： 使用最新的解码器/注意力包装 API，TensorFlow 1.2 数据迭代器- 结合我们在构建循环模型和 seq2seq 模型方面的专长- 提供构建最好的 NMT 模型以及复制谷歌的 NMT（GNMT）系统的提示和技巧。结合我们在构建循环模型和 seq2seq 模型方面的专长 我们认为，最重要的是提供可以让人轻松复制的基准。因此，我们提供了完整的实验结果，并在以下公开数据集对模型进行了预训练： 小规模：IWSLT Evaluation Campaign 提供的 TED 演讲（133K句子对）的英语 - 越南语平行语料库。- 大规模：WMT Evaluation Campaign 提供的德语 - 英语平行语料库（4.5M句子对）。大规模：WMT Evaluation Campaign 提供的德语 - 英语平行语料库（4.5M句子对）。 我们首先提供构建 NMT 的 seq2seq 模型的一些基本知识，说明如何构建和训练一个 NMT 模型。第二部分将详细介绍构建一个有竞争力的 NMT 模式的注意力机制。最后，我们将提供一些提示和技巧，以构建最佳性能的 NMT 模型（包括训练速度和翻译质量），例如 TensorFlow 的最佳实践（batching, bucketing），bidirectional RNN 和 beam search。 基础 神经机器翻译的背景知识 回到过去，传统的基于短语的翻译系统是通过将源语言的句子分解成多个部分，然后逐个短语地进行翻译。这导致机器翻译的结果与人类翻译的结果很不同。人类是通读整个源句子，理解它的含义，然后进行翻译。神经机器翻译（NMT）模拟了这样的过程！ 图1：编码器-解码器架构，NMT的一个通用方法的示例。编码器将源句子转换成一个“meaning”向量，这个向量通过解码器传递，产生翻译结果。 具体来说，NMT 系统首先使用编码器读取源语句来构建“meaning”向量，即表示句子意义的一个数字序列; 然后，解码器处理句子向量以输出翻译结果，如图1所示。这一架构同城被称为编码器-解码器架构（encoder-decoder architecture）。以这种方式，NMT 解决了传统的基于短语的方法中翻译局部性的问题：它可以捕获语言的远距离依赖性，例如性一致， 句法结构，等等，并产生更流畅的翻译，如谷歌的神经机器翻译系统所演示的。 NMT 模型的具体结构有所不同。序列数据的一般选择是大多数NMT模型使用的循环神经网络（RNN）。通常，RNN用于编码器和解码器。但是，RNN模型在以下方面不同：（a）方向性——单向或双向; （b）深度——单层或多层; 和（c）类型——通常是普通RNN，长短期记忆（LSTM）或循环门单位（Gated Recurrent Unit, GRU）。有兴趣的读者可以在这篇博客文章了解有关RNN和LSTM的更多信息：http&#58;//colah.github.io/posts/2015-08-Understanding-LSTMs/ 在本教程中，我们将一个单向的深度多层RNN作为示例，并将LSTM作为一个循环单元。图2是这样一个模型的例子。在这个示例中，我们构建一个模型来将源句子“I am a student”翻译成一个目标句子“Je suisétudiant”。在高层水平上，NMT模型由两个循环神经网络组成：编码器RNN简单地处理输入的源词汇，不进行任何预测; 另一方面，解码器RNN在预测下一个单词的同时处理目标句子。 更多信息请参阅Luong（2016）的教程（https&#58;//github.com/lmthang/thesis），本教程正是基于这个教程的扩充。 图2：神经机器翻译——将源句子“I am a student”翻译成目标句子“Je suisétudiant”，这是一个深度循环架构的例子。这里，“”表示解码处理的开始，“&lt;/ s&gt;”提示解码器停止。 安装教程 要安装本教程，你需要在系统上安装TensorFlow。本教程要求最新版本的TensorFlow（version 1.2.1）。要安装TensorFlow，请按照官方的安装说明进行操作（https&#58;//www.tensorflow.org/install）。 安装好TensorFlow之后，您可以通过运行下面的代码下载本教程的源代码： git clone https&#58;//github.com/tensorflow/nmt/ 训练——如何构建你的第一个NMT系统 我们先用一些具体的代码片段看看构建一个NMT模型的核心，详细解释一下图2。我们后面会提供数据准备和完整代码。这部分涉及model.py文件。 在底层，编码器RNN和解码器RNN作为输入接收以下内容：首先是源句子（source sentence），然后是一个边界标记“”，提示从编码模式到解码模式的切换，最后是目标句子（target sentence）。对于训练过程，我们将为系统提供以下张量，它们是time-major的格式，包含单词索引： encoder_inputs &#91;max_encoder_time, batch_size&#93;&#58; 源输入单词 decoder_inputs &#91;max_decoder_time, batch_size&#93;&#58; 目标输入单词 decoder_outputs &#91;max_decoder_time, batch_size&#93;&#58; 目标输出单词，即 decoder_inputs左移动一个时间步长，同时在右边附一个句末标记。 为了提高效率，我们一次训练多个句子（batch_size）。测试过程略有不同，我们会在后面讨论。 嵌入 给定词类属性，模型必须先查找源和目标嵌入以检索相应的词汇表示。为了使嵌入层工作，首先要为每种语言选择一个词汇表。通常，选择词汇大小V，并且只有最常用的V词汇被视为唯一的。其他所有词汇都转换成一个“unknown”字符（token），并且都得到相同的嵌入。通常在训练期间学习嵌入的权重，每种语言一套。 同样，我们可以构建 embedding_decoder 和 decode_emb_inp。请注意，可以选择使用预训练的单词表示（例如 word2vec 或 Glove vector）来初始化嵌入权重。一般来说，给定大量训练数据，我们可以从头开始学习这些嵌入。 编码器 一旦被检索到，那么嵌入词汇就作为输入被喂入主网络中，该主网络由两个多层RNN组成——用于源语言的编码器和用于目标语言的解码器。这两个RNN原则上可以共享相同的权重; 但是，在实践中，我们经常使用两种不同的RNN参数（这些模型在拟合大型训练数据集时做得更好）。编码器RNN使用零向量作为起始状态，构建如下： 请注意，句子具有不同的长度以避免计算上的浪费，我们通过source_seqence_length 告诉 dynamic_rnn 确切的源句子长度。由于我们的输入是 time major 的，因此设置 time_major = True。 在这里，我们只构建一个单层LSTM，encoder_cell。在后面的部分将介绍如何构建多层 LSTM，添加 dropout，以及使用 attention。 解码器 解码器也需要访问源信息，一个简单的方法就是用编码器的最后一个隐藏状态（encode_state）来初始化解码器。 在图2中，我们将源代码“student”的隐藏状态传递到解码器端。 这里，代码的核心部分是 BasicDecoder ，接收 decode_cell（类似于encoder_cell）的 decoder，一个 helper，以及作为输出的前一个 encoder_state。通过分开 decoders 和 helpers，我们可以重复利用不同的代码库，例如，可以用 reedyEmbeddingHelper 替代 TrainingHelper 进行 greedy decoding。更多信息请查看 helper.py。 最后，我们还没提到 projection_layer，它是一个密集矩阵（dense matrix），用于将顶部的隐藏状态转换为维度V的对数向量（logit vectors）。这个过程在图2的顶部说明了。 损失 有了上面的 logits，现在可以计算训练损失： 这里，target_weights 是与 decode_outputs 大小相同的0-1矩阵，它将目标序列长度之外的位置填充为值为0。 重要注意事项：我们用 batch_size 来分割损失，所以我们的超参数对 batch_size是“不变的”。有的人将损失以 batch_size * num_time_steps 进行分割，这可以减少短句子的翻译错误。更巧妙的是，我们的超参数（应用于前面的方法）不能用于后面的方法。例如，如果两种方法都使用学习律为1.0的SGD，那么后一种方法有效利用更小的学习率，即1 / num_time_steps。 梯度计算和优化 我们现在已经定义NMT模型的前向传播。计算反向传播只需要几行代码： 训练RNN的重要步骤之一是梯度剪切（gradient clipping）。这里，我们按照global norm警醒剪切。最大值max_gradient_norm通常设置为5或1。最后一步是选择优化器。Adam优化器是常见的选择。也需要选择学习率（learning rate）。learning_rate的值通常在0.0001到0.001之间; 也可以设置为随着训练的进行，学习率降低。 在我们自己的实验中，我们使用标准SGD（tf.train.GradientDescentOptimizer）以及可降低的学习率设置，从而产生更好的性能。具体见benchmark部分。 实践——训练一个NMT模型 让我们开始训练第一个NMT模型，将越南语翻译成英语！代码的入口点是 nmt.py 我们将使用一个小型的TED 演讲（133K训练样本）的平行语料库来进行这个实践。我们在这里使用的所有数据可以在下面网址找到：https：//nlp.stanford.edu/projects/nmt/。我们将使用tst2012作为dev数据集，tst2013作为测试数据集。 运行以下命令下载训练NMT模型的数据：nmt/scripts/download_iwslt15.sh /tmp/nmt_data 运行以下命令开始训练： 上面的命令训练一个具有128-dim的隐藏单元和12个epoch的嵌入的2层LSTM seq2seq模型。我们使用的dropout值为0.2（保持或然率为0.8）。如果不出现error，随着训练的困惑度值（perplexity value）降低，应该可以看到类似下面的logs： 详细信息请参阅train.py。 我们可以在训练期间启动Tensorboard来查看模型的概要： tensorboard –port 22222 –logdir /tmp/nmt_model/ 以上是从英语翻译成越南语的训练，通过下面的代码可以简单地变成从越南语翻译成英语： –src=en –tgt=vi 推理——如何生成翻译 在训练NMT模型时（以及已经训练完时），你可以得到之前模型没见过的源句子的翻译。这个过程称为推理（inference）。训练和推理（测试）之间有明确的区别：在推理时，我们只能访问源句子，即encoder_inputs。执行解码有很多种方法。解码方法包括greedy解码，采样解码和束搜索（beam-search）解码。这里，我们将讨论贪心解码策略。 它的想法是很简单的，如图3： 我们仍然以与训练期间相同的方式对源句子进行编码，以获得encoder_state，并使用该encoder_state来初始化解码器。- 一旦解码器接收到开始符号“&lt;s”（参见代码中的tgt_sos_id），就开始进行解码（转换）处理。- 对于解码器侧的每个时间步长，我们将RNN的输出视为一组logits。我们选择最有可能的单词，即与最大logit值相关联的id作为输出的单词（这就是“greedy”行为）。例如在图3中，在第一个解码步骤中，单词“moi”具有最高的翻译概率。然后，我们将这个词作为输入提供给下一个时间步长。- 这个过程继续进行，直到生成句尾标记“&lt;/ s&gt;”作为输出符号（在我们的代码中是tgt_eos_id）。一旦解码器接收到开始符号“&lt;s”（参见代码中的tgt_sos_id），就开始进行解码（转换）处理。 这个过程继续进行，直到生成句尾标记“&lt;/ s&gt;”作为输出符号（在我们的代码中是tgt_eos_id）。 图3：Greedy解码——训练好的NMT模型使用greedy搜索生成源句子“Je suisétudiant”的翻译。 令推理与训练不同的是步骤3。推理使用模型预测的单词，而不是总是正确的目标单词作为输入。以下是实现greedy解码的代码。它与解码器的训练代码非常相似。 在这里，我们使用GreedyEmbeddingHelper而不是TrainingHelper。由于我们预先不知道目标序列长度，所以使用maximum_iterations来限制翻译长度。 一个启发是解码最多两倍的源句子长度。 训练好一个模型后，现在可以创建一个推理文件并翻译一些句子： 注意，上述命令也可以在模型正在训练时运行，只要存在一个训练的检查点。 详细请参阅inference.py。 进阶版：注意力机制 说完了最基本的 seq2seq 模型后，下面是进阶版！ 注意力机制：背景 为了建立最先进的神经机器翻译系统，我们将需要更多的“特殊材料”：注意力机制，这是 Bahdanau 等人于 2015 年首次引入，然后由 Luong 等人在同年完善的。注意力机制的关键在于通过在翻译过程中，对相关来源内容进行“注意”，建立目标与来源之间的直接连接。注意力机制的一个很好的副产品，是源和目标句子之间的对齐矩阵（如图 4 所示）。 图4：注意力机制可视化：源和目标句子之间的比对的例子。图像来自论文 Bahdanau et al.，2015。 在简单的 seq2seq 模型中，开始解码时，我们将最后的源状态从编码器传递到解码器。这对比较短和中等长度的句子效果很好；然而，对于长句子，单个固定大小的隐藏状态就成了信息瓶颈。注意力机制并不是丢掉在源 RNN 中计算的所有隐藏状态，而是让解码器将它们视为源信息的动态存储器。通过这样做，注意力机制改善了较长句子的翻译质量。如今，注意力机制成为神经机器翻译的首选，而且也成功应用于许多其他任务（包括图说生成，语音识别和文本摘要）。 我们现在介绍注意力机制的一个实例，这个实例是 Luong 等人在 2015 年论文中提出的，已被用于 OpenNMT 开放源码工具包等多个最先进的系统，TF seq2seq API 教程中也使用了这个例子。 图5：注意力机制：Luong 等人 2015 年所述的基于注意力的 NMT 系统的例子。这里详细介绍了注意力计算的第一步。为了清楚起见，没有将图 2 中的嵌入和投射层绘制出来。 如图 5 所示，注意力计算在每个解码器时间步长都有发生，包括以下阶段： 比较当前目标隐藏状态与所有源状态，获得注意力权重“attention weight”（可以如图 4 所示）；1. 基于注意力权重，计算上下文矢量（context vector），作为源状态的加权平均值；1. 将上下文矢量与当前目标隐藏状态相结合，产生最终的注意力向量“attention vector”；1. 注意力向量作为输入，被传递到下一个时间步。基于注意力权重，计算上下文矢量（context vector），作为源状态的加权平均值； 注意力向量作为输入，被传递到下一个时间步。 注意力机制中最关键的是什么？ 根据 score 函数和 loss 函数的不同，存在很多不同的注意力变体。但在实践中，我们发现只有特定的一些选择很重要。首先是注意力的基本形式，也即目标和源之间的直接关系。 其次是将注意力向下馈送到下一个时间步长，这是告知网络过去的注意力做了什么决定（Luong 等人，2015）。最后，score 函数的选择往往会导致性能表现不同。 AttentionWrapper API 在部署 AttentionWrapper 时，我们借鉴了 Weston 等人 2015 年在 memory network 方面的一些术语。与可读写的 memory 不同，本教程中介绍的注意力机制是只读存储器。具体来说，源的一组隐藏状态被作为“记忆”（memory）。在每个时间步长中，使用当前目标隐藏状态作为“query”来决定要读取 memory 的哪个部分。通常，query 需要与对应于各个内存插槽的 key 进行比较。在我们的介绍中，恰好将源隐藏状态作为“key”。你可以受到记忆网络术语的启发，得出其他形式的注意力！ 由于有了 attention wrapper，用 attention 扩展普通 seq2seq 代码就十分简单了。这部分参考文件 attention_model.py 首先，我们需要定义注意机制，例如（Luong等人，2015）： 在以前的 Encoder 部分中，encoder_outputs 是顶层所有源隐藏状态的集合，其形状为 &#91;max_time，batch_size，num_units&#93;（因为我们将 dynamic_rnn 与 time_major 设置为 True）。对于注意力机制，我们需要确保传递的“记忆”是批处理的，所以需要转置 attention_states。 将 source_sequence_length 传递给注意力机制，以确保注意力权重正确归一化（仅在 non-padding 位置上发生）。 定义了注意力机制后，使用 AttentionWrapper 解码单元格： 代码的其余部分与 Decoder 那节是一样的！ 实践：构建基于注意力的 NMT 模型 为了实现注意力，我们需要使用 luong，scaled_luong，bahdanau 或 normed_bahdanau 中的一个，作为训练期间的注意力 flag 的值。这个 flag 指定了我们将要使用的注意力机制。 我们还需要为注意力模型创建一个新的目录，这样才不会重复使用以前训练过的基本 NMT 模型。 运行以下指令开始训练： 在训练完成后，使用同样的推理指令 model_dir 做推理： 玩转 NMT：窍门和技巧 构建训练图、评估图和推理图 在 TensorFlow 中构建机器学习模型时，最好建立 3 个独立的图： 首先是训练图，其中：1. 批次、bucket 和可能的子样本从一组文件/外部输入输入；1. 包括前向和后向 op；1. 构建优化器，并添加训练 op。包括前向和后向 op； 其次是评估图，其中：1. 批次和 bucket 从一组文件/外部输入数据；1. 包括 1 个训练前向 op 和不用于训练的其他评估 op包括 1 个训练前向 op 和不用于训练的其他评估 op 最后是推理图，其中：1. 可能不批量输入数据；1. 不会对输入数据进行子采样；1. 从占位符读取输入数据1. 包括模型前向 op 的一个子集，也可能含有用于存储 session.run 调用之间状态的其他特殊输入/输出。不会对输入数据进行子采样； 包括模型前向 op 的一个子集，也可能含有用于存储 session.run 调用之间状态的其他特殊输入/输出。 构建单独的图有几个好处： 推理图通常与其他两个不同，因此需要分开构建；- 这样评估图也更简单，因为没有了额外的反向 op；- 可以为每个图分别实现数据馈送；- 各种重用都更加简单。例如，在评估图中，不需要用 reuse = True 重新打开可变范围，因为训练模型已经创建了这些变量。不需要到处使用 reuse=；- 在分布式训练中，训练、评估和推断分开用不同的机器做很正常。反正都需要各自建图。因此，分开建图也有助于你构建分布式训练系统。这样评估图也更简单，因为没有了额外的反向 op； 各种重用都更加简单。例如，在评估图中，不需要用 reuse = True 重新打开可变范围，因为训练模型已经创建了这些变量。不需要到处使用 reuse=； 主要的问题是，在只有单机的情况下，如何在 3 个图中共享变量 Variables。这可以通过为每个图使用单独的 session 来解决。训练 session 定期保存检查点，评估和推理 session 定期从检查点恢复参数。 下面的例子显示了两种方法的主要区别。 统一建图：一个图里 3 个模型 分别建图：3 个 session 共享变量 注意，后一种方法很容易就能转换为分布式版本。 另一个区别在于，我们使用了有状态的迭代器对象，而不是使用 feed_dicts 来在每个 session.run 调用中提供数据。这些迭代器使输入管道在单机和分布式设置中都容易得多。 其他技巧：双向 RNN 编码器的双向性通常会带来更好的性能（但由于使用了更多层，速度会有一些降低）。在这里，我们给出一个简单的例子，说明如何用单个双向层构建编码器： 其他技巧：Beam Search 虽然贪婪解码得出的翻译质量不错，但是 beam search 解码器可以进一步提高性能。Beam search 在翻译时总是将一小部分顶级候选词留在身边，从而在搜索空间更好地探索所有可能的翻译。 Beam 的大小称为“宽度”width；大小为 10 的宽度基本就够了。以下是 Beam search 的示例： 其他技巧：超参数 有些超参数能带来性能的进一步提升。以下是根据我们的经验列出的一些超参数： 优化函数：虽然在“不太熟悉”的架构里，Adam 能带来不错的结果，但如果你能训练 SGD，SGD 通常会更好；- 注意力：Bahadnau 风格的注意力需要解码器双向性才好用；Luong 风格的注意力在不同设置下都挺好。在这份教程中，我们推荐两个变体： scaled_luong &amp; normed bahdanau其他技巧：多 GPU 训练 训练一个 NMT 模型需要好几天。将不同的 RNN 层放在不用的 GPU 上能提升训练速度。以下为一个例子： 你可能会发现，随着 GPU 数量的增长，基于注意力的 NMT 模型训练速度提升非常有限。这是因为标准注意力架构在每个时间步长使用顶层（最后一层）的输出做为 query 注意力。这意味着每一次解码都需要等前面的步骤完全结束了才行。因此，无法在多台 GPU 上并行解码 RNN。 谷歌提出的 GNMT 注意力架构使用底层（第一层）输出作为 query 注意力。因此，前一步刚刚结束就能实行注意力计算。我们实现了 GNMTAttentionMultiCell 中的架构，这是 tf.contrib.rnn.MultiRNNCell 的一个子类。 以下是使用 GNMTAttentionMultiCell 创建解码器单元的示例： 最后的基准部分请参考原文。 原文：https&#58;//github.com/tensorflow/nmt 点击阅读原文查看新智元招聘信息 转载来源：「TensorFlow 谷歌神经机器翻译」从零开始打造属于你的翻译系统]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Google翻译</tag>
        <tag>英语</tag>
        <tag>语音识别</tag>
        <tag>TED</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度 | 理解深度学习中的卷积]]></title>
    <url>%2F2017%2F19726d11%2F</url>
    <content type="text"><![CDATA[深度 | 理解深度学习中的卷积 转载来源：深度 | 理解深度学习中的卷积]]></content>
      <tags>
        <tag>机器之心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手把手教你打造一个曲风分类机器人]]></title>
    <url>%2F2017%2F0d0d3374%2F</url>
    <content type="text"><![CDATA[手把手教你打造一个曲风分类机器人 转载来源：手把手教你打造一个曲风分类机器人]]></content>
  </entry>
  <entry>
    <title><![CDATA[万字「全文」详解谷歌神经网络机器翻译NMT，人人可利用TensorFlow快速建立翻译模型]]></title>
    <url>%2F2017%2Fa87e959c%2F</url>
    <content type="text"><![CDATA[图：pixabay 原文来源：Google Research Blog、GitHub 作者：Thang Luong、Eugene Brevdo、Rui Zhao 「机器人圈」编译：BaymaxZ、嗯~阿童木呀、多啦A亮 机器翻译作为自动翻译语言之间的任务，是机器学习社区中最活跃的研究领域之一。在机器翻译的众多方法中，序列到序列（“seq2seq”）模型最近取得了巨大的成功，并已成为大多数商业翻译系统中的标准。然而，虽然seq2seq模型（如OpenNMT或tf-seq2seq）上有大量的材料，但是缺乏教学人员知识和技能的材料，可以轻松构建高质量的翻译系统。 近日，TensorFlow在GitHub上宣布一个新的神经机器翻译（NMT）教程，让读者能够充分了解seq2seq模型，并展示如何从零开始构建翻译模型。 •简介 •基础 oNMT背景知识 o安装教程 o训练 – 如何构建首个NMT系统 降维 编码 解码 损失 梯度计算和优化 o实践——让我们来训练NMT模型l o推理——如何生成翻译 •中级 o注意力机制背景知识 o注意力包装器 API o实践——建立基于注意力的NMT模型 •提示和技巧 o建立训练、评估和推理图 o数据输入流水线 o其他细节 双向循环神经网络 集束搜索 超参数 多GPU训练 •测试基准 oIWSLT 英语到越南语 oWMT 德文到英文 oWMT 英文到德文 — 完全比较 •其他资源 •声明 •参考 简介 序列到序列（seq2seq）模型在诸如机器翻译、语音识别和文本概括等各项任务中，取得了巨大的成功。本教程为读者提供了对seq2seq模型的全面介绍，并展示了如何从头构建一个seq2seq模型。我们专注于神经机器翻译（NMT）的任务，这是第一个成功的seq2seq模型的测试平台。包含的代码是轻量级的、高质量的、生产就绪的，并与最新的研究思想结合在一起。我们通过以下方式实现此目标： 1.使用最新的解码器/注意力包装器API，TensorFlow 1.2数据迭代器； 2.结合了我们在建立循环和seq2seq模型方面的专长； 3.提供提示和技巧，以构建最好的NMT模型，并复制Google的NMT（GNMT）系统； 我们认为重要的是，提供人们可以轻松复制的基准。因此，我们提供了完整的实验结果，并对以下公开数据集的模型进行了预先训练： 1.小规模：由IWSLT评估组织提供的平行语料库，包含TED谈话中的英语到越南语的133000个句子对； 2.大规模：WMT评估组织提供的德语到英语的平行语料库（450万个句子对）； 我们首先介绍关于NMT的seq2seq模型的一些基本知识，说明如何构建并训练vanilla NMT模型。第二部分将详细介绍建立一个高效的NMT模式的注意力机制。然后，我们将讨论提示和技巧，以构建最佳的NMT模型（包括速度和翻译质量），例如TensorFlow最佳实践（批处理、降级），双向RNN和集束搜索。 基础 •NMT背景知识 回到过去，传统的基于短语的翻译系统将源语句分解成多个组，然后逐句翻译。这导致翻译产品不一致性，而且翻译的水平跟人类相比差异很大。人类通读整个源句，理解它的含义，然后再翻译。而神经机器翻译（NMT）正是这么模拟的！ 图1.编码器-解码器架构。NMT一般方法的示例。编码器将源句子转换成通过解码器传递以生成翻译的“含义”向量。 具体来说，首先，NMT系统使用编码器，读取源语句，以构建“思想”向量，表示句子意义的数字序列；然后，解码器处理句子向量，以发出翻译，如图1所示。这通常被称为编码器-解码器架构。以这种方式，NMT解决了传统的、基于短语的方法中的本地翻译问题：它可以捕获语言的长期依赖性，例如语法结构等等，并产生更流畅的翻译。 NMT模型因具体结构而有所不同。顺序数据的自然选择是大多数NMT模型使用的循环神经网络（RNN）。通常，RNN用于编码器和解码器。然而，RNN模型在以下方面会不同：（a）方向性——单向或双向; （b）深度——单层或多层；（c）类型——通常是vanilla RNN、长短期记忆网络（LSTM）或门控循环单元（GRU）。有兴趣的读者可以在这篇博文上找到有关RNN和LSTM的更多信息。 在本教程中，我们将一个深度多层RNN视为单向，并将LSTM作为循环单元。我们在图2中展示了一个模型的例子。在这个例子中，我们建立一个模型，将源句子“我是一个学生”翻译成一个目标句子“Je suisétudiant”。NMT模型由两个循环神经网络组成：编码器RNN简单地处理输入源句子，而不进行任何预测；另一方面，解码器在预测下一个单词的同时，处理目标句子。 有关更多信息，请参阅本教程的作者Luong于2016年撰写的文章。 图2.神经机器翻译将源语句“我是一名学生”翻译成一个目标句子“Je suisétudiant”，展示一个深度循环架构。这里，“”表示解码处理的开始，而“&lt;/ s&gt;”告诉解码器停止。 安装教程 要安装本教程，你需要在系统上安装TensorFlow。本教程需要安装最新版本的TensorFlow（版本1.2.1）。要安装TensorFlow，请按照安装说明进行操作。 一旦安装了TensorFlow，你便可以通过运行以下方式，下载本教程的源代码： 训练-如何构建你的第一个NMT系统 我们先来看看，构建一个具体代码片段的NMT模型的核心，我们将更详细的解释图2。数据准备和完整的代码将稍后介绍。这部分可参考文件model.py。 在底层，编码器和解码器RNN作为输入接收以下内容：首先，源语句，然后指示从编码到解码模式的转换的边界标记“”和目标句子。对于训练，我们将为系统提供以下张量，包含单词索引： encoder_inputs &#91;max_encoder_time，batch_size&#93;：源输入字。 decode_inputs &#91;max_decoder_time，batch_size&#93;：目标输入字。 decode_outputs &#91;max_decoder_time，batch_size&#93;：目标输出字，这些是decode_inputs向左移动一个时间段，右边附加一个句末尾标记。 为了提高效率，我们一次训练多个句子（batch_size）。测试略有不同，所以我们稍后再讨论一下。 降维 考虑到词语的分类性质，模型必须首先查找源和目标降维，以检索相应的词表示。为了使降维层可以工作，首先要为每种语言选择一个词汇表。通常，选择词汇大小V，并且只有最频繁的V被视为唯一的。所有其他单词都转换为“未知”令牌，并且都获得相同的降维。通常，降维权重在训练期间学习，每种语言一套。 同样，我们可以构建embedding_decoder和decode_emb_inp。请注意，可以选择使用预训练的单词表示（如word2vec或Glove向量）初始化降维权重。一般来说，考虑到大量的训练数据，我们可以用scratch来学习这些降维。 编码器 一旦检索到，则将词语降维作为输入馈送到主网络中，该主网络由两个多层RNN组成——源语言的编码器以及用于目标语言的解码器。这两个RNN原则上可以共享相同的权重; 然而，在实践中，我们经常使用两种不同的RNN参数（这些模型在拟合大型训练数据集时做得更好）。编码器RNN使用零向量作为其起始状态，建立过程如下： 请注意，句子具有不同的长度，以避免浪费计算，我们通过source_seqence_length告诉dynamic_rnn确切的源句长度。由于我们的输入是基于时间的，我们设置time_major = True。 在这里，我们只构建一个单层LSTM，encoder_cell。我们将介绍如何构建多层LSTM，添加dropout，并在后面的部分中使用注意力。 解码 解码器还需要访问源信息，一个简单的方法就是用编码器的最后一个隐藏状态（encode_state）来初始化它。在图2中，我们将源代码“学生”的隐藏状态传递到解码器端。 这里，这个代码的核心部分是BasicDecoder的对象，解码器，它接收decode_cell（类似于encoder_cell），一个帮助器，和作为输入的encoder_state。通过分离解码器和帮助器，我们可以重用不同的代码库，例如，可以用GreedyEmbeddingHelper替代TrainingHelper进行贪婪解码。了解更多请查阅helper.py。 最后，我们还没有提到projection_layer，它是一个密集矩阵，将顶部隐藏状态转换为维度V的对数向量。我们在图2的最上面说明这一过程。 损失 鉴于上述情况，我们现在可以计算我们的训练损失： 这里，target_weights是与decode_outputs相同大小的零矩阵。它掩盖了值为0的目标序列长度之外的填充位置。 重要的注意事项：值得指出的是，我们用batch_size来划分损失，所以我们的超参数对batch_size是“不变的”。有些人将损失除以（batch_size * num_time_steps），它可以减少短句所造成的错误。更巧妙的是，我们的超参数（以前的方式应用）不能用于后一种方式。例如，如果两种方法都使用学习1.0的SGD（随机梯度下降），则后一种方法有效地使用了更小的1 / num_time_steps的学习速率。 梯度计算和优化 我们现在已经定义了我们的NMT的前进模式。计算反向传播传递只是几行代码的问题： 训练RNN的重要步骤之一是梯度剪切。在这里，我们按照规范剪辑。最大值max_gradient_norm通常设置为5或1的值。最后一步是选择优化器。Adam优化器是常见的选择，我们也选择学习率，学习率的值通常在0.0001到0.001之间；随着训练的进行，可以减少。 在我们自己的实验中，我们使用标准SGD（tf.train.GradientDescentOptimizer），具有降低的学习率调度，从而产生更好的性能。 参见基准。 实践——让我们来训练NMT模型 我们训练我们的第一个NMT模型，从越南语翻译成英语！ 我们的代码的入口是nmt.py。 我们将使用一个小型平行语言的TED谈话（133000个训练示例）来进行此练习。我们在这里使用的所有数据都可以在以下网址找到：https&#58;//nlp.stanford.edu/projects/nmt/。我们将使用tst2012作为我们的dev数据集，tst2013作为测试数据集。 运行以下命令下载培训NMT模型的数据： nmt/scripts/download_iwslt15.sh /tmp/nmt_data 运行以下命令开始训练： 上述命令在12个周期内，训练了一个具有128个隐藏单元和降维的2层LSTM seq2seq模型。 我们使用的dropout值为0.2（保持概率为0.8）。如果没有错误的话，我们应该在我们训练时看到类似于下面的日志。 查看train.py获取更多信息 我们可以在训练期间启动Tensorboard查看对模型的总结： 从英语和越南语训练反向翻译可以简单地实现： –src=en –tgt=vi 推理——如何生成翻译 当你训练你的NMT模型（一旦你拥有训练模型），你可以获得以前不可见的源语句的翻译。而这个过程就称为推理。训练和推理（测试）之间有明确的区别：在推理时，我们只能访问源语句，即编码器输入，而执行解码的方法有很多种。解码方法包括贪婪算法、采样和波束搜索解码。在这里，我们将讨论贪婪解码策略。 这个想法很简单，我们将图3中进行阐述： 1．我们依然使用与训练期间相同的方式对源语句进行编码从而获得encoder_state，并使用该encoder_state来初始化解码器。 2．一旦解码器接收到起始符号”“ （参见我们代码中的tgt_sos_id），解码（翻译）过程就开始了。 3．对于解码器端的每个时间步长，我们将RNN的输出视为一组逻辑。我们选择最可能的单词，id与最大逻辑值相关联，将其作为发出的单词（这就是“贪婪”行为）。例如在图3中，在第一解码步骤中，单词“moi”具有最高的翻译概率。然后，我们将这个词作为输入提供给下一个时间步长。 4．该过程将一直继续，直到生成句尾标记”“ 作为输出符号产生（参见我们代码中的tgt_eos_id）。 图3.贪婪解码——训练好的NMT模型如何使用贪婪搜索生成源语句“Je suisétudiant”的翻译。 第3步，是什么使推理与训练如此不同。推理使用的是模型预测的单词，而并非总是将正确的目标单词作为输入，以下是实现贪婪解码的代码。它与训练解码器非常相似。 在这里，我们使用的是GreedyEmbeddingHelper而不是TrainingHelper。由于我们预先不知道目标序列长度，所以我们使用maximum_iterations来限制翻译的长度。思路是将源句长度的两倍作为解码最大长度。 训练了一个模型后，我们现在可以创建一个推理文件并翻译一些句子： 注意，即使模型仍在训练中，但只要存在训练检查点，就可以运行上述命令。有关详细信息，请参阅inference.py。 中级 既然已经知晓最基本的seq2seq模型，那就来进一步完善！为了建立最先进的神经机器翻译系统，我们将需要更多的“秘密武器”：注意力机制，这是Bahdanau等人于2015年首次提出的，然后由Luong等人于2015年完善。注意力机制的关键在于，在翻译过程中通过对相关源文件内容进行“注意”，从而建立起目标文件与源文件之间的直接连接。注意力机制的一个很好的附加作用就是源句和目标句之间有个可便捷查看的对齐矩阵（如图4所示）。 图4.注意力可视化——源句和目标句之间的对齐示例。图像摘自（Bahdanau 等人在2015年发表的论文）。 请记住，在vanilla seq2seq模型中，当开始解码过程时，我们将最后的源状态从编码器传递到解码器中。这对于较短和中等长度的句子来说效果很好；但是，对于长句，单个固定大小的隐藏状态就成了信息瓶颈。注意力机制不是放弃在源RNN中计算的所有隐藏状态，而是提供了允许解码器窥视它们的方法（将它们视为源信息的动态存储器）。通过这样做，注意力机制改进了较长句子的翻译效果。现如今，注意力机制是一种流行的标准，并已经成功应用于许多其他任务中（包括图像字幕生成，语音识别和文本自动摘要）。 注意力机制的背景 我们现在在描述Luong等人在2015提出的注意力机制的一个实例，它已被用于包括像OpenNMT这样的开源工具包在内的多个最先进的系统，以及本教程中的TF seq2seq API中。我们还将提供与注意力机制其他变体的连接。 图5.注意力机制——（Luong等人于2015所著论文）中描述的基于注意力的NMT系统的示例。我们详细介绍了注意力计算的第一步。为了清晰起见，我们不在图（2）中显示降维和投影层。 如图5所示，注意力计算发生在每个解码器的时间步长中。它包括以下阶段： 1.将当前目标隐藏状态与所有源状态进行比较，以获得注意力权重（如图4所示）。 2.基于注意力权重，我们计算上下午矢量作为源状态的加权平均值。 3.将上下文矢量与当前目标隐藏状态相结合，产生最终的注意力向量。 4.注意向量作为输入馈送到下一个时间步长（输入馈送）。前三个步骤可以通过以下等式来总结： 在这里，函数score用于将目标隐藏状态$$h_t$$ 与每个源隐藏状态$$\overline&amp;#123h&amp;#125_s$$进行比较，并将结果归一化以产生注意权重（源位置的分布）。评分函数有多种选择；通用的评分函数包括方程式中（4）给出的乘法和加法形式。一旦计算，注意力矢量 $$a_t$$ 用于导出softmax logit和loss。这类似于vanilla seq2seq模型中顶层的目标隐藏状态。函数f也可以采取其他形式。 注意力机制的各种实现可以在attention_wrapper.py中找到。 •注意力机制中有什么是重要的？ 如上述方程式所示，有许多不同的注意事项。这些变体取决于评分函数和注意力函数的形式，以及在评分函数中是否使用的是先前的状态$$h_&amp;#123t-1&amp;#125$$， 而不是Bahdanau等人在2015年提出的的 $$h_t$$。根据经验来说，我们发现只有某些选择是很重要的。首先，注意力的基本形式，即目标和来源之间的直接关系。其次，将注意力向量向下馈送到下一个时间步长，以便通知网络关于过去的注意决定，正如Luong等人在2015年论文中所演示的那样。最后，评分函数的选择往往会导致不同的表现。参见基准测试结果部分。 注意力包装器 API 在执行注意力包装器时，我们借鉴了（本论文）在内存网络方面的一些术语。本教程中介绍的注意力机制是只读内存，而不是具有可读写的内存。具体来说，引用一组源隐藏状态（或其转换版本，例如，Luong评分方式中的$$W\overline&amp;#123h&amp;#125_s$$或者Bahong评分方式中的 $$W_2\overline&amp;#123h&amp;#125_s$$）来作为“记忆”。在每个时间步长中，我们使用当前目标隐藏状态作为“查询”来决定要读取内存的哪个部分。通常，查询需要与对应于各个内存插槽的keys进行比较。在上述注意力机制的介绍中，我们恰好将源隐藏状态（或其转换版本，例如Bahdanau评分风格中的$$W_1h_t$$ ）用作“keys”。这是一个可以从这种记忆网络术语中得到启发，以获得其他形式的注意的机制！ 得益于注意力包装器，延长我们的vanilla seq2seq代码的注意力就变得微不足道了。这部分可参考文件attention_model.py 首先，我们需要定义注意力机制，例如（Luong等人在2015所著论文中那样）： 在以前的编码器部分中，encoder_outputs是顶层所有源隐藏状态的集合，其形状为&#91;max_time，batch_size，num_units&#93;（因为我们将dynamic_rnn与time_major设置为True以达到高效的效果）。对于注意力机制来说，我们需要确保传递的“记忆”是批处理的，所以我们需要转置attention_states。我们将source_sequence_length传递给注意力机制，以确保注意权重正确归一化（仅在非填充位置上）。 定义了注意力机制后，我们使用AttentionWrapper来包装解码单元格： 代码中的其余部分与Section Decoder中的代码几乎相同！ 动手实践——建立以注意力为基础的NMT模型 为了确保能够维持注意力，我们需要使用luong, scaled_luong, bahdanau或normed_bahdanau中的一个作为训练期间的attention标志的值。该标志指定了我们将要使用的注意力机制。此外，我们需要为注意力模型创建一个新的目录，所以我们不用重复使用以前训练过的基本NMT模型。 运行以下命令从而开始训练： 训练后，我们可以使用相同的具有新的model_dir的推理命令，进行推理： 提示与技巧 •建立训练、评估和推理图形 在TensorFlow中构建机器学习模型时，最好建立三个独立的图形： •训练图，其中： 批处理、降级操作和可能的子样本从一组文件/外部输入中输入数据。 包括正向和反向操作。 构建优化器，并添加训练操作。 •评估图，其中： 从一组文件/外部输入中输入数据进行批处理和降级操作。 包括正向训练操作和不用于训练的其他评估操作。 •推理图，其中： 可能不会批量输入数据。 不会对数据进行子采样或者降级处理。 从占位符读取输入数据（数据可以通过feed_dict或C ++ TensorFlow服务二进制文档直接提供给图表）。 包括模型正向操作的一个子集，以及可能的用于存储session.run调用之间状态的附加特殊输入/输出。 构建单独的图表有几个好处： •推理图通常与其他两个不同，因此分开构建是有意义的。 •评估图变得更简单，因为它不再具有所有额外的反向运算。 •可以为每个图分别实现数据馈送。 •可变重用简单得多。例如，在评估图中，不需要重新打开具有reuse = True的可变范围，因为训练模型已经创建了这些变量。因此，相同的代码可以重用，而无需在任何地方都使用reuse = arguments。 •在分布式训练中，工作人员分别进行训练，评估和推理是很平常的。这些都需要建立自己的图形。因此，以这种方式构建系统将为你进行分布式训练做好准备。 复杂性的主要来源在于如何在单个机器设置中的三个图表中共享变量。这通过在每个图形中使用单独的会话来解决。训练会话定期保存检查点，并且评估会话，并推断会话会从检查点中恢复参数。下面的例子显示了两种方法的主要区别。 之前：三个模型在单个图表中共享单个会话 之后：三个模型在三个图表中，三个会话共享相同的变量 请注意后一种方法如何“准备”转换为分布式版本。 新方法的另一个区别在于，我们使用有状态的迭代器对象，而不是使用feed_dicts来在每个session.run调用（从而执行我们自己的批处理、降级和操作数据）中提供数据。这些迭代器使输入流水线在单机和分布式设置中都容易得多。我们将在下一节中介绍新的输入数据流水线（在TensorFlow 1.2中介绍）。 数据输入流水线 在TensorFlow 1.2之前，用户有两种方式将数据提供给TensorFlow训练和评估流水线： 1.直接通过feed_dict使用每个训练session.run读取数据。 2.在tf.train（例如tf.train.batch）和tf.contrib.train中使用排队机制。 3.使用像tf.contrib.learn或tf.contrib.slim这样的更高级别的框架帮助器。 第一种方法对于不熟悉TensorFlow的用户来说更容易，或者只需要在Python中完成异步输入修改（即自己的小型排队）即可。第二和第三种方法更加标准，但灵活性稍差一些，他们还需要启动多个python线程（队列运行器）。此外，如果使用不正确的队列可能会导致死锁或不透明的错误消息。然而，队列比使用feed_dict更有效，并且是单机和分布式训练的标准。 从TensorFlow 1.2开始，有一个新的系统可用于将数据读入TensorFlow模型：数据集迭代器，如tf.contrib.data模块中所述。数据迭代器是灵活的，易于理解和操纵，并通过利用TensorFlow C ++运行时提高效率和多线程。 可以从批量数据Tensor，文件名或包含多个文件名的Tensor创建数据集。例如： 所有数据集可以通过输入过程进行相似的处理。这包括读取和清理数据、降级（在训练和评估的情况下）、过滤和批处理。 要将每个句子转换成字串的向量，例如，我们使用数据集映射转换： 我们可以将每个句子向量切换成一个包含向量和它的动态长度的元组： 最后，我们可以对每个句子执行词汇查找。给定一个查找表对象表，该映射将第一个元组元素从字符串向量转换为整数向量。 连接两个数据集也很容易。如果两个文件包含彼此的逐行翻译，并将每个文件读入其自身的数据集，则可以通过以下方式创建一个包含压缩行元组的新数据集： 可变长度句子的分批是很直接明确的。以下转换从source_target_dataset批处理batch_size元素，并将源和目标向量分别贴到每个批次中最长源和目标向量的长度。 从此数据集发出的值将是嵌套元组，其张量具有最大尺寸为batch_size的尺寸。 结构将是： 1.迭代器&#91;0&#93; &#91;0&#93;具有批量和填充的源句子矩阵。 2.迭代器&#91;0&#93; &#91;1&#93;具有批量的源大小向量。 3.迭代器&#91;1&#93; &#91;0&#93;具有批量和填充的目标句子矩阵。 4.迭代器&#91;1&#93; &#91;1&#93;具有批量的目标大小向量。 最后，也可以将类似大小的源句子批量化在一起。有关详细信息和完整实现，请参阅utils / iterator_utils.py文件。 从数据集读取数据需要三行代码：创建迭代器，获取其值并初始化它。 一旦迭代器被初始化，访问源或目标张量的每个session.run调用将从基础数据集请求下一个小型数据。 更好的NMT模型的其他细节 •双向RNN 编码器侧的双向性通常会提供更好的性能（随着使用更多的层，速度有一些降低）。 在这里，我们给出一个简单的例子，说明如何用单个双向层构建编码器： 变量encoder_outputs和encoder_state可以与编码器一样使用。 请注意，对于多个双向层，我们需要对编码器_state进行一些操作，有关详细信息，请参阅model.py，更多细节请运行_build_bidirectional_rnn()。 集束搜索 虽然贪婪解码可以给我们相当合理的翻译质量，但是集束搜索解码器可以进一步提高性能。集束搜索的想法是通过在我们翻译的同时，保留一小堆顶级候选来更好地探索所有可能的翻译的搜索空间。集束的大小称为波束宽度；大小为10的最小波束宽度通常是足够的。有关更多信息，请参阅Neubig的第7.2.3节（2017）。 以下是集束搜索如何完成的示例： 请注意，使用相同的dynamic_decode（）API调用，类似于Section解码器。一旦解码，我们可以访问如下的翻译： 有关详细信息，请参阅model.py，或_build_decoder（）。 超参数 有几个超参数可以导致额外的性能。在这里，我们根据自己的经验列出一些&#91;免责声明：其他人可能不会同意我们写的内容！&#93;。 优化器：虽然Adam可以导致“陌生”体系结构的合理化，但如果你可以使用SGD训练，一般会导致更好的性能。 注意力：Bahdanau方式的注意力往往要求编码器方面的双向性运作良好; 而Luong方式的注意力往往适用于不同的设置。对于本教程代码，我们建议使用Luong＆Bahdanau方式的注意力的两个改进的变体：scaling_luong和normed bahdanau。 多GPU训练 训练NMT模型可能需要几天时间。 在不同的GPU上放置不同的RNN层可以提高训练速度。 以下是在多个GPU上创建RNN图层的示例。 此外，我们需要在tf.gradients中启用colocate_gradients_with_ops选项来并行化梯度计算。 你可能会注意到，随着GPU数量的增加，基于NMT模型的注意力的速度提高非常小。标准注意力架构的一个主要缺点是在每次步骤中使用顶层（最终）层的输出来查询注意力。这意味着每个解码步骤必须等待其前一步骤完成；因此，我们无法通过简单地将RNN层放置在多个GPU上来并行化解码过程。 GNMT注意力架构通过使用底部（第一）层的输出来查询注意力来并行化解码器的计算。因此，一旦上一步的第一层和注意力计算完成，每个解码步骤就可以开始。我们在GNMTAttentionMultiCell中实现了该架构，这是tf.contrib.rnn.MultiRNNCell的子类。以下是使用GNMTAttentionMultiCell创建解码器单元的示例。 基准 IWSLT英语到越南语 练习：133000个案例, dev=tst2012, test=tst2013，下载脚本。 训练细节：我们用双向编码器（即编码器的1个双向层）训练512单位的2层LSTM，降维dim为512. LuongAttention（scale = True），dropout keep_prob=0.8。所有参数都是一致的。我们使用学习率1.0的SGD如下：训练12000步（〜12个周期）; 经过8000步，我们每1000步开始减半学习率。 结论：TODO（rzhao）：添加从英文到越南语训练模型的URL。 以下是2个模型（模型1、模型2）的平均结果。 我们用BLEU评分来衡量翻译质量（Papineni 等人于2002年提出）。 训练速度： TitanX上K40m的（0.37s步进时间，15.3K wps）（0.17s步进，32.2K wps）。 这里，步进时间是指运行一个小批量（大小128）所需的时间。 对于wps，我们计算源和目标上的单词。 WMT：从德语到英语 训练：450万个样例，dev = newstest2013，test = newstest2015 下载脚本 训练细节：我们训练超参数的过程与英语到越南语的实验类似，但以下细节除外。使用BPE https&#58;//github.com/rsennrich/subword-nmt（32000个操作）将数据拆分为子字单元。我们用双向编码器（即编码器的2个双向层）训练1024单位的4层LSTM，降维dim为1024。我们训练350000步（〜10个周期）；在170000步之后，我们每17000步开始减半学习率。 结论：TODO（rzhao）：添加德文到英文训练模型的URL。 前2行是2个模型（模型1、模型2）的平均结果。 第三行的结果是使用GNMT注意力（&#91;model&#93;（LINK））在4个GPU上运行结果。 这些结果表明我们的代码为NMT建立了强大的基准系统。（请注意，WMT系统通常会使用我们目前没有的大量单语数据。） 训练速度：Nvidia K40m（2.1s步进时间、3.4K wps），Nvidia TitanX（0.7s步进、8.7K wps）。 我们仅对K40m进行了基准测试： 这些结果表明，没有GNMT注意力，使用多个GPU的收益是最小的。 如果有GNMT注意力，我们从多个GPU获得了50％-100％的加速。 WMT：英语到德语——完全比较 前两行是我们的GNMT注意力模型：模型1（4层）、模型2（8层）。 上述结果表明，我们的模型在类似架构的模型中具有很强的竞争力。 &#91;注意，OpenNMT使用较小的模型，目前的最佳结果（截至本文中）为28.4，由Transformer network（Vaswani等人于2017年提出）获得，其具有明显不同的架构。 其他资源 为了深入了解神经机器翻译和序列模型，我们强烈推荐以下材料：Luong，Cho，Manning（2016）、luong（2016），以及Neubig（2017）。 很多工具可以构建seq2seq模型，所以我们可以选择其中一种语言： Stanford NMT https&#58;//nlp.stanford.edu/projects/nmt/ &#91;Matlab&#93; tf-seq2seq https&#58;//github.com/google/seq2seq &#91;TensorFlow&#93; Nemantus https&#58;//github.com/rsennrich/nematus &#91;Theano&#93; OpenNMT http&#58;//opennmt.net/ &#91;Torch&#93; 声明 我们要感谢Denny Britz、Anna Goldie、Derek Murray和Cinjon Resnick为TensorFlow和seq2seq库带来了全新功能。另外感谢Lukasz Kaiser对seq2seq代码库的初步帮助； Quoc Le为复制GNMT提出的建议; Yonghui W和Zhifeng Chen对于GNMT系统的细节贡献， 以及谷歌大脑团队的支持和反馈！ 转载来源：万字「全文」详解谷歌神经网络机器翻译NMT，人人可利用TensorFlow快速建立翻译模型]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>英语</tag>
        <tag>脚本语言</tag>
        <tag>机器人</tag>
        <tag>WPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Facebook AI研究院提出了创造性对抗网络CAN，AI的艺术造诣也要超过人类了]]></title>
    <url>%2F2017%2F718d2bae%2F</url>
    <content type="text"><![CDATA[雷锋网 AI 科技评论按：能够迭代进化、模仿指定数据特征的GAN（生成式对抗性网络）已经是公认的处理图像生成问题的好方法，自从提出以来相关的研究成果不少，在图像增强、超分辨率、风格转换任务中的效果可谓是惊人的。 （具体可以参见 Valse 2017 | 生成对抗网络（GAN）研究年度进展评述 - 雷锋网） 利用GAN达到图像超分辨率和风格转换示例今年也有利用GAN做的简笔画到图像转换模型pix2pix（代码地址 https&#58;//github.com/phillipi/pix2pix，demo地址https&#58;//affinelayer.com/pixsrv/）。除了下图转换猫的，还有建筑物的、鞋子的、包包的，模型非常有想象力，随便画也没关系，感兴趣的读者可以自己到demo地址里画画看。 demo中用把线条转换成猫的示例GAN能生成艺术作品吗？GAN既然已经有如此的图像生成能力了，我们能不能用GAN生成艺术作品呢，毕竟许多现代艺术作品看照片好像也并不怎么复杂，比如下面这幅；超写实主义的就更不用说了。 蒙德里安《红黄蓝的构成》然而，要创造出一副人类觉得有艺术价值的作品并没有那么简单。人类喜欢创新性的作品，人类不喜欢完全模仿的作品；《蒙娜丽莎》和《兰亭集序》只有原作者的原版才被认可是世界艺术瑰宝，后世的人就算基于它们创作，也要有自己的创新，才能带来新的艺术价值，才能被观赏者认可。 根据GAN的基本结构，鉴别器D要判断生成器G生成的图像是否和其它已经提供给鉴别器D的图像是同一个类别（特征相符），这就决定了最好的情况下输出的图像也只能是对现有作品的模仿，如果有创新，就会被鉴别器D识别出来，就达不成目标了。上面几个GAN的例子就能体现出鉴别器D带来的这个特点，用GAN生成的艺术作品也就注定缺乏实质性的创新，艺术价值有限。 那么，能不能让GAN具有一些创新的能力，让这些创新有艺术价值、带有这些创新的作品还能够被人类认可呢？罗格斯大学艺术与人工智能实验室、Facebook人工智能研究院（FAIR）、查尔斯顿学院艺术史系三方合作的这篇论文就通过CAN（Creative Adversarial Network，创造性对抗网络）给出了一种答案。神经网络库Keras的作者François Chollet也在Twitter上推荐了这篇文章。 先看看作品如何CAN模型生成的一些艺术作品可以看到，生成的艺术作品风格非常多样，从简单的抽象画到复杂的线条组合都有，内容层次也有区分。论文中也有对比测试结果，CAN生成的作品不仅比GAN生成的更讨人喜欢，甚至来自巴塞尔艺术展的人类艺术作品都比不上CAN。（具体数据看后文） 如何认识艺术创新刚才说到，艺术作品需要有创新性，CAN中的C就是Creative，创新性的意思。那么创新性要如何衡量呢、如何达到呢？ 以往基于GAN的图像生成方法研究中，人类可以把训练好的网络生成的图像和客观事实相对比（超分辨率、图像补全问题中）或者根据经验判断（风格转换问题中），用来衡量网络的效果；也有过一些更早期的算法，让人类作为训练反馈的一环，引导网络的训练过程。但是对于这次的课题需要设计一个能自动训练和生成、还要衡量作品的创新性的系统而言，以往的方法就起不到什么帮助。 同时，在作者们看来，为了能模仿人类艺术创作的过程，算法中很重要的一部分就是要把算法的创意过程和人类艺术家以往的艺术作品联系起来，像人类一样把对以往艺术的理解和创造新艺术形态的能力整合在一起。 为了能够想办法找到一个能够衡量创新性、参与迭代训练的创新性指标，作者们找来了一组艺术理论。 D.E.Berlyne认为，从生理心理学的角度讲，人类的状态中有一种叫做“唤醒水平”的指标，它可以衡量一个人有多警醒、多兴奋；唤醒水平可以从最低的睡觉、休息，一直到暴怒、激动。而一副作品具有“唤醒潜力”的总体特质，它可以提升或者降低观者的唤醒水平；它是作品新颖性、意外性、复杂性、多义性和疑惑性高低的综合体现，这几个属性越高，作品的唤醒潜力就越高。- Colin Martindale（1943-2008）提出过一个假说，他认为在任一时刻，创意艺术家们都会尝试增加他们作品的“唤醒潜力”，这就是一种拓宽创作习惯边界的方法。但是，这种增加动作必须使得观察者的负面反应尽可能小（尽量使观察者不付出额外的努力），否则过于激进的产品就会受到负面的评价。- Colin Martindale还提出过一个假说，他认为当艺术家探索艺术风格的更多作用的时候，转换艺术风格就会有提高“唤醒潜力”的作用。 这组理论只是解释艺术创新的理论中的寥寥几个，但是它们综合起来给出了两个具有计算性的、可以用于迭代训练的指标： 创新作品的创新程度不能过高，观者不认为作品是艺术作品的可能性应当尽可能小；1. 新的艺术风格就是创新的体现。新的艺术风格就是创新的体现。 CAN网络的构建根据提炼出的这两个指标，论文中基于GAN的原型构建了这样一种新型的对抗性网络CAN。 CAN模型的系统框图首先，对于“指标1：创新作品的创新程度不能过高，观者不认为作品是艺术作品的可能性应当尽可能小”，就可以转换为经典的对抗性网络，G生成图像，经过艺术作品训练过的D判断G生成图像的是不是艺术作品。这样的对抗性网络生成的图像就已经可以被人类看作是艺术作品。 然后，论文中的模型还根据“指标2：新的艺术风格就是创新的体现”增加了一部分新结构用来处理艺术风格。 论文中使用了25类不同的带标签艺术作品用于D的训练，包含了抽象印象派、立体派、现代派、巴洛克、文艺复兴早期等等风格的共7万5千多幅。然后经过训练的D除了要反馈一幅图像“是否是艺术作品”外，还要反馈“能否分辨图像是哪种艺术风格”。G然后就会利用D的反馈生成尽量难以分辨艺术风格的图像——难以归类到现有分类中的，就是创新了。 “是否是艺术作品”、“是否难以分辨艺术风格”是两种对立的信号，前一种信号会迫使生成器G生成能够被看作的艺术的图像，但是假如它在现有的艺术风格范畴中就达到了这个目标，鉴别器D就能够分辨出图像的艺术风格了，然后生成器就会受到惩罚。这样后一种信号就会让生成器生成难以分辨风格的作品。所以两种信号就可以共同作用，让生成器能够尽可能探索整个创意空间中艺术作品的范围边界，同时最大化生成的作品尽可能游离于现有的标准艺术风格之外。 这也就是论文标题「CAN&#58; Creative Adversarial Networks Generating “Art” by Learning About Styles and Deviating from Style Norms」的含义，创造性对抗网络可以学习艺术风格，然后背离这些现有的风格进行艺术创作。 还说艺术风格，现在是“不好分辨”，“好分辨”不行吗？相比GAN，CAN增加的反馈是“是否难以分辨艺术风格”，追求的是生成的图像艺术风格难以分辨。虽然根据艺术理论的推导，新的艺术风格是一种创新，但既然是多加了一个反馈，追求“生成的图像艺术风格容易分辨”可以吗？会不会也能生成不错的作品呢？ 从另一个角度看，假如追求“难以分辨”的CAN确实比追求“容易分辨”的CAN生成的图像更好，那这就是模型选取了合理的反馈的最佳体现。 说做就做。除了CAN之外，论文中还建立了三种模型用来对比。 DCGAN 64x64：经过艺术作品训练的DCGAN（深度卷积生成式对抗网络），输出分辨率为64x64- DCGAN 256x256：相比DCGAN 64x64，生成器多加了两层网络，输出分辨率为256x256- scCAN：style-classification-CAN，追求“生成的图像艺术风格容易分辨”的CANDCGAN 256x256：相比DCGAN 64x64，生成器多加了两层网络，输出分辨率为256x256 这三种模型生成的画面像下面这样 两种DCGAN和scCAN生成的画面scCAN生成的画面中确实有了可辨认的风格，比如人物特写、风景或者群像。但是直观看上去并不怎么讨人喜欢。 让我们再来看一组CAN生成的图像，上方是人类评价最高的、下方是人类评价最低的。应该说都比scCAN生成的图像精彩得多。 人类评价最高和最低的CAN生成的图像人类能给CAN的图像打几分？根据刚才的图像可以看到，CAN的效果当然不错，DCGAN 256x256的图像其实也挺好。那么CAN的图像对观画的人来说是不是真的已经难以分辨创作者了呢？跟真的艺术家创作的作品相比高下又如何呢？ 为了具体比较，论文中做了几个实验，让人类给不同组的作品打分。 实验1、2：来自抽象印象派艺术家的作品、选自巴塞尔艺术展的作品、CAN生成的图像、DCGAN生成的图像，一共4组作品，由普通人判断这些作品来自人还是电脑，并给作品打分。 结果：实验1里有53%的人认为CAN的图像是来自人类的，认为DCGAN 64x64的图像来自人的有35%； 实验2里认为CAN的图像来自人类的比例是75%，DCGAN 256x256则是65%。来自抽象印象派艺术家的作品无疑是比例最高的，但有意思的是，两个实验里认为巴塞尔艺术展的作品来自人的比例都还不如CAN高（实验1中41%，实验2中48%）。 实验2的结果数据，先让人类评价者从几个角度评价作品，再判断是否是人类创作的。认为图像是人类创作的评价者比例为Q6实验3：让人类评价者从用心程度、视觉结构、互动性、启发性几个角度给作品评分，结果CAN全部得分最高。这个结果可谓出人意料。 实验3结果数据实验4：为了确认CAN和scCAN之间新颖性和美学表现的高低，请了一群艺术史学生对随机选出的CAN和scCAN图像进行评价。认为CAN的图像更新颖的比例为59.47%，认为CAN的图像更加有美学吸引力的比例为60%，确实有显著区别。 结论论文中表示，虽然这样的模型还是不能对艺术风格概念有任何语义方面的理解，不过它确实展现出了从以往的艺术作品中学习的能力。至于为什么人类会在多个方面给CAN打出高分，作者们也希望和大家进行开放性的探讨。 论文原文地址： https&#58;//arxiv.org/abs/1706.07068，雷锋网 AI 科技评论编译 转载来源：Facebook AI研究院提出了创造性对抗网络CAN，AI的艺术造诣也要超过人类了]]></content>
      <categories>
        <category>文化</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>艺术</tag>
        <tag>Facebook</tag>
        <tag>蒙娜丽莎的微笑</tag>
        <tag>蒙德里安</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无人机消费者报告]]></title>
    <url>%2F2017%2F4bb57de0%2F</url>
    <content type="text"><![CDATA[无人机消费者报告 转载来源：无人机消费者报告]]></content>
      <tags>
        <tag>爱否科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[市售主流 55 寸电视横评，教你如何选电视 | 消费者报告]]></title>
    <url>%2F2017%2F8c838c11%2F</url>
    <content type="text"><![CDATA[市售主流 55 寸电视横评，教你如何选电视 | 消费者报告 转载来源：市售主流 55 寸电视横评，教你如何选电视 | 消费者报告]]></content>
      <tags>
        <tag>爱否科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kaggle百万美元大赛优胜者：用CNN识别CT图像检测肺癌]]></title>
    <url>%2F2017%2F84d64692%2F</url>
    <content type="text"><![CDATA[王小新 编译自GitHub 量子位 出品 | 公众号 QbitAI 今年，Kaggle网站举办了一场用肺部CT图像进行肺癌检测的比赛Data Science Bowl 2017，提供百万美元奖金池。美国国家癌症研究所为比赛提供了高分辨率的肺部CT图像，在比赛中，参赛者根据给定的一组病人肺部CT三维图像，预测癌症风险。 Julian de Wit和Daniel Hammack合作完成的解决方案获得了比赛的第二名。Wit最近写了一篇博客来介绍他们的方案。他们通过3D卷积神经网络，来构建结节探测器，预测患癌可能性。Wit在64位的Windows10系统下，结合TensorFlow 0.12.0和Keras库实现该网络模型。 BTW，第2名的奖金是20万美元。 以下内容编译自Wit的文章： 初步了解和制定计划在决定参赛之前，我观看了一个Bram van Ginneken关于肺部CT图像的介绍视频，有了基本的了解。我试图直接观察一些CT扫描样本，发现这是一个很难的问题，难度与大海捞针相当。视频中提到，图像的信噪比大约为1&#58;1000。论坛中的一些讨论也提到，神经网络不能直接从这些原始图像中学习到有用信息。目前只有1300个训练样本及对应的癌症标签，这与网络提取出的图像实际特征相差甚远。 我们希望获得更高信噪比的训练集，或是找到标签和图像特征之间更直接的关系，来训练神经网络。幸运的是，比赛组织者指出，可以借鉴一个先前举办的比赛LUNA16。在LUNA16数据集中，医生为800多个病人CT图像中精心标记了1000多个肺结节。当然，LUNA16比赛也提供没有标记结节的数据集。 因此，你可以从整体CT图像中的标记周围裁剪出小型3D图像块，最终可以用更小的3D图像块与结节标记直接对应。结节大小是癌症的一个影响因素，数据集也说明了结节的大小，所以我认为这是一个有用的信息。 图1：方法网络示意图 我还注意到LUNA16数据集是由另一个公开数据集LIDC-IDRI转化过来的。在原始数据集中，医生不仅要检测结节，而且还评估了结节的恶性程度和其他指标。我们发现，恶性程度是评估患癌风险的最佳指标，也是神经网络可以学习的。 最终的计划方案是训练一个神经网络来检测结节，并评估结节的恶性程度。在预测时，网络通过滑动窗口来遍历整体CT图像，分别判断每个滑动窗口的区域包含恶性信息的可能性。最后基于这种信息和其他特征，估计该患者发展成癌症的可能性。 数据预处理和创建训练集在预处理中，要使扫描图像的尺度尽可能一致。我首先重新缩放了CT图像，使每个像素点只表示1x1x1毫米的体积。我们也尝试了一些其他尺度的实验，最终确定了采用1毫米的尺度，这能很好地平衡计算精度和计算负荷。对于CT图像，像素强度可以用Hounsfield来表示，一般叫做亨氏单位。论坛里提到，要尽量降低像素强度，即最大化hounsfield值，然后归一化处理。同时还要确保所有CT扫描都具有相同的方向，因为CT图像旋转超过45度，意味着在图像采集过程中出现错误。 极大部分关于结节检测的文献都是先从CT扫描图像中分离出肺组织。然而目前没有合适的分割方法，能够很好地处理隐藏在肺组织边缘周围的结节和肿块。在CT图像中，这些区域会直接被删除，更不用说使用结节探测器进行类型判定。我想要训练一个U-net网络，来更好地分割肺部。与传统的分割方法相比，U-net网络能够更有效地解决实际的图像分割问题，在同为Kaggle举办的卫星图像分割比赛中被广泛地使用。当我观察这些CT图像时，我认为可以通过肺组织的边缘，构建框架来找到肺结节。这么做可能是有用的，最后我决定对原始图像进行训练和预测。在调整训练数据后，该网络效果不错，似乎没有负面影响。 在这个竞赛中，给定了训练数据，可能没有很大的发挥空间。然而处理训练集是必须的，但不是最重要的那部分工作。我使用样本中的标签，自动生成训练集的标签，也采用主动学习方法，添加部分人工标记。以下是带有标记的不同数据集。 表1：标记后的训练集 LIDC数据集中被正面标记的数量是LUNA16数据集样本数的五倍。因为这些标记是4名医生的综合注释，所以一个结节可能被标记了4次。但LUNA16也忽略了不到3名医生标注的结节。我决定在训练集中保留这些被忽视的结节，因为他们也提供了宝贵的结节恶性信息。 LUNA16 v2数据集的标签是直接从LUNA16传来，一般是多个结节检测系统错误标出的假阳性结节。要注意的是，部分结节是上面提到的不到3名医生标记的结节。我保留了这些结节标记，是为了平衡那些可疑的假阳性结节。 为了得到肺部轮廓，我需要得到非肺组织的底片。我使用了论坛中提到的简单肺分割算法，在分割掩码边缘周围进行采样标注，从而分割得到肺部组织。 在进行第一轮训练之后，我在LUNA16数据集上进行结节预测，得到了所有假阳性结节，也并入LUNA16 v2数据集中。 随着比赛的进行，我想建立第二个模型。对于这个模型，我做了放射科医生的工作，在NDSB数据集上训练网络。我手动地从癌症样本中选择明显的阳性结节，并从非癌症样本中选择假阳性结节，用这些数据训练了第二个模型。我希望效果不错，但我是一个不合格的放射科医生，实际上第二个模型比无手动标注的模型要糟糕得多。但是结合这两个模型，这个得到的融合模型比单独的模型效果更好，所以我保留了第二个模型。 我简单地建立了一个结节观察器，来调试所有的标记。在观察时，我注意到医生忽略了一些大于3cm的大结节。在LIDC数据集的说明文档中，我发现医生被要求忽略掉大于3cm的结节。我担心这些被忽视的结节区域会迷惑分类器，故删除了相重叠的底片。下面是肺部CT图像的一些截图。 图2：图像中的标记。 左上：LUNA16 v2数据，右上：非肺组织的边缘， 左下：假阳性的区域，右下：被移除的无标注区域。 3D卷积神经网络的训练方法和网络结构在一个高质量的训练集下，我们仍需要多次调整来有效地训练神经网络。数据集的两类样本量严重不平衡，正反两类样本量的比为5000：500000，且正面例子的大小和形状有很大差异。我曾考虑使用U-net网络，但2D U-net不能完全利用结节本身的三维结构信息，3D U-net网络的训练过程非常缓慢而且不灵活。我不使用U-net的主要原因是不需要建立细粒度的概率图，而只是一个粗略的检测器。在CT图像的滑动窗口中，建立小型的3D Convnet，这更加轻便和灵活。 我的第一个目标是训练一个可作为基础的结节检测器。我先要对正面例子进行过采样，将正反两类的样本比上调到1&#58;20。为了提高模型的泛化能力，我尝试了一些图像增强操作，但是只有一些无损的操作是有用的。最后我用了大量的转化操作和所有3D翻转操作。 设计好分类器后，我想训练一个用于估计恶化程度的回归模型。将肿瘤恶化程度分为从1（很可能不是恶性）到5（很可能是恶性的）。为了强调肿瘤的恶性程度，我将标签平方，范围扩大为从1到25。最开始，我考虑了分阶段的一种方法，用第一个网络来分类节点，然后训练另一个网络估计结节的恶化程度。为了缩短计算时间，我尝试只用一个网络，以多任务学习的方法，同时进行训练这两个任务。当编程实现后，我发现这个方法简单快速，网络的效果也很好。 通常，神经网络的结构是比赛和案例研究中最重要的成果之一。对于这场比赛，我在神经网络的结构上花费的时间相对较少，因为已经有很多优秀网络可供参考。刚开始我使用了一些简单的VGG网络和Resnet网络的相似结构，但是它们的性能大致相同。然后我尝试用一个预训练好的C3D网络，原有的网络权重根本没有帮助，但直接初始化权重后，这种网络结构的效果很好。基于C3D网络进行若干次调整后，我得到最终的分类评估网络。 我首先调整了输入大小，设置为32x32x32 mm。这看起来可能太小，但是在后续的网络层中加入一些技巧，发现这种维度的实际效果很好。这个想法是保持一切轻量化，并在比赛结束后再建立一个更大输入维度的网络。但是由于Daniel的网络输入是64x64x64 mm，我决定保持目前的输入大小，使网络的输出互补。接下来我立即对z轴进行平均池化操作，使得每个体素表示2mm的区域。这进一步减少了网络的参数量，并没有影响到精度，因为在大多数扫描中，z轴会比x轴和y轴更粗糙。最后，我在网络顶部引入了64个节点的全连接层。这里，我们不是直接预测恶性肿瘤，而是通过训练图片的中级特征，输出结节的恶化程度。 表2：3D Convnet的网络结构示意图 有趣的插曲：“奇怪组织”检测器看着论坛的帖子，我发现所有的团队都在做类似的工作，我也在寻找一个能直接上手的方法。在观察CT扫描图像时，我发现了一些其他的事情。与LUNA16数据集一样，大部分的工作集中在识别肺结节上。然而，当癌症发展时，它们转变成肺肿块或更复杂的组织。并且我注意到，当扫描图像中有很多“奇怪组织”时，它发展为癌症的概率更大。此外，在很多CT图像中，我的结节探测器没有发现任何结节，这造成了一些很不好的假阴性现象。 在训练集中有10例存在上述现象，其中的5例为癌症病例。为了解决这些严重的假阴性，在扫描时，需要检测获得奇怪组织的数量。很幸运，在LUNA16数据集上包含了很多这样的样本，所以我很快对数据集进行标记并训练了一个U-net网络。加入奇怪组织检测器后，效果不错，我因此提高了本地CV值和LB上的排名。因为它对于不同的模型提升不同，很难评定实际效果，但我认为它大约提升了0.002-0.005。说实话，我认为这种改进是一个创新性的补充。以下是一些包含有奇怪组织的样本。 图3：带有奇怪组织的CT图像样本。 肺气肿基本上是由吸烟导致的，我也试图建立一个肺气肿检测器。论坛上的医生都说，当肺气肿存在时，患有癌症的概率升高。有一些简单的算法公布了如何评估CT扫描中肺气肿区域的数量，设置hounsfield单位为950，来扫描CT图像。然而，我应用这种方法后，发现效果并不好。然后我标记了一些例子来训练一个U-net，发现效果不错，但是我的本地CV值没有丝毫提升。我的猜测是，因为肺部出现问题，进行扫描得到数据集中的许多病例，因此很多肺气肿样本没有看做是肺结节和癌症病例。我不能确定这个想法的正确性。 最后一步：癌症预测训练好网络后，下一步是让神经网络检测结节并估计其恶化程度。我建立的CT结节观察器很容易查看网络结果。我觉得神经网络的效果很好：它检测到了许多我完全忽视的结节，而我只看到很少量的假阳性结节。但是还存在一个严重的问题：由于它错过了一些非常大的明显结节，所以影响了对于假阴性的得分，有时使LogLoss升高了3.00。作为尝试，我试图对CT图像进行了两次降采样，看看检测器是否会检测大结节。值得注意的是，它的效果非常好。因此，我调整了网络结构，让网络预测3个尺度，分别为1，1.5和2.0。我觉得值得花这么多的时候来改善这方面的性能。 图4：在缩放1x的左图中，没有很好地检测到大结节；但是在2x放大的右图时，效果较好。矩形的大小表示坚持到的恶性肿瘤。 鉴于这些数据和一些其他特征，我想训练一个以梯度推进的分类器来预测一年内癌症的发病率，这是比较容易实现的。但是问题在于，排行榜的得分是基于给定的200名患者，这里面意外地包含了大量异常患者。经过一些调整后，我通过交叉验证得到了本地的平均值为0.39-0.40，而排行榜得分在0.44和0.47之间变化。此时很难将排行榜得分与本地CV值相关联。提高了本地CV值可能导致LB评分的降低，反之亦然。 我花了很多时间来研究本地CV值和LB评分的关系。我没有成功，所以我只使用能同时改进CV值和LB排名的技巧和特征。这是一场两阶段的比赛，而且与实际的训练集相比，第二阶段的数据存在与LB数据集更相似的可能。在这个地方，很多队伍也只能碰运气，结果显示排行榜上的很多队伍模型处于过拟合状态。最后我只使用7个特征来训练梯度推进器，分别是3个尺度下的最大恶性结节及其Z轴的位置和样本中奇怪组织的数量。 我也融合了两个模型来提高效果。第一个模型是在完整的LUNA16数据集上训练的。第二次，我试图从NDSB训练集中选择明显的阳性样本和假阳性样本，应用主动学习来训练。由于我不是放射科医师，所以我为了保险起见，只选择癌症病例的阳性例子和非癌症病例的阴性例子。我做错了，因为第二个模型比没有额外标注的LUNA16模型更糟糕。通过平均两个模型的输出，对LB排名有了很好的推动作用，并且显著提高了本地CV值。 与Daniel合作在进行机器学习比赛时，将不同角度的解决方案组合在一起往往是个好主意。我和Daniel在以前的医疗比赛中一起合作过，知道他是一个非常聪明的人，且他的参赛思路一般和我不同。他是从研究的角度来看问题，而我一般以工程的角度来看问题。当我们合作时，我们确信结合两者互补的方法，能有一个很棒的解决方案。 我们这次组队，一开始就发现两个人对LIDC数据集中的恶性信息有完全相同的观察角度，解决方案也很相似，感到有点失望。不过幸运的是，剩余部分的设计方法完全不同，结合后显著改进了LB排名和本地CV值。下面列举出一些主要的区别。 表3：Julian和Daniel之间设计方法的差异 强强联合是一个很好的选择。虽然我因为LB得分感到担忧，但Daniel觉得应该主要关注本地CV值。所以最终我减少研究本地CV值和LB的匹配关系，并着重于改进本地CV值。在最后的排行榜上，证明这是一个很好的决定，因为在最后，第二阶段的排行榜与本地CV值相当匹配，我们获得了比赛的第二名。尽管有许多队伍，在第一阶段取得了很好的排行榜得分，后来被证明模型过拟合。 总结与感想我们在观察网络对CT图像的结节检测时，模型效果很好。第一阶段，logloss为0.43，公开排行榜的ROC准确率为0.85，第二阶段，logloss为0.40，私人数据集的ROC准确率更高。这让我很兴奋，因为在这个数据集上，我们的模型已经是一位训练有素的放射科医生了。 对于放射科医师来说，这个自动结节检测的模型可能很有帮助，因为在实际判断中，部分结节容易被忽视。模型对肿瘤恶化程度的评估效果也很好，但训练样本量只有1000个，所以应该有很大的改进空间。 在Daniel和我合作的解决方案中，应用了相当多的工程办法，许多步骤和决定是基于经验和直觉来确定的。我们没有足够的时间来准确地验证所有方法的效果。下面提出进一步研究的一些建议。 1. 建立放射科医师基准线。根据一个放射学家在这个数据集上的具体表现，建立一个具有参考意义的基准。 2. 对NDSB数据集的恶性肿瘤标注。在这场比赛中，训练样本只有约1000个结节。输入更多精确标记的例子，肯定进一步提升算法准确度。 3. 尝试更多不同的神经网络结构。我花了很少时间来选择效果最佳的网络结构，可能会错过一些效果更好的结构。 相关资源这次比赛的Kaggle地址（含说明、数据集等）：https&#58;//www.kaggle.com/c/data-science-bowl-2017/ 文中提到的另一个比赛LUNA16：https&#58;//luna16.grand-challenge.org/ 该项目的完整程序请查看GitHub链接：https&#58;//github.com/juliandewit/kaggle_ndsb2017 Dan Hammack也公布了他的代码：https&#58;//github.com/dhammack/DSB2017/ （完） 招聘 量子位正在招募编辑记者、运营、产品等岗位，工作地点在北京中关村。相关细节，请在公众号对话界面，回复：“招聘”。 One More Thing… 今天AI界还有哪些事值得关注？在量子位（QbitAI）公众号会话界面回复“今天”，看我们全网搜罗的AI行业和研究动态。笔芯~ 转载来源：Kaggle百万美元大赛优胜者：用CNN识别CT图像检测肺癌]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>肺癌</tag>
        <tag>癌症</tag>
        <tag>Kaggle</tag>
        <tag>肺气肿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[和女当事人复原中金黄洁事件始末]]></title>
    <url>%2F2017%2F5ebd8403%2F</url>
    <content type="text"><![CDATA[和女当事人复原中金黄洁事件始末 转载来源：和女当事人复原中金黄洁事件始末]]></content>
      <tags>
        <tag>山石观市</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[干货|提高你设计审美的那些网站（一）]]></title>
    <url>%2F2017%2Fb2a8f283%2F</url>
    <content type="text"><![CDATA[干货|提高你设计审美的那些网站（一） 转载来源：干货|提高你设计审美的那些网站（一）]]></content>
      <tags>
        <tag>一个干货</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国金融圈里的 9 大派系（史上最全，推荐收藏）]]></title>
    <url>%2F2017%2F61a03c30%2F</url>
    <content type="text"><![CDATA[中国金融圈里的 9 大派系（史上最全，推荐收藏） 转载来源：中国金融圈里的 9 大派系（史上最全，推荐收藏）]]></content>
      <tags>
        <tag>华尔街见闻</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人的中小型项目前端架构浅谈]]></title>
    <url>%2F2017%2Fcbf020a5%2F</url>
    <content type="text"><![CDATA[一、为什么要有一个好的架构 首先明确一点，架构是为需求服务的。前端架构存在的目的，就我个人理解来说，有以下几点： 1. 提高代码的可读性 一个好的架构，代码的可读性一定是很强的。 简单来说，假如有一个新人加入团队，那么他接手这个项目，一定是容易上手的，能简单轻松的了解整个前端部分的相互关系，从而找到自己需要重点关注的点。而不是需要花很多时间去熟悉这个项目的很多细节，才能开始上手做东西。 就文件来说，可以从文件名上，分清哪些是页面、哪些是逻辑、哪些是样式、哪些是可以复用的组件、哪些是图标组、又有哪些是移动端或是PC端专享的样式/逻辑等。 就代码来说，包括统一的命名风格，封装在同一个文件里的代码的相关性足够强等。 2. 提高代码的可维护性 一个好的架构，一定是易于维护的，例如在新增需求、更改需求、修正bug，都不会造成意料之外的变化，比如说修改了一个页面组件的内容，却导致另外一个页面组件发生变化（这也太坑了）。因此，要低耦合，高内聚，以及输入和输出是可预期的。 3. 提高代码的可扩展性 一个好的架构，一定扩展性要强，不能写死。 需求变更太TM正常了，新增需求也太TM正常了。因此好的架构，必须要考虑到这些情况的发生，因为这些是一定会发生的。所以，一定要避免把代码写死。 比如页面组件A里需要有一个日历组件，而这个日历组件引用的是别人的（比如从github上找的）。那么尽量不要直接在页面组件A里面直接引用这个日历组件，而是将写一个日历组件B，在这个日历组件B里封装你引用的日历组件C，然后通过这个日历组件B来进行操作。 原因很简单，假如某天产品经理说，这个日历组件太丑了，我们换一个吧。如果你直接在页面组件A里内嵌这个引用的日历组件C，你很可能就要改很多代码（因为不同日历组件的使用方法和暴露的接口可能不同）。假如你还在其他多个地方引用了这个日历组件，那就更糟糕了！每个地方都要改。 而若是将引用的日历组件C封装到自己写的日历组件B之中，那么你只需要改日历组件B里的相应代码即可，而因为日历组件B暴露的接口是不变的，那么自然不用修改页面中的代码了。 附图，以日历组件为例，是否考虑到扩展性的结果 未考虑到扩展性：考虑到扩展性： 4. 便于协同 包括前端和后端的协同，前端和前端之间的协同。 具体来说，前后端的协同通常是以ajax为交互，那么应至少有一个用于专门封装了所有ajax请求的文件，所有ajax请求都封装在这里。在开发时，这里封装的方法应该可以模拟发送和接收约定好的交互内容，方便开发联调。 而前端和前端的协同，主要体现在同时在更改代码时，不会影响对方代码的正常运行。因此要求封装、解耦以及低干扰度是必须的。 5. 自动化 自动打包，压缩，混淆，如果有必要，再加上自动单元测试。 总结：总结来说，一个好的架构的目的是，让前端写代码写的舒服，让后端联调的舒服，让产品经理改需求改的舒服。 二、我如何设计架构 我不敢说自己的架构是好的架构（显然不是啦），只能分享自己最近做的一个项目，它的架构的如何做的。 首先，确定需求：1、一个中小型网站，同时面向移动端和PC端（单端大概15个页面，算上弹窗大约20个）； 2、预算有限（给的钱少），开发时间有限（一个月）； 3、可能存在一定程度上的需求变更（比如增加页面或修改某些页面内容）； 4、客户可能不太在乎优化（但是我自己在乎啊）； 5、要求兼容IE9以上。 其次开始决定：1、兼容IE9以上说明可以使用主流框架，而无需必须使用jQuery。因此我采用了vue，版本是2.0； 2、预算有限，时间有限，因此PC端和移动端共html和js，独立css； 3、页面有限，因此无需将架构层级划分的比较细，只需要按其类型划分即可； 4、根据原型图来看，页面复杂程度有限，复用部分不是很多，因此可以确定哪些东西需要封装复用，哪些比较复杂需要独立封装，哪些比较简单为了简化开发难度可以直接耦合； 5、自己比较熟练单页面网站，因此采用以单页面为主，异步加载其他页面的形式。 于是使用相关配套的东西，比如webpack，vue-router等，另外为了开发和生产的方便性，采用以下模式进行开发。 第三，划分功能：首先有一个根html，用户需要通过访问它来加载我们的js逻辑，因此js逻辑的代码被写在main.js之中。 在main.js之下，我们的前端代码可以被划分为三部分： 组件树- 功能模块- 各种资源功能模块 如下图： 功能划分好之后，相同功能的放在同一个文件夹下，命名风格应该类似。 具体来说，组件树相关的东西，通常是以.vue结尾，放置在components文件夹下；资源，有图片或者国际化资源等，以.png或者.js或.json结尾，放置在resources文件夹下；而功能插件、服务等，因为可能被多处引用，因此为了方便引用，放在src文件夹下，并且该文件夹是components文件夹和resources文件夹的上级文件夹。 第四，细化功能模块：功能、组件树以及资源，我们已经明确了有哪些东西，那么接下来，我们要明确这些东西该如何以文件的形式来划分。 如下图： 1. 项目构建相关 因为要使用vue.js，也要使用es6语法，因此babel是必须的；- 又因为要自动化混淆打包，因此webpack也是必须的；- 最后因为要方便多人协同，因此npm的package.json的配置，方便不同人可以快速自动化通过npm install来安装依赖，也是必须的。又因为要自动化混淆打包，因此webpack也是必须的； 2. CDN相关而又因为我们要采用外部字体（需求要求引入非常见字体），因此CDN加速是必须的，该字体文件放在html中来配置引用即可。 3. 配置和插件 我们需要直接引入一些插件和配置文件；- 为了使用vue，我们需要一个根组件，那么就是App.vue；- 使用vue-router，我们需要配置路由文件，因此router-config.js这个路由配置也是必须的；- 然后我们还需要以插件形式引入一些功能和服务，因此有了Plugin-开头的若干个vue插件，这些都是根据需要封装好的低耦合高内聚方法；为了使用vue，我们需要一个根组件，那么就是App.vue； 然后我们还需要以插件形式引入一些功能和服务，因此有了Plugin-开头的若干个vue插件，这些都是根据需要封装好的低耦合高内聚方法； 4. 需要的npm依赖当然，要使用vue肯定要引入vue.js，类似的还有vue-router.js和各种兼容性polyfill和全局插件。 5. 抽离出的功能模块 除了直接引用的这些插件，我们还有一些和项目高度耦合的功能服务，我认为不能作为插件，但依然需要抽离出来封装好，方便使用和修改；- 如封装ajax请求的ajax.js，所有的ajax请求都放置其中，只对外暴露接口，方便管理和使用；- 又如实时国际化功能的组件LanguageManager.js，他需要引入国际化资源和管理国际化资源的加载；- 又例如实现跨组件通信的event-bus.js；- 又比如管理用户信息的user.js。如封装ajax请求的ajax.js，所有的ajax请求都放置其中，只对外暴露接口，方便管理和使用； 又例如实现跨组件通信的event-bus.js； 总结：而这些划分，都体现在上图之中。这就是src目录下的功能模块文件，我们需要的绝大多数功能都可以包括在其中，我们只需要按照实际开发中的需要，将对应的功能写入在这些文件中并引用即可。 第五，组件树：之前谈了功能模块的划分，接下来是组件树。 因为是中小型页面，因此组件树的层级无需太深，但该抽离出来的依然还是要抽离，尽量保证抽离出来的组件解耦以及一个页面组件的逻辑不要太多。如下图： 0. 根组件所有组件最终往上找，都会找到共同的根组件App.vue，根组件只负责管理他的直接子组件。 每个组件都只负责管理自己的直接子组件，不跨级管理，并且不依赖于自己的子组件（否则可能因为子组件的未加载或错误而导致父组件错误），做到解耦和内聚。 1. 弹窗dialog和弹窗tips因为弹窗dialog和弹窗提示tips可能同时存在，因此将其划分为2个组件，方便管理。 2. 未登录页面和登录页面因为页面存在登录和未登录状态，而为了加载速度考虑，当未登录时，不加载已登录页面，因此需要划分出来，并进行异步加载处理。 3. 未登录页面未登录页面又分为三种情况： 初始页面：毫无疑问要直接加载- 登录弹窗：点击登录时加载（异步）- 注册弹窗：点击注册时加载（异步）登录弹窗：点击登录时加载（异步） 之所以分拆开，是因为根据需求，已登录用户刷新页面，可以直接进入登录后页面，因此无需登录和注册，这种处理可以减少流量消耗，提升加载页面加载速度（特别是注册弹窗需要加载的内容还比较多）。 4. 已登录页面已登录页面有较多页面，采用默认加载初始页，然后异步加载其他页面（访问时）。 5. 弹窗dialog由于逻辑较少，代码量不多，因此为了方便管理，统一将其合并在一个vue文件中，共同相同的打开逻辑，根据传递的key决定打开哪一个。这样在新增弹窗时，无需再去写弹窗的打开、关闭逻辑。 假如有较复杂的弹窗，可以以子组件的形式引入到当前vue文件中，如此也方便管理； 6. 国际化管理和页面高耦合，负责加载对应的国际化资源，并进行切换管理。 7. 页面组件可能有子页面和复用的组件，按照正常方式引用即可。 8. 样式文件可以独立写为.css文件，但因为我的公共样式文件比较少，因此我还是将其放在一个.vue文件中，并在App.vue里来引用。 9. 页面组件起名 通常以.vue为结尾，除了国际化LanguageManager.js因为高耦合度，因此以.js结尾并是一个单独的vue实例，表示他更像是一个功能模块，而不是一个vue的页面组件；- 基础页面，如登录和未登录页面，公共组件（并且是header和footer这种），以base-开头；- 弹窗统一以box-为开头；- 可复用的组件以extend-开头；- 引入的外部组件以import-开头；- 普通页面组件以page-开头（这些页面往往是一个独立的页面，并且挂靠在登录或未登录页面下）；- 注册弹窗因为逻辑比较复杂，并且同类较多，因此以register-为开头。基础页面，如登录和未登录页面，公共组件（并且是header和footer这种），以base-开头； 可复用的组件以extend-开头； 普通页面组件以page-开头（这些页面往往是一个独立的页面，并且挂靠在登录或未登录页面下）； 通过以文件名来划分，不同的页面组件之间的区分可以说是一目了然，同时也方便管理。 本文来自CSDN博客：http&#58;//blog.csdn.net/qq20004604/article/details/70480932 转载来源：个人的中小型项目前端架构浅谈]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>路由器</tag>
        <tag>CSS</tag>
        <tag>HTML</tag>
        <tag>DIALOG</tag>
        <tag>腾讯TM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack+vuejs+element打造大型web项目]]></title>
    <url>%2F2017%2F3900e45f%2F</url>
    <content type="text"><![CDATA[webpack+vuejs+element打造大型web项目 转载来源：webpack+vuejs+element打造大型web项目]]></content>
  </entry>
  <entry>
    <title><![CDATA[用Python实现优先级队列的3种方法]]></title>
    <url>%2F2017%2Fac420b8c%2F</url>
    <content type="text"><![CDATA[你能想出几种方法来在Python中实现优先级队列？阅读下面文章并找出Python标准库提供了哪些方案？ 优先级队列是一种容器型数据结构，它能管理一队记录，并按照排序字段（例如一个数字类型的权重值）为其排序。由于是排序的，所以在优先级队列中你可以快速获取到最大的和最小的值。 你可以认为优先级队列是一种修改过的普通队列：普通队列依据记录插入的时间来获取下一个记录，优先级队列依据优先级来获取下一个记录，而优先级取决于排序字段的值。 优先级队列经常用来解决调度问题，比如给更紧急的任务更高的优先级。 我们以操作系统的任务调度为例：高优先级的任务（比如实时游戏）应该先于低优先级的任务（比如后台下载软件更新）执行。通过在优先级队列中依据任务的紧急程度排序，我们能让最紧急的任务优先得到执行。 我们下面讲解几种实现优先级队列的方法，有的使用的是Python的内置数据结构，有的使用的是Python标准库提供的数据结构。两种情况各有千秋，在我的心中其中有一种方法在绝大多数时候都是最优的方案，当然你也需要自己去判断哪个才是你最需要的。 手动维护排序列表 使用排序列表你可以快速地获取或删除最大的或者最小的元素，缺点是向列表中插入元素是一个很慢的操作，复杂度在O(n)。 不过标准库提供的bisect.insort方法让你能够在O(log n)的时间里找到需要插入的位置，这帮缓慢的插入操作改善了部分性能。 如果是把元素放到队列的最后，然后直接重新排序，那么复杂度是O(nlog n)。 所以排序列表的这种实现方法，只有在插入操作很少的时候才合适。 heapq模块 heapq是一个二叉堆的实现，它内部使用内置的list对象，它无论插入还是获取最小元素复杂度都在O(log n)。 这个模块是实现优先级队列的一个很好的选择。 由于heapq只是提供了一个最小的堆实现，所以为了让它成为实用的优先级队列，还需要添加很多额外的代码来保证顺序，和提供其他必不可少的功能。 queue.PriorityQueue类 这个优先级队列内部使用了heapq，所以它的时间复杂度和heapq是相同的。 不同的是PriorityQueue的操作是同步的，提供锁操作，支持并发的生产者和消费者。 依据使用场景，它可能很有用，也可能有点太大了。通常来说它的基于类接口要比heapq的基于函数的接口更友好。 一个比较好的默认选项 在你的程序中应该使用哪一个优先级队列的实现呢？上面三种实现都有自己的使用场景，但是在我心里queue.PriorityQueue是最好的选择。 确实有时候它显得有点过重了，但是我很看重它的面向对象的接口，以及一个清晰地表意的名字。 译者：诗书塞外英文原文：https&#58;//dbader.org/blog/priority-queues-in-python#. 转载来源：用Python实现优先级队列的3种方法]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>编程语言</tag>
        <tag>Python</tag>
        <tag>科技</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[想赶上机器学习的火车，你的企业现在应该怎么做？]]></title>
    <url>%2F2017%2F2d69e787%2F</url>
    <content type="text"><![CDATA[雷锋网按：本文为「范式大学系列课程」第 2 篇文章：机器学习老司机：如何成为 ML-ready 的公司？ 机器学习已经在商业领域展示了巨大潜力，那么管理者如何将其纳入日常决策和长期规划？一个公司怎样才能 ML-ready？ 当你考虑在企业中应用机器学习技术时，很多问题就会出现。 我的业务是否适合机器学习模型？- 我可以从机器学习模型中获得什么收益？- 这是一个降低成本的问题，还是增加收入的问题？- 我现在的数据积累足够吗，如果不够的话该怎么办？- 我需要什么样的人才帮助我实现企业人工智能的升级？ - 换句话说，如果你的企业想赶上机器学习的火车，现在应该怎么做？我可以从机器学习模型中获得什么收益？ 我现在的数据积累足够吗，如果不够的话该怎么办？ 换句话说，如果你的企业想赶上机器学习的火车，现在应该怎么做？ 先给你一张信息表，然后我们会从 6 个步骤详细解析。 步骤一：定义问题 应用机器学习的公司一般有两种： 一种是以机器学习模型作为企业核心业务的公司，例如今日头条、News in Palm；- 另一种是通过机器学习增强现有业务流程的公司，例如抱抱通过机器学习优化主播推荐。另一种是通过机器学习增强现有业务流程的公司，例如抱抱通过机器学习优化主播推荐。 对于后一种公司，清楚的定义问题会是第一个挑战。无论是个性化推荐、增加活跃度还是降本增收，都应该收敛到一个点，即我们可以通过获得正确的数据把任务变成机器学习可解决的问题。 例如，如果你想通过数据发现“高流失风险”的客户，以此降低用户的流失率，这就是机器学习可以解决的问题。你会拥有已经流失的用户（这就是机器学习的标签），流失行为背后相关的数据（例如社交媒体的活动、使用频率等），那就可以通过机器学习算法找到用户流失和用户行为之间的隐藏关系。 当然，这里面更重要的问题是，当你知道这个用户将要流失时，你准备做些什么？机器学习可以告诉你使用什么样的挽留策略能拉回他。 另一个例子是提高用户满意度。用户满意度是一个主观的指标，不同的人、场合对用户满意度的衡量标准都不一样。如果要通过机器学习来预测用户满意度，最终的结果可能就会不理想。 定义机器学习的问题，最终可以落在两个点上： 1、从业务出发，机器学习往往致力于解决标准商业逻辑和系列规则不能解决的问题。所以在考虑是否需要机器学习的时候，不妨问问自己，当你做决策的时候，有多经常是基于经验假设而非清晰的分析论据？ 2、从技术出发，机器学习往往需要客观的预测指标，例如流失率、点击率、停留时长等。同时你也需要考虑数据反馈的周期，例如在信用卡反欺诈的任务中，盗刷后被用户发现并提交反馈的时间往往需要 1 周甚至 1 个月，那么系统就要考虑到负面反馈的时间。 通过机器学习强化业务流程是一个非常广泛的领域，我们可以在内容推荐、金融反欺诈、医疗健康等各行各业都看到它的身影。 步骤二：强化业务流程 当你建立了机器学习模型，下一步便是结合模型强化业务流程。一般来说会有三个层次： 1、描述 采集数据进行机器学习分析，通过图表和报告描述现状 2、预测 找到业务发展的模式，做出预测 3、行动 结合模型预测，给出不同的解决方案 麦肯锡曾经披露了一家国际银行的故事，他们通过机器学习改进违约客户相关的业务流程。通过机器学习模型，他们发现有一群平时白天使用信用卡的客户，在晚上也在大量使用信用卡。机器学习发现该行为模式和违约风险紧密相关，在进一步的问询后发现，这群人正在经历某些紧张的时刻。银行的解决方案是向这群高风险的人提供财务建议，并为他们建立新的信用额度。 步骤三：确保你的数据质量足够好 机器学习是关于数据的科学，它从数据中获得有价值的洞察。一般来说，使用机器学习辅助决策是避免偏见的好方法，但这比想象的更为棘手，因为它不能避免数据本身的偏见。例如 Google 最近陷入了一起争议，在对男人和女人的广告中，他们在男人的广告中展示了更多高级岗位。Google 的数据科学家并没有性别歧视，但算法背后的数据是有偏见的，因为它是从社交网络的互动中收集上来的。 确保数据质量足够好 基本可以说，你所拥有的数据质量，定义了算法的质量。数据可能是嘈杂的、冲突的、有偏见的和缺失的，这会对问题解决有非常不良的影响。为了优化模型开发，你需要让数据更匹配要解决的问题，所以在早期最好有熟悉业务的数据科学家支持，逐步开发和收集解决问题所需的数据。不过这里需要注意的是，尽管业务决策者寻求的是具体建议和结果预测，但数据科学家往往只能提供相关的数据特征。只有真正把数据投入到机器学习系统，才能知道最终的结果会怎么样。 确定最小预测准确度 我们需要定义最小的预测准确度。不同的业务会有不同的准确度要求，例如在涉及医疗的业务中，有些任务需要高达 95% 以上的预测准确度。而在一个预测飞机票价的算法中，预测准确度高于 75% 就足以支持客户的预定任务。 打破数据孤岛，匿名化并共享数据 数据科学家小组经常面临一个障碍，在项目的谈判阶段就需要获取数据。对于业务人员来说，了解成本是决定是否开展机器学习业务的关键因素，但在看不到实际数据的情况下，几乎不可能准确估计预测准确度水平和实施价格，这往往是谈判瘫痪的原因。企业高管不能将商业敏感数据交给技术公司，而技术公司在获得数据之前几乎无法给出明确的答案。 我们的解决方案是提供数据子集而不是整个数据库，并将其匿名化。对于拥有数据科学家的公司，在不同的部门之间共享数据也是共同的管理挑战。过度管制的数据策略，或者仅仅在各部门囤积数据，会大大减缓数据分析的进程。这就是为什么要在更高层面给数据科学家和技术公司权限的原因。 好消息：即便数据不够好，它可以修复 即便你的数据集是凌乱的而非结构化，也有办法获得好的结果。今天，数据科学家已经准备好在起步阶段应用一些方法，重组、清洗数据集，并进一步优化得到更好的建模效果。 但坏消息是，数据科学家可能需要相当长的时间完成数据清洗并进行到建模阶段。如果你没有专业知识，是否应该提前自己处理？一般来说是否定的，因为即便自己做了，最后的数据集也可能需要重新处理。 步骤四：弥合技术和商业愿景之间的差距 如果你问数据科学家最喜欢的算法，你可能会听到决策树、神经网络、逻辑回归、Kernel 方法、主成分分析等。但是这些算法如何和商业愿景结合起来？你会需要一个懂得业务和基本数据分析知识的人，他能够在业务流程中找到机器学习能够起作用的指标，领导数据科学计划，扩大机器学习应用场景的选择，调整业务和技术的愿景。 一般来说有四种方法： 1、建立机器学习团队 机器学习科学家的价格要比普通程序员高很多。当你打算建立一个机器学习的团队时，一定要给他足够的支持，因为他需要创造性的工作才能发挥作用，而这往往会和很多组织的结构发生冲突。 2、公司内专家 + 机器学习平台 你可以使用公司已有的业务专家，在 1-2 个数据科学家的帮助下，就可以通过机器学习平台解决问题。这些平台往往拥有友好的界面，公司内部的业务专家可以通过短时间的培训学习如何使用，这样你就可以把数据计划扩展到更大的专家组，解决更多的公司业务问题。利益相关，我们推荐自家的产品：第四范式先知平台。 3、机器学习解决方案公司 现在市面上已经有一些机器学习解决方案公司了，但机器学习和传统的编程不同，因为它需要克服信任的门槛。机器学习解决方案的任务面临的挑战是共享数据。根据拥有的数据类型，也许你需要以某种方法匿名化，隐藏敏感信息，例如客户联系人和他们的位置。当然，当你匿名化的时候，你也要接受解决方案公司会难以使用外部数据来丰富数据集以得到更好的建模结果。 4、和大学院校、研究机构合作 大学院校、研究机构已经有很多数据科学的研究生和博士，他们大多拥有建立机器学习模型的能力。不过和高校研究机构合作的费用一般会比较贵。 步骤五：模型过时了，需要更新 大多数的机器学习模型是在静态数据子集上开发的。一旦部署了模型，它们将会随着时间的推移而变得过时，预测也会变得不准确。根据业务环境的变化，你应该在一段时间后更换模型，或者重新培训，一般来说会有两种基本方法： A/B测试：一个新的模型会被引入和旧的模型竞争。当新的模型超过了旧的模型，旧的模型就会被替代。这个过程将会一直重复。 在线更新：模型的参数会随着连续性的新数据流而变化。 因此，如果你希望机器学习的分析保持在稳定的水平，一定要及时更新机器学习的模型。 步骤六：是否需要定制的算法 定制的算法会有一些好处，例如它能够更匹配你的数据集和要解决的问题，训练的速度也会更快。但相对应的，它的开发和进一步迭代都价格不菲。所以如果你是一个大型企业，你可以考虑采用定制算法；如果你是中小型的企业，定制算法会带来严重的财务和管理负担。 实际上，如果是常见的预测任务，那么现成的算法模型是可行的。通过一些成熟的算法，集成好的机器学习软件，你可以很轻松的部署机器学习系统，快速解决业务流程中的问题。 无论你最终是否决定定制算法，我们都建议你先用成熟的算法试一试。 参考文章： Developing Machine Learning Strategy for Business in 7 Steps,altexsoft. How to Make Your Company Machine Learning Ready,hbr. 「范式大学」由第四范式发起，致力于成为“数据科学家”的黄埔军校。「范式大学系列课程」会和大家推荐戴文渊、杨强、陈雨强等机器学习领域顶尖从业人士的最新分享，以及由第四范式产品团队推荐和整理的机器学习材料。 转载来源：想赶上机器学习的火车，你的企业现在应该怎么做？]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>机器学习</tag>
        <tag>Google</tag>
        <tag>大学</tag>
        <tag>杨强</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[零基础写python爬虫之使用Scrapy框架编写爬虫 - 新客网]]></title>
    <url>%2F2017%2F84a01932%2F</url>
    <content type="text"><![CDATA[零基础写python爬虫之使用Scrapy框架编写爬虫 - 新客网 转载来源：零基础写python爬虫之使用Scrapy框架编写爬虫 - 新客网]]></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习和深度学习引用量最高的20篇论文：2014-2017]]></title>
    <url>%2F2017%2F491d612b%2F</url>
    <content type="text"><![CDATA[选自Kdnuggets 作者：Thuy T. Pham 机器之心编译 参与：邵明、黄小天 机器学习和深度学习的研究进展正深刻变革着人类的技术，本文列出了自 2014 年以来这两个领域发表的最重要（被引用次数最多）的 20 篇科学论文，以飨读者。 机器学习，尤其是其子领域深度学习，在近些年来取得了许多惊人的进展。重要的研究论文可能带来使全球数十亿人受益的技术突破。这一领域的研究目前发展非常快，为了帮助你了解进展状况，我们列出了自 2014 年以来最重要的 20 篇科学论文。 我们筛选论文的标准是来自三大学术搜索引擎谷歌学术（scholar.google.com）、微软学术（academic.microsoft.com）和 semanticscholar.org 的引用量。由于不同搜索引擎的引用量数据各不相同，所以我们在这里仅列出了微软学术的数据，其数据比其它两家稍低一点。 我们还给出了每篇论文的发表时间、高度有影响力的引用数量（HIC）和引用速度（CV），以上数据由 semanticscholar.org 提供。HIC 表示了以此为基础的论文情况和与其它论文的关系，代表了有意义的引用。CV 是最近 3 年每年引用数量的加权平均。有些引用的 CV 是 0，那是因为 semanticscholar.org 上没有给出数据。这 20 篇论文中大多数（包括前 8 篇）都是关于深度学习的，但同时也很多样性，仅有一位作者（Yoshua Bengio）有 2 篇论文，而且这些论文发表在很多不同的地方：CoRR (3)、ECCV (3)、IEEE CVPR (3)、NIPS (2)、ACM Comp Surveys、ICML、IEEE PAMI、IEEE TKDE、Information Fusion、Int. J. on Computers &amp; EE、JMLR、KDD 和 Neural Networks。前 2 篇论文的引用量目前远远高于其它论文。注意第 2 篇论文去年才发表！要了解机器学习和深度学习的最新进展，这些论文一定不能错过。 1. 论文：Dropout：一种防止神经网络过拟合的简单方法（Dropout&#58; a simple way to prevent neural networks from overfitting） 链接：http&#58;//suo.im/3o6l4B- 作者：Hinton, G.E., Krizhevsky, A., Srivastava, N., Sutskever, I., &amp; Salakhutdinov, R. (2014). Journal of Machine Learning Research, 15, 1929-1958.- 数据：引用：2084、HIC：142、CV：536- 摘要：其关键思想是在神经网络的训练过程中随机丢弃单元（连同它们的连接点）。这能防止单元适应过度，显著减少过拟合，并相对于其它正则化方法有重大改进。作者：Hinton, G.E., Krizhevsky, A., Srivastava, N., Sutskever, I., &amp; Salakhutdinov, R. (2014). Journal of Machine Learning Research, 15, 1929-1958. 摘要：其关键思想是在神经网络的训练过程中随机丢弃单元（连同它们的连接点）。这能防止单元适应过度，显著减少过拟合，并相对于其它正则化方法有重大改进。 2. 论文：用于图像识别的深度残差学习（Deep Residual Learning for Image Recognition） 链接：http&#58;//suo.im/1JrYXX- 作者：He, K., Ren, S., Sun, J., &amp; Zhang, X. (2016). CoRR- 数据：引用：1436、HIC：137、CV：582- 摘要：目前的深度学习网络层数越来越多，越来越难以训练，因此我们提出了一种减缓训练压力的残差学习框架。我们明确地将这些层重新定义为与输入层有关的学习残差函数，而不是学习未被引用的函数。与此同时，我们提供了全面的经验证据以表明残差网络更容易优化，并可通过增加其层数来提升精确度。作者：He, K., Ren, S., Sun, J., &amp; Zhang, X. (2016). CoRR 摘要：目前的深度学习网络层数越来越多，越来越难以训练，因此我们提出了一种减缓训练压力的残差学习框架。我们明确地将这些层重新定义为与输入层有关的学习残差函数，而不是学习未被引用的函数。与此同时，我们提供了全面的经验证据以表明残差网络更容易优化，并可通过增加其层数来提升精确度。 3. 论文：批标准化：通过减少内部协移加速深度神经网络训练（Batch Normalization&#58; Accelerating Deep Network Training by Reducing Internal Covariate Shift） 链接：http&#58;//suo.im/3sJtk1- 作者：Sergey Ioffe, Christian Szegedy (2015) ICML.- 数据：引用：946、HIC：56、CV：0- 摘要：训练深度神经网络的过程很复杂，原因在于每层的输入分布随着训练过程中引起的前面层的参数变化而变化。我们把这种现象称为内部协变量转移（internal covariate shift），并可利用归一化层输入来解决此问题。通过将此方法应用到最先进的图像分类模型，批标准化在训练次数减少了 14 倍的条件下达到了与原始模型相同的精度，这表明批标准化具有明显的优势。作者：Sergey Ioffe, Christian Szegedy (2015) ICML. 摘要：训练深度神经网络的过程很复杂，原因在于每层的输入分布随着训练过程中引起的前面层的参数变化而变化。我们把这种现象称为内部协变量转移（internal covariate shift），并可利用归一化层输入来解决此问题。通过将此方法应用到最先进的图像分类模型，批标准化在训练次数减少了 14 倍的条件下达到了与原始模型相同的精度，这表明批标准化具有明显的优势。 4. 论文：利用卷积神经网络进行大规模视频分类（Large-Scale Video Classification with Convolutional Neural Networks） 链接：http&#58;//suo.im/25lfXF- 作者：Fei-Fei, L., Karpathy, A., Leung, T., Shetty, S., Sukthankar, R., &amp; Toderici, G. (2014). IEEE Conference on Computer Vision and Pattern Recognition- 数据：引用：865、HIC：24、CV：239- 摘要：针对图像识别问题，卷积神经网络（CNN）被认为是一类强大的模型。受到这些结果的激励，我们使用了一个包含 487 个类别、100 万 YouTube 视频的大型数据集，对利用 CNN 进行大规模视频分类作了一次广泛的实证评估。作者：Fei-Fei, L., Karpathy, A., Leung, T., Shetty, S., Sukthankar, R., &amp; Toderici, G. (2014). IEEE Conference on Computer Vision and Pattern Recognition 摘要：针对图像识别问题，卷积神经网络（CNN）被认为是一类强大的模型。受到这些结果的激励，我们使用了一个包含 487 个类别、100 万 YouTube 视频的大型数据集，对利用 CNN 进行大规模视频分类作了一次广泛的实证评估。 5. 论文：Microsoft COCO：语境中的通用对象（Microsoft COCO&#58; Common Objects in Context） 链接：http&#58;//suo.im/DAXwA- 作者：Belongie, S.J., Dollár, P., Hays, J., Lin, T., Maire, M., Perona, P., Ramanan, D., &amp; Zitnick, C.L. (2014). ECCV.- 数据：引用：830、HIC：78、CV：279- 摘要：我们展示了一个新的数据集，通过将对象识别问题放入更广泛的场景理解问题的语境中，以推进当前对象识别领域中最先进的技术。我们的数据集包含了 91 种对象类型的照片，这些图片对于一个 4 岁大的孩子而言，很容易识别。最后，我们利用可变形部件模型（DPM）为边界框和分割检测结果提供了一个基线性能分析。作者：Belongie, S.J., Dollár, P., Hays, J., Lin, T., Maire, M., Perona, P., Ramanan, D., &amp; Zitnick, C.L. (2014). ECCV. 摘要：我们展示了一个新的数据集，通过将对象识别问题放入更广泛的场景理解问题的语境中，以推进当前对象识别领域中最先进的技术。我们的数据集包含了 91 种对象类型的照片，这些图片对于一个 4 岁大的孩子而言，很容易识别。最后，我们利用可变形部件模型（DPM）为边界框和分割检测结果提供了一个基线性能分析。 6. 论文：使用场景数据库学习场景识别中的深层特征（Learning deep features for scene recognition using places database） 链接：http&#58;//suo.im/2EOBTa- 作者：Lapedriza, À., Oliva, A., Torralba, A., Xiao, J., &amp; Zhou, B. (2014). NIPS.- 数据：引用：644、HIC：65、CV：0- 摘要：我们引入了一个以场景为中心的新数据库，这个数据库称为「Places」，里面包含了超过 700 万个标注好了的场景。我们提议使用新方法去比较图像数据集的密度和多样性，以表明 Places 与其它场景数据库一样密集并更具多样性。作者：Lapedriza, À., Oliva, A., Torralba, A., Xiao, J., &amp; Zhou, B. (2014). NIPS. 摘要：我们引入了一个以场景为中心的新数据库，这个数据库称为「Places」，里面包含了超过 700 万个标注好了的场景。我们提议使用新方法去比较图像数据集的密度和多样性，以表明 Places 与其它场景数据库一样密集并更具多样性。 7. 论文：生成对抗网络（Generative adversarial nets） 链接：http&#58;//suo.im/3YS5F6- 作者：Bengio, Y., Courville, A.C., Goodfellow, I.J., Mirza, M., Ozair, S., Pouget-Abadie, J., Warde-Farley, D., &amp; Xu, B. (2014) NIPS.- 数据：引用：463、HIC：55、CV：0- 摘要：通过对抗过程，我们提出了一个评估生成模型的新框架。在此框架中，我们同时训练两个模型：生成模型 G 捕获数据分布；判别模型 D 评估样本示来自训练数据集（而不是来自 G 中）的概率。作者：Bengio, Y., Courville, A.C., Goodfellow, I.J., Mirza, M., Ozair, S., Pouget-Abadie, J., Warde-Farley, D., &amp; Xu, B. (2014) NIPS. 摘要：通过对抗过程，我们提出了一个评估生成模型的新框架。在此框架中，我们同时训练两个模型：生成模型 G 捕获数据分布；判别模型 D 评估样本示来自训练数据集（而不是来自 G 中）的概率。 8. 论文：通过内核相关滤波器实现高速跟踪（High-Speed Tracking with Kernelized Correlation Filters） 链接：http&#58;//suo.im/2BBOea- 作者：Batista, J., Caseiro, R., Henriques, J.F., &amp; Martins, P. (2015). CoRR- 数据：引用：439、HIC：43、CV：0- 摘要：大多数的现代追踪器，为应对自然图像中的变化，典型的方法是采用翻译和缩放样本补丁训练分类器。我们针对包含成千上万个翻译补丁数据集提出了一个分析模型。结果表明结果数据矩阵是循环的，我们可以利用离散傅立叶变换对角化已有的循环矩阵，将存储和计算量降低了几个数量级。作者：Batista, J., Caseiro, R., Henriques, J.F., &amp; Martins, P. (2015). CoRR 摘要：大多数的现代追踪器，为应对自然图像中的变化，典型的方法是采用翻译和缩放样本补丁训练分类器。我们针对包含成千上万个翻译补丁数据集提出了一个分析模型。结果表明结果数据矩阵是循环的，我们可以利用离散傅立叶变换对角化已有的循环矩阵，将存储和计算量降低了几个数量级。 9. 论文：多标签学习算法综述（A Review on Multi-Label Learning Algorithms） 链接：http&#58;//suo.im/3LgpGf- 作者：Zhang, M., &amp; Zhou, Z. (2014). IEEE TKDE- 数据：引用：436、HIC：7、CV：91- 摘要：本论文的主要目的是对多标签学习问题进行及时回顾。在多标签学习问题中，一个实例代表一个样本，同时，一个样本与一组标签相关联。作者：Zhang, M., &amp; Zhou, Z. (2014). IEEE TKDE 摘要：本论文的主要目的是对多标签学习问题进行及时回顾。在多标签学习问题中，一个实例代表一个样本，同时，一个样本与一组标签相关联。 10. 论文：深层神经网络特征的可传递性（How transferable are features in deep neural networks） 链接：http&#58;//suo.im/aDLgu- 作者：Bengio, Y., Clune, J., Lipson, H., &amp; Yosinski, J. (2014) CoRR- 数据：引用：402、HIC：14、CV：0- 摘要：我们用实验量化了深层卷积神经网络中每层神经元的一般性与特异性，并报告了一些令人惊讶的结果。可传递性受到两个不同问题的不利影响：（1）以牺牲目标任务的性能为代价，实现更高层神经元对原始人物的专业化，这是预料之中的；（2）与分裂共同适应神经元（co-adapted neuron）之间的网络有关的优化困难，这是预料之外的。作者：Bengio, Y., Clune, J., Lipson, H., &amp; Yosinski, J. (2014) CoRR 摘要：我们用实验量化了深层卷积神经网络中每层神经元的一般性与特异性，并报告了一些令人惊讶的结果。可传递性受到两个不同问题的不利影响：（1）以牺牲目标任务的性能为代价，实现更高层神经元对原始人物的专业化，这是预料之中的；（2）与分裂共同适应神经元（co-adapted neuron）之间的网络有关的优化困难，这是预料之外的。 11. 论文：我们需要数百种分类器来解决真实世界的分类问题吗？（Do we need hundreds of classifiers to solve real world classification problems） 链接：http&#58;//suo.im/2w14RK- 作者：Amorim, D.G., Barro, S., Cernadas, E., &amp; Delgado, M.F. (2014). Journal of Machine Learning Research- 数据：引用：387、HIC：3、CV：0- 摘要：我们评估了来自 17 个「家族」（判别分析、贝叶斯、神经网络、支持向量机、决策树、基于规则的分类器、提升、装袋、堆叠、随机森林、集成方法、广义线性模型、最近邻、部分最小二乘和主成分回归、逻辑和多项回归、多元自适应回归样条法等）的 179 个分类器。我们使用了来自 UCI 数据库中的 121 个数据集来研究分类器行为，这些行为不依赖于所选取的数据集。最终胜出的是使用 R 语言实现的随机森林方法和 C 中使用 LibSVM 实现的带有高斯内核的 SVM。作者：Amorim, D.G., Barro, S., Cernadas, E., &amp; Delgado, M.F. (2014). Journal of Machine Learning Research 摘要：我们评估了来自 17 个「家族」（判别分析、贝叶斯、神经网络、支持向量机、决策树、基于规则的分类器、提升、装袋、堆叠、随机森林、集成方法、广义线性模型、最近邻、部分最小二乘和主成分回归、逻辑和多项回归、多元自适应回归样条法等）的 179 个分类器。我们使用了来自 UCI 数据库中的 121 个数据集来研究分类器行为，这些行为不依赖于所选取的数据集。最终胜出的是使用 R 语言实现的随机森林方法和 C 中使用 LibSVM 实现的带有高斯内核的 SVM。 12. 论文：知识库：一种概率知识融合的网络规模方法（Knowledge vault&#58; a web-scale approach to probabilistic knowledge fusion） 链接：http&#58;//suo.im/3qCSs6- 作者：Dong, X., Gabrilovich, E., Heitz, G., Horn, W., Lao, N., Murphy, K., … &amp; Zhang, W.(2014, August). In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining ACM- 数据：引用：334、HIC：7、CV：107- 摘要：我们引入了一个网络规模的概率知识库，它将网页内容提取（通过文本分析、表格数据、页面结构和人工注释获得）与来自现存知识库中的先验知识相结合，以构建新知识库。我们部署监督学习方法去融合不同的信息源。该知识库比先前发布的任何结构化知识库大得多，并且具有概率推理系统，该概率推理系统能计算事实准确性的校准概率。作者：Dong, X., Gabrilovich, E., Heitz, G., Horn, W., Lao, N., Murphy, K., … &amp; Zhang, W.(2014, August). In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining ACM 摘要：我们引入了一个网络规模的概率知识库，它将网页内容提取（通过文本分析、表格数据、页面结构和人工注释获得）与来自现存知识库中的先验知识相结合，以构建新知识库。我们部署监督学习方法去融合不同的信息源。该知识库比先前发布的任何结构化知识库大得多，并且具有概率推理系统，该概率推理系统能计算事实准确性的校准概率。 13. 论文：用于高维数据的可扩展最近邻算法（Scalable Nearest Neighbor Algorithms for High Dimensional Data） 链接：http&#58;//suo.im/hjTa4- 作者：Lowe, D.G., &amp; Muja, M. (2014). IEEE Trans. Pattern Anal. Mach. Intell.- 数据：引用：324、HIC：11、CV：69- 摘要：我们提出了用于近似最近邻匹配的新算法，并将其与以前的算法进行比较。为了将其扩展到大型数据集（不适合单机的存储处理）上，我们提出了一种分布式最近邻匹配框架，该框架可以与论文中描述的任何算法一起使用。作者：Lowe, D.G., &amp; Muja, M. (2014). IEEE Trans. Pattern Anal. Mach. Intell. 摘要：我们提出了用于近似最近邻匹配的新算法，并将其与以前的算法进行比较。为了将其扩展到大型数据集（不适合单机的存储处理）上，我们提出了一种分布式最近邻匹配框架，该框架可以与论文中描述的任何算法一起使用。 14. 论文：回顾超限学习机的发展趋势（Trends in extreme learning machines&#58; a review） 链接：http&#58;//suo.im/3WSEQi- 作者：Huang, G., Huang, G., Song, S., &amp; You, K. (2015). Neural Networks- 数据：引用：323、HIC：0、CV：0- 摘要：我们的目标是报告超限学习机（ELM）的理论研究和实践进展所处的现状。除了分类和回归，ELM 最近已经被扩展到集群、特征选择、代表性学习和许多其他学习任务。由于其惊人的高效性、简单性和令人印象深刻的泛化能力，ELM 已经被广泛用于各种领域，如生物医学工程、计算机视觉、系统识别、控制和机器人。作者：Huang, G., Huang, G., Song, S., &amp; You, K. (2015). Neural Networks 摘要：我们的目标是报告超限学习机（ELM）的理论研究和实践进展所处的现状。除了分类和回归，ELM 最近已经被扩展到集群、特征选择、代表性学习和许多其他学习任务。由于其惊人的高效性、简单性和令人印象深刻的泛化能力，ELM 已经被广泛用于各种领域，如生物医学工程、计算机视觉、系统识别、控制和机器人。 15. 论文：一份关于概念漂移适应的调查（A survey on concept drift adaptation） 链接：http&#58;//suo.im/3bQkiz- 作者：Bifet, A., Bouchachia, A., Gama, J., Pechenizkiy, M., &amp; Zliobaite, I. ACM Comput. Surv., 2014- 数据：引用：314、HIC：4、CV：23- 摘要：该文全面介绍了概念漂移适应。它指的是当输入数据与目标变量之间的关系随时间变化之时的在线监督学习场景。作者：Bifet, A., Bouchachia, A., Gama, J., Pechenizkiy, M., &amp; Zliobaite, I. ACM Comput. Surv., 2014 摘要：该文全面介绍了概念漂移适应。它指的是当输入数据与目标变量之间的关系随时间变化之时的在线监督学习场景。 16. 论文：深度卷积激活特征的多尺度无序池化（Multi-scale Orderless Pooling of Deep Convolutional Activation Features） 链接：http&#58;//suo.im/3gNw8e- 作者：Gong, Y., Guo, R., Lazebnik, S., &amp; Wang, L. (2014). ECCV- 数据：引用：293、HIC：23、CV：95- 摘要：为了在不降低其辨别力的同时改善卷积神经网络激活特征的不变性，本文提出了一种简单但有效的方案：多尺度无序池化（MOP-CNN）。作者：Gong, Y., Guo, R., Lazebnik, S., &amp; Wang, L. (2014). ECCV 摘要：为了在不降低其辨别力的同时改善卷积神经网络激活特征的不变性，本文提出了一种简单但有效的方案：多尺度无序池化（MOP-CNN）。 17. 论文：同时检测和分割（Simultaneous Detection and Segmentation） 链接：http&#58;//suo.im/4b0ye0- 作者：Arbeláez, P.A., Girshick, R.B., Hariharan, B., &amp; Malik, J. (2014) ECCV- 数据：引用：286、HIC：23、CV：94- 摘要：本文的目标是检测图像中一个类别的所有实例，并为每个实例标记属于它的像素。我们称将此任务称为同时检测和分割（SDS）。作者：Arbeláez, P.A., Girshick, R.B., Hariharan, B., &amp; Malik, J. (2014) ECCV 摘要：本文的目标是检测图像中一个类别的所有实例，并为每个实例标记属于它的像素。我们称将此任务称为同时检测和分割（SDS）。 18. 论文：一份关于特征选择方法的调查（A survey on feature selection methods） 链接：http&#58;//suo.im/4BDdKA- 作者：Chandrashekar, G., &amp; Sahin, F. Int. J. on Computers &amp; Electrical Engineering- 数据：引用：279、HIC：1、CV：58- 摘要：在文献中，有许多特征选择方法可用，由于某些数据集具有数百个可用的特征，这会导致数据具有非常高的维度。作者：Chandrashekar, G., &amp; Sahin, F. Int. J. on Computers &amp; Electrical Engineering 摘要：在文献中，有许多特征选择方法可用，由于某些数据集具有数百个可用的特征，这会导致数据具有非常高的维度。 19. 论文：用回归树集成方法在一毫秒内实现人脸校准（One Millisecond Face Alignment with an Ensemble of Regression Trees） 链接：http&#58;//suo.im/1iFyub- 作者：Kazemi, Vahid, and Josephine Sullivan, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2014- 数据：引用：277、HIC：15、CV：0- 摘要：本文解决了单个图像的人脸校准问题。我们展示了怎样使用回归树集成来直接从像素强度的稀疏子集估计面部的地标位置，并通过高质量的预测实现了超实时性能。作者：Kazemi, Vahid, and Josephine Sullivan, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2014 摘要：本文解决了单个图像的人脸校准问题。我们展示了怎样使用回归树集成来直接从像素强度的稀疏子集估计面部的地标位置，并通过高质量的预测实现了超实时性能。 20. 论文：关于作为混合系统的多分类器系统的调查（A survey of multiple classifier systems as hybrid systems） 链接：http&#58;//suo.im/3c9EFD- 作者：Corchado, E., Graña, M., &amp; Wozniak, M. (2014). Information Fusion, 16, 3-17.- 数据：引用：269、HIC：1、CV：22- 摘要：模式分类领域目前关注的焦点是几种分类器系统的组合，构建这些分类器系统可以使用相同或者不同的模型和／或数据集构建。作者：Corchado, E., Graña, M., &amp; Wozniak, M. (2014). Information Fusion, 16, 3-17. 摘要：模式分类领域目前关注的焦点是几种分类器系统的组合，构建这些分类器系统可以使用相同或者不同的模型和／或数据集构建。 转载来源：机器学习和深度学习引用量最高的20篇论文：2014-2017]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>机器学习</tag>
        <tag>微软</tag>
        <tag>科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3000多年的欧洲历史，BBC用10部纪录片讲完了]]></title>
    <url>%2F2017%2F162236a5%2F</url>
    <content type="text"><![CDATA[文 | 年牧（历史研习社社员） BBC的纪录片对于纪录片的爱好者而言是必追的，自然类、科技类还有文史类，款款都是小编的最爱，每天都煲个一两集，这不就有十部经典的历史类BBC纪录片在等着你吗！ 1十字军东征 &gt;&gt;&gt;&gt;内容简介 BBC的这部纪录片以三集的长度为我们介绍了关于这场十字军东征的历史，并且也详细地介绍了为争夺基督教世界最神圣土地–圣城耶路撒冷的控制权，教皇对伊斯兰世界发动的新的圣战，。而这场关乎基督教和伊斯兰教的斗争持续了两个世纪，直至今日仍引发争论。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av3051095/ 2文明的轨迹 &gt;&gt;&gt;&gt;内容简介 BBC的这部纪录片又名：西方艺术史话。其两年才拍摄完毕，剧组跨越13个国家，曾走访百多个城市拍摄。纪录片通过13集的长度为我们展现了西方文明艺术的历史，虽然由于拍摄时间较早，有些观点可能已经有所发展，但是这种通过艺术、音乐来呈现历史观点的做法，成为日后无数纪录片看齐并努力超越的基准。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av1990120/ 3英国司法史 &gt;&gt;&gt;&gt;内容简介 BBC这部纪录片系统地介绍了英国司法的三部曲，共分三集：法律的诞生、追求自由、无罪推定。虽然主题是法律（司法史），但跟随主持人的脚步，你将了解到英国法的历史不过是英国人民的历史。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av4096167/ 4中世纪思潮-系列 &gt;&gt;&gt;&gt;内容简介 4集长度的BBC纪录片，在不同层面为我们展现出中世纪的历史，其包括了中世纪欧洲的启蒙、基督教信仰、中世纪阶级等方面的概述，讲故事的叙述方式总让人觉得非常神秘。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av2940699/ 5维多利亚女王和她的子女们 &gt;&gt;&gt;&gt;内容简介 BBC这部纪录片既可以说是历史方面的纪录片，又可以说是一部有关于皇室家庭的纪录片，这三集纪录片通过维多利亚女王与她丈夫和九个孩子的私人关系来探索她的统治。三集分别包括：最佳的方案，屋内的暴君，终归是王子。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av5252177/ 6英国史 &gt;&gt;&gt;&gt;内容简介 BBC的这部纪录片对于想要了解与学习英国历史是很好的途径，通过介绍英国文明，让我们感受到了从新石器时代到伊丽莎白时代，从17世纪暴乱的国内战争到我们所知道的日不落大不列颠帝国的历史情节，再现了这一个伟大而又波澜壮阔的国家。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av4755161/ 7日耳曼部落 &gt;&gt;&gt;&gt;内容简介 BBC纪录片通过4集为一系列为我们展现了日耳曼部落的历史发展，这4集由四个章节组成，分别为野蛮人对阵罗马、条顿堡森林战役、帝国的和平以及在基督十字的引领下，为我们展现出这一段神秘的历史。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av3414258/ 8母老虎：英国的那些女王们 &gt;&gt;&gt;&gt;内容简介 这部BBC的纪录片很是特别，从其名字可以看出主要讲的是英国的女王们，就如网友评论所说的“……这部纪录片用一种更加悲悯的态度描述了性别歧视加诸于她们的不公以及她们的挣扎。中世纪女性只能牺牲原有性别的一些天性才能换得与男权主义对抗的筹码”。“探索她们的历史也让我们了解到，漫漫长路至今，世界似乎从未改变”。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av3100743/ 9古代埃及人 &gt;&gt;&gt;&gt;内容简介 这部BBC的纪录片很是特别，它不像是一般的纪录片，而是试图用叙事的方式来重现古埃及社会，在四集关于古代埃及的历史故事中，演员们都一丝不苟的用古埃及的语言来交流着，并且运用了CGI技术重现已经不复存在的历史场景。对于重新展现历史，了解历史有着特别的作用。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av5215173/ 10伦敦：双城记 &gt;&gt;&gt;&gt;内容简介 该部BBC纪录片以英国历史上最为引人注目的时期之一——17时期为开始时间，并且以这一时期的两份出色的调查行记为主题。而前后两份行记中所体现出的差异为我们揭示了伦敦的起源。而通过对这两份行记加以比对，可以帮助我们更好地了解伦敦如何能在这个不寻常的世纪中发生巨大变革。 &gt;&gt;&gt;&gt;网址链接 http&#58;//www.bilibili.com/video/av3147771/ 当然这十部历史记录片只是众多优秀历史纪录片的其中一小部分，只要大家多去留意，相信会有更多优秀历史纪录片在等待大家，同时也欢迎大家给予补充！（ps&#58;观看时请记得关弹幕哦~） 看10万历史学人逆时针“解毒”世界，请关注公众号“历史研习社”（ID mingqinghistory）。 转载来源：3000多年的欧洲历史，BBC用10部纪录片讲完了]]></content>
      <categories>
        <category>旅游</category>
      </categories>
      <tags>
        <tag>BBC</tag>
        <tag>欧洲</tag>
        <tag>英国</tag>
        <tag>基督教</tag>
        <tag>维多利亚女王</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习 Python 库 Top 20]]></title>
    <url>%2F2017%2F37b60b28%2F</url>
    <content type="text"><![CDATA[机器学习 Python 库 Top 20 转载来源：机器学习 Python 库 Top 20]]></content>
      <tags>
        <tag>Python开发者</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五大顶级CSS性能优化工具，值得程序员一试！]]></title>
    <url>%2F2017%2F234b915b%2F</url>
    <content type="text"><![CDATA[为什么Web页面的加载速度如此重要？在这个信息化的时代，如果一个网站的加载时间过长，大部分用户会极其不耐烦地选择“关掉”！这让辛辛苦苦熬夜敲代码的程序员们情何以堪，不管网站功能如何强大，用户根本都没来得及看一眼，结果网站访问量越来越少，粉丝转化率越来越低，最后，程序员可能就要下岗了。 了解前端开发的程序员都知道，影响网站性能的因素有很多，例如，HTTP请求数量，臃肿的代码，繁重的媒体文件等。如何编写CSS以及如何在浏览器中加载样式表都会对加载时间造成重大影响，接下来推荐五款针对CSS的性能提升工具，以帮助广大前端开发程序员创建一流的网站。 TestMyCSS TestMyCSS是一款免费的在线优化工具，具有很多功能。它可用来检查代码冗余，验证错误，未使用的CSS和寻求最佳做法。程序员只需将网址输入网站的CSS文件，就可以立即开始使用，TestMyCSS可以发现需要改进的所有项目。不仅如此，程序员还可以看到一些有用的提示： 如何简化复杂的选择器- 需要去掉的重复的CSS属性和选择器- 代码中存在的重要声明的数量- 不必要的类特异性- 不必要的IE修复- 不需要供应商前缀的CSS属性- 具有标签名的类或ID规则，例如a.primary-link- 通用选择器使用不当需要去掉的重复的CSS属性和选择器 不必要的类特异性 不需要供应商前缀的CSS属性 通用选择器使用不当 Stylelint StyleLint是一款相当强大的CSS linter，它与PostCSS（一种开发工具）一起编写了最先进的CSS，linter是一个可通过代码捕获潜在错误的程序。 StyleLint可以用来： 检查拼写错误，如打字错误，十六进制颜色无效，重复选择器等。- 寻求最佳做法实现- 统一编码风格，如每个CSS规则中的一致间距等。- 支持新的顶级CSS语法- 使用stylefmt自动修复一些警告，一种格式化CSS规则的工具- ……寻求最佳做法实现 支持新的顶级CSS语法 …… StyleLint非常强大，程序员可以使用其具备的： StyleLint CLI（命令行界面）- 构建工具的插件，例如webpack，gulp等。- 文本编辑器的插件，例如Atom，Sublime Text等。- StyleLint Node API- StyleLint PostCSS插件构建工具的插件，例如webpack，gulp等。 StyleLint Node API CSS Triggers CSS Triggers提供在线的页面解析参考，程序员可通过此参考了解哪些CSS属性触发了重绘和合成，但不引发布局，这些是浏览器在渲染网页时的执行过程。 Layout：浏览器生成每个元素的几何形状和位置- Paint：浏览器将每个元素的像素解析为图层- Composite：浏览器在屏幕上绘制图层。Paint：浏览器将每个元素的像素解析为图层 合成操作是浏览器执行的最廉价操作，如果你的CSS动画的代码反复触发合成和重绘操作的属性，则很难将60fps（每秒帧数）作为平滑网页动画的关键数字。 cssnano 当使用CSS呈现页面的关键路径时，使用精简的、结构良好的样式表文档就变得很重要。 换句话说，默认的浏览器网页渲染过程，直到样式表被加载，解析和执行完成后才停止。因此，如果CSS文档大而且杂乱，网站的加载时间就会很久。 cssnano是PostCSS的CSS优化和分解插件。cssnano采用格式很好的CSS，并通过许多优化，以确保最终的生产环境尽可能小。 Critical Critical是处理上一节提到的CSS关键路径问题的另一个工具。为了获得最佳性能，程序员可能需要考虑将关键CSS直接插入到HTML文档中，因为这消除了关键路径的额外往返行程…… 该想法的具体实践是查找关键的CSS规则，并将这些规则放在HTML文档的部分。Critical生成并内联关键路径CSS，程序员可同时使用Grunt和Gulp。有关使用此工具内联关键CSS的详细教程，可访问（https&#58;//www.sitepoint.com/how-and-why-you-should-inline-your-critical-css/） 以上五大工具可帮助前端开发程序员搭建一个可快速加载的网站，同时让样式表更精简，减少错误，进而方便浏览器的加载和解析。其实相关的性能优化工具有很多，但各有优劣，你会选择哪一款呢？ 转载来源：五大顶级CSS性能优化工具，值得程序员一试！]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>CSS</tag>
        <tag>程序员</tag>
        <tag>HTML</tag>
        <tag>Sublime Text</tag>
        <tag>文本编辑器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python里的黄金库，学会了你的工资至少翻一倍]]></title>
    <url>%2F2017%2F254d249b%2F</url>
    <content type="text"><![CDATA[Python里的黄金库，学会了你的工资至少翻一倍 转载来源：Python里的黄金库，学会了你的工资至少翻一倍]]></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习如何入门？Kaggle CTO刚刚写了份详细的指南]]></title>
    <url>%2F2017%2F3cbde866%2F</url>
    <content type="text"><![CDATA[李林 编译整理量子位 出品 | 公众号 QbitAI 上周，Ben Hamner很忙。 作为全球最大数据科学和机器学习竞赛平台Kaggle的联合创始人&amp;CTO，他在Quora上参加了一场AMA，还参加了一场机器学习会议。会议我们最后再说，先说AMA：它是ask me anything的首字母缩写，美国reddit、Quora等社区经常邀请名人参加这种在线问答活动，比如说盖茨就每年都会在reddit上搞AMA。 AMA中得票最高的答案是“研究机器学习和人工智能最好的资源是什么？”Hamner在答案中把机器学习的入门过程分成8步，写了一份详细的指南。量子位将要点编译如下： 你很幸运，要开始研究机器学习和人工智能，现在是比任何时候都好的时机。这个领域近年来在快速发展，专业人士发布并改进着高质量的开源软件工具和库，每天都有新的线上公开课和博客文章出现。机器学习在各个领域每天贡献着数十亿美元的营收，带来了无与伦比的资源和大量工作机会。 这也意味着，你在刚接触这个领域时会有被淹没的感觉。下面是我的入门方法，如果你在研究过程中卡住了，去Kaggle上搜索一下，很可能有人遇到过和你类似的问题，如果没有，可以在我们的论坛上发帖提问，这是个获得指引的好办法。 1. 找一个你感兴趣的问题从一个你想解决的问题入手，会更容易集中精力，也更有学习的动力，这种方法比照着一份长得吓人的散乱知识点清单来学习要好很多。和被动地阅读相比，解决问题也能驱使你深入到机器学习之中。 好的入门问题有以下几个标准： 涉及你个人感兴趣的领域；- 有现成的数据适合用来解决这个问题，否则你需要花大把的时间来找数据；- 你能够在一台机器上流畅地处理这些数据，或者它的子集。有现成的数据适合用来解决这个问题，否则你需要花大把的时间来找数据； 想不出来要解决的问题？上Kaggle嘛……Kaggle有个入门系列竞赛，提供了适用于新手的机器学习问题。推荐从泰坦尼克号乘客的生还概率预测（https&#58;//www.kaggle.com/c/titanic）开始。 2. 做一个快速、脏乱、黑客范儿的端到端解决方案初学者很容易陷入一个实现细节之中，或者为错误的机器学习算法仔细调试，你需要避免这种错误。你的目标，是尽可能快地把端到端的基本解决方法做出来：读入数据、把它处理成适用于机器学习的格式、训练一个基本的模型、得出结果、评估它的性能。 3. 改进你的解决方案现在，基本功能已经实现，发挥创造性的时候到了。你可以尝试对最初解决方案中的每个组件进行优化，然后测试修改带来的作用，搞清楚该在哪个部件上花时间。通常来说，获取更多的数据或者请洗数据之类的预处理步骤，比优化机器学习模型有着更高的投入产出比。 这些步骤可能需要你亲自上手处理数据，比如说通过检查特定的某一行、通过可视化方法来查看数据分布等方式，来更好地理解数据的结构和怪癖。 4. 写出来你的解决方案&amp;分享想要获得别人对你的解决方案的反馈，最好的方法就是写出来并分享。写出你的解决方案意味着你会以新的方式去看它，并加深理解，也能让别人理解你的工作并做出反馈、帮你学习进步。写作也有助于开始建立机器学习作品集，来展示你的能力，对找工作很有帮助。 我们以Kaggle数据集和Kaggle Kernels为例，它们分别可以用来分享数据和解决方案，从而获得反馈，看其他人如何对你的问题进行扩展。这也是丰富你的Kaggle资料的办法。 5. 在更多问题上重复1-4步现在，你已经完成了一个自己喜欢的问题，接下来应该在不同领域的问题上多试几次。 你在入门的时候是不是用了表格式的数据？选一个要用到非结构化文本的问题，再试试解决图像相关的问题。 你是不是先解决了一个结构化的机器学习问题？很多有价值的创造性工作，一开始都有赖于从宽泛的商业或研究对象找到一个定义清晰的机器学习问题。 Kaggle竞赛和数据集为机器学习的两个方面：定义清晰的机器学习问题和原始数据来源提供了一个良好的起步点。 6. 认真地参加Kaggle竞赛和上千人比赛着去解决同一个问题，尽力做到最好，是一个很好的学习机会，这能够驱使你在这个问题上不断迭代，找到解决问题的有效途径。 关于其他人是怎样解决问题排除bug的，针对某个竞赛的论坛上有着丰富的资源，kernels体现了其他人对数据的洞察，并且给你提供了一个轻易的上手途径，获胜者的博客文章则展示了什么样的方法效果最好。 Kaggle竞赛提供了和别人组队的机会，我们的社区成员有着不同的背景和技能，每个人都能从其他人身上学到东西。 7. 在专业领域应用机器学习这让你在大部分时间中都能接触到机器学习，有助于自我提升。决定你想要成为什么样的角色、建立和这个角色相关的个人项目列表，是一个很好的开端。 如果你还没准备好应聘机器学习相关职位，也可以在你现在的岗位上开辟新项目、寻找提供咨询的机会、参与黑客马拉松和数据相关的社区服务机会、这些都能帮你在机器学习领域立足。专业领域的工作通常需要比较强的编程能力。 在专业领域应用机器学习，有这些价值的机会： 将机器学习用于生产系统；- 专注于机器学习研究，将技术发展的最高水平向前推进；- 用机器学习进行探查、分析，来提升你的产品和商业决策。专注于机器学习研究，将技术发展的最高水平向前推进； 8. 帮助别人研究机器学习教人学习能帮你巩固对基础概念的掌握。教别人有很多不同的方法，你可以根据自己的风格选一个： 写论文；- 做演讲；- 写博客文章和教程；- 在Kaggle、Quora等网站上回答问题；- 亲自指导；- 在Kaggle Kernels和GitHub上分享代码；- 讲课；- 写书。做演讲； 在Kaggle、Quora等网站上回答问题； 在Kaggle Kernels和GitHub上分享代码； 写书。 One More Thing… 这次AMA，其实Hamner最想谈的是Kaggle的未来，他在资料里列出了自己愿意回答的话题： Kaggle的未来- 开放数据- Kaggle竞赛- 机器学习和AI- 数据科学工作流程- 产品和工程- Kaggle为何加入Google开放数据 机器学习和AI 产品和工程 可惜Quora上的群众对Kaggle的未来似乎并不关心，反正竞赛照常举行，数据集照常提供，量子位也不知道这个未来该从何问起。 不过，吃瓜群众不关心Kaggle的未来也没关系。周五，Hamner还去纽约的机器学习大会MLConf上做了以《Kaggle的未来：我们从何处来，到何处去》的演讲，也就是我们开头说的那场会议。 在量子位（公众号：QbitAI）对话界面回复“Kaggle”，我们会把Hamner这次演讲的PPT发给你。 今天AI界还有哪些事值得关注？在量子位（QbitAI）公众号会话界面回复“今天”，看我们全网搜罗的AI行业和研究动态。笔芯❤~另外，我们建了一个机器学习入门群，希望和大家互相帮助、共同进步。欢迎加量子位小助手的微信：qbitbot，介绍一下你自己，符合要求的，我们会拉你进群。 转载来源：机器学习如何入门？Kaggle CTO刚刚写了份详细的指南]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>人工智能</tag>
        <tag>Kaggle</tag>
        <tag>Quora</tag>
        <tag>Reddit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue2.0 实践，顺手撸了一个小项目]]></title>
    <url>%2F2017%2F08d53a1d%2F</url>
    <content type="text"><![CDATA[传送门：https&#58;//github.com/icepy/index-oa-template，或阅读原文。 这个项目的背景还要从“移动企业门户”说起，这是我厂的一个小项目，现也开源在Github上，其目的是为了给企业开发自己的企业门户提供参考和模板，可以快速的用起来，或者参考一下我们是如何来实现移动企业门户的。 Demo 效果如图： 这个项目，主要使用了Vue2.0和Vue-router，其实Vue-router不是必须的，因为这只有一个页面，但是也应用到了Vue的方方面面。在创建项目时，用了vue-cil来初始化这个项目，不过我也为它修改了一些自己想要的东西，没错就是weex相关的构建与入口，具体如何用同一个Vue2.0项目既可以跑Web也可以跑Native，你可以参考一下我这个项目中的weex分支。 既然用到了vue-router，那还是简单的贴一下代码，非常简单： importVuefrom’vue’ importRouterfrom’vue-router’ importHomefrom’pages/home/index.vue’ Vue.use(Router); constroutes= &#91; &amp;#123 path&#58;’/‘, name&#58;’home’, component&#58; Home &amp;#125 &#93;; exportdefaultnewRouter(&amp;#123 routes&#58; routes &amp;#125); importVuefrom’vue’; importAppfrom’./App’; importrouterfrom’./router’; newVue(&amp;#123 el&#58;’#app’, router, template&#58;’‘, components&#58; &amp;#123 App &amp;#125 &amp;#125); router的配置可以看的出来，非常的简单，一个对象用来描述一个path的所有，也是如此，你可以顺手的描述其它的规则，有path，component，等等。 整体的组件也是非常简单的，因为只需要引用即可。实际上稍微复杂一点的地方，主要在page/home/index.vue文件中，因为在这个文件里做了一些其它的事情，比如获取userid实现免登，那么只有当获取到userid之后才能去获取用户信息，也就是界面 下午好，管理员，icepy的变更。我用了$watch来处理这个问题，比较简单，： this.$watch(‘userId’,function()&amp;#123 this.getUserInfo(); &amp;#125); getUserInfo定义在methods中： getUserInfo&#58;function()&amp;#123 // 根据userid获取用户详细信息 constself=this; constgetUserInfoRequest= &amp;#123 url&#58;OPENAPIHOST+’/api/get’, params&#58; &amp;#123 userid&#58;this.userId &amp;#125 &#125; dingWISDK.getUserInfo(getUserInfoRequest).then(function(response)&amp;#123 constdata=response.data; self.meta.userInfo= data; &amp;#125).catch(function(error)&amp;#123 alert(‘获取用户信息 error：’+JSON.stringify(error)); &amp;#125); &amp;#125 当userid有变化时，立即调用getUserInfo来更新用户界面。 其实从源代码中可以看见，界面都是一个个单独的组件，通过数据的传递来渲染，单组件文件系统，没什么好说的，大家有兴趣可以多看一看官网的文档。当你不需要加入vuex时，对于驱动界面还是比较简单的，书写下来，只是有一些地方需要注意，特别是React开发者转过来的： props传递，需要用v-bind&#58;，并且在子组件中用props&#58;&#91;&#93;来声明- 监听事件时不需要bind，v-on&#58;click=”microAppsOpenLink(item,$event)”- 建议很多东西都写全，不要写简写，比如&#58;xxx这种，如果不是长期应用vue的开发者，看起来还要思考很久- 因为dom变成了模板，模板有编译的过程，处理类似比如自动触发一个事件这样的需求时需要想一想，ref的处理，看起来没那么直观- 引用组件的时候，需要显示的声明，比如：监听事件时不需要bind，v-on&#58;click=”microAppsOpenLink(item,$event)” 因为dom变成了模板，模板有编译的过程，处理类似比如自动触发一个事件这样的需求时需要想一想，ref的处理，看起来没那么直观 components&#58; &amp;#123 banner&#58; banner, applist&#58; applist, item&#58; item, admin&#58; admin, userlist&#58; userlist, appmanager&#58; appmanager &amp;#125, 也许还有很多需要注意的细微之处，待你慢慢挖掘了。 比较好的消息是WebStorm开始原生支持Vue了，可见其火热的趋势，回过头来可以看到我们做事情时的一些反思：贵在坚持。 你身边如果有朋友对混合领域（跨技术栈）或全栈，编程感悟感兴趣，可以转发给他们看哦，^_^先谢过啦。 更多精彩内容可关注我的个人微信公众号：搜索fed-talk或者扫描下列二维码，也欢迎您将它分享给自己的朋友。 转载来源：Vue2.0 实践，顺手撸了一个小项目]]></content>
      <categories>
        <category>科技</category>
      </categories>
      <tags>
        <tag>软件</tag>
        <tag>GitHub</tag>
        <tag>Pages</tag>
        <tag>多看阅读</tag>
        <tag>路由器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剖析Elasticsearch集群系列第一篇 Elasticsearch的存储模型和读写操作]]></title>
    <url>%2F2017%2F1f2b3fca%2F</url>
    <content type="text"><![CDATA[剖析Elasticsearch集群系列第一篇 Elasticsearch的存储模型和读写操作 转载来源：剖析Elasticsearch集群系列第一篇 Elasticsearch的存储模型和读写操作]]></content>
  </entry>
  <entry>
    <title><![CDATA[阳光宽频网]]></title>
    <url>%2F2017%2Ff77435e6%2F</url>
    <content type="text"><![CDATA[阳光宽频网 转载来源：阳光宽频网]]></content>
  </entry>
  <entry>
    <title><![CDATA[讲真，女人会穿衣服到底有多重要？]]></title>
    <url>%2F2017%2F0bb72fde%2F</url>
    <content type="text"><![CDATA[讲真，女人会穿衣服到底有多重要？ 转载来源：讲真，女人会穿衣服到底有多重要？]]></content>
      <tags>
        <tag>你喵姐</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017 春节 九州美食温泉之旅,九州旅游攻略 - 马蜂窝]]></title>
    <url>%2F2017%2Fe1f6a3d6%2F</url>
    <content type="text"><![CDATA[2017 春节 九州美食温泉之旅,九州旅游攻略 - 马蜂窝 转载来源：2017 春节 九州美食温泉之旅,九州旅游攻略 - 马蜂窝]]></content>
  </entry>
  <entry>
    <title><![CDATA[是男人就要多看这几本书，本本都是情商的提速器，为情商提速]]></title>
    <url>%2F2017%2Fb99ccb3d%2F</url>
    <content type="text"><![CDATA[是男人就要多看这几本书，本本都是情商的提速器，为情商提速 转载来源：是男人就要多看这几本书，本本都是情商的提速器，为情商提速]]></content>
  </entry>
  <entry>
    <title><![CDATA[武汉全市各开发区、功能区、行政区 对表报告明确定位狠抓落实]]></title>
    <url>%2F2017%2F901c5be3%2F</url>
    <content type="text"><![CDATA[万涓归流，汇为大海。拼搏赶超，加快复兴大武汉，全市各区域各领域都能从党代会报告中找到行动方向。坐不住、等不起、慢不得，紧跟党代会召开的脚步，全市各开发区、功能区和行政区闻鸡起舞，踏上新征程，精确对表党代会报告，狠抓贯彻落实。 市委常委︑东湖高新区党工委书记胡立山： 建设“四个先行区”走在前列 我们将围绕“建设天下谷——全球有影响力的创新创业中心”目标，以统筹、创新、开放和绿色发展为主线，建设好“四个先行区”，并走在前列。 统筹“双自联动”战略，做改革创新的先行区。紧密结合东湖国家自主创新示范区和自贸试验区建设，坚持“双自联动”，重点推进政务服务、科技体制机制等关键领域的改革创新，加速发展四新经济，加快形成以创新为主要引领和支撑的新兴产业体系和发展模式。 全面推进自主创新示范区建设，做战略性新兴产业发展的先行区。依托长江存储、武汉华星光电、武汉天马等，做大做强光电子产业；培育壮大人福医药等，大力发展生物健康产业；紧盯未来产业，超前加快布局智能化新能源汽车、AR/VR、人工智能等产业。 全面启动自贸区建设，做国际化能力提升的先行区。加快构建与国际规则相一致的营商环境，加快引进一批国际化企业，推动企业走出去，完善国际化城市功能，大力发展国际化教育、医疗、体育、文化和社区。 推动科技新城建设，做产城融合发展的先行区。落实“绿色发展”理念，坚持高水平规划建设和管理，建设生态宜居智慧科技新城。 （记者肖娟） 市委常委︑武汉临空港经开区管委会主任︑东西湖区委书记曹裕江： 制定实施临空产业发展行动计划 在奋力拼搏赶超的进程中，武汉临空港开发区要以只争朝夕的精神状态，以快干、实干、精干的工作作风，在培育新产业结构、培育发展新动能、扩大有效投资、建设美丽乡村等方面当好“四个示范”。 一是以通用航空产业为重点，着力培育新产业结构。在巩固壮大食品、机电、物流产业的同时，加快制定实施临空产业发展三年行动计划，推进汉北通航机场前期审批工作，适时启动通航产业园总体规划的编制。 二是以国家网络安全人才与创新基地为重点，着力培育发展新动能。加快确定产、学、研协同建设发展的总体规划与实施方案，及时制定出台政策措施，组建支持基地建设的产业基金，及时签约一批项目，启动建设一批项目。 三是以提高签约率、供地率、开工率为重点，着力扩大有效投资。建立招商引资“一号工程”领导机制，建立健全区级领导“一挂两包”工作制度，党政“一把手”亲自抓、直接抓。 四是以“一产三产化”为方向，着力建设美丽乡村。大力推进“四水共治”“湿地绿道”、农村新社区建设工程，深度发展乡村休闲游。 （记者罗京） 市委常委︑武汉开发区工委书记︑汉南区委书记胡亚波： 办世界飞行者大会发展通航产业 市第十三次党代会提出“发展先进制造业”，武汉开发区（汉南区）是全市重要的制造业区域，将以国家级开发区的使命感，具体到年度计划，具体到项目，用一个个小目标来推动产业转型升级。 2017年，开发区（汉南区）将继续做大汽车产业集群，促进东风雷诺、新兴重工全面量产，加快推进东本三厂建设，2017年整车产量力争达到140万辆，并大力发展智能制造和新兴产业，培育发展机器人、新材料、通用航空等新兴产业集群，构建迭代产业体系。 今年，首届“国际航联世界飞行者大会（WFE）”将在开发区（汉南区）举行，预计将有60多个国家、3000多名运动员、国内外约1000架飞行器齐聚武汉，300余家航材及装备生产商参展，60余万观众观赛。作为飞行者大会活动的主要场地，目前，汉南通用航空机场正在建设中。 以此为契机，开发区（汉南区）推动中航通飞、太航星河、珠海易航等项目落地建设，努力把我区打造成为国内最知名的通航产业发展区。 （记者康鹏 通讯员周明德） 东湖风景区管委会工委书记︑管委会主任陈光菊： 规划建设东湖城市生态绿心 东湖风景区作为我市唯一以生态保护为主的功能区，必须要在“建设生态化大武汉”中走在全市前列。2017年，我们的工作将紧紧围绕“规划建设东湖城市生态绿心，传承楚风汉韵，打造世界级城中湖典范”这一目标展开。 第一，加快推进东湖绿道二期项目建设。我们将按照市委市政府的统一部署，与地产集团密切配合，积极参与东湖绿道二期规划建设，全力做好征地拆迁、环境整治等服务保障工作。 第二，加快推进东湖水质提档升级。我们将按照“增二类、扩三类、转四类、灭五类”的全市治水总目标，继续完善《东湖水环境综合治理规划》，通过实施引江济湖、六湖连通、底泥疏浚等工程实施湖泊综合整治。 第三，加快推进东湖景中村改造。我们将遵循“景村交融、和谐共生”的核心理念，深入研究东湖景中村特点，切实找准适合不同片区的村庄改造模式。（见习记者晋晓慧） 硚口区委书记景新华： 加快汉正街核心区块建设 硚口区将以打造中部地区现代服务业标杆为目标，着力做好以下几方面工作： 全力推进汉正街建设改造，加快征收拆迁、转型升级、功能再造和文化保护，规划打造武汉金融中心、国际总部中心、高端商务中心，把汉正街·武汉中央服务区建设成为长江主轴核心区块。 做强现代商贸业，深化国家电子商务示范基地建设，推动实体商业和电子商务融合发展，支持中百、工贸、宜家、恒隆、凯德等重点企业发展，提升重点功能区的影响力和辐射力。 做大工业服务业，支持标致雪铁龙、远大等工业总部壮大发展，加快引进一批工业总部、研发、设计和售后服务企业，打造工业服务业集聚区。 做优健康服务业，依托同济医院、同济医学院等优质资源，重点发展高端医疗、精准医疗、智慧医疗、第三方检测、健康大数据平台，打造环同济健康城。 （记者董晓勋） 汉阳区委书记徐洪兰： 做强汉阳文化创意产业 汉阳区针对产业结构不优、城区功能不强这个最大短板，聚力改革创新，做强文化品牌，努力将汉阳打造成武汉建设国家级文化创意中心的核心区。 汉阳的优势在于文化资源丰富，我们将依托琴台大剧院、晴川创意谷和大归元改造项目，统筹推进琴台中央文化艺术区、归元太古里、五里城市综合体建设，努力打造琴台国际金融文化中心。发挥路桥工程设计建设企业相对集聚的优势，努力建设国家级路桥工程设计文化创意中心。 我们还将发挥武汉国际博览中心平台优势，对标国际一流会展功能区，加大招商引资力度，完善会展产业链，引进国际知名展会，努力将四新地区打造成会展文化产业聚集地。 “汉阳造”是工业文化的一个代表，我们计划依托黄金口智能制造园，引导企业弘扬“汉阳造”精神，提高产品质量和文化内涵，争当产品标准和行业规范制定者，努力将黄金口都市工业园建成都市工业文化试点示范园区。（记者蔡爽） 武昌区委书记张幸平： 建设好滨江高端商务区 武昌滨江文化商务区地处主城区内长江南岸核心区域，我们将勇于担当，将其打造成武汉长江中轴亮点区块。我们将遵循“一年打基础，两年求突破，三年见实效”的原则，对滨江文化商务区的建设时序进行控制。 2017年启动项目全面开工，启动滨江核心区地铁产业中心、福星惠誉、万吨冷库、华电总部、交职院、昙华林、斗级营等地块建设。2018年全面启动建设，集中启动武昌滨江核心片、337片地块、得胜桥沿线建设。2019-2020年初具规模，启动二桥南片及万吨冷库片周边地块建设。2021年核心区全面建成，推动月亮湾长江论坛、武车宿舍片等亮点项目建设。 未来几年，武昌滨江文化商务区将以高端商务为龙头，国际金融为主导，文化创意、信息咨询产业集群、国际社区、商业配套为支撑，人文生态发展为基底，建成代表武汉现代服务业聚集最高水平之一，人文底蕴最深厚的城市亮点区域。 （记者李咏） 青山区委书记苏霓斌： 从源头上减少排放 建设生态化大武汉，青山必须勇于担当、奋发作为。通过政企联动建设良好生态环境，为武汉成为国际知名宜居城市作出应有贡献。 一是针对青山地区工业“三废”排放占全市60%左右的实际，完成上级督办的突出环境问题整改等，切实从源头上减少排放。 二是启动30平方公里北湖生态试验区建设，强力推进已经策划的19个、投资590亿元的重点项目；对地区17个公园进行提档升级，进一步缩小空气质量优良天数与全市的差距。全力以赴抓好118项、投资112亿多元的海绵城市试点，坚决改变地下排水管网等基础设施建设滞后现状。 三是要大力弘扬干事创业精神，引导干部队伍提振“精气神”，始终保持干事创业的蓬勃朝气，克难攻坚的昂扬锐气，用实际行动投入全面复兴大武汉新征程中。 （记者李锐） 洪山区委书记黎东辉： “刻意人为”留住大学生 洪山将在推进“留住大学生”这一效益最高的发展战略上主动作为，在做好“学、城、人”结合这一最大文章上“刻意人为”，在将“大学之城”这一最大资源转化为经济发展的最大优势上“走在前列、做出样板”。 一是以融合发展为主攻方向，打造学城联动的大学之城。借鉴国际成功经验，打破大学与城市之间有形、无形的“围墙”，实施校区、社区、园区“三区联动”，以校带城、以城促校。 二是以凝聚青年为核心目标，打造育才聚才的青年之城。开展“百万大学生看武汉”等活动，增进大学生对武汉的热爱；实施“青桐计划”等项目，吸引更多的青年英才在洪山成家、立业、扎根。 三是以创新创业为关键抓手，打造筑梦圆梦的梦想之城。以“创谷”计划为引领，建设一批“三生融合”的创新平台；以高校、科研院所为依托，打造高端研发机构、创新创业平台、风险投资机构和高新技术企业集聚区。 （记者刘元聪） 武汉化工区党工委书记︑管委会主任黄家喜： 打造绿色石化产业集群 化工区将坚持以建设“一流生态化工园区”为目标，推进产业集聚发展、绿色发展和创新发展，努力打造国家重要石化产业基地、长江中游重要化工物流基地和国家新型工业化产业示范基地。 全区将强化一个目标。把招商引资作为经济工作主抓手，制定硬目标，出台硬举措，强化硬考核，努力实现招商引资提质增效。 我们将从五类项目入手，着力抓好项目引进，大力推进产业链招商。一是乙烯扩能项目，推动乙烯扩能改造，能够增加原料供应，进一步拉动下游产业链发展，提升规模效应和龙头效应；二是下游产业项目，包括奥克二期、百杰瑞、江苏大力士等6个项目；三是化工新材料项目；四是重点产业配套项目，拟定重点产业项目的责任分解表，明确时间节点、形象进度、责任单位和责任人，以铁的手腕推动项目落地；五是世界500强、化工50强项目，化工行业龙头项目，实现突破。 （记者汪文汉 通讯员王莉） 武汉新港管理委员会主任张林： 出台武汉航运中心实施方案 做足“水、港、人”三篇文章，对武汉新港来说，核心就是做足“港”文章，我们必须立足于“干”，在现代化、国际化、生态化建设各方面作出应有贡献。 一要抓紧完成阳逻国际港核心功能区系列规划，完成武汉长江中游航运中心总体规划的审批，出台实施方案。 二要稳定开行“江海直达”等品牌航线，完善上游全中转、下游全分流运输模式，提升“中三角省际集装箱公共班轮”航线效能，筹划近洋集装箱直航、汽车滚装江海直达运输的船型及运输组织工作，争取早日开通。 三要加快铁水联运设施建设，实现水运枢纽与铁路枢纽的“强强联合”，加快推进疏港公路改造和建设。 四要实现武汉新港空港综保区封关运营，首年进出口总货值达到4亿美元；实现武汉航交所年交易额突破20亿元，推出汽车滚装运价指数，形成定价机制；建成武汉电子口岸·国际贸易“单一窗口”，推动贸易便利化。 五要依托航运服务中心，引进大企业，发展国际结算，加快武汉航运产业总部区建设，提升供应链管理能力。 六要推进大招商，发展临港经济，打造长江经济带新的增长点。 （记者汪文汉） 江岸区委书记王炜： 勾画长江主轴上最美画卷 党代会提出“规划优化武汉长江主轴，打造世界级城市中轴文明景观带”，江岸作为首善之区，有条件、有责任为武汉打造长江主轴多做贡献，努力勾画出长江主轴上最美画卷。 突出功能布局，高水平建设亮点区块。推进历史文化风貌街区保护利用，通过景观提升、功能置换、以文聚气，形成演绎“老汉口”独特魅力的城市文化地标。加快汉口滨江国际商务区建设，发展总部经济、金融服务、高端商务，打造一流国际企业总部聚集区、滨江高端商务区。做足水文章，坚持“四水共治”，加强长江岸线自然生态环境保护，打造环抱江岸、开放舒适的城市绿色廊道。 我们还将总结推广“百步亭经验”，加快形成一批先进基层党组织示范群。实施“红色引擎工程”，以党组织的坚强有力引领带动各类群团组织和社会组织，以党员队伍的生机活力组织发动广大志愿者，密切联系服务群众，促进基层治理体系和治理能力现代化。 （记者李婷 通讯员祝丽芳） 江汉区委书记张俊勇： 建设国家现代服务业示范区 对照市第十三次党代会报告提出“发展现代服务业”和“建设世界一流的城市亮点区块”的要求，江汉区将高举现代服务业大旗，坚持产城融合，聚力高端高效，建设国家现代服务业示范区，构筑富裕活力美丽幸福新江汉。 在做强优势产业上积极作为。以国家服务业综合改革示范区建设为抓手，推动生产性服务业向价值链高端延伸，做强金融、商贸流通、商务服务、通信信息、文化创意、科技服务等“六中心”。推动生活性服务业向高品质升级，建设一批一流的国际学校、国际医院、国际社区。 在提升城区品质上积极作为。以《江汉区城市土地集约利用评价与发展规划》为引导，提高土地复合利用率。以“三旧改造”为抓手，改善群众居住环境，拓宽产业发展空间。围绕打造世界级城市中轴景观，把武汉中央商务区等建设成为城区转型和形象品质提升的亮点区块。（记者刘元聪） 蔡甸区委书记刘子清︓ 突出“法”字创新招商 蔡甸区要高标准建设中法武汉生态示范城，做好“法”字文章，创新招商方式。 蔡甸全区上下正牢牢抓住这一历史上最大的发展机遇，推动大保护、大开放、大开发，以中法科技谷为核心，以产兴城，打造中法国际合作创新区和湖北对外开放新高地；实施经济强镇改革，超常规推进常福、奓山、沌口一体化发展，按国家级开发区标准，做大做强蔡甸经济开发区；抢占战略性新兴产业高地，大力发展通航产业，开展低空旅游；坚持绿色发展不动摇，深挖蔡甸绿色宝藏，加快建设泛沉湖湿地国际旅游度假区。 蔡甸区已启动招商“一号工程”，党政主要负责人带头落实周末赴外地招商制度，以项目为中心组织经济活动，强化对干部抓经济发展能力的考核和评价，选拔了15名招商专员。目前，蔡甸已在法国、北京、上海、深圳等地设立招商联络处，建立了招商网络开展工作。 （记者朱波） 江夏区委书记王清华： 今年经济增速不低于12% 江夏将坚定“生态立区、工业兴区、创新强区”战略，紧抓发展第一要务，在前两年GDP增速分别以13.1%、12.8%领跑全市各区的基础上，今年也要实现不低于12%的增速。 实施“创新强区”战略。以阳光创谷为主要载体，以腾讯武汉研发中心为主要龙头，以区科投公司为主要平台，着力打造创新创业生态系统；加强政府、企业与高校有效衔接，通过“以校带城、以城促校”持续推动大学与城市融合发展。 实施“生态立区”战略。按照“四水共治”理念，加快组建湖泊管理局，持续巩固“三非”整治、“三网”拆除、“三退”还湖等水体治理成果；充分利用湖泊面积占全市近一半的独特水资源优势，规划建设一批环湖创新创业生态区。 实施“工业兴区”战略。聚焦汽车及零部件、智能装备制造、战略性新兴产业等产业，创新招商引资方式方法，持续扩大有效投资。 （记者林敏） 黄陂区委书记吴祖云： 推进大临空大临港国际化 黄陂是我市拥有大临空大临港优势的第一大区，我们要打好“水、港、人”三张王牌，促进大临空大临港发展向国际化迈进。 把招商引资、招商引智作为赶超发展的“一号工程”精心实施，运用多种方式大招商、招大商，全力培育临空制造与服务、智慧物流、全域旅游等骨干产业，并向规模化、集群化、高端化发展。 加快建设“铁水公空”多式联运综合交通枢纽区，充分发挥黄陂作为天河机场所在地、亚洲最大铁路编组站场所在地和武汉新港规划总部聚集地的优势，按照产城融合思路，高标准建设100平方公里的临空经济示范园、汉口北配套产业园和武湖、前川新城（罗汉）工业园等重点园区，特别在航空货运、飞机维修保养、通用航空、航空物流、临空商贸、仓储服务等方面要有大手笔、新突破。 坚定不移提升现代服务业，形成金融、商贸、物流、旅游、会展、运动、康养和高端酒店等优势功能版块，加快建设航交所、物流交易所、公共物流信息平台和行业总部。 （记者彭仲） 新洲区委书记陈新垓： 加快建设多式联运核心区 市第十三次党代会报告提出，“在阳逻地区规划建设多式联运核心区”。作为武汉“大临港”的主战场，我们将加快多式联运集疏运体系建设。 一是强力推动招商引资。围绕港口经济和先进制造业发展，努力引进港口物流、仓储服务、航空航天、节能环保等一批产业大项目、大企业。 二是做好阳逻新城“港、产、城”一体化发展“多规合一”工作。合理划分阳逻新城边界，在此区域内进一步完善城市总体规划、土地利用规划、产业发展规划和综合交通规划，科学划分“港在哪里、产在哪里、城在哪里”，明确阳逻新城各功能定位。 三是超前谋划建设阳逻新城的对外交通通道。提前完工轨道交通21号线，力争轨道交通10号线、21号线邾城延伸线建设项目纳入武汉市第四期轨道交通建设规划；全力推动江北铁路建设，力争提速外环东扩，打通阳逻港与鄂州顺丰机场连接通道，谋划建设临港大道，打通阳逻板块和光谷板块的连接通道。（记者谭德磊） 长江日报（官方微信ID：whcjrb)全媒体讯 转载来源：武汉全市各开发区、功能区、行政区 对表报告明确定位狠抓落实]]></content>
      <categories>
        <category>时政</category>
      </categories>
      <tags>
        <tag>投资</tag>
        <tag>经济</tag>
        <tag>武汉东湖</tag>
        <tag>长江</tag>
        <tag>新能源汽车</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[适合3月龄宝宝早教的6个小方法_宝宝树孕育知识_宝宝树]]></title>
    <url>%2F2017%2F0c260037%2F</url>
    <content type="text"><![CDATA[适合3月龄宝宝早教的6个小方法宝宝树孕育知识宝宝树 转载来源：适合3月龄宝宝早教的6个小方法宝宝树孕育知识宝宝树]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘 知识重点（整理版）]]></title>
    <url>%2F2017%2Fa0803723%2F</url>
    <content type="text"><![CDATA[数据挖掘 知识重点（整理版） 转载来源：数据挖掘 知识重点（整理版）]]></content>
      <tags>
        <tag>大数据挖掘DT数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[每日一笑，大王叫我来巡山，鸡宝宝们排队来拜年啦]]></title>
    <url>%2F2017%2F882ce809%2F</url>
    <content type="text"><![CDATA[每日一笑，大王叫我来巡山，鸡宝宝们排队来拜年啦 转载来源：每日一笑，大王叫我来巡山，鸡宝宝们排队来拜年啦]]></content>
  </entry>
  <entry>
    <title><![CDATA[下一代Web应用模型——Progressive Web App]]></title>
    <url>%2F2017%2Fc48cafa1%2F</url>
    <content type="text"><![CDATA[下一代Web应用模型——Progressive Web App 转载来源：下一代Web应用模型——Progressive Web App]]></content>
      <tags>
        <tag>CSDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[嵌入式视觉的概念及关键因素解析]]></title>
    <url>%2F2017%2F8f539df5%2F</url>
    <content type="text"><![CDATA[嵌入式视觉的概念及关键因素解析 转载来源：嵌入式视觉的概念及关键因素解析]]></content>
      <tags>
        <tag>CSDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双语视频 | BBC拍了一部《中国春节》纪录片，这才是春节的正确打开方式]]></title>
    <url>%2F2017%2F2fad95e1%2F</url>
    <content type="text"><![CDATA[双语视频 | BBC拍了一部《中国春节》纪录片，这才是春节的正确打开方式 转载来源：双语视频 | BBC拍了一部《中国春节》纪录片，这才是春节的正确打开方式]]></content>
      <tags>
        <tag>留学家长圈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[史上最强100种PPT标题做法！]]></title>
    <url>%2F2017%2F0906cc27%2F</url>
    <content type="text"><![CDATA[史上最强100种PPT标题做法！ 转载来源：史上最强100种PPT标题做法！]]></content>
      <tags>
        <tag>PPT研究院</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[据说这是柯基的标准睡姿]]></title>
    <url>%2F2017%2Fc9068afd%2F</url>
    <content type="text"><![CDATA[柯老板标准睡姿，好像用锅铲翻个面~肿么办 柯老板标准睡姿，好像用锅铲翻个面~肿么办 柯老板标准睡姿，好像用锅铲翻个面~肿么办 柯老板标准睡姿，好像用锅铲翻个面~肿么办 柯老板标准睡姿，好像用锅铲翻个面~肿么办 柯老板标准睡姿，好像用锅铲翻个面~肿么办 柯老板标准睡姿，好像用锅铲翻个面~肿么办 柯老板标准睡姿，好像用锅铲翻个面~肿么办 关注微信公众号：有宠资讯（yczx-pet），参与更多公益活动，和韩红一起关爱小动物。 转载来源：据说这是柯基的标准睡姿]]></content>
      <categories>
        <category>宠物</category>
      </categories>
      <tags>
        <tag>柯基犬</tag>
        <tag>宠物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天上装逼哪家强？一日千里坐俄航！]]></title>
    <url>%2F2017%2F25b644dd%2F</url>
    <content type="text"><![CDATA[天上装逼哪家强？一日千里坐俄航！ 转载来源：天上装逼哪家强？一日千里坐俄航！]]></content>
      <tags>
        <tag>视觉志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序1万字实操指南]]></title>
    <url>%2F2017%2Fa072b859%2F</url>
    <content type="text"><![CDATA[微信小程序1万字实操指南 转载来源：微信小程序1万字实操指南]]></content>
      <tags>
        <tag>虎嗅网</tag>
      </tags>
  </entry>
</search>
